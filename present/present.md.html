<meta charset="utf-8" emacsmode="-*- markdown -*-">

# Introduction

- Hi ... 
- in meiner MAsterarbeit ging es darum, 2 Analysen im GHC zu vergleichen
- bevor wir uns ins Schlachtgetümmel werfen, ein paar Sätze dazu, warum

# Motivation

- GHC altes und mittelgroßes Softwareprojekt, >100k Zeilen Code
- Vor dem Hintergrund ... angesprochenen zwei Analysen, Call Arity und Demand Analysis, ... in Logik überlappen
- Allein aus softwaretechnischer Sicht, macht es Sinn die gemeinsame Logik zu extrahieren (DRY)
- Beide Analysen können von den u.U. präziseren Ergebnissen der extrahierten Analyse profitieren

# Cardinality Analysis

- Bevor wir uns den beiden Analysen zuwenden, beschäftigen wir uns zunächst mit Kardinalitätsanalysen
- KA berechnet untere und obere Schranken für Auswertungsmultiplizitäten
- In Anlehnung an Alias Analyse kann man die Analyse in MinCard/MaxCard aufteilen
- Zur Notation: Intervallschreibweise, interessante Kardinalitäten nur 0,1,mehrmals
- Beispiel, was eine Kardinalitätsanalyse herausfinden kann:  
  - a wird mindestens einmal, möglicherweise mehrmals ausgewertet
  - b wird genau einmal ausgewertet
  - c möglicherweise gar nicht oder mehrmals
  - d möglicherweise einmal, aber nicht mehrmals
  - e ist tot
- Was kann man nun mit dieser Information anfangen?  
  - Call-by-value
  - Call-by-need
  - Dead code elimination

# Call-by-value

- vermeidet den Overhead durch lazy evaluation (call-by-need), indem strikte bindings direkt ausgwertet werden
- erlaubt weitere wichtige Optimierungen wie Unboxing von primitiven Typen um Allokationen komplett zu vermeiden
- Blind Call-by-value benutzen verändert Terminationsverhalten
- Daher: 'Welche bindings werden mind. einmal ausgewertet?' (MinCard)  
  - strictness analyse € MinCard
- Hier: a und b sind strikt, was durch das Bang Pattern angedeutet wird

# Call-by-name

- Call-by-need muss grundsätzlich einmal berechnete Ergebnisse memoisieren
- Unnötig bei Thunks, die sowieso nur höchstens einmal ausgewertet werden!
- Verwandelt solche single-entry thunks in Funktionen, um Thunk updates zu sparen
- Alte Ergebnisse gehen von 70% single-entry aus
- Dazu: 'Welche Bindings werden höchstens einmal ausgewertet' (MaxCard)
- Im Beispiel durch zusätzliches unit argument angedeutet: b, d, e

# Usage Analysis

- Damit sind wir schon bei Usage Analysen, dem eigentlichen Thema meiner Arbeit
- Usage Analysen berechnen MaxCard Informationen, also obere Grenzen zu Auswertungsmultiplizitäten von Bindings
- Verwandt: Identifikation von one-shot lambdas, also lambdas, die höchstens einmal aufgerufen werden  
  - genauer: Anzahl an Auswertungen des Körpers relativ zu einer einzigen Auswertung des Lambda Ausdrucks
- f wird zweimal aufgerufen, daher äußeres Lambda mit $\omega$ annotiert
- Jede partielle Funktionsanwendung wird aber nur einmal aufgerufen, daher inneres lambda in beiden Fällen one-shot  
  - falls nicht verstanden: Partielle Funktionsanwendung wertet einmal zu innerem lambda Ausdruck aus, der dann relative genau einmal aufgerufen wird
- g dagegen wird nur einmal aufgerufen, daher alle lambdas one-shot
- Ermöglicht wichtige Optimierungen:  
  - let floating
  - eta expansion
  - inlining
- Wir interessieren uns heute nur für eta-expansion

# Eta-expansion

- Eta-expansion hebt effektiv lambdas nach außen
- Ist nicht immer sicher, weil Arbeit von d hier dupliziert werden könnte
- Weil zu hebendes Lambda aber one-shot ist, dürfen wir das! 
- Der Körper wird nicht öfter ausgeführt als der umgebende Ausdruck

# Demand Analysis

- Damit haben wir alle Grundlagen zusammen, um die beiden Analysen zu besprechen
- GHC's Demand Analyser ist eine Kardinalitätsanalyse (berechnet also obere und untere Grenzen für Auswertungsmultiplizitäten)
- Insbesondere bemüht der Demand Analyser eine Usage Analyse, um single-entry thunks, one-shot lambdas und tote Ausdrücke zu identifizieren
- Berechnet für jeden Ausdruck, wie er seine freien Variablen benutzt
- Drei Besonderheiten zu besprechen

# Call Uses

- Bis jetzt haben unsere Analysen immmer nur bestimmt, wie oft ein Binding ausgewertet wurde
- Die Information, *wie* ein Binding ausgewertet wurde ist aber auch wichtig, um one-shot lambdas zu identifizieren
- Call uses leisten genau das
- Im Beispiel:  
- Hier wird f folgender Usage ausgesetzt: höchstens einmal ausgewertet, dann höchstens einmal aufgerufen und das Ergebnis höchstens einmal aufgerufen
- Im zweiten Beispiel wird f mehrmals ausgewertet, mehrmals aufgerufen, aber das Ergebnis in beiden Fällen höchstens einmal aufgerufen
- Die one-shot annotationen entsprechen genau diesen Usages

# Usage Signatures

- GHC hat einen sehr aggressiven Inliner, aber manchmal nicht genug (Rekursiv, zu groß)
- Interprozeduraler Datenfluss über Signaturen, die angeben wie eine Funktion ihre Argumente benutzt
- Kombination aus Usage für freie Variablen + UsageSig = Usage Type
- Um UsageSignaturen an den Call Sites verfügbar zu haben, wird der gebundene Ausdruck vor dem let body analysiert, top-down
- Für Funktionen wird also die LetDn Regel benutzt: Usage types werden an Benutzungsstellen frei gelassen
- Hier: Const benutzt nur sein erstes ARgument, daher die Usage Signature
- An der Aufrufstelle wird dann y als einmal benutzt identifiziert und fac 1000 als tot

# Thunks

- Bei Thunks funktioniert LetDn nicht so gut, weil die Auswertung der rechten Seite zwischen Aufrufen geteilt wird
- hier hat `y` zwei Benutzungsstellen, mit LetDn daher zwei Benutzungen von `x`
- Die Auswertung der rechten Seite von `y` wird aber geteilt! Nur eine Benutzung von `x`
- Daher bei Thunks LetUp: Erst let body analysieren, Usage merken und dann rechte Seite in dem festgehaltenen Use, hier $U$, analysieren
- Das wäre schon alles wichtige zum Demand Analyser (vielleicht Fragen?)

# Call Arity

1. Grundsätzliche Idee: Eta-Expansion basierend darauf, wie Bindings benutzt werden  
  - Hier: `f` wird immer mit zwei Argumenten aufgerufen, Sharing ist so nie sichtbar
2. `f` kann zu Arity 2 expandiert werden
3. Wie sieht das in dieser Situation aus?
  - `f` wird zwar immer noch mit 2 Argumenten aufgerufen
4. Aber `f` ist auch ein Thunk, daher wird zwischen den Aufrufen die Arbeit des `if` Ausdrucks geteilt  
  - Insbesondere die Auswertung von `expensive`, die beliebig teuer sein kann
  - Eta-Expansion würde Sharing zunichte machen und den teuren Ausdruck mehrmals auswerten
5. Hier ist `f` wieder ein Thunk, mit zwei Argumenten aufgerufen  
6. Und weil `f` nur einmal aufgerufen wird, wird kein Sharing sichtbar  
  - Eta-Expansion ist sicher
  - Insbesondere zeigt das Beispiel auch, dass selbst in Situationen in denen statisch klar ist, dass `f` nur einmal aufgerufen wird, Inlining trotzdem nicht immer möglich ist
  - Called Once information also wichtig (für unsere Zwecke wie single-entry)

# Call Arity (Co-call graphs)

1. 



<!-- Markdeep: --><style class="fallback">body{visibility:hidden;white-space:pre;font-family:monospace}</style><script src="markdeep.min.js"></script><script src="https://casual-effects.com/markdeep/latest/markdeep.min.js"></script><script>window.alreadyProcessedMarkdeep||(document.body.style.visibility="visible")</script>
