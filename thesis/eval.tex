\chapter{Evaluation}\label{sec:eval}

With implementation considerations sorted out in \cref{sec:impl}, we turn to assessing the analysis by means of the performance of the generated code in \cref{sec:bench}.
We also discuss compiler performance in \cref{sec:compperf} and see ways to trade artifact performance for faster analysis time in \cref{sec:tradeoff}.

\section{Benchmarks}\label{sec:bench}

Enough with the mathy chit chat, give me numbers!

In this section we will look at how the analysis influences benchmark results in GHC's nofib \parencite{nofib} benchmark suite.

A GHC 8.2.1 release candidate, revision \texttt{83a6dd8}, serves as a baseline. We compare to three variants of our fork\footnote{Available at https://github.com/sgraf812/ghc under the branches \texttt{cocall-full}, \texttt{cocall-approximate-calls} and \texttt{cocall-complete-graphs}.}:

\begin{enumerate}
  \item[\varfull] 
    The most precise form of our analysis. 
    Replaces Call Arity entirely and is run two additional times, immediately after the Demand Analyser. 
    The usage information the Demand Analyser produces is only accessed to check for regressions.
  \item[\varcalls]
    This variant discards any product use at call sites. 
    E.g., $C^1(U(1*U,A))$ will be truncated to $C^1(U)$. 
    This is so that less nodes in the data-flow framework are accessed, to save space and time.
  \item[\varedges]
    In addition to the changes of \varcalls, replace the co-call graph by a structure which only tracks self-edges and conservatively assumes the existence of all other co-call edges.
    The intention is to measure if the worst case quadratic space usage of co-call graphs matters in practice.
    Note that regressions in some cases are expected, as the baseline employs Call Arity with accurate modelling of edges in co-call graphs at least between `interesting' variables.
\end{enumerate}

Ein Beispiel ist in \cref{tbl:nofib} zu sehen.

\begin{figure}[hb]
\begin{center}
\begin{tabular}{lrrr}
  \toprule
          & \multicolumn{3}{c}{Bytes allocated} \\
            \cmidrule(lr){2-4}
  Program & \multicolumn{1}{c}{\varfull} & \multicolumn{1}{c}{\varcalls} & \multicolumn{1}{c}{\varedges} \\
  \midrule
  ansi & -0.5\% & +0.3\% & +0.1\%\\
  awards & -0.2\% & +0.1\% & +0.0\%\\
  expert & -0.2\% & +0.2\% & +0.1\%\\
  fft2 & -2.2\% & -2.2\% & -2.2\%\\
  fluid & -1.5\% & -1.5\% & -1.5\%\\
  grep & -0.6\% & +0.5\% & +0.2\%\\
  infer & +0.0\% & +0.0\% & +0.0\%\\
  n-body & -0.5\% & +0.0\% & -0.1\%\\
  queens & -0.7\% & -0.7\% & -0.7\%\\
  rfib & -0.5\% & +0.3\% & +0.1\%\\
  scc & -0.3\% &  0.0\% & -0.3\%\\
  spectral-norm & -0.3\% & +0.1\% & -0.0\%\\
  tak & -0.7\% & +0.1\% & -0.1\%\\
  x2n1 & -0.2\% & +0.1\% & +0.0\%\\
  \midrule
  Min & -2.2\% & -2.2\% & -2.2\%\\
  Max & +0.0\% & +0.5\% & +0.2\%\\
  Geometric Mean & -0.1\% & -0.0\% & -0.0\%\\
  \bottomrule
\end{tabular}
\end{center}
\caption{
  Benchmark results of running nofib. 
  A GHC 8.2.1 release candidate on which all work is based was used as a baseline.
  Variants \varfull to \varedges are increasingly approximate, but theoretically speaking, only \varedges may possibly yield worse results than the current combination of Call Arity and Demand Analysis.
}
\label{tbl:nofib}
\end{figure}

