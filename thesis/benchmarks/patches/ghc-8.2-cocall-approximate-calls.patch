From 4c184aec29996da162abf4d329755ad566ef76c0 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 30 Aug 2016 10:26:16 +0200
Subject: [PATCH 001/117] Refactored callArityTopLvl It now uses mapAccumL and
 mapAccumR as does dmdAnalProgram

---
 compiler/simplCore/CallArity.hs | 36 ++++++++++++++++++++++--------------
 1 file changed, 22 insertions(+), 14 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index c051dae456..40c3a86125 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -11,6 +11,8 @@ import VarSet
 import VarEnv
 import DynFlags ( DynFlags )
 
+import Data.List (mapAccumL, mapAccumR)
+
 import BasicTypes
 import CoreSyn
 import Id
@@ -411,23 +413,29 @@ Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
 -- Main entry point
 
 callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
-callArityAnalProgram _dflags binds = binds'
-  where
-    (_, binds') = callArityTopLvl [] emptyVarSet binds
+callArityAnalProgram _dflags binds = callArityTopLvl binds
 
 -- See Note [Analysing top-level-binds]
-callArityTopLvl :: [Var] -> VarSet -> [CoreBind] -> (CallArityRes, [CoreBind])
-callArityTopLvl exported _ []
-    = ( calledMultipleTimes $ (emptyUnVarGraph, mkVarEnv $ [(v, 0) | v <- exported])
-      , [] )
-callArityTopLvl exported int1 (b:bs)
-    = (ae2, b':bs')
+callArityTopLvl :: [CoreBind] -> [CoreBind]
+callArityTopLvl binds
+    = snd $ mapAccumR analyseBind exportedArityResult annotatedBinds
   where
-    int2 = bindersOf b
-    exported' = filter isExportedId int2 ++ exported
-    int' = int1 `addInterestingBinds` b
-    (ae1, bs') = callArityTopLvl exported' int' bs
-    (ae2, b')  = callArityBind (boringBinds b) ae1 int1 b
+    exported :: [Var]
+    annotatedBinds :: [(VarSet, CoreBind)]
+    ((exported, _), annotatedBinds) = mapAccumL annotate ([], emptyVarSet) binds
+
+    annotate :: ([Var], VarSet) -> CoreBind -> (([Var], VarSet), (VarSet, CoreBind))
+    annotate (exported, interesting) b =
+      ( (filter isExportedId (bindersOf b) ++ exported, addInterestingBinds interesting b)
+      , (interesting, b) )
+
+    exportedArityResult :: CallArityRes
+    exportedArityResult =
+      calledMultipleTimes (emptyUnVarGraph, mkVarEnv [(v, 0) | v <- exported])
+
+    analyseBind :: CallArityRes -> (VarSet, CoreBind) -> (CallArityRes, CoreBind)
+    analyseBind ae (interesting, b) =
+      callArityBind (boringBinds b) ae interesting b
 
 
 callArityRHS :: CoreExpr -> CoreExpr
-- 
2.12.1


From ffac8ef97e9efd7599496b1c1ad6cc4a24b7a9ed Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 30 Aug 2016 10:29:22 +0200
Subject: [PATCH 002/117] Inlined callArityTopLvl

Since the only simple usage was within callArityAnalProgram anyway.
---
 compiler/simplCore/CallArity.hs | 7 ++-----
 1 file changed, 2 insertions(+), 5 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index 40c3a86125..b1b835aea9 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -412,12 +412,9 @@ Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
 
 -- Main entry point
 
-callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
-callArityAnalProgram _dflags binds = callArityTopLvl binds
-
 -- See Note [Analysing top-level-binds]
-callArityTopLvl :: [CoreBind] -> [CoreBind]
-callArityTopLvl binds
+callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
+callArityAnalProgram _dflags binds
     = snd $ mapAccumR analyseBind exportedArityResult annotatedBinds
   where
     exported :: [Var]
-- 
2.12.1


From de59ca1aefad4356f59f6c303606dcd9946a3512 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Wed, 2 Nov 2016 23:39:16 +0100
Subject: [PATCH 003/117] Some first refactorings introducing an AnalEnv for
 Call Arity

---
 compiler/simplCore/CallArity.hs | 191 +++++++++++++++++++++++++---------------
 compiler/stranal/DmdAnal.hs     |  36 ++++++--
 2 files changed, 146 insertions(+), 81 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index b1b835aea9..0dd7771925 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -7,22 +7,22 @@ module CallArity
     , callArityRHS -- for testing
     ) where
 
-import VarSet
-import VarEnv
-import DynFlags ( DynFlags )
+import           DynFlags      (DynFlags)
+import           VarEnv
+import           VarSet
 
-import Data.List (mapAccumL, mapAccumR)
+import           Data.List     (mapAccumL, mapAccumR)
 
-import BasicTypes
-import CoreSyn
-import Id
-import CoreArity ( typeArity )
-import CoreUtils ( exprIsCheap, exprIsTrivial )
---import Outputable
-import UnVarGraph
-import Demand
+import           BasicTypes
+import           CoreArity     (typeArity)
+import           CoreSyn
+import           CoreUtils     (exprIsHNF, exprIsTrivial)
+import           Id
+import Outputable
+import           Demand
+import           UnVarGraph
 
-import Control.Arrow ( first, second )
+import           Control.Arrow (first, second)
 
 
 {-
@@ -415,33 +415,49 @@ Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
 -- See Note [Analysing top-level-binds]
 callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
 callArityAnalProgram _dflags binds
-    = snd $ mapAccumR analyseBind exportedArityResult annotatedBinds
+    = snd $ mapAccumR analyse_bind exp_arity_result tagged_binds
   where
+    -- In the following left fold, we identify @exported@ binders and @tag@ each
+    -- binder with an @AnalEnv@ just prepared with interesting vars from outer
+    -- binding groups.
     exported :: [Var]
-    annotatedBinds :: [(VarSet, CoreBind)]
-    ((exported, _), annotatedBinds) = mapAccumL annotate ([], emptyVarSet) binds
-
-    annotate :: ([Var], VarSet) -> CoreBind -> (([Var], VarSet), (VarSet, CoreBind))
-    annotate (exported, interesting) b =
-      ( (filter isExportedId (bindersOf b) ++ exported, addInterestingBinds interesting b)
-      , (interesting, b) )
-
-    exportedArityResult :: CallArityRes
-    exportedArityResult =
+    tagged_binds :: [(AnalEnv, CoreBind)]
+    ((exported, _), tagged_binds) = mapAccumL tag ([], emptyAnalEnv) binds
+
+    -- This is more complicated than it needs to be, because we must not include
+    -- the binding group itself as interesting. Why not actually?!
+    -- TODO: I'm doing this. Let's see if it works
+    --   I think it's mostly because in the non-rec case, the identifier will
+    --   be referenced. The boringness check relies on them however and in the
+    --   recursive case, the binders are also interesting. Seems like a micro
+    --   optimization.
+    tag :: ([Var], AnalEnv) -> CoreBind -> (([Var], AnalEnv), (AnalEnv, CoreBind))
+    tag (exported, env) b =
+        ( (filter isExportedId (bindersOf b) ++ exported, env_body)
+        , (env_body, b) )
+      where
+        env_body = addInterestingBinds b env
+
+    -- We start with the assumption that all exported identifiers
+    -- call each other, including itself.
+    -- Is this necessary? Wouldn't it be enough to concentrate on interesting
+    -- variables?
+    exp_arity_result:: CallArityRes
+    exp_arity_result =
       calledMultipleTimes (emptyUnVarGraph, mkVarEnv [(v, 0) | v <- exported])
 
-    analyseBind :: CallArityRes -> (VarSet, CoreBind) -> (CallArityRes, CoreBind)
-    analyseBind ae (interesting, b) =
-      callArityBind (boringBinds b) ae interesting b
+    analyse_bind :: CallArityRes -> (AnalEnv, CoreBind) -> (CallArityRes, CoreBind)
+    analyse_bind ae (env, b) =
+      callArityBind env ae b
 
 
 callArityRHS :: CoreExpr -> CoreExpr
-callArityRHS = snd . callArityAnal 0 emptyVarSet
+callArityRHS = snd . callArityAnal emptyAnalEnv 0
 
 -- The main analysis function. See Note [Analysis type signature]
 callArityAnal ::
+    AnalEnv -> -- analysis environment
     Arity ->  -- The arity this expression is called with
-    VarSet -> -- The set of interesting variables
     CoreExpr ->  -- The expression to analyse
     (CallArityRes, CoreExpr)
         -- How this expression uses its interesting variables
@@ -455,44 +471,44 @@ callArityAnal _     _   e@(Type _)
 callArityAnal _     _   e@(Coercion _)
     = (emptyArityRes, e)
 -- The transparent cases
-callArityAnal arity int (Tick t e)
-    = second (Tick t) $ callArityAnal arity int e
-callArityAnal arity int (Cast e co)
-    = second (\e -> Cast e co) $ callArityAnal arity int e
+callArityAnal env arity (Tick t e)
+    = second (Tick t) $ callArityAnal env arity e
+callArityAnal env arity (Cast e co)
+    = second (\e -> Cast e co) $ callArityAnal env arity e
 
 -- The interesting case: Variables, Lambdas, Lets, Applications, Cases
-callArityAnal arity int e@(Var v)
-    | v `elemVarSet` int
+callArityAnal env arity e@(Var v)
+    | v `elemVarSet` ae_interesting env
     = (unitArityRes v arity, e)
     | otherwise
     = (emptyArityRes, e)
 
 -- Non-value lambdas are ignored
-callArityAnal arity int (Lam v e) | not (isId v)
-    = second (Lam v) $ callArityAnal arity (int `delVarSet` v) e
+callArityAnal env arity (Lam v e) | not (isId v)
+    = second (Lam v) $ callArityAnal (setUninteresting v env) arity e
 
 -- We have a lambda that may be called multiple times, so its free variables
 -- can all be co-called.
-callArityAnal 0     int (Lam v e)
+callArityAnal env 0     (Lam v e)
     = (ae', Lam v e')
   where
-    (ae, e') = callArityAnal 0 (int `delVarSet` v) e
+    (ae, e') = callArityAnal (setUninteresting v env) 0 e
     ae' = calledMultipleTimes ae
 -- We have a lambda that we are calling. decrease arity.
-callArityAnal arity int (Lam v e)
+callArityAnal env arity (Lam v e)
     = (ae, Lam v e')
   where
-    (ae, e') = callArityAnal (arity - 1) (int `delVarSet` v) e
+    (ae, e') = callArityAnal (setUninteresting v env) (arity - 1) e
 
 -- Application. Increase arity for the called expression, nothing to know about
 -- the second
-callArityAnal arity int (App e (Type t))
-    = second (\e -> App e (Type t)) $ callArityAnal arity int e
-callArityAnal arity int (App e1 e2)
+callArityAnal env arity (App e (Type t))
+    = second (\e -> App e (Type t)) $ callArityAnal env arity e
+callArityAnal env arity (App e1 e2)
     = (final_ae, App e1' e2')
   where
-    (ae1, e1') = callArityAnal (arity + 1) int e1
-    (ae2, e2') = callArityAnal 0           int e2
+    (ae1, e1') = callArityAnal env (arity + 1) e1
+    (ae2, e2') = callArityAnal env 0           e2
     -- If the argument is trivial (e.g. a variable), then it will _not_ be
     -- let-bound in the Core to STG transformation (CorePrep actually),
     -- so no sharing will happen here, and we have to assume many calls.
@@ -501,27 +517,27 @@ callArityAnal arity int (App e1 e2)
     final_ae = ae1 `both` ae2'
 
 -- Case expression.
-callArityAnal arity int (Case scrut bndr ty alts)
+callArityAnal env arity (Case scrut bndr ty alts)
     = -- pprTrace "callArityAnal:Case"
       --          (vcat [ppr scrut, ppr final_ae])
       (final_ae, Case scrut' bndr ty alts')
   where
     (alt_aes, alts') = unzip $ map go alts
-    go (dc, bndrs, e) = let (ae, e') = callArityAnal arity int e
+    go (dc, bndrs, e) = let (ae, e') = callArityAnal env arity e
                         in  (ae, (dc, bndrs, e'))
     alt_ae = lubRess alt_aes
-    (scrut_ae, scrut') = callArityAnal 0 int scrut
+    (scrut_ae, scrut') = callArityAnal env 0 scrut
     final_ae = scrut_ae `both` alt_ae
 
 -- For lets, use callArityBind
-callArityAnal arity int (Let bind e)
+callArityAnal env arity (Let bind e)
   = -- pprTrace "callArityAnal:Let"
     --          (vcat [ppr v, ppr arity, ppr n, ppr final_ae ])
     (final_ae, Let bind' e')
   where
-    int_body = int `addInterestingBinds` bind
-    (ae_body, e') = callArityAnal arity int_body e
-    (final_ae, bind') = callArityBind (boringBinds bind) ae_body int bind
+    env_body = addInterestingBinds bind env
+    (ae_body, e') = callArityAnal env_body arity e
+    (final_ae, bind') = callArityBind env_body ae_body bind
 
 -- Which bindings should we look at?
 -- See Note [Which variables are interesting]
@@ -534,24 +550,27 @@ interestingBinds = filter isInteresting . bindersOf
 boringBinds :: CoreBind -> VarSet
 boringBinds = mkVarSet . filter (not . isInteresting) . bindersOf
 
-addInterestingBinds :: VarSet -> CoreBind -> VarSet
-addInterestingBinds int bind
-    = int `delVarSetList`    bindersOf bind -- Possible shadowing
-          `extendVarSetList` interestingBinds bind
+addInterestingBinds :: CoreBind -> AnalEnv -> AnalEnv
+addInterestingBinds bind env
+    = env
+    { ae_interesting = ae_interesting env
+        `delVarSetList` bindersOf bind -- Possible shadowing
+        `extendVarSetList` interestingBinds bind
+    }
 
 -- Used for both local and top-level binds
 -- Second argument is the demand from the body
-callArityBind :: VarSet -> CallArityRes -> VarSet -> CoreBind -> (CallArityRes, CoreBind)
+callArityBind :: AnalEnv -> CallArityRes -> CoreBind -> (CallArityRes, CoreBind)
 -- Non-recursive let
-callArityBind boring_vars ae_body int (NonRec v rhs)
+callArityBind env ae_body (NonRec v rhs)
   | otherwise
-  = -- pprTrace "callArityBind:NonRec"
-    --          (vcat [ppr v, ppr ae_body, ppr int, ppr ae_rhs, ppr safe_arity])
+  = --pprTrace "callArityBind:NonRec"
+    --        (vcat [ppr v, ppr ae_body, ppr (ae_interesting env), ppr ae_rhs, ppr safe_arity])
     (final_ae, NonRec v' rhs')
   where
     is_thunk = not (exprIsCheap rhs) -- see note [What is a thunk]
     -- If v is boring, we will not find it in ae_body, but always assume (0, False)
-    boring = v `elemVarSet` boring_vars
+    boring = not (elemInteresting v env)
 
     (arity, called_once)
         | boring    = (0, False) -- See Note [Taking boring variables into account]
@@ -563,7 +582,7 @@ callArityBind boring_vars ae_body int (NonRec v rhs)
     -- See Note [Trimming arity]
     trimmed_arity = trimArity v safe_arity
 
-    (ae_rhs, rhs') = callArityAnal trimmed_arity int rhs
+    (ae_rhs, rhs') = callArityAnal env trimmed_arity rhs
 
 
     ae_rhs'| called_once     = ae_rhs
@@ -580,16 +599,16 @@ callArityBind boring_vars ae_body int (NonRec v rhs)
 
 
 -- Recursive let. See Note [Recursion and fixpointing]
-callArityBind boring_vars ae_body int b@(Rec binds)
-  = -- (if length binds > 300 then
-    -- pprTrace "callArityBind:Rec"
-    --           (vcat [ppr (Rec binds'), ppr ae_body, ppr int, ppr ae_rhs]) else id) $
+callArityBind env ae_body b@(Rec binds)
+  = --(if True then
+    --pprTrace "callArityBind:Rec"
+    --         (vcat [ppr (Rec binds'), ppr ae_body, ppr (ae_interesting env), ppr ae_rhs]) else id) $
     (final_ae, Rec binds')
   where
     -- See Note [Taking boring variables into account]
-    any_boring = any (`elemVarSet` boring_vars) [ i | (i, _) <- binds]
+    any_boring = any (not . flip elemInteresting env) [ i | (i, _) <- binds]
 
-    int_body = int `addInterestingBinds` b
+    env_body = addInterestingBinds b env
     (ae_rhs, binds') = fix initial_binds
     final_ae = bindersOf b `resDelList` ae_rhs
 
@@ -607,7 +626,7 @@ callArityBind boring_vars ae_body int b@(Rec binds)
         ae = callArityRecEnv any_boring aes_old ae_body
 
         rerun (i, mbLastRun, rhs)
-            | i `elemVarSet` int_body && not (i `elemUnVarSet` domRes ae)
+            | i `elemInteresting` env_body && not (i `elemUnVarSet` domRes ae)
             -- No call to this yet, so do nothing
             = (False, (i, Nothing, rhs))
 
@@ -627,7 +646,7 @@ callArityBind boring_vars ae_body int b@(Rec binds)
                   -- See Note [Trimming arity]
                   trimmed_arity = trimArity i safe_arity
 
-                  (ae_rhs, rhs') = callArityAnal trimmed_arity int_body rhs
+                  (ae_rhs, rhs') = callArityAnal env_body trimmed_arity rhs
 
                   ae_rhs' | called_once     = ae_rhs
                           | safe_arity == 0 = ae_rhs -- If it is not a function, its body is evaluated only once
@@ -636,8 +655,8 @@ callArityBind boring_vars ae_body int b@(Rec binds)
               in (True, (i `setIdCallArity` trimmed_arity, Just (called_once, new_arity, ae_rhs'), rhs'))
           where
             -- See Note [Taking boring variables into account]
-            (new_arity, called_once) | i `elemVarSet` boring_vars = (0, False)
-                                     | otherwise                  = lookupCallArityRes ae i
+            (new_arity, called_once) | not (elemInteresting i env) = (0, False)
+                                     | otherwise                   = lookupCallArityRes ae i
 
         (changes, ann_binds') = unzip $ map rerun ann_binds
         any_change = or changes
@@ -696,9 +715,32 @@ trimArity v a = minimum [a, max_arity_by_type, max_arity_by_strsig]
 -- and Note [Analysis II: The Co-Called analysis]
 type CallArityRes = (UnVarGraph, VarEnv Arity)
 
+data AnalEnv
+  = AE
+  { ae_sigs :: VarEnv CallAritySig
+  , ae_interesting :: VarSet
+  }
+
+data CallAritySig
+  = CAS
+  { cas_cocalled :: UnVarGraph
+  , cas_arities :: VarEnv Arity
+  , cas_args :: [Var]
+  }
+
+emptyAnalEnv :: AnalEnv
+emptyAnalEnv = AE { ae_sigs = emptyVarEnv, ae_interesting = emptyVarSet }
+
 emptyArityRes :: CallArityRes
 emptyArityRes = (emptyUnVarGraph, emptyVarEnv)
 
+setUninteresting :: Var -> AnalEnv -> AnalEnv
+setUninteresting v env
+  = env { ae_interesting = delVarSet (ae_interesting env) v }
+
+elemInteresting :: Var -> AnalEnv -> Bool
+elemInteresting v env = elemVarSet v (ae_interesting env)
+
 unitArityRes :: Var -> Arity -> CallArityRes
 unitArityRes v arity = (emptyUnVarGraph, unitVarEnv v arity)
 
@@ -711,6 +753,9 @@ resDel v (g, ae) = (g `delNode` v, ae `delVarEnv` v)
 domRes :: CallArityRes -> UnVarSet
 domRes (_, ae) = varEnvDom ae
 
+extendSigsWithLam :: CallArityRes -> Id -> CallArityRes
+extendSigsWithLam = undefined
+
 -- In the result, find out the minimum arity and whether the variable is called
 -- at most once.
 lookupCallArityRes :: CallArityRes -> Var -> (Arity, Bool)
diff --git a/compiler/stranal/DmdAnal.hs b/compiler/stranal/DmdAnal.hs
index 2fc33a48b8..12496104b4 100644
--- a/compiler/stranal/DmdAnal.hs
+++ b/compiler/stranal/DmdAnal.hs
@@ -1066,22 +1066,42 @@ type DFunFlag = Bool  -- indicates if the lambda being considered is in the
 notArgOfDfun :: DFunFlag
 notArgOfDfun = False
 
+-- ^ Holds all (mostly read-only) state of the analysis.
 data AnalEnv
   = AE { ae_dflags :: DynFlags
+       -- ^ Compiler flags
        , ae_sigs   :: SigEnv
-       , ae_virgin :: Bool    -- True on first iteration only
-                              -- See Note [Initialising strictness]
+       -- ^ @SigEnv@ storing signatures and top-level information for all
+       --   currently visible free function variables, according to the LetDn
+       --   rule. This contains the actual state of the analysis!
+       , ae_virgin :: Bool
+       -- ^ True on first iteration only
+       --   See Note [Initialising strictness]
        , ae_rec_tc :: RecTcChecker
+       -- ^ Used to track recursive product types when trying to unbox.
+       --   As such we have to carry it around and update it as we go, but it's
+       --   rather unimportant to the implementation.
+       --   See Note [Expanding newtypes and products] in types/TyCon.hs
        , ae_fam_envs :: FamInstEnvs
+       -- ^ See @FamInst@. Unimportant for comprehension.
+       --   Related to type families, exclusively needed for
+       --   calls to @deepSplitProductType_maybe@ and @findTypeShape@, which is
+       --   worker/wrapper related.
  }
 
-        -- We use the se_env to tell us whether to
-        -- record info about a variable in the DmdEnv
-        -- We do so if it's a LocalId, but not top-level
-        --
-        -- The DmdEnv gives the demand on the free vars of the function
-        -- when it is given enough args to satisfy the strictness signature
+{-| Stores a @StrictSig@ per @Var@ (which represent functions).
+
+If the the @StrictSig@ of a function is satisfied (e.g. if the function is given
+enough args), it gives
+
+    * the demand on free vars of the function in the @DmdEnv@
 
+    * the demand on its arguments as a @[Demand]@
+
+    * the @DmdResult@ of that call
+
+See also all notes and comments above the definition of @StrictSig@.
+-}
 type SigEnv = VarEnv (StrictSig, TopLevelFlag)
 
 instance Outputable AnalEnv where
-- 
2.12.1


From 5f76a7b09e31621dc54850f4924d526b1a2828c4 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 3 Nov 2016 10:54:38 +0100
Subject: [PATCH 004/117] Printing out call arity sigs for manifest arity
 (hardly useful)

---
 compiler/simplCore/CallArity.hs | 57 +++++++++++++++++++++++++++--------------
 1 file changed, 38 insertions(+), 19 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index 0dd7771925..8c9dfee63e 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -415,14 +415,13 @@ Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
 -- See Note [Analysing top-level-binds]
 callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
 callArityAnalProgram _dflags binds
-    = snd $ mapAccumR analyse_bind exp_arity_result tagged_binds
+    = snd $ mapAccumR analyse_bind (emptyUnVarGraph, mkVarEnv []) tagged_binds
   where
     -- In the following left fold, we identify @exported@ binders and @tag@ each
     -- binder with an @AnalEnv@ just prepared with interesting vars from outer
     -- binding groups.
-    exported :: [Var]
     tagged_binds :: [(AnalEnv, CoreBind)]
-    ((exported, _), tagged_binds) = mapAccumL tag ([], emptyAnalEnv) binds
+    tagged_binds = snd (mapAccumL tag emptyAnalEnv binds)
 
     -- This is more complicated than it needs to be, because we must not include
     -- the binding group itself as interesting. Why not actually?!
@@ -431,21 +430,12 @@ callArityAnalProgram _dflags binds
     --   be referenced. The boringness check relies on them however and in the
     --   recursive case, the binders are also interesting. Seems like a micro
     --   optimization.
-    tag :: ([Var], AnalEnv) -> CoreBind -> (([Var], AnalEnv), (AnalEnv, CoreBind))
-    tag (exported, env) b =
-        ( (filter isExportedId (bindersOf b) ++ exported, env_body)
-        , (env_body, b) )
+    tag :: AnalEnv -> CoreBind -> (AnalEnv, (AnalEnv, CoreBind))
+    tag env b =
+        (env_body, (env_body, b))
       where
         env_body = addInterestingBinds b env
 
-    -- We start with the assumption that all exported identifiers
-    -- call each other, including itself.
-    -- Is this necessary? Wouldn't it be enough to concentrate on interesting
-    -- variables?
-    exp_arity_result:: CallArityRes
-    exp_arity_result =
-      calledMultipleTimes (emptyUnVarGraph, mkVarEnv [(v, 0) | v <- exported])
-
     analyse_bind :: CallArityRes -> (AnalEnv, CoreBind) -> (CallArityRes, CoreBind)
     analyse_bind ae (env, b) =
       callArityBind env ae b
@@ -582,7 +572,15 @@ callArityBind env ae_body (NonRec v rhs)
     -- See Note [Trimming arity]
     trimmed_arity = trimArity v safe_arity
 
-    (ae_rhs, rhs') = callArityAnal env trimmed_arity rhs
+    -- Mud
+    (binders, rhs_body) = collectBinders rhs
+    ((cocalled, arities), rhs_body') = callArityAnal env (length binders) rhs_body
+    ca_sig = CAS cocalled arities binders
+    env' = extendAnalEnv v' ca_sig env
+    -- /Mud
+
+    (ae_rhs, rhs') = pprTrace "callArityBind:NonRec:sig" (text "id:" <+> ppr v <+> text "sig:" <+> ppr ca_sig) $
+        callArityAnal env trimmed_arity rhs
 
 
     ae_rhs'| called_once     = ae_rhs
@@ -603,8 +601,22 @@ callArityBind env ae_body b@(Rec binds)
   = --(if True then
     --pprTrace "callArityBind:Rec"
     --         (vcat [ppr (Rec binds'), ppr ae_body, ppr (ae_interesting env), ppr ae_rhs]) else id) $
+    pprTrace "callArityBind:Rec:sigs"
+             (vcat (map (\(b, sig) -> text "id:" <+> ppr b <+> text "sig:" <+> ppr sig) sigs)) $
     (final_ae, Rec binds')
   where
+
+    -- Mud
+    sigs = map mk_sig binds
+
+    mk_sig (v, rhs) = (v, ca_sig)
+      where
+        (binders, rhs_body) = collectBinders rhs
+        ((cocalled, arities), rhs_body') = callArityAnal env (length binders) rhs_body
+        ca_sig = CAS cocalled arities binders
+        env' = extendAnalEnv v ca_sig env
+    -- /Mud
+
     -- See Note [Taking boring variables into account]
     any_boring = any (not . flip elemInteresting env) [ i | (i, _) <- binds]
 
@@ -728,12 +740,22 @@ data CallAritySig
   , cas_args :: [Var]
   }
 
+instance Outputable CallAritySig where
+  ppr (CAS cocalled arities args) =
+    text "args:" <+> ppr args
+    <+> text "co-calls:" <+> ppr cocalled
+    <+> text "arities:" <+> ppr arities
+
 emptyAnalEnv :: AnalEnv
 emptyAnalEnv = AE { ae_sigs = emptyVarEnv, ae_interesting = emptyVarSet }
 
 emptyArityRes :: CallArityRes
 emptyArityRes = (emptyUnVarGraph, emptyVarEnv)
 
+extendAnalEnv :: Id -> CallAritySig -> AnalEnv -> AnalEnv
+extendAnalEnv v sig env
+  = env { ae_sigs = extendVarEnv (ae_sigs env) v sig }
+
 setUninteresting :: Var -> AnalEnv -> AnalEnv
 setUninteresting v env
   = env { ae_interesting = delVarSet (ae_interesting env) v }
@@ -753,9 +775,6 @@ resDel v (g, ae) = (g `delNode` v, ae `delVarEnv` v)
 domRes :: CallArityRes -> UnVarSet
 domRes (_, ae) = varEnvDom ae
 
-extendSigsWithLam :: CallArityRes -> Id -> CallArityRes
-extendSigsWithLam = undefined
-
 -- In the result, find out the minimum arity and whether the variable is called
 -- at most once.
 lookupCallArityRes :: CallArityRes -> Var -> (Arity, Bool)
-- 
2.12.1


From 3b915b16f49901eb94c2028150593f666c6bad5b Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 3 Nov 2016 23:13:16 +0100
Subject: [PATCH 005/117] Brought back exported arity result, because removing
 it introduced a bug

---
 compiler/simplCore/CallArity.hs | 72 +++++++++++++++++++++++++----------------
 1 file changed, 45 insertions(+), 27 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index 8c9dfee63e..86bfa8b20b 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -415,13 +415,24 @@ Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
 -- See Note [Analysing top-level-binds]
 callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
 callArityAnalProgram _dflags binds
-    = snd $ mapAccumR analyse_bind (emptyUnVarGraph, mkVarEnv []) tagged_binds
+    = snd $ mapAccumR analyse_bind exp_arity_result tagged_binds
   where
+    -- Represents the fact that a CoreProgram is like a sequence of
+    -- nested lets, where the exports are returned in the inner-most let
+    -- as a tuple. As a result, all exported identifiers are handled as called
+    -- with each other, with arity 0.
+    -- Note that we could unify this with @callArityAnal@ by simply transforming
+    -- a @CoreProgram@ to said sequence of let-bindings.
+    exp_arity_result :: CallArityRes
+    exp_arity_result = calledMultipleTimes (emptyUnVarGraph, mkVarEnv [(v, 0) | v <- exportedVars])
+      where
+        exportedVars = binds >>= filter isExportedId . bindersOf
+
     -- In the following left fold, we identify @exported@ binders and @tag@ each
     -- binder with an @AnalEnv@ just prepared with interesting vars from outer
     -- binding groups.
     tagged_binds :: [(AnalEnv, CoreBind)]
-    tagged_binds = snd (mapAccumL tag emptyAnalEnv binds)
+    tagged_binds = tail (scanl tag (emptyAnalEnv, error "tagged_binds: unused") binds)
 
     -- This is more complicated than it needs to be, because we must not include
     -- the binding group itself as interesting. Why not actually?!
@@ -430,11 +441,9 @@ callArityAnalProgram _dflags binds
     --   be referenced. The boringness check relies on them however and in the
     --   recursive case, the binders are also interesting. Seems like a micro
     --   optimization.
-    tag :: AnalEnv -> CoreBind -> (AnalEnv, (AnalEnv, CoreBind))
-    tag env b =
-        (env_body, (env_body, b))
-      where
-        env_body = addInterestingBinds b env
+    --
+    tag :: (AnalEnv, CoreBind) -> CoreBind -> (AnalEnv, CoreBind)
+    tag (env, _) b = (addInterestingVars (bindersOf b) env, b)
 
     analyse_bind :: CallArityRes -> (AnalEnv, CoreBind) -> (CallArityRes, CoreBind)
     analyse_bind ae (env, b) =
@@ -525,7 +534,7 @@ callArityAnal env arity (Let bind e)
     --          (vcat [ppr v, ppr arity, ppr n, ppr final_ae ])
     (final_ae, Let bind' e')
   where
-    env_body = addInterestingBinds bind env
+    env_body = addInterestingVars (bindersOf bind) env
     (ae_body, e') = callArityAnal env_body arity e
     (final_ae, bind') = callArityBind env_body ae_body bind
 
@@ -534,18 +543,12 @@ callArityAnal env arity (Let bind e)
 isInteresting :: Var -> Bool
 isInteresting v = not $ null (typeArity (idType v))
 
-interestingBinds :: CoreBind -> [Var]
-interestingBinds = filter isInteresting . bindersOf
-
-boringBinds :: CoreBind -> VarSet
-boringBinds = mkVarSet . filter (not . isInteresting) . bindersOf
-
-addInterestingBinds :: CoreBind -> AnalEnv -> AnalEnv
-addInterestingBinds bind env
+addInterestingVars :: [Var] -> AnalEnv -> AnalEnv
+addInterestingVars vars env
     = env
     { ae_interesting = ae_interesting env
-        `delVarSetList` bindersOf bind -- Possible shadowing
-        `extendVarSetList` interestingBinds bind
+        `delVarSetList` vars -- Possible shadowing
+        `extendVarSetList` filter isInteresting vars
     }
 
 -- Used for both local and top-level binds
@@ -573,13 +576,18 @@ callArityBind env ae_body (NonRec v rhs)
     trimmed_arity = trimArity v safe_arity
 
     -- Mud
-    (binders, rhs_body) = collectBinders rhs
-    ((cocalled, arities), rhs_body') = callArityAnal env (length binders) rhs_body
-    ca_sig = CAS cocalled arities binders
-    env' = extendAnalEnv v' ca_sig env
+    mk_sig k v rhs = ca_sig
+      where
+        (binders, rhs_body) = collectBinders rhs
+        ((cocalled, arities), rhs_body') =
+            callArityAnal (addInterestingVars binders env) (length binders + k) rhs_body
+        ca_sig = CAS cocalled arities binders
+        env' = extendAnalEnv v ca_sig env
+
     -- /Mud
 
-    (ae_rhs, rhs') = pprTrace "callArityBind:NonRec:sig" (text "id:" <+> ppr v <+> text "sig:" <+> ppr ca_sig) $
+    (ae_rhs, rhs') = pprTrace "callArityBind:NonRec:sig"
+        (text "id:" <+> ppr v <+> text "sig0:" <+> ppr (mk_sig 0 v rhs) <+> text "sig1:" <+> ppr (mk_sig 1 v rhs)) $
         callArityAnal env trimmed_arity rhs
 
 
@@ -607,12 +615,13 @@ callArityBind env ae_body b@(Rec binds)
   where
 
     -- Mud
-    sigs = map mk_sig binds
+    sigs = map (uncurry (mk_sig 1)) binds
 
-    mk_sig (v, rhs) = (v, ca_sig)
+    mk_sig k v rhs = (v, ca_sig)
       where
         (binders, rhs_body) = collectBinders rhs
-        ((cocalled, arities), rhs_body') = callArityAnal env (length binders) rhs_body
+        ((cocalled, arities), rhs_body') =
+            callArityAnal env_body (length binders + k) rhs_body
         ca_sig = CAS cocalled arities binders
         env' = extendAnalEnv v ca_sig env
     -- /Mud
@@ -620,7 +629,7 @@ callArityBind env ae_body b@(Rec binds)
     -- See Note [Taking boring variables into account]
     any_boring = any (not . flip elemInteresting env) [ i | (i, _) <- binds]
 
-    env_body = addInterestingBinds b env
+    env_body = addInterestingVars (bindersOf b) env
     (ae_rhs, binds') = fix initial_binds
     final_ae = bindersOf b `resDelList` ae_rhs
 
@@ -806,3 +815,12 @@ lubArityEnv = plusVarEnv_C min
 
 lubRess :: [CallArityRes] -> CallArityRes
 lubRess = foldl lubRes emptyArityRes
+
+memoize :: (Int -> a) -> Int -> Int -> Maybe a
+memoize f min = lookup
+  where
+    cache = [f n | n <- [start..]]
+
+    lookup n
+      | n < min = Nothing
+      | otherwise = Just (cache ! n - start)
-- 
2.12.1


From 52bb095325086ac078e8f347933c4db1c0a6a72e Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 4 Nov 2016 18:42:36 +0100
Subject: [PATCH 006/117] Refactored callArityAnalProgram (again). Removed
 tracking of interesting vars in a VarSet

---
 compiler/.haskell-ghc-mod.json  |   4 ++
 compiler/simplCore/CallArity.hs | 155 +++++++++++++++++++---------------------
 2 files changed, 76 insertions(+), 83 deletions(-)
 create mode 100644 compiler/.haskell-ghc-mod.json

diff --git a/compiler/.haskell-ghc-mod.json b/compiler/.haskell-ghc-mod.json
new file mode 100644
index 0000000000..067c9fc64e
--- /dev/null
+++ b/compiler/.haskell-ghc-mod.json
@@ -0,0 +1,4 @@
+{
+  "disable": false,
+  "suppressErrors": true
+}
diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index 86bfa8b20b..39a3ab6e72 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -414,8 +414,7 @@ Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
 
 -- See Note [Analysing top-level-binds]
 callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
-callArityAnalProgram _dflags binds
-    = snd $ mapAccumR analyse_bind exp_arity_result tagged_binds
+callArityAnalProgram _dflags binds = snd (go emptyAnalEnv binds)
   where
     -- Represents the fact that a CoreProgram is like a sequence of
     -- nested lets, where the exports are returned in the inner-most let
@@ -426,37 +425,45 @@ callArityAnalProgram _dflags binds
     exp_arity_result :: CallArityRes
     exp_arity_result = calledMultipleTimes (emptyUnVarGraph, mkVarEnv [(v, 0) | v <- exportedVars])
       where
+        -- we could even filter out @v@ that @not (isInteresting v)@
         exportedVars = binds >>= filter isExportedId . bindersOf
 
-    -- In the following left fold, we identify @exported@ binders and @tag@ each
-    -- binder with an @AnalEnv@ just prepared with interesting vars from outer
-    -- binding groups.
-    tagged_binds :: [(AnalEnv, CoreBind)]
-    tagged_binds = tail (scanl tag (emptyAnalEnv, error "tagged_binds: unused") binds)
-
-    -- This is more complicated than it needs to be, because we must not include
-    -- the binding group itself as interesting. Why not actually?!
-    -- TODO: I'm doing this. Let's see if it works
-    --   I think it's mostly because in the non-rec case, the identifier will
-    --   be referenced. The boringness check relies on them however and in the
-    --   recursive case, the binders are also interesting. Seems like a micro
-    --   optimization.
-    --
-    tag :: (AnalEnv, CoreBind) -> CoreBind -> (AnalEnv, CoreBind)
-    tag (env, _) b = (addInterestingVars (bindersOf b) env, b)
-
-    analyse_bind :: CallArityRes -> (AnalEnv, CoreBind) -> (CallArityRes, CoreBind)
-    analyse_bind ae (env, b) =
-      callArityBind env ae b
-
+    -- think @ReaderT AnalEnv (State CoreProgram CallArityRes)
+    -- actually giving it that type would do no good, because we
+    -- repeatedly have to unwrap the state.
+    go :: AnalEnv -> CoreProgram -> (CallArityRes, CoreProgram)
+    go env [] = (exp_arity_result, [])
+    go env (b:bs) = (res', b':bs')
+      where
+        -- 1. prepare the environment for the body
+        --    TODO: differentiate between thunks and non-thunks
+        --          thunks will not unleash any demand via their sigs,
+        --          but will when the RHS is analyzed, whereas
+        --          lambdas will unleash demands via sigs, but not when
+        --          analyzed.
+        env' = env
+        -- 2. analyse the body, get back a demand on free vars
+        (res, bs') = go env' bs
+        -- 3. analyse the RHS according to that demand
+        --    If the RHS is a thunk, we have to lub with the resulting demand,
+        --    otherwise we don't.
+        --    For now, we have to pass @env'@, because of the interesting var
+        --    mechanism
+        (res', b') = callArityBind env' res b
+
+useLetUp :: CoreExpr -> Bool
+useLetUp = isThunk
+
+isThunk :: CoreExpr -> Bool
+isThunk = not . exprIsHNF
 
 callArityRHS :: CoreExpr -> CoreExpr
-callArityRHS = snd . callArityAnal emptyAnalEnv 0
+callArityRHS = snd . callArityAnal 0 emptyAnalEnv
 
 -- The main analysis function. See Note [Analysis type signature]
 callArityAnal ::
-    AnalEnv -> -- analysis environment
     Arity ->  -- The arity this expression is called with
+    AnalEnv -> -- analysis environment
     CoreExpr ->  -- The expression to analyse
     (CallArityRes, CoreExpr)
         -- How this expression uses its interesting variables
@@ -470,44 +477,44 @@ callArityAnal _     _   e@(Type _)
 callArityAnal _     _   e@(Coercion _)
     = (emptyArityRes, e)
 -- The transparent cases
-callArityAnal env arity (Tick t e)
-    = second (Tick t) $ callArityAnal env arity e
-callArityAnal env arity (Cast e co)
-    = second (\e -> Cast e co) $ callArityAnal env arity e
+callArityAnal arity env (Tick t e)
+    = second (Tick t) $ callArityAnal arity env e
+callArityAnal arity env (Cast e co)
+    = second (\e -> Cast e co) $ callArityAnal arity env e
 
 -- The interesting case: Variables, Lambdas, Lets, Applications, Cases
-callArityAnal env arity e@(Var v)
-    | v `elemVarSet` ae_interesting env
+callArityAnal arity env e@(Var v)
+    | isInteresting v
     = (unitArityRes v arity, e)
     | otherwise
     = (emptyArityRes, e)
 
 -- Non-value lambdas are ignored
-callArityAnal env arity (Lam v e) | not (isId v)
-    = second (Lam v) $ callArityAnal (setUninteresting v env) arity e
+callArityAnal arity env (Lam v e) | not (isId v)
+    = second (Lam v) $ callArityAnal arity env e
 
 -- We have a lambda that may be called multiple times, so its free variables
 -- can all be co-called.
-callArityAnal env 0     (Lam v e)
+callArityAnal 0     env (Lam v e)
     = (ae', Lam v e')
   where
-    (ae, e') = callArityAnal (setUninteresting v env) 0 e
+    (ae, e') = callArityAnal 0 env e
     ae' = calledMultipleTimes ae
 -- We have a lambda that we are calling. decrease arity.
-callArityAnal env arity (Lam v e)
+callArityAnal arity env (Lam v e)
     = (ae, Lam v e')
   where
-    (ae, e') = callArityAnal (setUninteresting v env) (arity - 1) e
+    (ae, e') = callArityAnal (arity - 1) env e
 
 -- Application. Increase arity for the called expression, nothing to know about
 -- the second
-callArityAnal env arity (App e (Type t))
-    = second (\e -> App e (Type t)) $ callArityAnal env arity e
-callArityAnal env arity (App e1 e2)
+callArityAnal arity env (App e (Type t))
+    = second (\e -> App e (Type t)) $ callArityAnal arity env e
+callArityAnal arity env (App e1 e2)
     = (final_ae, App e1' e2')
   where
-    (ae1, e1') = callArityAnal env (arity + 1) e1
-    (ae2, e2') = callArityAnal env 0           e2
+    (ae1, e1') = callArityAnal (arity + 1) env e1
+    (ae2, e2') = callArityAnal 0           env e2
     -- If the argument is trivial (e.g. a variable), then it will _not_ be
     -- let-bound in the Core to STG transformation (CorePrep actually),
     -- so no sharing will happen here, and we have to assume many calls.
@@ -516,26 +523,26 @@ callArityAnal env arity (App e1 e2)
     final_ae = ae1 `both` ae2'
 
 -- Case expression.
-callArityAnal env arity (Case scrut bndr ty alts)
+callArityAnal arity env (Case scrut bndr ty alts)
     = -- pprTrace "callArityAnal:Case"
       --          (vcat [ppr scrut, ppr final_ae])
       (final_ae, Case scrut' bndr ty alts')
   where
     (alt_aes, alts') = unzip $ map go alts
-    go (dc, bndrs, e) = let (ae, e') = callArityAnal env arity e
+    go (dc, bndrs, e) = let (ae, e') = callArityAnal arity env e
                         in  (ae, (dc, bndrs, e'))
     alt_ae = lubRess alt_aes
-    (scrut_ae, scrut') = callArityAnal env 0 scrut
+    (scrut_ae, scrut') = callArityAnal 0 env scrut
     final_ae = scrut_ae `both` alt_ae
 
 -- For lets, use callArityBind
-callArityAnal env arity (Let bind e)
+callArityAnal arity env (Let bind e)
   = -- pprTrace "callArityAnal:Let"
     --          (vcat [ppr v, ppr arity, ppr n, ppr final_ae ])
     (final_ae, Let bind' e')
   where
-    env_body = addInterestingVars (bindersOf bind) env
-    (ae_body, e') = callArityAnal env_body arity e
+    env_body = env
+    (ae_body, e') = callArityAnal arity env_body e
     (final_ae, bind') = callArityBind env_body ae_body bind
 
 -- Which bindings should we look at?
@@ -543,14 +550,6 @@ callArityAnal env arity (Let bind e)
 isInteresting :: Var -> Bool
 isInteresting v = not $ null (typeArity (idType v))
 
-addInterestingVars :: [Var] -> AnalEnv -> AnalEnv
-addInterestingVars vars env
-    = env
-    { ae_interesting = ae_interesting env
-        `delVarSetList` vars -- Possible shadowing
-        `extendVarSetList` filter isInteresting vars
-    }
-
 -- Used for both local and top-level binds
 -- Second argument is the demand from the body
 callArityBind :: AnalEnv -> CallArityRes -> CoreBind -> (CallArityRes, CoreBind)
@@ -558,12 +557,12 @@ callArityBind :: AnalEnv -> CallArityRes -> CoreBind -> (CallArityRes, CoreBind)
 callArityBind env ae_body (NonRec v rhs)
   | otherwise
   = --pprTrace "callArityBind:NonRec"
-    --        (vcat [ppr v, ppr ae_body, ppr (ae_interesting env), ppr ae_rhs, ppr safe_arity])
+    --        (vcat [ppr v, ppr ae_body, ppr ae_rhs, ppr safe_arity])
     (final_ae, NonRec v' rhs')
   where
     is_thunk = not (exprIsCheap rhs) -- see note [What is a thunk]
     -- If v is boring, we will not find it in ae_body, but always assume (0, False)
-    boring = not (elemInteresting v env)
+    boring = not (isInteresting v)
 
     (arity, called_once)
         | boring    = (0, False) -- See Note [Taking boring variables into account]
@@ -580,15 +579,14 @@ callArityBind env ae_body (NonRec v rhs)
       where
         (binders, rhs_body) = collectBinders rhs
         ((cocalled, arities), rhs_body') =
-            callArityAnal (addInterestingVars binders env) (length binders + k) rhs_body
+            callArityAnal (length binders + k) env rhs_body
         ca_sig = CAS cocalled arities binders
-        env' = extendAnalEnv v ca_sig env
 
     -- /Mud
 
     (ae_rhs, rhs') = pprTrace "callArityBind:NonRec:sig"
         (text "id:" <+> ppr v <+> text "sig0:" <+> ppr (mk_sig 0 v rhs) <+> text "sig1:" <+> ppr (mk_sig 1 v rhs)) $
-        callArityAnal env trimmed_arity rhs
+        callArityAnal trimmed_arity env rhs
 
 
     ae_rhs'| called_once     = ae_rhs
@@ -608,7 +606,7 @@ callArityBind env ae_body (NonRec v rhs)
 callArityBind env ae_body b@(Rec binds)
   = --(if True then
     --pprTrace "callArityBind:Rec"
-    --         (vcat [ppr (Rec binds'), ppr ae_body, ppr (ae_interesting env), ppr ae_rhs]) else id) $
+    --         (vcat [ppr (Rec binds'), ppr ae_body, ppr ae_rhs]) else id) $
     pprTrace "callArityBind:Rec:sigs"
              (vcat (map (\(b, sig) -> text "id:" <+> ppr b <+> text "sig:" <+> ppr sig) sigs)) $
     (final_ae, Rec binds')
@@ -621,15 +619,14 @@ callArityBind env ae_body b@(Rec binds)
       where
         (binders, rhs_body) = collectBinders rhs
         ((cocalled, arities), rhs_body') =
-            callArityAnal env_body (length binders + k) rhs_body
+            callArityAnal (length binders + k) env_body rhs_body
         ca_sig = CAS cocalled arities binders
-        env' = extendAnalEnv v ca_sig env
     -- /Mud
 
     -- See Note [Taking boring variables into account]
-    any_boring = any (not . flip elemInteresting env) [ i | (i, _) <- binds]
+    any_boring = any (not . isInteresting) [ i | (i, _) <- binds]
 
-    env_body = addInterestingVars (bindersOf b) env
+    env_body = env
     (ae_rhs, binds') = fix initial_binds
     final_ae = bindersOf b `resDelList` ae_rhs
 
@@ -647,7 +644,7 @@ callArityBind env ae_body b@(Rec binds)
         ae = callArityRecEnv any_boring aes_old ae_body
 
         rerun (i, mbLastRun, rhs)
-            | i `elemInteresting` env_body && not (i `elemUnVarSet` domRes ae)
+            | isInteresting i && not (i `elemUnVarSet` domRes ae)
             -- No call to this yet, so do nothing
             = (False, (i, Nothing, rhs))
 
@@ -667,7 +664,7 @@ callArityBind env ae_body b@(Rec binds)
                   -- See Note [Trimming arity]
                   trimmed_arity = trimArity i safe_arity
 
-                  (ae_rhs, rhs') = callArityAnal env_body trimmed_arity rhs
+                  (ae_rhs, rhs') = callArityAnal trimmed_arity env_body rhs
 
                   ae_rhs' | called_once     = ae_rhs
                           | safe_arity == 0 = ae_rhs -- If it is not a function, its body is evaluated only once
@@ -676,7 +673,7 @@ callArityBind env ae_body b@(Rec binds)
               in (True, (i `setIdCallArity` trimmed_arity, Just (called_once, new_arity, ae_rhs'), rhs'))
           where
             -- See Note [Taking boring variables into account]
-            (new_arity, called_once) | not (elemInteresting i env) = (0, False)
+            (new_arity, called_once) | not (isInteresting i) = (0, False)
                                      | otherwise                   = lookupCallArityRes ae i
 
         (changes, ann_binds') = unzip $ map rerun ann_binds
@@ -738,8 +735,7 @@ type CallArityRes = (UnVarGraph, VarEnv Arity)
 
 data AnalEnv
   = AE
-  { ae_sigs :: VarEnv CallAritySig
-  , ae_interesting :: VarSet
+  { ae_sigs :: VarEnv (Int -> CallAritySig)
   }
 
 data CallAritySig
@@ -756,22 +752,15 @@ instance Outputable CallAritySig where
     <+> text "arities:" <+> ppr arities
 
 emptyAnalEnv :: AnalEnv
-emptyAnalEnv = AE { ae_sigs = emptyVarEnv, ae_interesting = emptyVarSet }
+emptyAnalEnv = AE { ae_sigs = emptyVarEnv }
 
 emptyArityRes :: CallArityRes
 emptyArityRes = (emptyUnVarGraph, emptyVarEnv)
 
-extendAnalEnv :: Id -> CallAritySig -> AnalEnv -> AnalEnv
+extendAnalEnv :: Id -> (Int -> CallAritySig) -> AnalEnv -> AnalEnv
 extendAnalEnv v sig env
   = env { ae_sigs = extendVarEnv (ae_sigs env) v sig }
 
-setUninteresting :: Var -> AnalEnv -> AnalEnv
-setUninteresting v env
-  = env { ae_interesting = delVarSet (ae_interesting env) v }
-
-elemInteresting :: Var -> AnalEnv -> Bool
-elemInteresting v env = elemVarSet v (ae_interesting env)
-
 unitArityRes :: Var -> Arity -> CallArityRes
 unitArityRes v arity = (emptyUnVarGraph, unitVarEnv v arity)
 
@@ -817,10 +806,10 @@ lubRess :: [CallArityRes] -> CallArityRes
 lubRess = foldl lubRes emptyArityRes
 
 memoize :: (Int -> a) -> Int -> Int -> Maybe a
-memoize f min = lookup
+memoize f start = lookup
   where
     cache = [f n | n <- [start..]]
 
     lookup n
-      | n < min = Nothing
-      | otherwise = Just (cache ! n - start)
+      | n < start = Nothing
+      | otherwise = Just (cache !! (n - start))
-- 
2.12.1


From 978688ada0805ffe296f840b8afd7b736110df0b Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 8 Nov 2016 10:24:50 +0100
Subject: [PATCH 007/117] Some intermediate changes

---
 compiler/simplCore/CallArity.hs | 30 +++++++++---------------------
 1 file changed, 9 insertions(+), 21 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index 39a3ab6e72..3e662790c7 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -318,7 +318,7 @@ Note [Taking boring variables into account]
 If we decide that the variable bound in `let x = e1 in e2` is not interesting,
 the analysis of `e2` will not report anything about `x`. To ensure that
 `callArityBind` does still do the right thing we have to take that into account
-everytime we would be lookup up `x` in the analysis result of `e2`.
+everytime we look up up `x` in the analysis result of `e2`.
   * Instead of calling lookupCallArityRes, we return (0, True), indicating
     that this variable might be called many times with no arguments.
   * Instead of checking `calledWith x`, we assume that everything can be called
@@ -560,7 +560,6 @@ callArityBind env ae_body (NonRec v rhs)
     --        (vcat [ppr v, ppr ae_body, ppr ae_rhs, ppr safe_arity])
     (final_ae, NonRec v' rhs')
   where
-    is_thunk = not (exprIsCheap rhs) -- see note [What is a thunk]
     -- If v is boring, we will not find it in ae_body, but always assume (0, False)
     boring = not (isInteresting v)
 
@@ -568,7 +567,7 @@ callArityBind env ae_body (NonRec v rhs)
         | boring    = (0, False) -- See Note [Taking boring variables into account]
         | otherwise = lookupCallArityRes ae_body v
     safe_arity | called_once = arity
-               | is_thunk    = 0      -- A thunk! Do not eta-expand
+               | isThunk rhs = 0      -- A thunk! Do not eta-expand
                | otherwise   = arity
 
     -- See Note [Trimming arity]
@@ -607,22 +606,8 @@ callArityBind env ae_body b@(Rec binds)
   = --(if True then
     --pprTrace "callArityBind:Rec"
     --         (vcat [ppr (Rec binds'), ppr ae_body, ppr ae_rhs]) else id) $
-    pprTrace "callArityBind:Rec:sigs"
-             (vcat (map (\(b, sig) -> text "id:" <+> ppr b <+> text "sig:" <+> ppr sig) sigs)) $
     (final_ae, Rec binds')
   where
-
-    -- Mud
-    sigs = map (uncurry (mk_sig 1)) binds
-
-    mk_sig k v rhs = (v, ca_sig)
-      where
-        (binders, rhs_body) = collectBinders rhs
-        ((cocalled, arities), rhs_body') =
-            callArityAnal (length binders + k) env_body rhs_body
-        ca_sig = CAS cocalled arities binders
-    -- /Mud
-
     -- See Note [Taking boring variables into account]
     any_boring = any (not . isInteresting) [ i | (i, _) <- binds]
 
@@ -630,6 +615,10 @@ callArityBind env ae_body b@(Rec binds)
     (ae_rhs, binds') = fix initial_binds
     final_ae = bindersOf b `resDelList` ae_rhs
 
+    -- The Maybe signifies that the expression was not yet called.
+    -- If it were, we had the called_once information, the call arity and
+    -- the arity result after analysing i.
+    initial_binds :: [(Id, Maybe (Bool, Arity, CallArityRes), CoreExpr)]
     initial_binds = [(i,Nothing,e) | (i,e) <- binds]
 
     fix :: [(Id, Maybe (Bool, Arity, CallArityRes), CoreExpr)] -> (CallArityRes, [(Id, CoreExpr)])
@@ -643,6 +632,7 @@ callArityBind env ae_body b@(Rec binds)
         aes_old = [ (i,ae) | (i, Just (_,_,ae), _) <- ann_binds ]
         ae = callArityRecEnv any_boring aes_old ae_body
 
+        -- iterates a single binding
         rerun (i, mbLastRun, rhs)
             | isInteresting i && not (i `elemUnVarSet` domRes ae)
             -- No call to this yet, so do nothing
@@ -655,10 +645,8 @@ callArityBind env ae_body b@(Rec binds)
             = (False, (i, mbLastRun, rhs))
 
             | otherwise
-            -- We previously analyzed this with a different arity (or not at all)
-            = let is_thunk = not (exprIsCheap rhs) -- see note [What is a thunk]
-
-                  safe_arity | is_thunk    = 0  -- See Note [Thunks in recursive groups]
+            -- We previously analized this with a different arity (or not at all)
+            = let safe_arity | isThunk rhs = 0  -- See Note [Thunks in recursive groups]
                              | otherwise   = new_arity
 
                   -- See Note [Trimming arity]
-- 
2.12.1


From 184080ff23fb3ed1832b07ead1ef5f1f42d2a186 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 17 Nov 2016 18:04:14 +0100
Subject: [PATCH 008/117] Intermediate commit

---
 compiler/simplCore/CallArity.hs | 411 +++++++++++++++++++++++++++-------------
 1 file changed, 276 insertions(+), 135 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index 3e662790c7..f02169e4bf 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -12,6 +12,8 @@ import           VarEnv
 import           VarSet
 
 import           Data.List     (mapAccumL, mapAccumR)
+import           Data.IntMap   (IntMap)
+import qualified Data.IntMap as IntMap
 
 import           BasicTypes
 import           CoreArity     (typeArity)
@@ -22,6 +24,8 @@ import Outputable
 import           Demand
 import           UnVarGraph
 
+import State
+
 import           Control.Arrow (first, second)
 
 
@@ -279,12 +283,12 @@ Note [Analysis type signature]
 The work-hourse of the analysis is the function `callArityAnal`, with the
 following type:
 
-    type CallArityRes = (UnVarGraph, VarEnv Arity)
+    type CallArityType = (UnVarGraph, VarEnv Arity)
     callArityAnal ::
         Arity ->  -- The arity this expression is called with
         VarSet -> -- The set of interesting variables
         CoreExpr ->  -- The expression to analyse
-        (CallArityRes, CoreExpr)
+        (CallArityType, CoreExpr)
 
 and the following specification:
 
@@ -319,7 +323,7 @@ If we decide that the variable bound in `let x = e1 in e2` is not interesting,
 the analysis of `e2` will not report anything about `x`. To ensure that
 `callArityBind` does still do the right thing we have to take that into account
 everytime we look up up `x` in the analysis result of `e2`.
-  * Instead of calling lookupCallArityRes, we return (0, True), indicating
+  * Instead of calling lookupCallArityType, we return (0, True), indicating
     that this variable might be called many times with no arguments.
   * Instead of checking `calledWith x`, we assume that everything can be called
     with it.
@@ -338,7 +342,7 @@ Note [Recursion and fixpointing]
 For a mutually recursive let, we begin by
  1. analysing the body, using the same incoming arity as for the whole expression.
  2. Then we iterate, memoizing for each of the bound variables the last
-    analysis call, i.e. incoming arity, whether it is called once, and the CallArityRes.
+    analysis call, i.e. incoming arity, whether it is called once, and the CallArityType.
  3. We combine the analysis result from the body and the memoized results for
     the arguments (if already present).
  4. For each variable, we find out the incoming arity and whether it is called
@@ -373,7 +377,7 @@ Note [Analysing top-level binds]
 We can eta-expand top-level-binds if they are not exported, as we see all calls
 to them. The plan is as follows: Treat the top-level binds as nested lets around
 a body representing “all external calls”, which returns a pessimistic
-CallArityRes (the co-call graph is the complete graph, all arityies 0).
+CallArityType (the co-call graph is the complete graph, all arityies 0).
 
 Note [Trimming arity]
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
@@ -414,7 +418,7 @@ Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
 
 -- See Note [Analysing top-level-binds]
 callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
-callArityAnalProgram _dflags binds = snd (go emptyAnalEnv binds)
+callArityAnalProgram _dflags binds = snd (evalState emptyAnalEnv (go binds))
   where
     -- Represents the fact that a CoreProgram is like a sequence of
     -- nested lets, where the exports are returned in the inner-most let
@@ -422,34 +426,46 @@ callArityAnalProgram _dflags binds = snd (go emptyAnalEnv binds)
     -- with each other, with arity 0.
     -- Note that we could unify this with @callArityAnal@ by simply transforming
     -- a @CoreProgram@ to said sequence of let-bindings.
-    exp_arity_result :: CallArityRes
-    exp_arity_result = calledMultipleTimes (emptyUnVarGraph, mkVarEnv [(v, 0) | v <- exportedVars])
+    exp_arity_type :: CallArityType
+    exp_arity_type = calledMultipleTimes (CAT emptyUnVarGraph exported_vars_env [])
       where
         -- we could even filter out @v@ that @not (isInteresting v)@
-        exportedVars = binds >>= filter isExportedId . bindersOf
+        exported_vars = binds >>= filter isExportedId . bindersOf
+        exported_vars_env = mkVarEnv [(v, 0) | v <- exported_vars]
 
-    -- think @ReaderT AnalEnv (State CoreProgram CallArityRes)
+    -- think @ReaderT AnalEnv (State CoreProgram CallArityType)
     -- actually giving it that type would do no good, because we
     -- repeatedly have to unwrap the state.
-    go :: AnalEnv -> CoreProgram -> (CallArityRes, CoreProgram)
-    go env [] = (exp_arity_result, [])
-    go env (b:bs) = (res', b':bs')
+    go :: CoreProgram -> State AnalEnv (CallArityType, CoreProgram)
+    go [] = return (exp_arity_type, [])
+    go (b@(NonRec v rhs):bs)
+      = do
+        (ca_type, b', bs') <- callArityBind b (go bs)
+        return (ca_type, b':bs')
+        do
+        -- 1. prepare the environment for the body, adding
+        --    a potential signature for every possible arity.
+        --    Which is computed lazily and memoized.
+        --    For each binding we will *either* do LetUp
+        --    *or* LetDown, depending on whether rhs is a thunk or not.
+        extendAnalEnv v (\arity -> callArityLetDown arity v rhs)
+        -- 1. analyse the body, get back a demand on free vars
+        (ca_type, bs') <- go bs
+        -- 2. analyse the RHS according to that demand with the LetUp rule.
+        --    This will extend the demand with that posed by the body of the
+        --    thunk. It will also annotate the binder with the right arity.
+        (ca_type', v', rhs') <- callArityLetUp ca_type v rhs
+        return (ca_type', (NonRec v' rhs'):bs')
+      | otherwise
+      = (res', b':bs')
       where
-        -- 1. prepare the environment for the body
-        --    TODO: differentiate between thunks and non-thunks
-        --          thunks will not unleash any demand via their sigs,
-        --          but will when the RHS is analyzed, whereas
-        --          lambdas will unleash demands via sigs, but not when
-        --          analyzed.
-        env' = env
-        -- 2. analyse the body, get back a demand on free vars
-        (res, bs') = go env' bs
-        -- 3. analyse the RHS according to that demand
-        --    If the RHS is a thunk, we have to lub with the resulting demand,
-        --    otherwise we don't.
-        --    For now, we have to pass @env'@, because of the interesting var
-        --    mechanism
-        (res', b') = callArityBind env' res b
+        extendEnvWithBindingGroup :: CoreBind -> State AnalEnv ()
+        extendEnvWithBindingGroup (NonRec v rhs) =
+          extendAnalEnv v (\arity -> callArityBind )
+
+callArityBind' :: CoreBind -> (State AnalEnv (CallArityType, a)) -> State AnalEnv (CallArityType, CoreBind, a)
+callArityLetUp :: CallArityType -> Id -> CoreExpr -> State AnalEnv (CallArityType, Id, CoreExpr)
+callArityLetDown :: Arity -> Id -> CoreExpr -> State AnalEnv LetDownResult
 
 useLetUp :: CoreExpr -> Bool
 useLetUp = isThunk
@@ -460,56 +476,55 @@ isThunk = not . exprIsHNF
 callArityRHS :: CoreExpr -> CoreExpr
 callArityRHS = snd . callArityAnal 0 emptyAnalEnv
 
--- The main analysis function. See Note [Analysis type signature]
-callArityAnal ::
-    Arity ->  -- The arity this expression is called with
-    AnalEnv -> -- analysis environment
-    CoreExpr ->  -- The expression to analyse
-    (CallArityRes, CoreExpr)
-        -- How this expression uses its interesting variables
+-- | The main analysis function. See Note [Analysis type signature]
+callArityAnal
+  :: Arity    -- ^ The arity this expression is called with
+  -> CoreExpr -- ^ The expression to analyse
+  -> State AnalEnv (CallArityType, CoreExpr)
+        -- ^ How this expression uses its interesting variables
         -- and the expression with IdInfo updated
 
 -- The trivial base cases
-callArityAnal _     _   e@(Lit _)
-    = (emptyArityRes, e)
-callArityAnal _     _   e@(Type _)
-    = (emptyArityRes, e)
-callArityAnal _     _   e@(Coercion _)
-    = (emptyArityRes, e)
+callArityAnal _     e@(Lit _)
+    = return (emptyArityType, e)
+callArityAnal _     e@(Type _)
+    = return (emptyArityType, e)
+callArityAnal _     e@(Coercion _)
+    = return (emptyArityType, e)
 -- The transparent cases
-callArityAnal arity env (Tick t e)
-    = second (Tick t) $ callArityAnal arity env e
-callArityAnal arity env (Cast e co)
-    = second (\e -> Cast e co) $ callArityAnal arity env e
+callArityAnal arity (Tick t e)
+    = second (Tick t) <$> callArityAnal arity e
+callArityAnal arity (Cast e co)
+    = second (\e -> Cast e co) <$> callArityAnal arity e
 
 -- The interesting case: Variables, Lambdas, Lets, Applications, Cases
-callArityAnal arity env e@(Var v)
+callArityAnal arity e@(Var v)
     | isInteresting v
-    = (unitArityRes v arity, e)
+    = return (unitArityType v arity, e)
     | otherwise
-    = (emptyArityRes, e)
+    = return (emptyArityType, e)
 
 -- Non-value lambdas are ignored
-callArityAnal arity env (Lam v e) | not (isId v)
-    = second (Lam v) $ callArityAnal arity env e
+callArityAnal arity (Lam v e) | not (isId v)
+    = second (Lam v) <$> callArityAnal arity e
 
 -- We have a lambda that may be called multiple times, so its free variables
 -- can all be co-called.
-callArityAnal 0     env (Lam v e)
-    = (ae', Lam v e')
-  where
-    (ae, e') = callArityAnal 0 env e
-    ae' = calledMultipleTimes ae
+callArityAnal 0     (Lam v e)
+    = do
+      (ca_type, e') <- callArityAnal 0 e
+      return (calledMultipleTimes ca_type, Lam v e')
+
 -- We have a lambda that we are calling. decrease arity.
-callArityAnal arity env (Lam v e)
-    = (ae, Lam v e')
-  where
-    (ae, e') = callArityAnal (arity - 1) env e
+callArityAnal arity (Lam v e)
+  = do
+    (ca_type, e') <- callArityAnal (arity - 1) e
+    return (addArgToType v ca_type, e')
 
 -- Application. Increase arity for the called expression, nothing to know about
 -- the second
-callArityAnal arity env (App e (Type t))
-    = second (\e -> App e (Type t)) $ callArityAnal arity env e
+callArityAnal arity (App e (Type t))
+    = second (\e -> App e (Type t)) <$> callArityAnal arity e
 callArityAnal arity env (App e1 e2)
     = (final_ae, App e1' e2')
   where
@@ -523,7 +538,7 @@ callArityAnal arity env (App e1 e2)
     final_ae = ae1 `both` ae2'
 
 -- Case expression.
-callArityAnal arity env (Case scrut bndr ty alts)
+callArityAnal arity (Case scrut bndr ty alts)
     = -- pprTrace "callArityAnal:Case"
       --          (vcat [ppr scrut, ppr final_ae])
       (final_ae, Case scrut' bndr ty alts')
@@ -531,12 +546,12 @@ callArityAnal arity env (Case scrut bndr ty alts)
     (alt_aes, alts') = unzip $ map go alts
     go (dc, bndrs, e) = let (ae, e') = callArityAnal arity env e
                         in  (ae, (dc, bndrs, e'))
-    alt_ae = lubRess alt_aes
+    alt_ae = lubTypes alt_aes
     (scrut_ae, scrut') = callArityAnal 0 env scrut
     final_ae = scrut_ae `both` alt_ae
 
 -- For lets, use callArityBind
-callArityAnal arity env (Let bind e)
+callArityAnal arity (Let bind e)
   = -- pprTrace "callArityAnal:Let"
     --          (vcat [ppr v, ppr arity, ppr n, ppr final_ae ])
     (final_ae, Let bind' e')
@@ -550,9 +565,94 @@ callArityAnal arity env (Let bind e)
 isInteresting :: Var -> Bool
 isInteresting v = not $ null (typeArity (idType v))
 
+callArityBind' :: CoreBind -> (State AnalEnv (CallArityType, a)) -> State AnalEnv (CallArityType, CoreBind, a)
+callArityBind' (NonRec v rhs) anal_body
+  = do
+    -- 1. prepare the environment for the body, adding
+    --    a potential signature for every possible arity.
+    --    Which is computed lazily and memoized.
+    --    For each binding we will *either* do LetUp
+    --    *or* LetDown, depending on whether rhs is a thunk or not.
+    extendAnalEnv v (\arity -> callArityLetDown arity v rhs)
+    -- 2. analyse the body, get back a demand on free vars to be handled with
+    --    LetUp
+    (ca_type, a) <- anal_body
+    -- 3. analyse the RHS according to that demand with the LetUp rule.
+    --    This will extend the demand with that posed by the body of the
+    --    thunk. It will also annotate the binder with the right arity.
+    (ca_type', v', rhs') <- callArityLetUp ca_type v rhs
+    return (ca_type', (NonRec v' rhs'), a)
+
+callArityLetDown :: Arity -> Id -> CoreExpr -> State AnalEnv LetDownResult
+callArityLetDown arity v rhs
+  = do
+    (ca_type, rhs') <- callArityAnal arity rhs
+    let ret = (ca_type, v `setIdCallArity` arity, rhs')
+    -- Remember that we have to save the result (along with all results
+    -- computed in callArityAnal) in the SigCache.
+    cacheSig v arity ret
+    return ret
+
+callArityLetUp :: CallArityType -> Id -> CoreExpr -> State AnalEnv (CallArityType, Id, CoreExpr)
+callArityLetUp ca_body v rhs
+  = do
+    -- If v is boring, we will not find it in ae_body, but always assume (0, False)
+    let boring = not (isInteresting v)
+
+        (arity, called_once)
+            | boring    = (0, False) -- See Note [Taking boring variables into account]
+            | otherwise = lookupCallArityType ca_body v
+
+        safe_arity
+            | isThunk rhs && not called_once = 0 -- A thunk was called multiple times! Do not eta-expand
+            | otherwise = arity -- in the other cases it's safe to expand
+
+        -- See Note [Trimming arity]
+        trimmed_arity = trimArity v safe_arity
+
+    lookupResult <- lookupCachedSig v trimmed_arity >>= alwaysRetrieve
+    case lookupResult of
+        Nothing -> do
+            -- This is to be analyzed now with trimmed_arity.
+            -- trimmed_arity took into account the called_once information
+            -- so it will only expand thunks if they are called once.
+            -- Since rhs should never be a function, we can be sure rhs is
+            -- only evaluated once, regardless of the called_once information.
+            --
+            -- Precondition to this branch: called_once || safe_arity == 0
+            --
+            -- There's one edge case that's unfortunate: Suppose the thunk
+            -- is called with more than zero arguments. Then we can't propagate
+            -- demands to the arguments, since we have no signature available
+            -- for the rhs (rightly so, we must not duplicate the thunk part),
+            -- so we have to be conservative and assume the argument to be called
+            -- with all other free vars.
+            -- TODO: how handle the args in the graph?!
+            (ca_rhs, rhs') <- callArityAnal trimmed_arity rhs
+            -- following is the substitution procedure for any variable
+            -- 1. add cross calls between all vars cocalled with v in rhs to
+            --    all vars cocalled with v in the body, connecting calls
+            --    in the body with calls in the rhs
+            -- 2. lub with the all calls from the body, so that transitive
+            --    calls are made visible
+            let called_by_v = domRes ca_rhs
+            let called_with_v
+                    | boring = domRes ca_body -- See Note [Taking boring variables into account]
+                    -- This will also weed out unreachable calls, in which case
+                    -- called_with_v will be empty.
+                    | otherwise = calledWith ca_body v `delUnVarSet` v
+            let ca_final =
+                    lubType (addCrossCoCalls called_by_v called_with_v ca_rhs) (typeDel v ca_body)
+            return (ca_final, v `setIdCallArity` trimmed_arity, rhs')
+        Just (_, v', rhs') -> do
+            -- Call demands were unleashed while analyzing the body.
+            -- Don't unleash the sig again, just return the annotated binder.
+            return (typeDel v ca_body, v', rhs')
+
+
 -- Used for both local and top-level binds
 -- Second argument is the demand from the body
-callArityBind :: AnalEnv -> CallArityRes -> CoreBind -> (CallArityRes, CoreBind)
+callArityBind :: AnalEnv -> CallArityType -> CoreBind -> (CallArityType, CoreBind)
 -- Non-recursive let
 callArityBind env ae_body (NonRec v rhs)
   | otherwise
@@ -565,7 +665,7 @@ callArityBind env ae_body (NonRec v rhs)
 
     (arity, called_once)
         | boring    = (0, False) -- See Note [Taking boring variables into account]
-        | otherwise = lookupCallArityRes ae_body v
+        | otherwise = lookupCallArityType ae_body v
     safe_arity | called_once = arity
                | isThunk rhs = 0      -- A thunk! Do not eta-expand
                | otherwise   = arity
@@ -573,20 +673,7 @@ callArityBind env ae_body (NonRec v rhs)
     -- See Note [Trimming arity]
     trimmed_arity = trimArity v safe_arity
 
-    -- Mud
-    mk_sig k v rhs = ca_sig
-      where
-        (binders, rhs_body) = collectBinders rhs
-        ((cocalled, arities), rhs_body') =
-            callArityAnal (length binders + k) env rhs_body
-        ca_sig = CAS cocalled arities binders
-
-    -- /Mud
-
-    (ae_rhs, rhs') = pprTrace "callArityBind:NonRec:sig"
-        (text "id:" <+> ppr v <+> text "sig0:" <+> ppr (mk_sig 0 v rhs) <+> text "sig1:" <+> ppr (mk_sig 1 v rhs)) $
-        callArityAnal trimmed_arity env rhs
-
+    (ae_rhs, rhs') = callArityAnal trimmed_arity env rhs
 
     ae_rhs'| called_once     = ae_rhs
            | safe_arity == 0 = ae_rhs -- If it is not a function, its body is evaluated only once
@@ -596,7 +683,7 @@ callArityBind env ae_body (NonRec v rhs)
     called_with_v
         | boring    = domRes ae_body
         | otherwise = calledWith ae_body v `delUnVarSet` v
-    final_ae = addCrossCoCalls called_by_v called_with_v $ ae_rhs' `lubRes` resDel v ae_body
+    final_ae = addCrossCoCalls called_by_v called_with_v $ ae_rhs' `lubType` typeDel v ae_body
 
     v' = v `setIdCallArity` trimmed_arity
 
@@ -613,15 +700,15 @@ callArityBind env ae_body b@(Rec binds)
 
     env_body = env
     (ae_rhs, binds') = fix initial_binds
-    final_ae = bindersOf b `resDelList` ae_rhs
+    final_ae = bindersOf b `typeDelList` ae_rhs
 
     -- The Maybe signifies that the expression was not yet called.
     -- If it were, we had the called_once information, the call arity and
     -- the arity result after analysing i.
-    initial_binds :: [(Id, Maybe (Bool, Arity, CallArityRes), CoreExpr)]
+    initial_binds :: [(Id, Maybe (Bool, Arity, CallArityType), CoreExpr)]
     initial_binds = [(i,Nothing,e) | (i,e) <- binds]
 
-    fix :: [(Id, Maybe (Bool, Arity, CallArityRes), CoreExpr)] -> (CallArityRes, [(Id, CoreExpr)])
+    fix :: [(Id, Maybe (Bool, Arity, CallArityType), CoreExpr)] -> (CallArityType, [(Id, CoreExpr)])
     fix ann_binds
         | -- pprTrace "callArityBind:fix" (vcat [ppr ann_binds, ppr any_change, ppr ae]) $
           any_change
@@ -662,21 +749,21 @@ callArityBind env ae_body b@(Rec binds)
           where
             -- See Note [Taking boring variables into account]
             (new_arity, called_once) | not (isInteresting i) = (0, False)
-                                     | otherwise                   = lookupCallArityRes ae i
+                                     | otherwise                   = lookupCallArityType ae i
 
         (changes, ann_binds') = unzip $ map rerun ann_binds
         any_change = or changes
 
 -- Combining the results from body and rhs, (mutually) recursive case
 -- See Note [Analysis II: The Co-Called analysis]
-callArityRecEnv :: Bool -> [(Var, CallArityRes)] -> CallArityRes -> CallArityRes
+callArityRecEnv :: Bool -> [(Var, CallArityType)] -> CallArityType -> CallArityType
 callArityRecEnv any_boring ae_rhss ae_body
     = -- (if length ae_rhss > 300 then pprTrace "callArityRecEnv" (vcat [ppr ae_rhss, ppr ae_body, ppr ae_new]) else id) $
       ae_new
   where
     vars = map fst ae_rhss
 
-    ae_combined = lubRess (map snd ae_rhss) `lubRes` ae_body
+    ae_combined = lubTypes (map snd ae_rhss) `lubType` ae_body
 
     cross_calls
         -- See Note [Taking boring variables into account]
@@ -691,7 +778,7 @@ callArityRecEnv any_boring ae_rhss ae_body
         -- What rhs are relevant as happening before (or after) calling v?
         --    If v is a thunk, everything from all the _other_ variables
         --    If v is not a thunk, everything can happen.
-        ae_before_v | is_thunk  = lubRess (map snd $ filter ((/= v) . fst) ae_rhss) `lubRes` ae_body
+        ae_before_v | is_thunk  = lubTypes (map snd $ filter ((/= v) . fst) ae_rhss) `lubType` ae_body
                     | otherwise = ae_combined
         -- What do we want to know from these?
         -- Which calls can happen next to any recursive call.
@@ -713,28 +800,44 @@ trimArity v a = minimum [a, max_arity_by_type, max_arity_by_strsig]
     (demands, result_info) = splitStrictSig (idStrictness v)
 
 ---------------------------------------
--- Functions related to CallArityRes --
+-- Functions related to CallArityType --
 ---------------------------------------
 
 -- Result type for the two analyses.
 -- See Note [Analysis I: The arity analyis]
 -- and Note [Analysis II: The Co-Called analysis]
-type CallArityRes = (UnVarGraph, VarEnv Arity)
-
 data AnalEnv
   = AE
-  { ae_sigs :: VarEnv (Int -> CallAritySig)
+  { ae_sigs :: VarEnv SigCache
   }
 
-data CallAritySig
-  = CAS
-  { cas_cocalled :: UnVarGraph
-  , cas_arities :: VarEnv Arity
-  , cas_args :: [Var]
+type LetDownResult = (CallAritySig, Id, CoreExpr)
+
+data SigCache = SigCache !(Arity -> State LetDownResult) !(IntMap LetDownResult)
+
+{-| @Left (ret, cache')@ means that we had a cache miss, so that we had to
+    compute @ret@ by a call to the function wrapped in @SigCache@, thereby
+    updating the cache to @cache'@.
+
+    @Right ret@ means that we hit a cached value @ret@ without the need to
+    execute the wrapped function.
+-}
+data CacheLookupResult
+  = NotFound
+  | CacheHit LetDownResult
+  | CacheMiss (State AnalEnv LetDownResult)
+
+-- TODO: Separate Sig and Type like in DmdAnal
+type CallAritySig = CallArityType
+data CallArityType
+  = CAT
+  { cat_cocalled :: UnVarGraph
+  , cat_arities :: VarEnv Arity
+  , cat_args :: [Var]
   }
 
-instance Outputable CallAritySig where
-  ppr (CAS cocalled arities args) =
+instance Outputable CallArityType where
+  ppr (CAT cocalled arities args) =
     text "args:" <+> ppr args
     <+> text "co-calls:" <+> ppr cocalled
     <+> text "arities:" <+> ppr arities
@@ -742,62 +845,100 @@ instance Outputable CallAritySig where
 emptyAnalEnv :: AnalEnv
 emptyAnalEnv = AE { ae_sigs = emptyVarEnv }
 
-emptyArityRes :: CallArityRes
-emptyArityRes = (emptyUnVarGraph, emptyVarEnv)
+emptyArityType :: CallArityType
+emptyArityType = CAT emptyUnVarGraph emptyVarEnv []
+
+overSigs :: (VarEnv SigCache -> VarEnv SigCache) -> AnalEnv -> AnalEnv
+overSigs modifier env = AE { ae_sigs = modifier (ae_sigs env) }
+
+extendAnalEnv :: Id -> (Arity -> State AnalEnv ()) -> State AnalEnv ()
+extendAnalEnv id sig
+  = modify . overSigs $ \sigs -> extendVarEnv sigs v (SigCache f IntMap.empty)
+
+lookupCachedSig :: Id -> Arity -> State AnalEnv CacheLookupResult
+lookupCachedSig id arity = do
+  sigs <- gets ae_sigs
+  case lookupVarEnv sigs id of
+    Nothing -> return NotFound
+    Just (SigCache f cache) -> do
+      maybe_sig <- IntMap.lookup arity cache
+      case maybe_sig of
+        Just sig -> return (CacheHit sig)
+        Nothing -> return (CacheMiss retrieve)
+      where
+        retrieve :: State AnalEnv CallAritySig
+        retrieve = do
+          f arity -- f is obliged to at least save the sig for @id@
+          caches <- gets ae_sigs
+          maybe
+            (error "lookupSigCache: f didn't save the sig like it ought to")
+            return $ do
+              -- we should still find the cache in the env
+              SigCache _ cache <- lookupVarEnv caches id
+              -- also the signature for the appropriate arity should have been cached
+              IntMap.lookup n cache
+
+alwaysRetrieve :: CacheLookupResult -> State AnalEnv (Maybe LetDownResult)
+alwaysRetrieve NotFound = return Nothing
+alwaysRetrieve (CacheHit sig) = return (Just sig)
+alwaysRetrieve (CacheMiss retrieve) = fmap Just retrieve
+
+cacheSig :: Id -> Arity -> LetDownResult -> State AnalEnv ()
+cacheSig id arity res = modify . overSigs $ \sigs -> modifyVarEnv modifier sigs id
+  where
+    modifier (SigCache f cache) =
+      SigCache f (IntMap.insert arity res cache)
 
-extendAnalEnv :: Id -> (Int -> CallAritySig) -> AnalEnv -> AnalEnv
-extendAnalEnv v sig env
-  = env { ae_sigs = extendVarEnv (ae_sigs env) v sig }
+unitArityType :: Var -> Arity -> CallArityType
+unitArityType v arity = CAT emptyUnVarGraph (unitVarEnv v arity) []
 
-unitArityRes :: Var -> Arity -> CallArityRes
-unitArityRes v arity = (emptyUnVarGraph, unitVarEnv v arity)
+typeDelList :: [Var] -> CallArityType -> CallArityType
+typeDelList vs ae = foldr typeDel ae vs
 
-resDelList :: [Var] -> CallArityRes -> CallArityRes
-resDelList vs ae = foldr resDel ae vs
+-- TODO: args handling
+typeDel :: Var -> CallArityType -> CallArityType
+typeDel v (CAT g ae args) = CAT (g `delNode` v) (ae `delVarEnv` v) (args \\ v)
 
-resDel :: Var -> CallArityRes -> CallArityRes
-resDel v (g, ae) = (g `delNode` v, ae `delVarEnv` v)
+domType :: CallArityType -> UnVarSet
+domType ca_type = varEnvDom (cat_arities ca_type)
 
-domRes :: CallArityRes -> UnVarSet
-domRes (_, ae) = varEnvDom ae
+addArgToType :: Id -> CallArityType -> CallArityType
+addArgToType id ca_type = ca_type { cat_args = id : cat_args ca_type }
 
 -- In the result, find out the minimum arity and whether the variable is called
 -- at most once.
-lookupCallArityRes :: CallArityRes -> Var -> (Arity, Bool)
-lookupCallArityRes (g, ae) v
+lookupCallArityType :: CallArityType -> Var -> (Arity, Bool)
+lookupCallArityType (CAT g ae _) v
     = case lookupVarEnv ae v of
         Just a -> (a, not (v `elemUnVarSet` (neighbors g v)))
         Nothing -> (0, False)
 
-calledWith :: CallArityRes -> Var -> UnVarSet
-calledWith (g, _) v = neighbors g v
+calledWith :: CallArityType -> Var -> UnVarSet
+calledWith ca_type v = neighbors (cat_cocalled ca_type) v
+
+modifyCoCalls :: (UnVarGraph -> UnVarGraph) -> CallArityType -> CallArityType
+modifyCoCalls modifier ca_type
+  = ca_type { cat_cocalls = modifier (cat_cocalls ca_type) }
 
-addCrossCoCalls :: UnVarSet -> UnVarSet -> CallArityRes -> CallArityRes
-addCrossCoCalls set1 set2 = first (completeBipartiteGraph set1 set2 `unionUnVarGraph`)
+addCrossCoCalls :: UnVarSet -> UnVarSet -> CallArityType -> CallArityType
+addCrossCoCalls set1 set2
+  = modifyCoCalls (completeBipartiteGraph set1 set2 `unionUnVarGraph`)
 
 -- Replaces the co-call graph by a complete graph (i.e. no information)
-calledMultipleTimes :: CallArityRes -> CallArityRes
-calledMultipleTimes res = first (const (completeGraph (domRes res))) res
+calledMultipleTimes :: CallArityType -> CallArityType
+calledMultipleTimes res = modifyCoCalls (const (completeGraph (domRes res))) res
 
 -- Used for application and cases
-both :: CallArityRes -> CallArityRes -> CallArityRes
-both r1 r2 = addCrossCoCalls (domRes r1) (domRes r2) $ r1 `lubRes` r2
+both :: CallArityType -> CallArityType -> CallArityType
+both r1 r2 = addCrossCoCalls (domRes r1) (domRes r2) (r1 `lubType` r2)
 
 -- Used when combining results from alternative cases; take the minimum
-lubRes :: CallArityRes -> CallArityRes -> CallArityRes
-lubRes (g1, ae1) (g2, ae2) = (g1 `unionUnVarGraph` g2, ae1 `lubArityEnv` ae2)
+lubType :: CallArityType -> CallArityType -> CallArityType
+lubType (CAT g1 ae1 args) (CAT g2 ae2 _) -- both args should really be the same
+  = CAT (g1 `unionUnVarGraph` g2) (ae1 `lubArityEnv` ae2) args
 
 lubArityEnv :: VarEnv Arity -> VarEnv Arity -> VarEnv Arity
 lubArityEnv = plusVarEnv_C min
 
-lubRess :: [CallArityRes] -> CallArityRes
-lubRess = foldl lubRes emptyArityRes
-
-memoize :: (Int -> a) -> Int -> Int -> Maybe a
-memoize f start = lookup
-  where
-    cache = [f n | n <- [start..]]
-
-    lookup n
-      | n < start = Nothing
-      | otherwise = Just (cache !! (n - start))
+lubTypes :: [CallArityType] -> CallArityType
+lubTypes = foldl lubType emptyArityType
-- 
2.12.1


From 58c137e3998fd49878575933c2de5e9f61146835 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sat, 3 Dec 2016 10:09:38 +0100
Subject: [PATCH 009/117] Intermediate commit

---
 compiler/simplCore/CallArity.hs | 76 ++++++++++++++++++++++-------------------
 1 file changed, 41 insertions(+), 35 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index f02169e4bf..7ad953b766 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -442,26 +442,6 @@ callArityAnalProgram _dflags binds = snd (evalState emptyAnalEnv (go binds))
       = do
         (ca_type, b', bs') <- callArityBind b (go bs)
         return (ca_type, b':bs')
-        do
-        -- 1. prepare the environment for the body, adding
-        --    a potential signature for every possible arity.
-        --    Which is computed lazily and memoized.
-        --    For each binding we will *either* do LetUp
-        --    *or* LetDown, depending on whether rhs is a thunk or not.
-        extendAnalEnv v (\arity -> callArityLetDown arity v rhs)
-        -- 1. analyse the body, get back a demand on free vars
-        (ca_type, bs') <- go bs
-        -- 2. analyse the RHS according to that demand with the LetUp rule.
-        --    This will extend the demand with that posed by the body of the
-        --    thunk. It will also annotate the binder with the right arity.
-        (ca_type', v', rhs') <- callArityLetUp ca_type v rhs
-        return (ca_type', (NonRec v' rhs'):bs')
-      | otherwise
-      = (res', b':bs')
-      where
-        extendEnvWithBindingGroup :: CoreBind -> State AnalEnv ()
-        extendEnvWithBindingGroup (NonRec v rhs) =
-          extendAnalEnv v (\arity -> callArityBind )
 
 callArityBind' :: CoreBind -> (State AnalEnv (CallArityType, a)) -> State AnalEnv (CallArityType, CoreBind, a)
 callArityLetUp :: CallArityType -> Id -> CoreExpr -> State AnalEnv (CallArityType, Id, CoreExpr)
@@ -519,23 +499,24 @@ callArityAnal 0     (Lam v e)
 callArityAnal arity (Lam v e)
   = do
     (ca_type, e') <- callArityAnal (arity - 1) e
+    -- regardless of the variable not being interesting,
+    -- we have to add the var as an argument.
     return (addArgToType v ca_type, e')
 
 -- Application. Increase arity for the called expression, nothing to know about
 -- the second
-callArityAnal arity (App e (Type t))
-    = second (\e -> App e (Type t)) <$> callArityAnal arity e
-callArityAnal arity env (App e1 e2)
-    = (final_ae, App e1' e2')
-  where
-    (ae1, e1') = callArityAnal (arity + 1) env e1
-    (ae2, e2') = callArityAnal 0           env e2
-    -- If the argument is trivial (e.g. a variable), then it will _not_ be
-    -- let-bound in the Core to STG transformation (CorePrep actually),
-    -- so no sharing will happen here, and we have to assume many calls.
-    ae2' | exprIsTrivial e2 = calledMultipleTimes ae2
-         | otherwise        = ae2
-    final_ae = ae1 `both` ae2'
+callArityAnal arity (App f (Type t))
+    = second (\f -> App f (Type t)) <$> callArityAnal arity e
+callArityAnal arity (App f a)
+    = do
+      (ca_f, f') <- callArityAnal (arity + 1) f
+      -- peel off one argument from the type
+      let (arg_arity, called_once, ca_f') = peelCallArityType ca_f
+      -- TODO: Actually use called with information instead of just called_once
+      (ca_a, a') <- callArityAnal arg_arity a
+      let ca_a' | called_once = ca_a
+                | otherwise   = calledMultipleTimes ca_a
+      return (ca_f' `both` ca_a', a')
 
 -- Case expression.
 callArityAnal arity (Case scrut bndr ty alts)
@@ -560,12 +541,32 @@ callArityAnal arity (Let bind e)
     (ae_body, e') = callArityAnal arity env_body e
     (final_ae, bind') = callArityBind env_body ae_body bind
 
+-- TODO: add the set of neighbors
+peelCallArityType :: CallArityType -> (Arity, Bool, CallArityType)
+peelCallArityType ca_type = case cat_args ca_type of
+  arg:args | isInteresting arg ->
+    -- TODO: not (exprIsTrivial a)?
+    let (arity, called_once) = lookupCallArityType ca_type arg
+        ca_type' = typeDel arg ca_type
+    in  (arity, called_once, ca_type')
+  arg:args -> (0, False, ca_type) -- See Note [Taking boring variables into account]
+  [] -> (0, not (exprIsTrivial a), ca_type)
+    -- the called function had no signature or has not
+    -- been analysed with high enough incoming arity
+    -- (e.g. when loading the signature from an imported id).
+    -- ca_f is rather useless for analysing a, so
+    -- be consersative assume incoming arity 0.
+    --
+    -- Also, if the argument is trivial (e.g. a variable), then it will _not_ be
+    -- let-bound in the Core to STG transformation (CorePrep actually),
+    -- so no sharing will happen here, and we have to assume many calls.
+
 -- Which bindings should we look at?
 -- See Note [Which variables are interesting]
 isInteresting :: Var -> Bool
 isInteresting v = not $ null (typeArity (idType v))
 
-callArityBind' :: CoreBind -> (State AnalEnv (CallArityType, a)) -> State AnalEnv (CallArityType, CoreBind, a)
+callArityBind' :: CoreBind -> State AnalEnv (CallArityType, a) -> State AnalEnv (CallArityType, CoreBind, a)
 callArityBind' (NonRec v rhs) anal_body
   = do
     -- 1. prepare the environment for the body, adding
@@ -581,7 +582,9 @@ callArityBind' (NonRec v rhs) anal_body
     --    This will extend the demand with that posed by the body of the
     --    thunk. It will also annotate the binder with the right arity.
     (ca_type', v', rhs') <- callArityLetUp ca_type v rhs
-    return (ca_type', (NonRec v' rhs'), a)
+    return (ca_type', NonRec v' rhs', a)
+callArityBind' (Rec pairs) anal_body
+  = do
 
 callArityLetDown :: Arity -> Id -> CoreExpr -> State AnalEnv LetDownResult
 callArityLetDown arity v rhs
@@ -942,3 +945,6 @@ lubArityEnv = plusVarEnv_C min
 
 lubTypes :: [CallArityType] -> CallArityType
 lubTypes = foldl lubType emptyArityType
+
+predecessors :: VarEnv (IntMap (VarEnv IntSet))
+predecessors = emptyVarEnv
-- 
2.12.1


From e5f60db3849fc6c1c5cb97dd5a0abcf218f90368 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Wed, 28 Dec 2016 01:08:03 +0100
Subject: [PATCH 010/117] Refactored stuff to use a Worklist, but it doesn't
 build yet.

---
 compiler/simplCore/CallArity.hs | 739 ++++++++++++++++++----------------------
 compiler/utils/Worklist.hs      | 161 +++++++++
 2 files changed, 497 insertions(+), 403 deletions(-)
 create mode 100644 compiler/utils/Worklist.hs

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index 7ad953b766..f1d0d77285 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -1,3 +1,4 @@
+{-# LANGUAGE GeneralizedNewtypeDeriving #-}
 --
 -- Copyright (c) 2014 Joachim Breitner
 --
@@ -9,24 +10,32 @@ module CallArity
 
 import           DynFlags      (DynFlags)
 import           VarEnv
-import           VarSet
 
-import           Data.List     (mapAccumL, mapAccumR)
-import           Data.IntMap   (IntMap)
-import qualified Data.IntMap as IntMap
+import Control.Monad.Fix
+import Data.Monoid
+import           Data.List     (delete)
+import           Data.IntMap.Lazy (IntMap)
+import qualified Data.IntMap.Lazy as IntMap
+import           Data.Map.Strict   (Map)
+import qualified Data.Map.Strict as Map
+import Data.Maybe
+import qualified Data.Set as Set
 
 import           BasicTypes
 import           CoreArity     (typeArity)
 import           CoreSyn
 import           CoreUtils     (exprIsHNF, exprIsTrivial)
+import           MkCore
 import           Id
-import Outputable
+import Outputable hiding ((<>))
 import           Demand
 import           UnVarGraph
+import Worklist
+import Util
 
-import State
+import Control.Monad.Trans.State.Strict
 
-import           Control.Arrow (first, second)
+import           Control.Arrow (first)
 
 
 {-
@@ -414,142 +423,289 @@ oughtweigh the cost of doing that repeatedly. Therefore, this implementation of
 Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
 -}
 
--- Main entry point
 
 -- See Note [Analysing top-level-binds]
-callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
-callArityAnalProgram _dflags binds = snd (evalState emptyAnalEnv (go binds))
+-- Represents the fact that a CoreProgram is like a sequence of
+-- nested lets, where the exports are returned in the inner-most let
+-- as a tuple. As a result, all exported identifiers are handled as called
+-- with each other, with arity 0.
+moduleToExpr :: CoreProgram -> CoreExpr
+moduleToExpr = impl []
   where
-    -- Represents the fact that a CoreProgram is like a sequence of
-    -- nested lets, where the exports are returned in the inner-most let
-    -- as a tuple. As a result, all exported identifiers are handled as called
-    -- with each other, with arity 0.
-    -- Note that we could unify this with @callArityAnal@ by simply transforming
-    -- a @CoreProgram@ to said sequence of let-bindings.
-    exp_arity_type :: CallArityType
-    exp_arity_type = calledMultipleTimes (CAT emptyUnVarGraph exported_vars_env [])
-      where
-        -- we could even filter out @v@ that @not (isInteresting v)@
-        exported_vars = binds >>= filter isExportedId . bindersOf
-        exported_vars_env = mkVarEnv [(v, 0) | v <- exported_vars]
-
-    -- think @ReaderT AnalEnv (State CoreProgram CallArityType)
-    -- actually giving it that type would do no good, because we
-    -- repeatedly have to unwrap the state.
-    go :: CoreProgram -> State AnalEnv (CallArityType, CoreProgram)
-    go [] = return (exp_arity_type, [])
-    go (b@(NonRec v rhs):bs)
-      = do
-        (ca_type, b', bs') <- callArityBind b (go bs)
-        return (ca_type, b':bs')
-
-callArityBind' :: CoreBind -> (State AnalEnv (CallArityType, a)) -> State AnalEnv (CallArityType, CoreBind, a)
-callArityLetUp :: CallArityType -> Id -> CoreExpr -> State AnalEnv (CallArityType, Id, CoreExpr)
-callArityLetDown :: Arity -> Id -> CoreExpr -> State AnalEnv LetDownResult
-
-useLetUp :: CoreExpr -> Bool
-useLetUp = isThunk
+    impl exported [] = mkBigCoreTup (map Var exported)
+    impl exported (bind:prog) = Let bind (impl (filter isExportedId (bindersOf bind) ++ exported) prog)
 
-isThunk :: CoreExpr -> Bool
-isThunk = not . exprIsHNF
+exprToModule :: CoreExpr -> CoreProgram
+exprToModule (Let bind e) = bind : exprToModule e
+exprToModule _ = []
+
+-- Main entry point
+callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
+callArityAnalProgram _dflags = exprToModule . callArityRHS . moduleToExpr
 
 callArityRHS :: CoreExpr -> CoreExpr
-callArityRHS = snd . callArityAnal 0 emptyAnalEnv
+callArityRHS e = lookup_expr (runFramework fw (Set.singleton (node, 0)))
+  where
+    (node, fw) = buildFramework $
+      registerTransferFunction $ \node -> do
+        transfer <- callArityExpr emptyVarEnv e
+        return (node, (transfer, alwaysChangeDetector))
+
+    lookup_expr :: Map (FrameworkNode, Arity) AnalResult -> CoreExpr
+    lookup_expr result_map = case Map.lookup (node, 0) result_map of
+      Nothing -> pprPanic "callArityRHS" empty
+      Just (AR _ annotations) -> annotate annotations e
+
+newtype Annotations
+  = Annotations (VarEnv Arity)
+  deriving (Eq, Outputable)
+
+mkAnnotation :: Id -> Arity -> Annotations
+mkAnnotation id arity = Annotations (unitVarEnv id arity)
+
+lookupAnnotatedArity :: Annotations -> Id -> Arity
+lookupAnnotatedArity (Annotations ann) id = fromMaybe (idCallArity id) (lookupVarEnv ann id)
+
+instance Monoid Annotations where
+  mempty = Annotations mempty
+  mappend (Annotations a) (Annotations b)
+    = Annotations (plusVarEnv_C panicOnConflict a b)
+    where
+      panicOnConflict n m
+        | n == m    = n
+        | otherwise = pprPanic "CallArity.Annotations.mappend conflict" empty
+
+-- | How an expression uses its interesting variables
+-- and the arity annotations for local bindings
+data AnalResult = AR !CallArityType !Annotations
+
+unzipAnalResult :: [AnalResult] -> ([CallArityType], Annotations)
+unzipAnalResult ar = (map cat ar, foldMap ann ar)
+  where
+    cat (AR cat _) = cat
+    ann (AR _ ann) = ann
+
+newtype FrameworkNode
+  = FrameworkNode Int
+  deriving (Show, Eq, Ord)
+
+type TransferFunction' a = TransferFunction (FrameworkNode, Arity) AnalResult a
+type ChangeDetector' = ChangeDetector (FrameworkNode, Arity) AnalResult
+type DataFlowFramework' = DataFlowFramework (FrameworkNode, Arity) AnalResult
+
+newtype FrameworkBuilder a
+  = FB { unFB :: State (IntMap (Arity -> TransferFunction' AnalResult, ChangeDetector')) a }
+  deriving (Functor, Applicative, Monad)
+
+data LetAnalKind
+  = LetDown
+  | LetUp
+  deriving (Show, Eq, Ord)
+
+isLetUp :: LetAnalKind -> Bool
+isLetUp LetUp = True
+isLetUp LetDown = False
+
+buildFramework :: FrameworkBuilder a -> (a, DataFlowFramework')
+buildFramework (FB state) = (res, DFF dff)
+  where
+    (res, env) = runState state IntMap.empty
+    dff (FrameworkNode node, arity) = case IntMap.lookup node env of
+      Nothing -> pprPanic "CallArity.buildFramework" (ppr node)
+      Just (transfer, detectChange) -> (transfer arity, detectChange)
+
+registerTransferFunction
+  :: (FrameworkNode -> FrameworkBuilder (a, (Arity -> TransferFunction' AnalResult, ChangeDetector')))
+  -> FrameworkBuilder a
+registerTransferFunction f = FB $ do
+  node <- gets IntMap.size
+  (result, _) <- mfix $ \ ~(_, entry) -> do
+    -- Using mfix so that we can spare an unnecessary Int counter in the state
+    modify' (IntMap.insert node entry)
+    unFB (f (FrameworkNode node))
+  return result
+
+dependOn' :: FrameworkNode -> Arity -> TransferFunction' AnalResult
+dependOn' node arity = fromMaybe emptyAnalResult <$> dependOn (node, arity)
+
+callArityBind :: VarEnv LetAnalKind -> CoreBind -> FrameworkBuilder (VarEnv FrameworkNode)
+callArityBind let_anal_kinds = build_binds emptyVarEnv . flattenBinds . singleton
+  where
+    build_binds env [] = return env
+    build_binds env ((id, rhs):binds) = registerTransferFunction $ \node -> do
+      env' <- build_binds (extendVarEnv env id node) binds
+      transfer <- callArityExpr let_anal_kinds rhs
+      let transfer' arity = do
+            -- TODO: trim arity
+            AR cat_rhs ann_rhs <- transfer arity
+            return (AR cat_rhs (mkAnnotation id arity <> ann_rhs))
+      return (env', (transfer', alwaysChangeDetector))
 
 -- | The main analysis function. See Note [Analysis type signature]
-callArityAnal
-  :: Arity    -- ^ The arity this expression is called with
-  -> CoreExpr -- ^ The expression to analyse
-  -> State AnalEnv (CallArityType, CoreExpr)
-        -- ^ How this expression uses its interesting variables
-        -- and the expression with IdInfo updated
+callArityExpr
+  :: VarEnv LetAnalKind
+  -> CoreExpr
+  -> FrameworkBuilder (Arity -> TransferFunction' AnalResult)
+
+callArityExprTrivial
+  :: FrameworkBuilder (Arity -> TransferFunction' AnalResult)
+callArityExprTrivial = return (\_ -> return emptyAnalResult)
 
 -- The trivial base cases
-callArityAnal _     e@(Lit _)
-    = return (emptyArityType, e)
-callArityAnal _     e@(Type _)
-    = return (emptyArityType, e)
-callArityAnal _     e@(Coercion _)
-    = return (emptyArityType, e)
+callArityExpr _ (Lit _) = callArityExprTrivial
+callArityExpr _ (Type _) = callArityExprTrivial
+callArityExpr _ (Coercion _) = callArityExprTrivial
+
 -- The transparent cases
-callArityAnal arity (Tick t e)
-    = second (Tick t) <$> callArityAnal arity e
-callArityAnal arity (Cast e co)
-    = second (\e -> Cast e co) <$> callArityAnal arity e
-
--- The interesting case: Variables, Lambdas, Lets, Applications, Cases
-callArityAnal arity e@(Var v)
-    | isInteresting v
-    = return (unitArityType v arity, e)
-    | otherwise
-    = return (emptyArityType, e)
+callArityExpr let_anal_kinds (Tick _ e) = callArityExpr let_anal_kinds e
+callArityExpr let_anal_kinds (Cast e _) = callArityExpr let_anal_kinds e
+
+-- The interesting cases: Variables, Lambdas, Lets, Applications, Cases
+callArityExpr let_anal_kinds (Var v) = return transfer
+  where
+    transfer = case lookupVarEnv let_anal_kinds v of
+      Nothing | not (isInteresting v) -> \_ -> return emptyAnalResult -- v is boring
+      Nothing -> \_ -> return emptyAnalResult -- TODO: use an exported sig here
+      Just LetUp -> \arity -> return (AR (unitArityType v arity) mempty) -- the demand is unleashed later
+      Just LetDown -> \arity ->
+        -- unleash cat directly
+        dependOn' undefined arity
 
 -- Non-value lambdas are ignored
-callArityAnal arity (Lam v e) | not (isId v)
-    = second (Lam v) <$> callArityAnal arity e
-
--- We have a lambda that may be called multiple times, so its free variables
--- can all be co-called.
-callArityAnal 0     (Lam v e)
-    = do
-      (ca_type, e') <- callArityAnal 0 e
-      return (calledMultipleTimes ca_type, Lam v e')
-
--- We have a lambda that we are calling. decrease arity.
-callArityAnal arity (Lam v e)
-  = do
-    (ca_type, e') <- callArityAnal (arity - 1) e
-    -- regardless of the variable not being interesting,
+callArityExpr let_anal_kinds (Lam v e)
+    | not (isId v)
+    = callArityExpr let_anal_kinds e
+
+callArityExpr let_anal_kinds (Lam v e) = transfer' <$> callArityExpr let_anal_kinds e
+  where
+    -- We have a lambda that may be called multiple times, so its free variables
+    -- can all be co-called.
+    -- Also regardless of the variable not being interesting,
     -- we have to add the var as an argument.
-    return (addArgToType v ca_type, e')
+    transfer' transfer 0 = do
+      AR cat ann <- transfer 0
+      return (AR (addArgToType v (calledMultipleTimes cat)) ann)
+    -- We have a lambda that we are calling. decrease arity.
+    transfer' transfer arity = do
+      AR cat ann <- transfer (arity - 1)
+      return (AR (addArgToType v cat) ann)
+
+callArityExpr let_anal_kinds (App f (Type _)) = callArityExpr let_anal_kinds f
 
 -- Application. Increase arity for the called expression, nothing to know about
 -- the second
-callArityAnal arity (App f (Type t))
-    = second (\f -> App f (Type t)) <$> callArityAnal arity e
-callArityAnal arity (App f a)
-    = do
-      (ca_f, f') <- callArityAnal (arity + 1) f
-      -- peel off one argument from the type
-      let (arg_arity, called_once, ca_f') = peelCallArityType ca_f
-      -- TODO: Actually use called with information instead of just called_once
-      (ca_a, a') <- callArityAnal arg_arity a
-      let ca_a' | called_once = ca_a
-                | otherwise   = calledMultipleTimes ca_a
-      return (ca_f' `both` ca_a', a')
+callArityExpr let_anal_kinds (App f a) = do
+  transfer_f <- callArityExpr let_anal_kinds f
+  transfer_a <- callArityExpr let_anal_kinds a
+  return $ \arity -> do
+    AR ca_f ann_f <- transfer_f (arity + 1)
+    -- peel off one argument from the type
+    let (arg_arity, called_once, ca_f') = peelCallArityType a ca_f
+    -- TODO: Actually use called with information instead of just called_once
+    --       Maybe this is enough for higher-order signature information?
+    AR ca_a ann_a <- transfer_a arg_arity
+    let ca_a' | called_once    = ca_a
+              | arg_arity == 0 = ca_a
+              | otherwise      = calledMultipleTimes ca_a
+    return (AR (ca_f' `both` ca_a') (ann_f <> ann_a))
 
 -- Case expression.
-callArityAnal arity (Case scrut bndr ty alts)
-    = -- pprTrace "callArityAnal:Case"
-      --          (vcat [ppr scrut, ppr final_ae])
-      (final_ae, Case scrut' bndr ty alts')
-  where
-    (alt_aes, alts') = unzip $ map go alts
-    go (dc, bndrs, e) = let (ae, e') = callArityAnal arity env e
-                        in  (ae, (dc, bndrs, e'))
-    alt_ae = lubTypes alt_aes
-    (scrut_ae, scrut') = callArityAnal 0 env scrut
-    final_ae = scrut_ae `both` alt_ae
-
--- For lets, use callArityBind
-callArityAnal arity (Let bind e)
-  = -- pprTrace "callArityAnal:Let"
-    --          (vcat [ppr v, ppr arity, ppr n, ppr final_ae ])
-    (final_ae, Let bind' e')
-  where
-    env_body = env
-    (ae_body, e') = callArityAnal arity env_body e
-    (final_ae, bind') = callArityBind env_body ae_body bind
+callArityExpr let_anal_kinds (Case scrut bndr ty alts) = do
+  transfer_scrut <- callArityExpr let_anal_kinds scrut
+    -- TODO: Do we have to do something special with bndr?
+  transfer_alts <- mapM (\(dc, bndrs, e) -> callArityExpr let_anal_kinds e) alts
+  return $ \arity -> do
+    AR cat_scrut ann_scrut <- transfer_scrut 0
+    (cat_alts, ann_alts) <- unzipAnalResult <$> mapM ($ arity) transfer_alts
+    let cat = cat_scrut `both` lubTypes cat_alts
+    -- pprTrace "callArityExpr:Case"
+    --          (vcat [ppr scrut, ppr cat])
+    return (AR cat (ann_scrut <> ann_alts))
+
+callArityExpr let_anal_kinds (Let bind e) = do
+  let add_let_kind (id, rhs) env
+        | isInteresting id = extendVarEnv env id (determineLetAnalKind rhs)
+        | otherwise = env
+  let binds = flattenBinds [bind]
+  let let_anal_kinds' = foldr add_let_kind let_anal_kinds binds
+
+  nodes <- callArityBind let_anal_kinds' bind
+  transfer_body <- callArityExpr let_anal_kinds' e
+
+  node <- registerTransferFunction $ \node -> do
+    let transfer arity = do
+          ar_body@(AR cat_body ann_body) <- transfer_body arity
+          case bind of
+            -- TODO: handle LetDown. Probably just return emptyArityType in unleashCalls?
+            NonRec id rhs -> do
+              -- We don't need to use cat_old here, because only the let body can
+              -- call id.
+              AR cat ann_bind <- unleashCalls nodes False cat_body (id, rhs)
+              let cat_final = callArityLetEnv (not (isInteresting id)) ann_body [(id, cat)] cat_body
+              return (AR cat_final (ann_body <> ann_bind))
+            Rec pairs -> do
+              AR cat_old ann_old <- fromMaybe ar_body <$> dependOn (node, arity)
+              (cat_rhss, ann_rhss) <- unzipAnalResult <$> mapM (unleashCalls nodes True cat_old) pairs
+              let ids = map fst pairs
+              let any_boring = any (not . isInteresting) ids
+              let cat_final = callArityLetEnv any_boring ann_old (zip ids cat_rhss) cat_body
+              return (AR cat_final (ann_body <> ann_rhss))
+
+    let changeDetector changedRefs (AR old _) (AR new _) =
+          map fst (Set.toList changedRefs) /= [node]
+          || any (\id -> lookupCallArityType old id /= lookupCallArityType new id) (map fst binds)
+
+    return (node, (transfer, changeDetector))
+
+  return $ \arity -> do
+    AR cat ann <- dependOn' node arity
+    return (AR (typeDelList (bindersOf bind) cat) ann)
+
+
+unleashCalls :: VarEnv FrameworkNode -> Bool -> CallArityType -> (Id, CoreExpr) -> TransferFunction' AnalResult
+unleashCalls nodes is_recursive cat_usage (id, rhs) = do
+  let boring = not (isInteresting id)
+      -- If v is boring, we will not find it in cat_usage, but always assume (0, False)
+      (arity, called_once)
+          | boring    = (0, False) -- See Note [Taking boring variables into account]
+          | otherwise = lookupCallArityType cat_usage id
+
+      -- See Note [Thunks in recursive groups]
+      safe_arity
+          | isThunk rhs && (is_recursive || not called_once) = 0 -- A thunk was called multiple times! Do not eta-expand
+          | otherwise = arity -- in the other cases it's safe to expand
+
+      -- See Note [Trimming arity]
+      trimmed_arity = trimArity id safe_arity
+
+      node = fromMaybe (pprPanic "CallArity.unleashCalls" (ppr id)) (lookupVarEnv nodes id)
+
+  -- TODO: Find out if (where) we need the trimmed_arity here or not
+  -- We probably want to analyze with arity und annotate trimmed_arity.
+  -- Although CA analyzes with trimmed_arity, so we do that for now
+  AR cat_rhs ann_rhs <- dependOn' node trimmed_arity
+  let cat_rhs' | called_once || safe_arity == 0 = cat_rhs
+               | otherwise = calledMultipleTimes cat_rhs
+  return (AR cat_rhs' (mkAnnotation id trimmed_arity <> ann_rhs) )
+
+determineLetAnalKind :: CoreExpr -> LetAnalKind
+determineLetAnalKind rhs
+  | isThunk rhs || True = LetUp
+  | otherwise = LetDown
+
+isThunk :: CoreExpr -> Bool
+isThunk = not . exprIsHNF
 
 -- TODO: add the set of neighbors
-peelCallArityType :: CallArityType -> (Arity, Bool, CallArityType)
-peelCallArityType ca_type = case cat_args ca_type of
-  arg:args | isInteresting arg ->
+peelCallArityType :: CoreExpr -> CallArityType -> (Arity, Bool, CallArityType)
+peelCallArityType a ca_type = case cat_args ca_type of
+  arg:_ | isInteresting arg ->
     -- TODO: not (exprIsTrivial a)?
+    -- TODO: called_once when arity = 0?
     let (arity, called_once) = lookupCallArityType ca_type arg
         ca_type' = typeDel arg ca_type
     in  (arity, called_once, ca_type')
-  arg:args -> (0, False, ca_type) -- See Note [Taking boring variables into account]
+  _:_ -> (0, False, ca_type) -- See Note [Taking boring variables into account]
   [] -> (0, not (exprIsTrivial a), ca_type)
     -- the called function had no signature or has not
     -- been analysed with high enough incoming arity
@@ -566,230 +722,55 @@ peelCallArityType ca_type = case cat_args ca_type of
 isInteresting :: Var -> Bool
 isInteresting v = not $ null (typeArity (idType v))
 
-callArityBind' :: CoreBind -> State AnalEnv (CallArityType, a) -> State AnalEnv (CallArityType, CoreBind, a)
-callArityBind' (NonRec v rhs) anal_body
-  = do
-    -- 1. prepare the environment for the body, adding
-    --    a potential signature for every possible arity.
-    --    Which is computed lazily and memoized.
-    --    For each binding we will *either* do LetUp
-    --    *or* LetDown, depending on whether rhs is a thunk or not.
-    extendAnalEnv v (\arity -> callArityLetDown arity v rhs)
-    -- 2. analyse the body, get back a demand on free vars to be handled with
-    --    LetUp
-    (ca_type, a) <- anal_body
-    -- 3. analyse the RHS according to that demand with the LetUp rule.
-    --    This will extend the demand with that posed by the body of the
-    --    thunk. It will also annotate the binder with the right arity.
-    (ca_type', v', rhs') <- callArityLetUp ca_type v rhs
-    return (ca_type', NonRec v' rhs', a)
-callArityBind' (Rec pairs) anal_body
-  = do
-
-callArityLetDown :: Arity -> Id -> CoreExpr -> State AnalEnv LetDownResult
-callArityLetDown arity v rhs
-  = do
-    (ca_type, rhs') <- callArityAnal arity rhs
-    let ret = (ca_type, v `setIdCallArity` arity, rhs')
-    -- Remember that we have to save the result (along with all results
-    -- computed in callArityAnal) in the SigCache.
-    cacheSig v arity ret
-    return ret
-
-callArityLetUp :: CallArityType -> Id -> CoreExpr -> State AnalEnv (CallArityType, Id, CoreExpr)
-callArityLetUp ca_body v rhs
-  = do
-    -- If v is boring, we will not find it in ae_body, but always assume (0, False)
-    let boring = not (isInteresting v)
-
-        (arity, called_once)
-            | boring    = (0, False) -- See Note [Taking boring variables into account]
-            | otherwise = lookupCallArityType ca_body v
-
-        safe_arity
-            | isThunk rhs && not called_once = 0 -- A thunk was called multiple times! Do not eta-expand
-            | otherwise = arity -- in the other cases it's safe to expand
-
-        -- See Note [Trimming arity]
-        trimmed_arity = trimArity v safe_arity
-
-    lookupResult <- lookupCachedSig v trimmed_arity >>= alwaysRetrieve
-    case lookupResult of
-        Nothing -> do
-            -- This is to be analyzed now with trimmed_arity.
-            -- trimmed_arity took into account the called_once information
-            -- so it will only expand thunks if they are called once.
-            -- Since rhs should never be a function, we can be sure rhs is
-            -- only evaluated once, regardless of the called_once information.
-            --
-            -- Precondition to this branch: called_once || safe_arity == 0
-            --
-            -- There's one edge case that's unfortunate: Suppose the thunk
-            -- is called with more than zero arguments. Then we can't propagate
-            -- demands to the arguments, since we have no signature available
-            -- for the rhs (rightly so, we must not duplicate the thunk part),
-            -- so we have to be conservative and assume the argument to be called
-            -- with all other free vars.
-            -- TODO: how handle the args in the graph?!
-            (ca_rhs, rhs') <- callArityAnal trimmed_arity rhs
-            -- following is the substitution procedure for any variable
-            -- 1. add cross calls between all vars cocalled with v in rhs to
-            --    all vars cocalled with v in the body, connecting calls
-            --    in the body with calls in the rhs
-            -- 2. lub with the all calls from the body, so that transitive
-            --    calls are made visible
-            let called_by_v = domRes ca_rhs
-            let called_with_v
-                    | boring = domRes ca_body -- See Note [Taking boring variables into account]
-                    -- This will also weed out unreachable calls, in which case
-                    -- called_with_v will be empty.
-                    | otherwise = calledWith ca_body v `delUnVarSet` v
-            let ca_final =
-                    lubType (addCrossCoCalls called_by_v called_with_v ca_rhs) (typeDel v ca_body)
-            return (ca_final, v `setIdCallArity` trimmed_arity, rhs')
-        Just (_, v', rhs') -> do
-            -- Call demands were unleashed while analyzing the body.
-            -- Don't unleash the sig again, just return the annotated binder.
-            return (typeDel v ca_body, v', rhs')
-
-
--- Used for both local and top-level binds
--- Second argument is the demand from the body
-callArityBind :: AnalEnv -> CallArityType -> CoreBind -> (CallArityType, CoreBind)
--- Non-recursive let
-callArityBind env ae_body (NonRec v rhs)
-  | otherwise
-  = --pprTrace "callArityBind:NonRec"
-    --        (vcat [ppr v, ppr ae_body, ppr ae_rhs, ppr safe_arity])
-    (final_ae, NonRec v' rhs')
-  where
-    -- If v is boring, we will not find it in ae_body, but always assume (0, False)
-    boring = not (isInteresting v)
-
-    (arity, called_once)
-        | boring    = (0, False) -- See Note [Taking boring variables into account]
-        | otherwise = lookupCallArityType ae_body v
-    safe_arity | called_once = arity
-               | isThunk rhs = 0      -- A thunk! Do not eta-expand
-               | otherwise   = arity
-
-    -- See Note [Trimming arity]
-    trimmed_arity = trimArity v safe_arity
-
-    (ae_rhs, rhs') = callArityAnal trimmed_arity env rhs
-
-    ae_rhs'| called_once     = ae_rhs
-           | safe_arity == 0 = ae_rhs -- If it is not a function, its body is evaluated only once
-           | otherwise       = calledMultipleTimes ae_rhs
-
-    called_by_v = domRes ae_rhs'
-    called_with_v
-        | boring    = domRes ae_body
-        | otherwise = calledWith ae_body v `delUnVarSet` v
-    final_ae = addCrossCoCalls called_by_v called_with_v $ ae_rhs' `lubType` typeDel v ae_body
-
-    v' = v `setIdCallArity` trimmed_arity
-
-
--- Recursive let. See Note [Recursion and fixpointing]
-callArityBind env ae_body b@(Rec binds)
-  = --(if True then
-    --pprTrace "callArityBind:Rec"
-    --         (vcat [ppr (Rec binds'), ppr ae_body, ppr ae_rhs]) else id) $
-    (final_ae, Rec binds')
-  where
-    -- See Note [Taking boring variables into account]
-    any_boring = any (not . isInteresting) [ i | (i, _) <- binds]
-
-    env_body = env
-    (ae_rhs, binds') = fix initial_binds
-    final_ae = bindersOf b `typeDelList` ae_rhs
-
-    -- The Maybe signifies that the expression was not yet called.
-    -- If it were, we had the called_once information, the call arity and
-    -- the arity result after analysing i.
-    initial_binds :: [(Id, Maybe (Bool, Arity, CallArityType), CoreExpr)]
-    initial_binds = [(i,Nothing,e) | (i,e) <- binds]
-
-    fix :: [(Id, Maybe (Bool, Arity, CallArityType), CoreExpr)] -> (CallArityType, [(Id, CoreExpr)])
-    fix ann_binds
-        | -- pprTrace "callArityBind:fix" (vcat [ppr ann_binds, ppr any_change, ppr ae]) $
-          any_change
-        = fix ann_binds'
-        | otherwise
-        = (ae, map (\(i, _, e) -> (i, e)) ann_binds')
-      where
-        aes_old = [ (i,ae) | (i, Just (_,_,ae), _) <- ann_binds ]
-        ae = callArityRecEnv any_boring aes_old ae_body
-
-        -- iterates a single binding
-        rerun (i, mbLastRun, rhs)
-            | isInteresting i && not (i `elemUnVarSet` domRes ae)
-            -- No call to this yet, so do nothing
-            = (False, (i, Nothing, rhs))
-
-            | Just (old_called_once, old_arity, _) <- mbLastRun
-            , called_once == old_called_once
-            , new_arity == old_arity
-            -- No change, no need to re-analyze
-            = (False, (i, mbLastRun, rhs))
-
-            | otherwise
-            -- We previously analized this with a different arity (or not at all)
-            = let safe_arity | isThunk rhs = 0  -- See Note [Thunks in recursive groups]
-                             | otherwise   = new_arity
-
-                  -- See Note [Trimming arity]
-                  trimmed_arity = trimArity i safe_arity
-
-                  (ae_rhs, rhs') = callArityAnal trimmed_arity env_body rhs
-
-                  ae_rhs' | called_once     = ae_rhs
-                          | safe_arity == 0 = ae_rhs -- If it is not a function, its body is evaluated only once
-                          | otherwise       = calledMultipleTimes ae_rhs
-
-              in (True, (i `setIdCallArity` trimmed_arity, Just (called_once, new_arity, ae_rhs'), rhs'))
-          where
-            -- See Note [Taking boring variables into account]
-            (new_arity, called_once) | not (isInteresting i) = (0, False)
-                                     | otherwise                   = lookupCallArityType ae i
-
-        (changes, ann_binds') = unzip $ map rerun ann_binds
-        any_change = or changes
-
--- Combining the results from body and rhs, (mutually) recursive case
+-- Combining the results from body and rhs of a let binding
 -- See Note [Analysis II: The Co-Called analysis]
-callArityRecEnv :: Bool -> [(Var, CallArityType)] -> CallArityType -> CallArityType
-callArityRecEnv any_boring ae_rhss ae_body
-    = -- (if length ae_rhss > 300 then pprTrace "callArityRecEnv" (vcat [ppr ae_rhss, ppr ae_body, ppr ae_new]) else id) $
-      ae_new
+callArityLetEnv
+  :: Bool
+  -> Annotations
+  -> [(Var, CallArityType)]
+  -> CallArityType
+  -> CallArityType
+callArityLetEnv any_boring ann_old cat_rhss cat_body
+    = -- (if length ae_rhss > 300 then pprTrace "callArityLetEnv" (vcat [ppr ae_rhss, ppr ae_body, ppr ae_new]) else id) $
+      cat_new
   where
-    vars = map fst ae_rhss
+    vars = map fst cat_rhss
 
-    ae_combined = lubTypes (map snd ae_rhss) `lubType` ae_body
+    -- This is already the complete type, but with references from the current
+    -- binding group not resolved.
+    -- For the non-recursive case, at least cat_body may refer to some bound var
+    -- which we have to handle, for the recursive case even any of cat_rhss may.
+    -- This is why we have to union in appropriate cross_calls, which basically
+    -- perform substitution of Id to CallArityType.
+    cat_combined = lubTypes (map snd cat_rhss) `lubType` cat_body
 
     cross_calls
         -- See Note [Taking boring variables into account]
-        | any_boring          = completeGraph (domRes ae_combined)
+        | any_boring          = completeGraph (domType cat_combined)
         -- Also, calculating cross_calls is expensive. Simply be conservative
         -- if the mutually recursive group becomes too large.
-        | length ae_rhss > 25 = completeGraph (domRes ae_combined)
-        | otherwise           = unionUnVarGraphs $ map cross_call ae_rhss
-    cross_call (v, ae_rhs) = completeBipartiteGraph called_by_v called_with_v
+        | length cat_rhss > 25 = completeGraph (domType cat_combined)
+        | otherwise           = unionUnVarGraphs $ map cross_call cat_rhss
+    cross_call (v, cat_rhs) = completeBipartiteGraph called_by_v called_with_v
       where
-        is_thunk = idCallArity v == 0
+        is_thunk = lookupAnnotatedArity ann_old v == 0
+        -- We only add self cross calls if we really can recurse into ourselves.
+        -- This is not the case for thunks (and non-recursive bindings, but
+        -- then there won't be any mention of v in the rhs).
+        -- A thunk is not evaluated more than once, so the only
+        -- relevant calls are from other bindings or the body.
         -- What rhs are relevant as happening before (or after) calling v?
-        --    If v is a thunk, everything from all the _other_ variables
-        --    If v is not a thunk, everything can happen.
-        ae_before_v | is_thunk  = lubTypes (map snd $ filter ((/= v) . fst) ae_rhss) `lubType` ae_body
-                    | otherwise = ae_combined
+        --    If v doesn't recurse into itself, everything from all the _other_ variables
+        --    If v is self-recursive, everything can happen.
+        cat_before_v
+            | is_thunk  = lubTypes (map snd $ filter ((/= v) . fst) cat_rhss) `lubType` cat_body
+            | otherwise = cat_combined
         -- What do we want to know from these?
         -- Which calls can happen next to any recursive call.
-        called_with_v
-            = unionUnVarSets $ map (calledWith ae_before_v) vars
-        called_by_v = domRes ae_rhs
+        called_with_v = unionUnVarSets $ map (calledWith cat_before_v) vars
+        called_by_v = domType cat_rhs
 
-    ae_new = first (cross_calls `unionUnVarGraph`) ae_combined
+    cat_new = modifyCoCalls (cross_calls `unionUnVarGraph`) cat_combined
 
 -- See Note [Trimming arity]
 trimArity :: Id -> Arity -> Arity
@@ -802,6 +783,24 @@ trimArity v a = minimum [a, max_arity_by_type, max_arity_by_strsig]
 
     (demands, result_info) = splitStrictSig (idStrictness v)
 
+annotate :: Annotations -> CoreExpr -> CoreExpr
+annotate _ e@(Lit _) = e
+annotate _ e@(Type _) = e
+annotate _ e@(Coercion _) = e
+annotate _ e@(Var _) = e
+annotate ann (Tick t e) = Tick t (annotate ann e)
+annotate ann (Cast e co) = Cast (annotate ann e) co
+annotate ann (Lam v e) = Lam v (annotate ann e)
+annotate ann (App f a) = App (annotate ann f) (annotate ann a)
+annotate ann (Let (NonRec id rhs) e) = Let (NonRec (annotateId ann id) rhs) e
+annotate ann (Let (Rec pairs) e) = Let (Rec (map (first (annotateId ann)) pairs)) e
+annotate ann (Case scrut bndr ty alts) = Case (annotate ann scrut) bndr ty (map annotate_alt alts)
+  where
+    annotate_alt (dc, bndrs, e) = (dc, bndrs, annotate ann e)
+
+annotateId :: Annotations -> Id -> Id
+annotateId ann id = id `setIdCallArity` lookupAnnotatedArity ann id
+
 ---------------------------------------
 -- Functions related to CallArityType --
 ---------------------------------------
@@ -809,29 +808,6 @@ trimArity v a = minimum [a, max_arity_by_type, max_arity_by_strsig]
 -- Result type for the two analyses.
 -- See Note [Analysis I: The arity analyis]
 -- and Note [Analysis II: The Co-Called analysis]
-data AnalEnv
-  = AE
-  { ae_sigs :: VarEnv SigCache
-  }
-
-type LetDownResult = (CallAritySig, Id, CoreExpr)
-
-data SigCache = SigCache !(Arity -> State LetDownResult) !(IntMap LetDownResult)
-
-{-| @Left (ret, cache')@ means that we had a cache miss, so that we had to
-    compute @ret@ by a call to the function wrapped in @SigCache@, thereby
-    updating the cache to @cache'@.
-
-    @Right ret@ means that we hit a cached value @ret@ without the need to
-    execute the wrapped function.
--}
-data CacheLookupResult
-  = NotFound
-  | CacheHit LetDownResult
-  | CacheMiss (State AnalEnv LetDownResult)
-
--- TODO: Separate Sig and Type like in DmdAnal
-type CallAritySig = CallArityType
 data CallArityType
   = CAT
   { cat_cocalled :: UnVarGraph
@@ -845,52 +821,11 @@ instance Outputable CallArityType where
     <+> text "co-calls:" <+> ppr cocalled
     <+> text "arities:" <+> ppr arities
 
-emptyAnalEnv :: AnalEnv
-emptyAnalEnv = AE { ae_sigs = emptyVarEnv }
-
 emptyArityType :: CallArityType
 emptyArityType = CAT emptyUnVarGraph emptyVarEnv []
 
-overSigs :: (VarEnv SigCache -> VarEnv SigCache) -> AnalEnv -> AnalEnv
-overSigs modifier env = AE { ae_sigs = modifier (ae_sigs env) }
-
-extendAnalEnv :: Id -> (Arity -> State AnalEnv ()) -> State AnalEnv ()
-extendAnalEnv id sig
-  = modify . overSigs $ \sigs -> extendVarEnv sigs v (SigCache f IntMap.empty)
-
-lookupCachedSig :: Id -> Arity -> State AnalEnv CacheLookupResult
-lookupCachedSig id arity = do
-  sigs <- gets ae_sigs
-  case lookupVarEnv sigs id of
-    Nothing -> return NotFound
-    Just (SigCache f cache) -> do
-      maybe_sig <- IntMap.lookup arity cache
-      case maybe_sig of
-        Just sig -> return (CacheHit sig)
-        Nothing -> return (CacheMiss retrieve)
-      where
-        retrieve :: State AnalEnv CallAritySig
-        retrieve = do
-          f arity -- f is obliged to at least save the sig for @id@
-          caches <- gets ae_sigs
-          maybe
-            (error "lookupSigCache: f didn't save the sig like it ought to")
-            return $ do
-              -- we should still find the cache in the env
-              SigCache _ cache <- lookupVarEnv caches id
-              -- also the signature for the appropriate arity should have been cached
-              IntMap.lookup n cache
-
-alwaysRetrieve :: CacheLookupResult -> State AnalEnv (Maybe LetDownResult)
-alwaysRetrieve NotFound = return Nothing
-alwaysRetrieve (CacheHit sig) = return (Just sig)
-alwaysRetrieve (CacheMiss retrieve) = fmap Just retrieve
-
-cacheSig :: Id -> Arity -> LetDownResult -> State AnalEnv ()
-cacheSig id arity res = modify . overSigs $ \sigs -> modifyVarEnv modifier sigs id
-  where
-    modifier (SigCache f cache) =
-      SigCache f (IntMap.insert arity res cache)
+emptyAnalResult :: AnalResult
+emptyAnalResult = AR emptyArityType mempty
 
 unitArityType :: Var -> Arity -> CallArityType
 unitArityType v arity = CAT emptyUnVarGraph (unitVarEnv v arity) []
@@ -899,8 +834,9 @@ typeDelList :: [Var] -> CallArityType -> CallArityType
 typeDelList vs ae = foldr typeDel ae vs
 
 -- TODO: args handling
+-- TODO: What about transitive co-call relationships over v?
 typeDel :: Var -> CallArityType -> CallArityType
-typeDel v (CAT g ae args) = CAT (g `delNode` v) (ae `delVarEnv` v) (args \\ v)
+typeDel v (CAT g ae args) = CAT (g `delNode` v) (ae `delVarEnv` v) (delete v args)
 
 domType :: CallArityType -> UnVarSet
 domType ca_type = varEnvDom (cat_arities ca_type)
@@ -913,7 +849,7 @@ addArgToType id ca_type = ca_type { cat_args = id : cat_args ca_type }
 lookupCallArityType :: CallArityType -> Var -> (Arity, Bool)
 lookupCallArityType (CAT g ae _) v
     = case lookupVarEnv ae v of
-        Just a -> (a, not (v `elemUnVarSet` (neighbors g v)))
+        Just a -> (a, not (v `elemUnVarSet` neighbors g v))
         Nothing -> (0, False)
 
 calledWith :: CallArityType -> Var -> UnVarSet
@@ -921,7 +857,7 @@ calledWith ca_type v = neighbors (cat_cocalled ca_type) v
 
 modifyCoCalls :: (UnVarGraph -> UnVarGraph) -> CallArityType -> CallArityType
 modifyCoCalls modifier ca_type
-  = ca_type { cat_cocalls = modifier (cat_cocalls ca_type) }
+  = ca_type { cat_cocalled = modifier (cat_cocalled ca_type) }
 
 addCrossCoCalls :: UnVarSet -> UnVarSet -> CallArityType -> CallArityType
 addCrossCoCalls set1 set2
@@ -929,11 +865,11 @@ addCrossCoCalls set1 set2
 
 -- Replaces the co-call graph by a complete graph (i.e. no information)
 calledMultipleTimes :: CallArityType -> CallArityType
-calledMultipleTimes res = modifyCoCalls (const (completeGraph (domRes res))) res
+calledMultipleTimes res = modifyCoCalls (const (completeGraph (domType res))) res
 
 -- Used for application and cases
 both :: CallArityType -> CallArityType -> CallArityType
-both r1 r2 = addCrossCoCalls (domRes r1) (domRes r2) (r1 `lubType` r2)
+both r1 r2 = addCrossCoCalls (domType r1) (domType r2) (r1 `lubType` r2)
 
 -- Used when combining results from alternative cases; take the minimum
 lubType :: CallArityType -> CallArityType -> CallArityType
@@ -945,6 +881,3 @@ lubArityEnv = plusVarEnv_C min
 
 lubTypes :: [CallArityType] -> CallArityType
 lubTypes = foldl lubType emptyArityType
-
-predecessors :: VarEnv (IntMap (VarEnv IntSet))
-predecessors = emptyVarEnv
diff --git a/compiler/utils/Worklist.hs b/compiler/utils/Worklist.hs
new file mode 100644
index 0000000000..b2c6c90fb8
--- /dev/null
+++ b/compiler/utils/Worklist.hs
@@ -0,0 +1,161 @@
+{-# LANGUAGE ScopedTypeVariables #-}
+{-# LANGUAGE GeneralizedNewtypeDeriving #-}
+{-# OPTIONS_GHC -funbox-strict-fields #-}
+module Worklist where
+
+import Control.Monad.Trans.State.Strict
+import Data.Map.Strict (Map)
+import qualified Data.Map.Strict as Map
+import Data.Set (Set)
+import qualified Data.Set as Set
+import Data.Maybe (fromMaybe)
+import Control.Monad (forM_)
+
+newtype TransferFunction node lattice a
+  = TFM (State (WorklistState node lattice) a)
+  deriving (Functor, Applicative, Monad)
+
+type ChangeDetector node lattice
+  = Set node -> lattice -> lattice -> Bool
+
+newtype DataFlowFramework node lattice
+  = DFF { getTransfer :: node -> (TransferFunction node lattice lattice, ChangeDetector node lattice) }
+
+eqChangeDetector :: Eq lattice => ChangeDetector node lattice
+eqChangeDetector _ = (/=)
+
+alwaysChangeDetector :: ChangeDetector node lattice
+alwaysChangeDetector _ _ _ = True
+
+frameworkWithEqChangeDetector
+  :: Eq lattice
+  => (node -> TransferFunction node lattice lattice)
+  -> DataFlowFramework node lattice
+frameworkWithEqChangeDetector transfer = DFF transfer'
+  where
+    transfer' node = (transfer node, eqChangeDetector)
+
+data NodeInfo node lattice
+  = NodeInfo
+  { value :: !(Maybe lattice) -- ^ the value at this node. can be Nothing only when a loop was detected
+  , references :: !(Set node) -- ^  nodes this value depends on
+  , referrers :: !(Set node) -- ^ nodes depending on this value
+  } deriving (Show, Eq)
+
+emptyNodeInfo :: NodeInfo node lattice
+emptyNodeInfo = NodeInfo Nothing Set.empty Set.empty
+
+type Graph node lattice = Map node (NodeInfo node lattice)
+
+data WorklistState node lattice
+  = WorklistState
+  { graph :: !(Graph node lattice)
+  , callStack :: !(Set node)
+  , referencedNodes :: !(Set node)
+  , framework :: !(DataFlowFramework node lattice)
+  }
+
+zoomGraph :: State (Graph node lattice) a -> State (WorklistState node lattice) a
+zoomGraph modifyGraph = state $ \st ->
+  let (res, g) = runState modifyGraph (graph st)
+  in  (res, st { graph = g })
+
+zoomReferencedNodes :: State (Set node) a -> State (WorklistState node lattice) a
+zoomReferencedNodes modifier = state $ \st ->
+  let (res, an) = runState modifier (referencedNodes st)
+  in  (res, st { referencedNodes = an })
+
+initialWorklistState :: DataFlowFramework node lattice -> WorklistState node lattice
+initialWorklistState = WorklistState Map.empty Set.empty Set.empty
+
+dependOn :: Ord node => node -> TransferFunction node lattice (Maybe lattice)
+dependOn node = TFM $ do
+  loopDetected <- Set.member node <$> gets callStack
+  maybeNodeInfo <- Map.lookup node <$> gets graph
+  zoomReferencedNodes (modify' (Set.insert node)) -- save that we depend on this value
+  case maybeNodeInfo of
+    Nothing | loopDetected -> return Nothing
+    Nothing -> fmap (\(val, _, _) -> Just val) (recompute node)
+    Just info -> return (value info)
+
+data Diff a
+  = Diff
+  { added :: !(Set a)
+  , removed :: !(Set a)
+  }
+
+computeDiff :: Ord a => Set a -> Set a -> Diff a
+computeDiff from to = Diff (to `Set.difference` from) (from `Set.difference` to)
+
+updateGraphNode
+  :: Ord node
+  => node
+  -> lattice
+  -> Set node
+  -> State (WorklistState node lattice) (NodeInfo node lattice)
+updateGraphNode node val refs = zoomGraph $ do
+  -- if we are lucky (e.g. no refs changed), we get away with one map access
+  -- first update `node`s NodeInfo
+  let newInfo = emptyNodeInfo { value = Just val, references = refs }
+  let merger _ new old = new { referrers = referrers old }
+  oldInfo <- fromMaybe emptyNodeInfo <$> state (Map.insertLookupWithKey merger node newInfo)
+
+  -- Now compute the diff of changed references
+  let diff = computeDiff (references oldInfo) refs
+
+  -- finally register/unregister at all references as referrer.
+  let updater f dep = modify' (Map.alter (Just . f . fromMaybe emptyNodeInfo) dep)
+  let addReferrer ni = ni { referrers = Set.insert node (referrers ni) }
+  let removeReferrer ni = ni { referrers = Set.delete node (referrers ni) }
+  forM_ (added diff) (updater addReferrer)
+  forM_ (removed diff) (updater removeReferrer)
+
+  return oldInfo
+
+recompute
+  :: Ord node
+  => node
+  -> State (WorklistState node lattice) (lattice, NodeInfo node lattice, ChangeDetector node lattice)
+recompute node = do
+  oldState <- get
+  put $ oldState
+    { referencedNodes = Set.empty
+    , callStack = Set.insert node (callStack oldState)
+    }
+  let (TFM transfer, changeDetector) = getTransfer (framework oldState) node
+  res <- transfer
+  refs <- gets referencedNodes
+  oldInfo <- updateGraphNode node res refs
+  modify' $ \st -> st
+    { referencedNodes = referencedNodes oldState
+    , callStack = callStack oldState
+    }
+  return (res, oldInfo, changeDetector)
+
+enqueue :: Ord node => node -> Set node -> Map node (Set node) -> Map node (Set node)
+enqueue reference referrers_ = Map.unionWith Set.union referrersMap
+  where
+    referrersMap = Map.fromSet (\_ -> Set.singleton reference) referrers_
+
+dequeue :: Map node (Set node) -> Maybe ((node, Set node), Map node (Set node))
+dequeue = Map.maxViewWithKey
+
+work :: Ord node => Map node (Set node) -> State (WorklistState node lattice) ()
+work nodes =
+  case dequeue nodes of
+    Nothing -> return ()
+    Just ((node, changedRefs), nodes') -> do
+      (newVal, oldInfo, detectChange) <- recompute node
+      case value oldInfo of
+        Just oldVal | not (detectChange changedRefs oldVal newVal) -> work nodes'
+        _ -> work (enqueue node (referrers oldInfo) nodes')
+
+runFramework
+  :: Ord node
+  => DataFlowFramework node lattice
+  -> Set node
+  -> Map node lattice
+runFramework framework_ interestingNodes = run framework_
+  where
+    st = work (Map.fromSet (const Set.empty) interestingNodes)
+    run = Map.mapMaybe value . graph . execState st . initialWorklistState
-- 
2.12.1


From 30f2db76e8bcfc8a11ede159b1f3fa0743eeb61b Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Wed, 28 Dec 2016 09:34:32 +0100
Subject: [PATCH 011/117] Fixed the build, but the test suite still fails

---
 compiler/ghc.cabal.in | 1 +
 1 file changed, 1 insertion(+)

diff --git a/compiler/ghc.cabal.in b/compiler/ghc.cabal.in
index 2c837fda7f..4849c56443 100644
--- a/compiler/ghc.cabal.in
+++ b/compiler/ghc.cabal.in
@@ -539,6 +539,7 @@ Library
         Vectorise.Env
         Vectorise.Exp
         Vectorise
+        Worklist
         Hoopl.Dataflow
         Hoopl
 --        CgInfoTbls used in ghci/DebuggerUtils
-- 
2.12.1


From 3ec7bcfb3f8ea797de396728037be011cbd8d401 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 29 Dec 2016 20:53:29 +0100
Subject: [PATCH 012/117] Mostly works after this big refactoring. LocalId's
 realUnique isn't unique though

---
 compiler/simplCore/CallArity.hs                    | 233 +++++++++++----------
 compiler/utils/Worklist.hs                         |  44 +++-
 testsuite/tests/callarity/unittest/CallArity1.hs   |   7 +-
 .../tests/callarity/unittest/CallArity1.stderr     |   4 +-
 4 files changed, 160 insertions(+), 128 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index f1d0d77285..8649da7ef5 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -8,34 +8,34 @@ module CallArity
     , callArityRHS -- for testing
     ) where
 
-import           DynFlags      (DynFlags)
-import           VarEnv
+import DynFlags      (DynFlags)
+import VarEnv
 
-import Control.Monad.Fix
 import Data.Monoid
-import           Data.List     (delete)
-import           Data.IntMap.Lazy (IntMap)
+import Data.List     (delete)
+import Data.IntMap.Lazy (IntMap)
 import qualified Data.IntMap.Lazy as IntMap
-import           Data.Map.Strict   (Map)
+import Data.Map.Strict   (Map)
 import qualified Data.Map.Strict as Map
 import Data.Maybe
 import qualified Data.Set as Set
 
-import           BasicTypes
-import           CoreArity     (typeArity)
-import           CoreSyn
-import           CoreUtils     (exprIsHNF, exprIsTrivial)
-import           MkCore
-import           Id
+import BasicTypes
+import CoreArity     (typeArity)
+import CoreSyn
+import CoreUtils     (exprIsHNF, exprIsTrivial)
+import MkCore
+import Id
 import Outputable hiding ((<>))
-import           Demand
-import           UnVarGraph
+import Demand
+import UnVarGraph
 import Worklist
 import Util
-
+import Control.Monad
+import Control.Monad.Fix
 import Control.Monad.Trans.State.Strict
 
-import           Control.Arrow (first)
+import Control.Arrow ((***), first)
 
 
 {-
@@ -449,6 +449,8 @@ callArityRHS e = lookup_expr (runFramework fw (Set.singleton (node, 0)))
     (node, fw) = buildFramework $
       registerTransferFunction $ \node -> do
         transfer <- callArityExpr emptyVarEnv e
+        -- We only get away with using alwaysChangeDetector because this won't
+        -- introduce a cycle.
         return (node, (transfer, alwaysChangeDetector))
 
     lookup_expr :: Map (FrameworkNode, Arity) AnalResult -> CoreExpr
@@ -473,12 +475,16 @@ instance Monoid Annotations where
     where
       panicOnConflict n m
         | n == m    = n
-        | otherwise = pprPanic "CallArity.Annotations.mappend conflict" empty
+        | otherwise = pprPanic "CallArity.Annotations.mappend conflict"
+                               (vcat [ppr n <+> text "vs" <+> ppr m, ppr a, ppr b])
 
 -- | How an expression uses its interesting variables
 -- and the arity annotations for local bindings
 data AnalResult = AR !CallArityType !Annotations
 
+instance Outputable AnalResult where
+  ppr (AR cat ann) = vcat [text "type:" <+> ppr cat, text "annotations:" <+> ppr ann]
+
 unzipAnalResult :: [AnalResult] -> ([CallArityType], Annotations)
 unzipAnalResult ar = (map cat ar, foldMap ann ar)
   where
@@ -487,7 +493,7 @@ unzipAnalResult ar = (map cat ar, foldMap ann ar)
 
 newtype FrameworkNode
   = FrameworkNode Int
-  deriving (Show, Eq, Ord)
+  deriving (Show, Eq, Ord, Outputable)
 
 type TransferFunction' a = TransferFunction (FrameworkNode, Arity) AnalResult a
 type ChangeDetector' = ChangeDetector (FrameworkNode, Arity) AnalResult
@@ -528,19 +534,6 @@ registerTransferFunction f = FB $ do
 dependOn' :: FrameworkNode -> Arity -> TransferFunction' AnalResult
 dependOn' node arity = fromMaybe emptyAnalResult <$> dependOn (node, arity)
 
-callArityBind :: VarEnv LetAnalKind -> CoreBind -> FrameworkBuilder (VarEnv FrameworkNode)
-callArityBind let_anal_kinds = build_binds emptyVarEnv . flattenBinds . singleton
-  where
-    build_binds env [] = return env
-    build_binds env ((id, rhs):binds) = registerTransferFunction $ \node -> do
-      env' <- build_binds (extendVarEnv env id node) binds
-      transfer <- callArityExpr let_anal_kinds rhs
-      let transfer' arity = do
-            -- TODO: trim arity
-            AR cat_rhs ann_rhs <- transfer arity
-            return (AR cat_rhs (mkAnnotation id arity <> ann_rhs))
-      return (env', (transfer', alwaysChangeDetector))
-
 -- | The main analysis function. See Note [Analysis type signature]
 callArityExpr
   :: VarEnv LetAnalKind
@@ -565,7 +558,7 @@ callArityExpr let_anal_kinds (Var v) = return transfer
   where
     transfer = case lookupVarEnv let_anal_kinds v of
       Nothing | not (isInteresting v) -> \_ -> return emptyAnalResult -- v is boring
-      Nothing -> \_ -> return emptyAnalResult -- TODO: use an exported sig here
+      Nothing -> \arity -> return (AR (unitArityType v arity) mempty) -- TODO: use an exported sig here
       Just LetUp -> \arity -> return (AR (unitArityType v arity) mempty) -- the demand is unleashed later
       Just LetDown -> \arity ->
         -- unleash cat directly
@@ -607,7 +600,7 @@ callArityExpr let_anal_kinds (App f a) = do
     let ca_a' | called_once    = ca_a
               | arg_arity == 0 = ca_a
               | otherwise      = calledMultipleTimes ca_a
-    return (AR (ca_f' `both` ca_a') (ann_f <> ann_a))
+    return (AR (ca_f' `both` ca_a') (pprTrace "ann_f" empty ann_f <> pprTrace "ann_a" empty ann_a))
 
 -- Case expression.
 callArityExpr let_anal_kinds (Case scrut bndr ty alts) = do
@@ -620,7 +613,7 @@ callArityExpr let_anal_kinds (Case scrut bndr ty alts) = do
     let cat = cat_scrut `both` lubTypes cat_alts
     -- pprTrace "callArityExpr:Case"
     --          (vcat [ppr scrut, ppr cat])
-    return (AR cat (ann_scrut <> ann_alts))
+    return (AR cat (pprTrace "ann_scrut" empty ann_scrut <> ann_alts))
 
 callArityExpr let_anal_kinds (Let bind e) = do
   let add_let_kind (id, rhs) env
@@ -629,64 +622,80 @@ callArityExpr let_anal_kinds (Let bind e) = do
   let binds = flattenBinds [bind]
   let let_anal_kinds' = foldr add_let_kind let_anal_kinds binds
 
-  nodes <- callArityBind let_anal_kinds' bind
+  -- The order in which we call callArityExpr here is important: This makes sure
+  -- we first stabilize bindings before analyzing the body.
+  transferred_binds <- forM binds $ \(id, rhs) -> do
+    transfer_rhs <- callArityExpr let_anal_kinds' rhs
+    return (id, rhs, transfer_rhs)
   transfer_body <- callArityExpr let_anal_kinds' e
 
-  node <- registerTransferFunction $ \node -> do
-    let transfer arity = do
-          ar_body@(AR cat_body ann_body) <- transfer_body arity
-          case bind of
-            -- TODO: handle LetDown. Probably just return emptyArityType in unleashCalls?
-            NonRec id rhs -> do
-              -- We don't need to use cat_old here, because only the let body can
-              -- call id.
-              AR cat ann_bind <- unleashCalls nodes False cat_body (id, rhs)
-              let cat_final = callArityLetEnv (not (isInteresting id)) ann_body [(id, cat)] cat_body
-              return (AR cat_final (ann_body <> ann_bind))
-            Rec pairs -> do
-              AR cat_old ann_old <- fromMaybe ar_body <$> dependOn (node, arity)
-              (cat_rhss, ann_rhss) <- unzipAnalResult <$> mapM (unleashCalls nodes True cat_old) pairs
-              let ids = map fst pairs
-              let any_boring = any (not . isInteresting) ids
-              let cat_final = callArityLetEnv any_boring ann_old (zip ids cat_rhss) cat_body
-              return (AR cat_final (ann_body <> ann_rhss))
-
-    let changeDetector changedRefs (AR old _) (AR new _) =
-          map fst (Set.toList changedRefs) /= [node]
-          || any (\id -> lookupCallArityType old id /= lookupCallArityType new id) (map fst binds)
-
-    return (node, (transfer, changeDetector))
-
-  return $ \arity -> do
-    AR cat ann <- dependOn' node arity
-    return (AR (typeDelList (bindersOf bind) cat) ann)
-
-
-unleashCalls :: VarEnv FrameworkNode -> Bool -> CallArityType -> (Id, CoreExpr) -> TransferFunction' AnalResult
-unleashCalls nodes is_recursive cat_usage (id, rhs) = do
-  let boring = not (isInteresting id)
-      -- If v is boring, we will not find it in cat_usage, but always assume (0, False)
-      (arity, called_once)
-          | boring    = (0, False) -- See Note [Taking boring variables into account]
-          | otherwise = lookupCallArityType cat_usage id
-
-      -- See Note [Thunks in recursive groups]
-      safe_arity
-          | isThunk rhs && (is_recursive || not called_once) = 0 -- A thunk was called multiple times! Do not eta-expand
-          | otherwise = arity -- in the other cases it's safe to expand
-
-      -- See Note [Trimming arity]
-      trimmed_arity = trimArity id safe_arity
-
-      node = fromMaybe (pprPanic "CallArity.unleashCalls" (ppr id)) (lookupVarEnv nodes id)
-
-  -- TODO: Find out if (where) we need the trimmed_arity here or not
-  -- We probably want to analyze with arity und annotate trimmed_arity.
-  -- Although CA analyzes with trimmed_arity, so we do that for now
-  AR cat_rhs ann_rhs <- dependOn' node trimmed_arity
-  let cat_rhs' | called_once || safe_arity == 0 = cat_rhs
-               | otherwise = calledMultipleTimes cat_rhs
-  return (AR cat_rhs' (mkAnnotation id trimmed_arity <> ann_rhs) )
+  case bind of
+    NonRec _ _ ->
+      -- We don't need to dependOn ourselves here, because only the let body can
+      -- call id.
+      return $ \arity -> do
+        ar_body <- transfer_body arity
+        AR cat ann <- unleashLet False transferred_binds ar_body ar_body
+        return (AR (typeDelList (bindersOf bind) cat) ann)
+    Rec _ -> do
+      -- This is a little more complicated, as we'll introduce a new FrameworkNode
+      -- which we'll depend on ourselves.
+      node <- registerTransferFunction $ \node -> do
+        let transfer arity = do
+              ar_body <- transfer_body arity
+              -- This is the actual fixed-point iteration: we depend on usage
+              -- results from the previous iteration, defaulting to just the body.
+              ar_usage <- fromMaybe ar_body <$> dependOn (node, arity)
+              unleashLet True transferred_binds ar_usage ar_body
+
+        let changeDetector changedRefs (AR old _) (AR new _) =
+              -- since we only care for arity and called once information of the
+              -- previous iteration, we cann efficiently test for changes.
+              map fst (Set.toList changedRefs) /= [node]
+              || any (\id -> lookupCallArityType old id /= lookupCallArityType new id) (map fst binds)
+
+        return (node, (transfer, changeDetector))
+
+      -- Now for the actual TransferFunction of this expr...
+      return $ \arity -> do
+        AR cat ann <- dependOn' node arity
+        return (AR (typeDelList (bindersOf bind) cat) ann)
+
+unleashLet :: Bool -> [(Id, CoreExpr, Arity -> TransferFunction' AnalResult)] -> AnalResult -> AnalResult -> TransferFunction' AnalResult
+unleashLet is_recursive transferred_binds (AR cat_usage ann_usage) (AR cat_body ann_body) = do
+  (cat_rhss, ann_rhss) <- unzipAnalResult <$> mapM (unleashCall is_recursive cat_usage) transferred_binds
+  let ids = map (\(id, _, _) -> id) transferred_binds
+  let cat_final = callArityLetEnv ann_usage (zip ids cat_rhss) cat_body
+  return (AR cat_final (pprTraceIt "ann_body" ann_body <> pprTraceIt "ann_rhss" ann_rhss))
+
+unleashCall :: Bool -> CallArityType -> (Id, CoreExpr, Arity -> TransferFunction' AnalResult) -> TransferFunction' AnalResult
+unleashCall is_recursive cat_usage (id, rhs, transfer_rhs)
+  | isInteresting id && not (id `elemUnVarSet` domType cat_usage)
+  = return emptyAnalResult -- No call to `id` (yet)
+  | otherwise
+  = do
+    let boring = not (isInteresting id)
+        -- If v is boring, we will not find it in cat_usage, but always assume (0, False)
+        (arity, called_once)
+            | boring    = (0, False) -- See Note [Taking boring variables into account]
+            | otherwise = --pprTrace "CallArity.unleashCalls" (ppr id <+> ppr (lookupCallArityType cat_usage id)) $
+                          lookupCallArityType cat_usage id
+
+        -- See Note [Thunks in recursive groups]
+        safe_arity
+            | isThunk rhs && (is_recursive || not called_once) = 0 -- A thunk was called multiple times! Do not eta-expand
+            | otherwise = arity -- in the other cases it's safe to expand
+
+        -- See Note [Trimming arity]
+        trimmed_arity = trimArity id safe_arity
+
+    -- TODO: Find out if (where) we need the trimmed_arity here or not
+    -- We probably want to analyze with arity und annotate trimmed_arity.
+    -- Although CA analyzes with trimmed_arity, so we do that for now
+    AR cat_rhs ann_rhs <- transfer_rhs trimmed_arity
+    let cat_rhs' | called_once || safe_arity == 0 = cat_rhs
+                 | otherwise = calledMultipleTimes cat_rhs
+    return (AR cat_rhs' ((pprTrace "annotating" (ppr id <+> ppr trimmed_arity) mkAnnotation id trimmed_arity) <> ann_rhs))
 
 determineLetAnalKind :: CoreExpr -> LetAnalKind
 determineLetAnalKind rhs
@@ -725,12 +734,11 @@ isInteresting v = not $ null (typeArity (idType v))
 -- Combining the results from body and rhs of a let binding
 -- See Note [Analysis II: The Co-Called analysis]
 callArityLetEnv
-  :: Bool
-  -> Annotations
+  :: Annotations
   -> [(Var, CallArityType)]
   -> CallArityType
   -> CallArityType
-callArityLetEnv any_boring ann_old cat_rhss cat_body
+callArityLetEnv ann_old cat_rhss cat_body
     = -- (if length ae_rhss > 300 then pprTrace "callArityLetEnv" (vcat [ppr ae_rhss, ppr ae_body, ppr ae_new]) else id) $
       cat_new
   where
@@ -745,12 +753,10 @@ callArityLetEnv any_boring ann_old cat_rhss cat_body
     cat_combined = lubTypes (map snd cat_rhss) `lubType` cat_body
 
     cross_calls
-        -- See Note [Taking boring variables into account]
-        | any_boring          = completeGraph (domType cat_combined)
-        -- Also, calculating cross_calls is expensive. Simply be conservative
+        -- Calculating cross_calls is expensive. Simply be conservative
         -- if the mutually recursive group becomes too large.
         | length cat_rhss > 25 = completeGraph (domType cat_combined)
-        | otherwise           = unionUnVarGraphs $ map cross_call cat_rhss
+        | otherwise            = unionUnVarGraphs $ map cross_call cat_rhss
     cross_call (v, cat_rhs) = completeBipartiteGraph called_by_v called_with_v
       where
         is_thunk = lookupAnnotatedArity ann_old v == 0
@@ -784,19 +790,20 @@ trimArity v a = minimum [a, max_arity_by_type, max_arity_by_strsig]
     (demands, result_info) = splitStrictSig (idStrictness v)
 
 annotate :: Annotations -> CoreExpr -> CoreExpr
-annotate _ e@(Lit _) = e
-annotate _ e@(Type _) = e
-annotate _ e@(Coercion _) = e
-annotate _ e@(Var _) = e
-annotate ann (Tick t e) = Tick t (annotate ann e)
-annotate ann (Cast e co) = Cast (annotate ann e) co
-annotate ann (Lam v e) = Lam v (annotate ann e)
-annotate ann (App f a) = App (annotate ann f) (annotate ann a)
-annotate ann (Let (NonRec id rhs) e) = Let (NonRec (annotateId ann id) rhs) e
-annotate ann (Let (Rec pairs) e) = Let (Rec (map (first (annotateId ann)) pairs)) e
-annotate ann (Case scrut bndr ty alts) = Case (annotate ann scrut) bndr ty (map annotate_alt alts)
-  where
-    annotate_alt (dc, bndrs, e) = (dc, bndrs, annotate ann e)
+annotate ann e = case e of
+  Lit _ -> e
+  Type _ -> e
+  Coercion _ -> e
+  Var _ -> e
+  Tick t e -> Tick t (annotate ann e)
+  Cast e co -> Cast (annotate ann e) co
+  Lam v e -> Lam v (annotate ann e) -- TODO: Also annotate v? Seems important for LetDown
+  App f a -> App (annotate ann f) (annotate ann a)
+  Let (NonRec id rhs) e -> Let (NonRec (annotateId ann id) (annotate ann rhs)) (annotate ann e)
+  Let (Rec pairs) e -> Let (Rec (map (annotateId ann *** annotate ann) pairs)) (annotate ann e)
+  Case scrut bndr ty alts -> Case (annotate ann scrut) bndr ty (map annotate_alt alts)
+    where
+      annotate_alt (dc, bndrs, e) = (dc, bndrs, annotate ann e)
 
 annotateId :: Annotations -> Id -> Id
 annotateId ann id = id `setIdCallArity` lookupAnnotatedArity ann id
@@ -853,7 +860,11 @@ lookupCallArityType (CAT g ae _) v
         Nothing -> (0, False)
 
 calledWith :: CallArityType -> Var -> UnVarSet
-calledWith ca_type v = neighbors (cat_cocalled ca_type) v
+calledWith ca_type v
+  | isInteresting v
+  = neighbors (cat_cocalled ca_type) v
+  | otherwise
+  = domType ca_type
 
 modifyCoCalls :: (UnVarGraph -> UnVarGraph) -> CallArityType -> CallArityType
 modifyCoCalls modifier ca_type
diff --git a/compiler/utils/Worklist.hs b/compiler/utils/Worklist.hs
index b2c6c90fb8..693f2a7508 100644
--- a/compiler/utils/Worklist.hs
+++ b/compiler/utils/Worklist.hs
@@ -4,12 +4,13 @@
 module Worklist where
 
 import Control.Monad.Trans.State.Strict
-import Data.Map.Strict (Map)
-import qualified Data.Map.Strict as Map
+import Data.Map (Map)
+import qualified Data.Map as Map
 import Data.Set (Set)
 import qualified Data.Set as Set
 import Data.Maybe (fromMaybe)
 import Control.Monad (forM_)
+import Debug.Trace
 
 newtype TransferFunction node lattice a
   = TFM (State (WorklistState node lattice) a)
@@ -52,6 +53,7 @@ data WorklistState node lattice
   { graph :: !(Graph node lattice)
   , callStack :: !(Set node)
   , referencedNodes :: !(Set node)
+  , loopBreakers :: !(Set node)
   , framework :: !(DataFlowFramework node lattice)
   }
 
@@ -62,11 +64,16 @@ zoomGraph modifyGraph = state $ \st ->
 
 zoomReferencedNodes :: State (Set node) a -> State (WorklistState node lattice) a
 zoomReferencedNodes modifier = state $ \st ->
-  let (res, an) = runState modifier (referencedNodes st)
-  in  (res, st { referencedNodes = an })
+  let (res, rn) = runState modifier (referencedNodes st)
+  in  (res, st { referencedNodes = rn })
+
+zoomLoopBreakers :: State (Set node) a -> State (WorklistState node lattice) a
+zoomLoopBreakers modifier = state $ \st ->
+  let (res, lb) = runState modifier (loopBreakers st)
+  in  (res, st { loopBreakers = lb })
 
 initialWorklistState :: DataFlowFramework node lattice -> WorklistState node lattice
-initialWorklistState = WorklistState Map.empty Set.empty Set.empty
+initialWorklistState = WorklistState Map.empty Set.empty Set.empty Set.empty
 
 dependOn :: Ord node => node -> TransferFunction node lattice (Maybe lattice)
 dependOn node = TFM $ do
@@ -74,7 +81,10 @@ dependOn node = TFM $ do
   maybeNodeInfo <- Map.lookup node <$> gets graph
   zoomReferencedNodes (modify' (Set.insert node)) -- save that we depend on this value
   case maybeNodeInfo of
-    Nothing | loopDetected -> return Nothing
+    Nothing | loopDetected -> do
+      -- We have to revisit these later
+      zoomLoopBreakers (modify' (Set.insert node))
+      return Nothing
     Nothing -> fmap (\(val, _, _) -> Just val) (recompute node)
     Just info -> return (value info)
 
@@ -123,14 +133,14 @@ recompute node = do
     , callStack = Set.insert node (callStack oldState)
     }
   let (TFM transfer, changeDetector) = getTransfer (framework oldState) node
-  res <- transfer
+  val <- transfer
   refs <- gets referencedNodes
-  oldInfo <- updateGraphNode node res refs
+  oldInfo <- updateGraphNode node val refs
   modify' $ \st -> st
     { referencedNodes = referencedNodes oldState
     , callStack = callStack oldState
     }
-  return (res, oldInfo, changeDetector)
+  return (val, oldInfo, changeDetector)
 
 enqueue :: Ord node => node -> Set node -> Map node (Set node) -> Map node (Set node)
 enqueue reference referrers_ = Map.unionWith Set.union referrersMap
@@ -140,15 +150,27 @@ enqueue reference referrers_ = Map.unionWith Set.union referrersMap
 dequeue :: Map node (Set node) -> Maybe ((node, Set node), Map node (Set node))
 dequeue = Map.maxViewWithKey
 
+lookupReferrers :: Ord node => node -> Graph node lattice -> Set node
+lookupReferrers node = maybe Set.empty referrers . Map.lookup node
+
 work :: Ord node => Map node (Set node) -> State (WorklistState node lattice) ()
 work nodes =
   case dequeue nodes of
     Nothing -> return ()
     Just ((node, changedRefs), nodes') -> do
+      modify' $ \st -> st { loopBreakers = Set.empty }
       (newVal, oldInfo, detectChange) <- recompute node
+      -- We have to enqueue all referrers to loop breakers, e.g. nodes which we
+      -- returned `Nothing` from `dependOn` to break cyclic dependencies.
+      -- Their referrers probably aren't carrying safe values, so we have to
+      -- revisit them. This looks expensive, but loopBreakers should be pretty
+      -- rare later on.
+      g <- gets graph
+      lbs <- gets loopBreakers
+      let nodes'' = Set.foldr (\lb -> enqueue lb (lookupReferrers lb g)) nodes' lbs
       case value oldInfo of
-        Just oldVal | not (detectChange changedRefs oldVal newVal) -> work nodes'
-        _ -> work (enqueue node (referrers oldInfo) nodes')
+        Just oldVal | not (detectChange changedRefs oldVal newVal) -> work nodes''
+        _ -> work (enqueue node (referrers oldInfo) nodes'')
 
 runFramework
   :: Ord node
diff --git a/testsuite/tests/callarity/unittest/CallArity1.hs b/testsuite/tests/callarity/unittest/CallArity1.hs
index 6b9591e6a1..048f6ab02a 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.hs
+++ b/testsuite/tests/callarity/unittest/CallArity1.hs
@@ -41,7 +41,7 @@ go, go2, x, d, n, y, z, scrutf, scruta :: Id
 
 exprs :: [(String, CoreExpr)]
 exprs =
-  [ ("go2",) $
+  [ ("go2",) $ -- pprTraceIt "go2" $
      mkRFun go [x]
         (mkNrLet d (mkACase (Var go `mkVarApps` [x])
                           (mkLams [y] $ Var y)
@@ -142,10 +142,10 @@ exprs =
     mkNrLet d (f `mkLApps` [0]) $
         mkNrLet n (Var f `mkApps` [d `mkLApps` [1]]) $
             mkLams [x] $ Var n `mkVarApps` [x]
-  , ("a thunk (non-function-type), in mutual recursion, still calls once (d 1 would be good)",) $
+  , ("a thunk (non-function-type), in mutual recursion, still calls once (d 0 would be bad)",) $
     mkNrLet d (f `mkLApps` [0]) $
         Let (Rec [ (x, Var d `mkApps` [go `mkLApps` [1,2]])
-                 , (go, mkLams [x] $ mkACase (mkLams [z] $ Var x) (Var go `mkVarApps` [x]) ) ]) $
+                 , (go, mkLams [y] $ mkACase (mkLams [z] $ Var x) (Var go `mkVarApps` [x]) ) ]) $
             Var go `mkApps` [mkLit 0, go `mkLApps` [0,1]]
   , ("a thunk (non-function-type), in mutual recursion, causes many calls (d 1 would be bad)",) $
     mkNrLet d (f `mkLApps` [0]) $
@@ -222,4 +222,3 @@ allBoundIds (Lam _ e)  = allBoundIds e
 allBoundIds (Tick _ e) = allBoundIds e
 allBoundIds (Cast e _) = allBoundIds e
 allBoundIds _ = emptyVarSet
-
diff --git a/testsuite/tests/callarity/unittest/CallArity1.stderr b/testsuite/tests/callarity/unittest/CallArity1.stderr
index 82cbc2ba01..010e516ed2 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.stderr
+++ b/testsuite/tests/callarity/unittest/CallArity1.stderr
@@ -60,10 +60,10 @@ a thunk (non-function-type), called twice, still calls once:
 a thunk (function type), called multiple times, still calls once:
     d 1
     n 0
-a thunk (non-function-type), in mutual recursion, still calls once (d 1 would be good):
+a thunk (non-function-type), in mutual recursion, still calls once (d 0 would be bad):
     go 2
     x 0
-    d 0
+    d 1
 a thunk (non-function-type), in mutual recursion, causes many calls (d 1 would be bad):
     go 2
     x 0
-- 
2.12.1


From b2529f7a33796e14f5188a627c0baa76ba9c9ff0 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 30 Dec 2016 09:32:40 +0100
Subject: [PATCH 013/117] Appearently LocalId's realUnique isn't as unique as
 it should be. Switched back to carrying around expressions again.

---
 compiler/simplCore/CallArity.hs | 216 +++++++++++++++++-----------------------
 1 file changed, 93 insertions(+), 123 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index 8649da7ef5..6193bc5599 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -1,4 +1,5 @@
 {-# LANGUAGE GeneralizedNewtypeDeriving #-}
+{-# LANGUAGE TupleSections #-}
 --
 -- Copyright (c) 2014 Joachim Breitner
 --
@@ -11,7 +12,6 @@ module CallArity
 import DynFlags      (DynFlags)
 import VarEnv
 
-import Data.Monoid
 import Data.List     (delete)
 import Data.IntMap.Lazy (IntMap)
 import qualified Data.IntMap.Lazy as IntMap
@@ -26,17 +26,14 @@ import CoreSyn
 import CoreUtils     (exprIsHNF, exprIsTrivial)
 import MkCore
 import Id
-import Outputable hiding ((<>))
+import Outputable
 import Demand
 import UnVarGraph
 import Worklist
-import Util
 import Control.Monad
 import Control.Monad.Fix
 import Control.Monad.Trans.State.Strict
 
-import Control.Arrow ((***), first)
-
 
 {-
 %************************************************************************
@@ -456,40 +453,11 @@ callArityRHS e = lookup_expr (runFramework fw (Set.singleton (node, 0)))
     lookup_expr :: Map (FrameworkNode, Arity) AnalResult -> CoreExpr
     lookup_expr result_map = case Map.lookup (node, 0) result_map of
       Nothing -> pprPanic "callArityRHS" empty
-      Just (AR _ annotations) -> annotate annotations e
-
-newtype Annotations
-  = Annotations (VarEnv Arity)
-  deriving (Eq, Outputable)
-
-mkAnnotation :: Id -> Arity -> Annotations
-mkAnnotation id arity = Annotations (unitVarEnv id arity)
-
-lookupAnnotatedArity :: Annotations -> Id -> Arity
-lookupAnnotatedArity (Annotations ann) id = fromMaybe (idCallArity id) (lookupVarEnv ann id)
-
-instance Monoid Annotations where
-  mempty = Annotations mempty
-  mappend (Annotations a) (Annotations b)
-    = Annotations (plusVarEnv_C panicOnConflict a b)
-    where
-      panicOnConflict n m
-        | n == m    = n
-        | otherwise = pprPanic "CallArity.Annotations.mappend conflict"
-                               (vcat [ppr n <+> text "vs" <+> ppr m, ppr a, ppr b])
+      Just (_, e) -> e
 
 -- | How an expression uses its interesting variables
--- and the arity annotations for local bindings
-data AnalResult = AR !CallArityType !Annotations
-
-instance Outputable AnalResult where
-  ppr (AR cat ann) = vcat [text "type:" <+> ppr cat, text "annotations:" <+> ppr ann]
-
-unzipAnalResult :: [AnalResult] -> ([CallArityType], Annotations)
-unzipAnalResult ar = (map cat ar, foldMap ann ar)
-  where
-    cat (AR cat _) = cat
-    ann (AR _ ann) = ann
+-- and the expression with annotated Ids
+type AnalResult = (CallArityType, CoreExpr)
 
 newtype FrameworkNode
   = FrameworkNode Int
@@ -531,9 +499,6 @@ registerTransferFunction f = FB $ do
     unFB (f (FrameworkNode node))
   return result
 
-dependOn' :: FrameworkNode -> Arity -> TransferFunction' AnalResult
-dependOn' node arity = fromMaybe emptyAnalResult <$> dependOn (node, arity)
-
 -- | The main analysis function. See Note [Analysis type signature]
 callArityExpr
   :: VarEnv LetAnalKind
@@ -541,49 +506,64 @@ callArityExpr
   -> FrameworkBuilder (Arity -> TransferFunction' AnalResult)
 
 callArityExprTrivial
-  :: FrameworkBuilder (Arity -> TransferFunction' AnalResult)
-callArityExprTrivial = return (\_ -> return emptyAnalResult)
+  :: CoreExpr
+  -> FrameworkBuilder (Arity -> TransferFunction' AnalResult)
+callArityExprTrivial e
+  = return (\_ -> return (emptyArityType, e))
+
+callArityExprTransparent
+  :: VarEnv LetAnalKind
+  -> (CoreExpr -> a)
+  -> CoreExpr
+  -> FrameworkBuilder (Arity -> TransferFunction' (CallArityType, a))
+callArityExprTransparent let_anal_kinds f e
+  = transfer' <$> callArityExpr let_anal_kinds e
+  where
+    transfer' transfer arity = do
+      (cat, e') <- transfer arity
+      return (cat, f e')
 
 -- The trivial base cases
-callArityExpr _ (Lit _) = callArityExprTrivial
-callArityExpr _ (Type _) = callArityExprTrivial
-callArityExpr _ (Coercion _) = callArityExprTrivial
+callArityExpr _ e@(Lit _) = callArityExprTrivial e
+callArityExpr _ e@(Type _) = callArityExprTrivial e
+callArityExpr _ e@(Coercion _) = callArityExprTrivial e
 
 -- The transparent cases
-callArityExpr let_anal_kinds (Tick _ e) = callArityExpr let_anal_kinds e
-callArityExpr let_anal_kinds (Cast e _) = callArityExpr let_anal_kinds e
+callArityExpr let_anal_kinds (Tick t e)
+  = callArityExprTransparent let_anal_kinds (Tick t) e
+callArityExpr let_anal_kinds (Cast e c)
+  = callArityExprTransparent let_anal_kinds (flip Cast c) e
 
 -- The interesting cases: Variables, Lambdas, Lets, Applications, Cases
-callArityExpr let_anal_kinds (Var v) = return transfer
+callArityExpr let_anal_kinds e@(Var v) = return transfer
   where
     transfer = case lookupVarEnv let_anal_kinds v of
-      Nothing | not (isInteresting v) -> \_ -> return emptyAnalResult -- v is boring
-      Nothing -> \arity -> return (AR (unitArityType v arity) mempty) -- TODO: use an exported sig here
-      Just LetUp -> \arity -> return (AR (unitArityType v arity) mempty) -- the demand is unleashed later
-      Just LetDown -> \arity ->
-        -- unleash cat directly
-        dependOn' undefined arity
+      Nothing | not (isInteresting v) -> \_ -> return (emptyArityType, e) -- v is boring
+      Nothing -> \arity -> return (unitArityType v arity, e) -- TODO: use an exported sig here
+      Just LetUp -> \arity -> return (unitArityType v arity, e) -- the demand is unleashed later
+      Just LetDown -> error "not implemented" -- unleash cat directly
 
 -- Non-value lambdas are ignored
 callArityExpr let_anal_kinds (Lam v e)
-    | not (isId v)
-    = callArityExpr let_anal_kinds e
-
-callArityExpr let_anal_kinds (Lam v e) = transfer' <$> callArityExpr let_anal_kinds e
+  | not (isId v)
+  = callArityExpr let_anal_kinds e
+  | otherwise
+  = transfer' <$> callArityExpr let_anal_kinds e
   where
     -- We have a lambda that may be called multiple times, so its free variables
     -- can all be co-called.
     -- Also regardless of the variable not being interesting,
     -- we have to add the var as an argument.
     transfer' transfer 0 = do
-      AR cat ann <- transfer 0
-      return (AR (addArgToType v (calledMultipleTimes cat)) ann)
+      (cat, e') <- transfer 0
+      return (addArgToType v (calledMultipleTimes cat), Lam v e')
     -- We have a lambda that we are calling. decrease arity.
     transfer' transfer arity = do
-      AR cat ann <- transfer (arity - 1)
-      return (AR (addArgToType v cat) ann)
+      (cat, e') <- transfer (arity - 1)
+      return (addArgToType v cat, Lam v e')
 
-callArityExpr let_anal_kinds (App f (Type _)) = callArityExpr let_anal_kinds f
+callArityExpr let_anal_kinds (App f (Type t))
+  = callArityExprTransparent let_anal_kinds (flip App (Type t)) f
 
 -- Application. Increase arity for the called expression, nothing to know about
 -- the second
@@ -591,29 +571,30 @@ callArityExpr let_anal_kinds (App f a) = do
   transfer_f <- callArityExpr let_anal_kinds f
   transfer_a <- callArityExpr let_anal_kinds a
   return $ \arity -> do
-    AR ca_f ann_f <- transfer_f (arity + 1)
+    (cat_f, f') <- transfer_f (arity + 1)
     -- peel off one argument from the type
-    let (arg_arity, called_once, ca_f') = peelCallArityType a ca_f
+    let (arg_arity, called_once, cat_f') = peelCallArityType a cat_f
     -- TODO: Actually use called with information instead of just called_once
     --       Maybe this is enough for higher-order signature information?
-    AR ca_a ann_a <- transfer_a arg_arity
-    let ca_a' | called_once    = ca_a
-              | arg_arity == 0 = ca_a
-              | otherwise      = calledMultipleTimes ca_a
-    return (AR (ca_f' `both` ca_a') (pprTrace "ann_f" empty ann_f <> pprTrace "ann_a" empty ann_a))
+    (cat_a, a') <- transfer_a arg_arity
+    let cat_a' | called_once    = cat_a
+               | arg_arity == 0 = cat_a
+               | otherwise      = calledMultipleTimes cat_a
+    return (cat_f' `both` cat_a', App f' a')
 
 -- Case expression.
 callArityExpr let_anal_kinds (Case scrut bndr ty alts) = do
   transfer_scrut <- callArityExpr let_anal_kinds scrut
     -- TODO: Do we have to do something special with bndr?
-  transfer_alts <- mapM (\(dc, bndrs, e) -> callArityExpr let_anal_kinds e) alts
+  transfer_alts <- forM alts $ \(dc, bndrs, e) ->
+    callArityExprTransparent let_anal_kinds (dc, bndrs,) e
   return $ \arity -> do
-    AR cat_scrut ann_scrut <- transfer_scrut 0
-    (cat_alts, ann_alts) <- unzipAnalResult <$> mapM ($ arity) transfer_alts
+    (cat_scrut, scrut') <- transfer_scrut 0
+    (cat_alts, alts') <- unzip <$> mapM ($ arity) transfer_alts
     let cat = cat_scrut `both` lubTypes cat_alts
     -- pprTrace "callArityExpr:Case"
     --          (vcat [ppr scrut, ppr cat])
-    return (AR cat (pprTrace "ann_scrut" empty ann_scrut <> ann_alts))
+    return (cat, Case scrut' bndr ty alts')
 
 callArityExpr let_anal_kinds (Let bind e) = do
   let add_let_kind (id, rhs) env
@@ -624,31 +605,34 @@ callArityExpr let_anal_kinds (Let bind e) = do
 
   -- The order in which we call callArityExpr here is important: This makes sure
   -- we first stabilize bindings before analyzing the body.
-  transferred_binds <- forM binds $ \(id, rhs) -> do
-    transfer_rhs <- callArityExpr let_anal_kinds' rhs
-    return (id, rhs, transfer_rhs)
+  transfer_rhss <- mapM (callArityExpr let_anal_kinds' . snd) binds
   transfer_body <- callArityExpr let_anal_kinds' e
 
+  let zip213 = zipWith (\(a, b) c -> (a, b, c))
+
   case bind of
     NonRec _ _ ->
       -- We don't need to dependOn ourselves here, because only the let body can
       -- call id.
       return $ \arity -> do
-        ar_body <- transfer_body arity
-        AR cat ann <- unleashLet False transferred_binds ar_body ar_body
-        return (AR (typeDelList (bindersOf bind) cat) ann)
+        (cat_body, e') <- transfer_body arity
+        let bind_with_transfer = zip213 binds transfer_rhss
+        (cat, [(id', rhs')]) <- unleashLet False bind_with_transfer cat_body cat_body
+        return (typeDelList (bindersOf bind) cat, Let (NonRec id' rhs') e')
     Rec _ -> do
       -- This is a little more complicated, as we'll introduce a new FrameworkNode
       -- which we'll depend on ourselves.
       node <- registerTransferFunction $ \node -> do
         let transfer arity = do
-              ar_body <- transfer_body arity
+              (cat_body, e') <- transfer_body arity
               -- This is the actual fixed-point iteration: we depend on usage
               -- results from the previous iteration, defaulting to just the body.
-              ar_usage <- fromMaybe ar_body <$> dependOn (node, arity)
-              unleashLet True transferred_binds ar_usage ar_body
+              (cat_usage, Let (Rec old_bind) _) <- fromMaybe (cat_body, Let bind e') <$> dependOn (node, arity)
+              let bind_with_transfer = zip213 old_bind transfer_rhss
+              (cat, bind') <- unleashLet True bind_with_transfer cat_usage cat_body
+              return (cat, Let (Rec bind') e')
 
-        let changeDetector changedRefs (AR old _) (AR new _) =
+        let changeDetector changedRefs (old, _) (new, _) =
               -- since we only care for arity and called once information of the
               -- previous iteration, we cann efficiently test for changes.
               map fst (Set.toList changedRefs) /= [node]
@@ -658,20 +642,29 @@ callArityExpr let_anal_kinds (Let bind e) = do
 
       -- Now for the actual TransferFunction of this expr...
       return $ \arity -> do
-        AR cat ann <- dependOn' node arity
-        return (AR (typeDelList (bindersOf bind) cat) ann)
+        (cat, let') <- fromMaybe (emptyArityType, Let bind e) <$> dependOn (node, arity)
+        return (typeDelList (bindersOf bind) cat, let')
 
-unleashLet :: Bool -> [(Id, CoreExpr, Arity -> TransferFunction' AnalResult)] -> AnalResult -> AnalResult -> TransferFunction' AnalResult
-unleashLet is_recursive transferred_binds (AR cat_usage ann_usage) (AR cat_body ann_body) = do
-  (cat_rhss, ann_rhss) <- unzipAnalResult <$> mapM (unleashCall is_recursive cat_usage) transferred_binds
-  let ids = map (\(id, _, _) -> id) transferred_binds
-  let cat_final = callArityLetEnv ann_usage (zip ids cat_rhss) cat_body
-  return (AR cat_final (pprTraceIt "ann_body" ann_body <> pprTraceIt "ann_rhss" ann_rhss))
-
-unleashCall :: Bool -> CallArityType -> (Id, CoreExpr, Arity -> TransferFunction' AnalResult) -> TransferFunction' AnalResult
+unleashLet
+  :: Bool
+  -> [(Id, CoreExpr, Arity -> TransferFunction' AnalResult)]
+  -> CallArityType
+  -> CallArityType
+  -> TransferFunction' (CallArityType, [(Id, CoreExpr)])
+unleashLet is_recursive transferred_binds cat_usage cat_body = do
+  (cat_rhss, binds') <- unzip <$> mapM (unleashCall is_recursive cat_usage) transferred_binds
+  let ids = map fst binds'
+  let cat_final = callArityLetEnv (zip ids cat_rhss) cat_body
+  return (cat_final, binds')
+
+unleashCall
+  :: Bool
+  -> CallArityType
+  -> (Id, CoreExpr, Arity -> TransferFunction' AnalResult)
+  -> TransferFunction' (CallArityType, (Id, CoreExpr))
 unleashCall is_recursive cat_usage (id, rhs, transfer_rhs)
   | isInteresting id && not (id `elemUnVarSet` domType cat_usage)
-  = return emptyAnalResult -- No call to `id` (yet)
+  = return (emptyArityType, (id, rhs)) -- No call to `id` (yet)
   | otherwise
   = do
     let boring = not (isInteresting id)
@@ -692,10 +685,10 @@ unleashCall is_recursive cat_usage (id, rhs, transfer_rhs)
     -- TODO: Find out if (where) we need the trimmed_arity here or not
     -- We probably want to analyze with arity und annotate trimmed_arity.
     -- Although CA analyzes with trimmed_arity, so we do that for now
-    AR cat_rhs ann_rhs <- transfer_rhs trimmed_arity
+    (cat_rhs, rhs') <- transfer_rhs trimmed_arity
     let cat_rhs' | called_once || safe_arity == 0 = cat_rhs
                  | otherwise = calledMultipleTimes cat_rhs
-    return (AR cat_rhs' ((pprTrace "annotating" (ppr id <+> ppr trimmed_arity) mkAnnotation id trimmed_arity) <> ann_rhs))
+    return (cat_rhs', (id `setIdCallArity` trimmed_arity, rhs'))
 
 determineLetAnalKind :: CoreExpr -> LetAnalKind
 determineLetAnalKind rhs
@@ -734,11 +727,10 @@ isInteresting v = not $ null (typeArity (idType v))
 -- Combining the results from body and rhs of a let binding
 -- See Note [Analysis II: The Co-Called analysis]
 callArityLetEnv
-  :: Annotations
-  -> [(Var, CallArityType)]
+  :: [(Var, CallArityType)]
   -> CallArityType
   -> CallArityType
-callArityLetEnv ann_old cat_rhss cat_body
+callArityLetEnv cat_rhss cat_body
     = -- (if length ae_rhss > 300 then pprTrace "callArityLetEnv" (vcat [ppr ae_rhss, ppr ae_body, ppr ae_new]) else id) $
       cat_new
   where
@@ -759,7 +751,7 @@ callArityLetEnv ann_old cat_rhss cat_body
         | otherwise            = unionUnVarGraphs $ map cross_call cat_rhss
     cross_call (v, cat_rhs) = completeBipartiteGraph called_by_v called_with_v
       where
-        is_thunk = lookupAnnotatedArity ann_old v == 0
+        is_thunk = idCallArity v == 0 -- This is an old annotation, possibly from the last FP iteration
         -- We only add self cross calls if we really can recurse into ourselves.
         -- This is not the case for thunks (and non-recursive bindings, but
         -- then there won't be any mention of v in the rhs).
@@ -789,25 +781,6 @@ trimArity v a = minimum [a, max_arity_by_type, max_arity_by_strsig]
 
     (demands, result_info) = splitStrictSig (idStrictness v)
 
-annotate :: Annotations -> CoreExpr -> CoreExpr
-annotate ann e = case e of
-  Lit _ -> e
-  Type _ -> e
-  Coercion _ -> e
-  Var _ -> e
-  Tick t e -> Tick t (annotate ann e)
-  Cast e co -> Cast (annotate ann e) co
-  Lam v e -> Lam v (annotate ann e) -- TODO: Also annotate v? Seems important for LetDown
-  App f a -> App (annotate ann f) (annotate ann a)
-  Let (NonRec id rhs) e -> Let (NonRec (annotateId ann id) (annotate ann rhs)) (annotate ann e)
-  Let (Rec pairs) e -> Let (Rec (map (annotateId ann *** annotate ann) pairs)) (annotate ann e)
-  Case scrut bndr ty alts -> Case (annotate ann scrut) bndr ty (map annotate_alt alts)
-    where
-      annotate_alt (dc, bndrs, e) = (dc, bndrs, annotate ann e)
-
-annotateId :: Annotations -> Id -> Id
-annotateId ann id = id `setIdCallArity` lookupAnnotatedArity ann id
-
 ---------------------------------------
 -- Functions related to CallArityType --
 ---------------------------------------
@@ -831,9 +804,6 @@ instance Outputable CallArityType where
 emptyArityType :: CallArityType
 emptyArityType = CAT emptyUnVarGraph emptyVarEnv []
 
-emptyAnalResult :: AnalResult
-emptyAnalResult = AR emptyArityType mempty
-
 unitArityType :: Var -> Arity -> CallArityType
 unitArityType v arity = CAT emptyUnVarGraph (unitVarEnv v arity) []
 
-- 
2.12.1


From 9a24719e6ba477cb70c411b9184dc3870d1d6be7 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 30 Dec 2016 09:56:43 +0100
Subject: [PATCH 014/117] Green again

---
 compiler/simplCore/CallArity.hs | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index 6193bc5599..aac61eb0b1 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -546,7 +546,7 @@ callArityExpr let_anal_kinds e@(Var v) = return transfer
 -- Non-value lambdas are ignored
 callArityExpr let_anal_kinds (Lam v e)
   | not (isId v)
-  = callArityExpr let_anal_kinds e
+  = callArityExprTransparent let_anal_kinds (Lam v) e
   | otherwise
   = transfer' <$> callArityExpr let_anal_kinds e
   where
-- 
2.12.1


From f3f742e74c54f492d728810c2b2be95467bbe158 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 2 Jan 2017 21:55:04 +0100
Subject: [PATCH 015/117] Cleaned up some LetUp/LetDown related stuff that
 won't happen as planned

---
 compiler/simplCore/CallArity.hs | 84 ++++++++++++++---------------------------
 1 file changed, 28 insertions(+), 56 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index aac61eb0b1..f6ad0aad3a 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -445,7 +445,7 @@ callArityRHS e = lookup_expr (runFramework fw (Set.singleton (node, 0)))
   where
     (node, fw) = buildFramework $
       registerTransferFunction $ \node -> do
-        transfer <- callArityExpr emptyVarEnv e
+        transfer <- callArityExpr e
         -- We only get away with using alwaysChangeDetector because this won't
         -- introduce a cycle.
         return (node, (transfer, alwaysChangeDetector))
@@ -471,15 +471,6 @@ newtype FrameworkBuilder a
   = FB { unFB :: State (IntMap (Arity -> TransferFunction' AnalResult, ChangeDetector')) a }
   deriving (Functor, Applicative, Monad)
 
-data LetAnalKind
-  = LetDown
-  | LetUp
-  deriving (Show, Eq, Ord)
-
-isLetUp :: LetAnalKind -> Bool
-isLetUp LetUp = True
-isLetUp LetDown = False
-
 buildFramework :: FrameworkBuilder a -> (a, DataFlowFramework')
 buildFramework (FB state) = (res, DFF dff)
   where
@@ -501,8 +492,7 @@ registerTransferFunction f = FB $ do
 
 -- | The main analysis function. See Note [Analysis type signature]
 callArityExpr
-  :: VarEnv LetAnalKind
-  -> CoreExpr
+  :: CoreExpr
   -> FrameworkBuilder (Arity -> TransferFunction' AnalResult)
 
 callArityExprTrivial
@@ -512,43 +502,36 @@ callArityExprTrivial e
   = return (\_ -> return (emptyArityType, e))
 
 callArityExprTransparent
-  :: VarEnv LetAnalKind
-  -> (CoreExpr -> a)
+  :: (CoreExpr -> a)
   -> CoreExpr
   -> FrameworkBuilder (Arity -> TransferFunction' (CallArityType, a))
-callArityExprTransparent let_anal_kinds f e
-  = transfer' <$> callArityExpr let_anal_kinds e
+callArityExprTransparent f e
+  = transfer' <$> callArityExpr e
   where
     transfer' transfer arity = do
       (cat, e') <- transfer arity
       return (cat, f e')
 
 -- The trivial base cases
-callArityExpr _ e@(Lit _) = callArityExprTrivial e
-callArityExpr _ e@(Type _) = callArityExprTrivial e
-callArityExpr _ e@(Coercion _) = callArityExprTrivial e
+callArityExpr e@(Lit _) = callArityExprTrivial e
+callArityExpr e@(Type _) = callArityExprTrivial e
+callArityExpr e@(Coercion _) = callArityExprTrivial e
 
 -- The transparent cases
-callArityExpr let_anal_kinds (Tick t e)
-  = callArityExprTransparent let_anal_kinds (Tick t) e
-callArityExpr let_anal_kinds (Cast e c)
-  = callArityExprTransparent let_anal_kinds (flip Cast c) e
+callArityExpr (Tick t e) = callArityExprTransparent (Tick t) e
+callArityExpr (Cast e c) = callArityExprTransparent (flip Cast c) e
 
 -- The interesting cases: Variables, Lambdas, Lets, Applications, Cases
-callArityExpr let_anal_kinds e@(Var v) = return transfer
+callArityExpr e@(Var v) = return transfer
   where
-    transfer = case lookupVarEnv let_anal_kinds v of
-      Nothing | not (isInteresting v) -> \_ -> return (emptyArityType, e) -- v is boring
-      Nothing -> \arity -> return (unitArityType v arity, e) -- TODO: use an exported sig here
-      Just LetUp -> \arity -> return (unitArityType v arity, e) -- the demand is unleashed later
-      Just LetDown -> error "not implemented" -- unleash cat directly
+    transfer
+      | isInteresting v = \arity -> return (unitArityType v arity, e)
+      | otherwise       = \_ -> return (emptyArityType, e)
 
 -- Non-value lambdas are ignored
-callArityExpr let_anal_kinds (Lam v e)
-  | not (isId v)
-  = callArityExprTransparent let_anal_kinds (Lam v) e
-  | otherwise
-  = transfer' <$> callArityExpr let_anal_kinds e
+callArityExpr (Lam v e)
+  | not (isId v) = callArityExprTransparent (Lam v) e
+  | otherwise    = transfer' <$> callArityExpr e
   where
     -- We have a lambda that may be called multiple times, so its free variables
     -- can all be co-called.
@@ -562,14 +545,13 @@ callArityExpr let_anal_kinds (Lam v e)
       (cat, e') <- transfer (arity - 1)
       return (addArgToType v cat, Lam v e')
 
-callArityExpr let_anal_kinds (App f (Type t))
-  = callArityExprTransparent let_anal_kinds (flip App (Type t)) f
+callArityExpr (App f (Type t)) = callArityExprTransparent (flip App (Type t)) f
 
 -- Application. Increase arity for the called expression, nothing to know about
 -- the second
-callArityExpr let_anal_kinds (App f a) = do
-  transfer_f <- callArityExpr let_anal_kinds f
-  transfer_a <- callArityExpr let_anal_kinds a
+callArityExpr (App f a) = do
+  transfer_f <- callArityExpr f
+  transfer_a <- callArityExpr a
   return $ \arity -> do
     (cat_f, f') <- transfer_f (arity + 1)
     -- peel off one argument from the type
@@ -583,11 +565,11 @@ callArityExpr let_anal_kinds (App f a) = do
     return (cat_f' `both` cat_a', App f' a')
 
 -- Case expression.
-callArityExpr let_anal_kinds (Case scrut bndr ty alts) = do
-  transfer_scrut <- callArityExpr let_anal_kinds scrut
+callArityExpr (Case scrut bndr ty alts) = do
+  transfer_scrut <- callArityExpr scrut
     -- TODO: Do we have to do something special with bndr?
   transfer_alts <- forM alts $ \(dc, bndrs, e) ->
-    callArityExprTransparent let_anal_kinds (dc, bndrs,) e
+    callArityExprTransparent (dc, bndrs,) e
   return $ \arity -> do
     (cat_scrut, scrut') <- transfer_scrut 0
     (cat_alts, alts') <- unzip <$> mapM ($ arity) transfer_alts
@@ -596,17 +578,12 @@ callArityExpr let_anal_kinds (Case scrut bndr ty alts) = do
     --          (vcat [ppr scrut, ppr cat])
     return (cat, Case scrut' bndr ty alts')
 
-callArityExpr let_anal_kinds (Let bind e) = do
-  let add_let_kind (id, rhs) env
-        | isInteresting id = extendVarEnv env id (determineLetAnalKind rhs)
-        | otherwise = env
+callArityExpr (Let bind e) = do
   let binds = flattenBinds [bind]
-  let let_anal_kinds' = foldr add_let_kind let_anal_kinds binds
-
   -- The order in which we call callArityExpr here is important: This makes sure
-  -- we first stabilize bindings before analyzing the body.
-  transfer_rhss <- mapM (callArityExpr let_anal_kinds' . snd) binds
-  transfer_body <- callArityExpr let_anal_kinds' e
+  -- the FP iteration will first stabilize bindings before analyzing the body.
+  transfer_rhss <- mapM (callArityExpr . snd) binds
+  transfer_body <- callArityExpr e
 
   let zip213 = zipWith (\(a, b) c -> (a, b, c))
 
@@ -690,11 +667,6 @@ unleashCall is_recursive cat_usage (id, rhs, transfer_rhs)
                  | otherwise = calledMultipleTimes cat_rhs
     return (cat_rhs', (id `setIdCallArity` trimmed_arity, rhs'))
 
-determineLetAnalKind :: CoreExpr -> LetAnalKind
-determineLetAnalKind rhs
-  | isThunk rhs || True = LetUp
-  | otherwise = LetDown
-
 isThunk :: CoreExpr -> Bool
 isThunk = not . exprIsHNF
 
-- 
2.12.1


From 3a94bbddfce3cf78de5ea9110fc4b8530ae444aa Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 8 Jan 2017 21:11:09 +0100
Subject: [PATCH 016/117] First try at higher-order information, but doesn't
 terminate (yet)

---
 compiler/simplCore/CallArity.hs | 154 ++++++++++++++++++++++++++--------------
 1 file changed, 101 insertions(+), 53 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index f6ad0aad3a..5fb591df87 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -12,7 +12,6 @@ module CallArity
 import DynFlags      (DynFlags)
 import VarEnv
 
-import Data.List     (delete)
 import Data.IntMap.Lazy (IntMap)
 import qualified Data.IntMap.Lazy as IntMap
 import Data.Map.Strict   (Map)
@@ -445,7 +444,7 @@ callArityRHS e = lookup_expr (runFramework fw (Set.singleton (node, 0)))
   where
     (node, fw) = buildFramework $
       registerTransferFunction $ \node -> do
-        transfer <- callArityExpr e
+        transfer <- callArityExpr emptyVarEnv e
         -- We only get away with using alwaysChangeDetector because this won't
         -- introduce a cycle.
         return (node, (transfer, alwaysChangeDetector))
@@ -492,7 +491,8 @@ registerTransferFunction f = FB $ do
 
 -- | The main analysis function. See Note [Analysis type signature]
 callArityExpr
-  :: CoreExpr
+  :: VarEnv FrameworkNode
+  -> CoreExpr
   -> FrameworkBuilder (Arity -> TransferFunction' AnalResult)
 
 callArityExprTrivial
@@ -502,36 +502,46 @@ callArityExprTrivial e
   = return (\_ -> return (emptyArityType, e))
 
 callArityExprTransparent
-  :: (CoreExpr -> a)
+  :: VarEnv FrameworkNode
+  -> (CoreExpr -> a)
   -> CoreExpr
   -> FrameworkBuilder (Arity -> TransferFunction' (CallArityType, a))
-callArityExprTransparent f e
-  = transfer' <$> callArityExpr e
+callArityExprTransparent nodes f e
+  = transfer' <$> callArityExpr nodes e
   where
     transfer' transfer arity = do
       (cat, e') <- transfer arity
       return (cat, f e')
 
 -- The trivial base cases
-callArityExpr e@(Lit _) = callArityExprTrivial e
-callArityExpr e@(Type _) = callArityExprTrivial e
-callArityExpr e@(Coercion _) = callArityExprTrivial e
+callArityExpr _ e@(Lit _) = callArityExprTrivial e
+callArityExpr _ e@(Type _) = callArityExprTrivial e
+callArityExpr _ e@(Coercion _) = callArityExprTrivial e
 
 -- The transparent cases
-callArityExpr (Tick t e) = callArityExprTransparent (Tick t) e
-callArityExpr (Cast e c) = callArityExprTransparent (flip Cast c) e
+callArityExpr nodes (Tick t e) = callArityExprTransparent nodes (Tick t) e
+callArityExpr nodes (Cast e c) = callArityExprTransparent nodes (flip Cast c) e
 
 -- The interesting cases: Variables, Lambdas, Lets, Applications, Cases
-callArityExpr e@(Var v) = return transfer
+callArityExpr nodes e@(Var v) = return transfer
   where
-    transfer
-      | isInteresting v = \arity -> return (unitArityType v arity, e)
-      | otherwise       = \_ -> return (emptyArityType, e)
+    transfer arity
+      | isInteresting v
+      , Just node <- lookupVarEnv nodes v
+      = do
+        (cat_callee, _) <- fromMaybe (unusedArgsArityType arity, e) <$> dependOn (node, arity)
+        return ((unitArityType v arity) { cat_args = cat_args cat_callee }, e)
+
+      | isInteresting v
+      = return (unitArityType v arity, e) -- TODO: lookup sig if present
+
+      | otherwise
+      = return (emptyArityType, e)
 
 -- Non-value lambdas are ignored
-callArityExpr (Lam v e)
-  | not (isId v) = callArityExprTransparent (Lam v) e
-  | otherwise    = transfer' <$> callArityExpr e
+callArityExpr nodes (Lam v e)
+  | not (isId v) = callArityExprTransparent nodes (Lam v) e
+  | otherwise    = transfer' <$> callArityExpr nodes e
   where
     -- We have a lambda that may be called multiple times, so its free variables
     -- can all be co-called.
@@ -539,37 +549,37 @@ callArityExpr (Lam v e)
     -- we have to add the var as an argument.
     transfer' transfer 0 = do
       (cat, e') <- transfer 0
-      return (addArgToType v (calledMultipleTimes cat), Lam v e')
+      return (makeIdArg v (calledMultipleTimes cat), Lam v e')
     -- We have a lambda that we are calling. decrease arity.
     transfer' transfer arity = do
       (cat, e') <- transfer (arity - 1)
-      return (addArgToType v cat, Lam v e')
+      return (makeIdArg v cat, Lam v e')
 
-callArityExpr (App f (Type t)) = callArityExprTransparent (flip App (Type t)) f
+callArityExpr nodes (App f (Type t)) = callArityExprTransparent nodes (flip App (Type t)) f
 
 -- Application. Increase arity for the called expression, nothing to know about
 -- the second
-callArityExpr (App f a) = do
-  transfer_f <- callArityExpr f
-  transfer_a <- callArityExpr a
+callArityExpr nodes (App f a) = do
+  transfer_f <- callArityExpr nodes f
+  transfer_a <- callArityExpr nodes a
   return $ \arity -> do
     (cat_f, f') <- transfer_f (arity + 1)
     -- peel off one argument from the type
-    let (arg_arity, called_once, cat_f') = peelCallArityType a cat_f
-    -- TODO: Actually use called with information instead of just called_once
-    --       Maybe this is enough for higher-order signature information?
-    (cat_a, a') <- transfer_a arg_arity
-    let cat_a' | called_once    = cat_a
-               | arg_arity == 0 = cat_a
-               | otherwise      = calledMultipleTimes cat_a
-    return (cat_f' `both` cat_a', App f' a')
+    case peelCallArityType a cat_f of
+      (Nothing, cat_f') -> return (cat_f', App f' a) -- TODO: Visit a, too? Seems unnecessary, wasn't called at all
+      (Just (arg_arity, called_once), cat_f') -> do
+        (cat_a, a') <- transfer_a arg_arity
+        let cat_a' | called_once    = cat_a
+                   | arg_arity == 0 = cat_a
+                   | otherwise      = calledMultipleTimes cat_a
+        return (cat_f' `both` cat_a', App f' a')
 
 -- Case expression.
-callArityExpr (Case scrut bndr ty alts) = do
-  transfer_scrut <- callArityExpr scrut
+callArityExpr nodes (Case scrut bndr ty alts) = do
+  transfer_scrut <- callArityExpr nodes scrut
     -- TODO: Do we have to do something special with bndr?
   transfer_alts <- forM alts $ \(dc, bndrs, e) ->
-    callArityExprTransparent (dc, bndrs,) e
+    callArityExprTransparent nodes (dc, bndrs,) e
   return $ \arity -> do
     (cat_scrut, scrut') <- transfer_scrut 0
     (cat_alts, alts') <- unzip <$> mapM ($ arity) transfer_alts
@@ -578,12 +588,15 @@ callArityExpr (Case scrut bndr ty alts) = do
     --          (vcat [ppr scrut, ppr cat])
     return (cat, Case scrut' bndr ty alts')
 
-callArityExpr (Let bind e) = do
+callArityExpr letdown_nodes (Let bind e) = do
   let binds = flattenBinds [bind]
   -- The order in which we call callArityExpr here is important: This makes sure
   -- the FP iteration will first stabilize bindings before analyzing the body.
-  transfer_rhss <- mapM (callArityExpr . snd) binds
-  transfer_body <- callArityExpr e
+  (letdown_nodes', letup_nodes) <- callArityBind letdown_nodes binds
+  let transfer_rhs (id, rhs) arity =
+        fromMaybe (unusedArgsArityType arity, rhs) <$> dependOn (fromJust (lookupVarEnv letup_nodes id), arity)
+  let transfer_rhss = map transfer_rhs binds
+  transfer_body <- callArityExpr letdown_nodes' e
 
   let zip213 = zipWith (\(a, b) c -> (a, b, c))
 
@@ -609,19 +622,48 @@ callArityExpr (Let bind e) = do
               (cat, bind') <- unleashLet True bind_with_transfer cat_usage cat_body
               return (cat, Let (Rec bind') e')
 
-        let changeDetector changedRefs (old, _) (new, _) =
+        let change_detector changed_refs (old, _) (new, _) =
               -- since we only care for arity and called once information of the
               -- previous iteration, we cann efficiently test for changes.
-              map fst (Set.toList changedRefs) /= [node]
+              map fst (Set.toList changed_refs) /= [node]
               || any (\id -> lookupCallArityType old id /= lookupCallArityType new id) (map fst binds)
 
-        return (node, (transfer, changeDetector))
+        return (node, (transfer, change_detector))
 
       -- Now for the actual TransferFunction of this expr...
       return $ \arity -> do
         (cat, let') <- fromMaybe (emptyArityType, Let bind e) <$> dependOn (node, arity)
         return (typeDelList (bindersOf bind) cat, let')
 
+callArityBind
+  :: VarEnv FrameworkNode
+  -> [(Id, CoreExpr)]
+  -> FrameworkBuilder (VarEnv FrameworkNode, VarEnv FrameworkNode)
+callArityBind letdown_nodes = go letdown_nodes emptyVarEnv
+  where
+    go letdown_nodes letup_nodes [] = return (letdown_nodes, letup_nodes)
+    go letdown_nodes letup_nodes ((id, rhs):binds) =
+      registerTransferFunction $ \letup_node ->
+        registerTransferFunction $ \letdown_node -> do
+          (letdown_nodes', letup_nodes') <- go
+            (extendVarEnv letdown_nodes id letdown_node)
+            (extendVarEnv letup_nodes id letup_node)
+            binds
+          transfer_up <- callArityExpr letdown_nodes' rhs
+          let transfer_down arity = fromMaybe (unusedArgsArityType arity, rhs) <$> dependOn (letup_node, arity)
+          let change_detector_down _ (old, _) (new, _) =
+                -- The only reason we split the transfer fuctions up is cheap
+                -- change detection for the LetDown case. This implies that
+                -- use sites of the LetDown component may only use the cat_args
+                -- component!
+                -- FIXME: Encode this in the FrameworkNode type somehow, but I
+                -- don't think it's worth the trouble.
+                cat_args old /= cat_args new
+          let ret = (letdown_nodes', letup_nodes') -- What we return from callArityBind
+          let letup = (transfer_up, alwaysChangeDetector) -- What we register for letup_node
+          let letdown = (transfer_down, change_detector_down) -- What we register for letdown_node
+          return ((ret, letup), letdown) -- registerTransferFunction  will peel `snd`s away for registration
+
 unleashLet
   :: Bool
   -> [(Id, CoreExpr, Arity -> TransferFunction' AnalResult)]
@@ -670,10 +712,12 @@ unleashCall is_recursive cat_usage (id, rhs, transfer_rhs)
 isThunk :: CoreExpr -> Bool
 isThunk = not . exprIsHNF
 
--- TODO: add the set of neighbors
-peelCallArityType :: CoreExpr -> CallArityType -> (Arity, Bool, CallArityType)
+peelCallArityType :: CoreExpr -> CallArityType -> (Maybe (Arity, Bool), CallArityType)
 peelCallArityType a ca_type = case cat_args ca_type of
-  arg:_ | isInteresting arg ->
+  arg:args -> (arg, ca_type { cat_args = args })
+  _ -> (Just (0, False), ca_type)
+  {- TODO: worry about this later
+  arg:args | isInteresting arg ->
     -- TODO: not (exprIsTrivial a)?
     -- TODO: called_once when arity = 0?
     let (arity, called_once) = lookupCallArityType ca_type arg
@@ -690,6 +734,7 @@ peelCallArityType a ca_type = case cat_args ca_type of
     -- Also, if the argument is trivial (e.g. a variable), then it will _not_ be
     -- let-bound in the Core to STG transformation (CorePrep actually),
     -- so no sharing will happen here, and we have to assume many calls.
+    -}
 
 -- Which bindings should we look at?
 -- See Note [Which variables are interesting]
@@ -719,7 +764,8 @@ callArityLetEnv cat_rhss cat_body
     cross_calls
         -- Calculating cross_calls is expensive. Simply be conservative
         -- if the mutually recursive group becomes too large.
-        | length cat_rhss > 25 = completeGraph (domType cat_combined)
+        -- TODO: I *think* 5 is enough here, but this used to be 25.
+        | length cat_rhss > 5 = completeGraph (domType cat_combined)
         | otherwise            = unionUnVarGraphs $ map cross_call cat_rhss
     cross_call (v, cat_rhs) = completeBipartiteGraph called_by_v called_with_v
       where
@@ -764,12 +810,12 @@ data CallArityType
   = CAT
   { cat_cocalled :: UnVarGraph
   , cat_arities :: VarEnv Arity
-  , cat_args :: [Var]
+  , cat_args :: [Maybe (Arity, Bool)]
   }
 
 instance Outputable CallArityType where
   ppr (CAT cocalled arities args) =
-    text "args:" <+> ppr args
+    text "arg demands:" <+> ppr args
     <+> text "co-calls:" <+> ppr cocalled
     <+> text "arities:" <+> ppr arities
 
@@ -777,21 +823,23 @@ emptyArityType :: CallArityType
 emptyArityType = CAT emptyUnVarGraph emptyVarEnv []
 
 unitArityType :: Var -> Arity -> CallArityType
-unitArityType v arity = CAT emptyUnVarGraph (unitVarEnv v arity) []
+unitArityType v arity = emptyArityType { cat_arities = unitVarEnv v arity }
+
+unusedArgsArityType :: Int -> CallArityType
+unusedArgsArityType arity = emptyArityType { cat_args = replicate arity Nothing }
 
 typeDelList :: [Var] -> CallArityType -> CallArityType
 typeDelList vs ae = foldr typeDel ae vs
 
--- TODO: args handling
--- TODO: What about transitive co-call relationships over v?
 typeDel :: Var -> CallArityType -> CallArityType
-typeDel v (CAT g ae args) = CAT (g `delNode` v) (ae `delVarEnv` v) (delete v args)
+typeDel v (CAT g ae args) = CAT (g `delNode` v) (ae `delVarEnv` v) args
 
 domType :: CallArityType -> UnVarSet
 domType ca_type = varEnvDom (cat_arities ca_type)
 
-addArgToType :: Id -> CallArityType -> CallArityType
-addArgToType id ca_type = ca_type { cat_args = id : cat_args ca_type }
+makeIdArg :: Id -> CallArityType -> CallArityType
+makeIdArg id ca_type = typeDel id ca_type
+  { cat_args = Just (lookupCallArityType ca_type id) : cat_args ca_type }
 
 -- In the result, find out the minimum arity and whether the variable is called
 -- at most once.
-- 
2.12.1


From 037757cb925868169ea20c68c7c17c2825d0eac8 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 9 Jan 2017 10:36:07 +0100
Subject: [PATCH 017/117] Fixed visit order, so that it actually terminates

---
 compiler/simplCore/CallArity.hs | 78 ++++++++++++++++++++++++++++++-----------
 1 file changed, 57 insertions(+), 21 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index 5fb591df87..b8248a53cc 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -27,6 +27,7 @@ import MkCore
 import Id
 import Outputable
 import Demand
+import UniqFM
 import UnVarGraph
 import Worklist
 import Control.Monad
@@ -443,7 +444,7 @@ callArityRHS :: CoreExpr -> CoreExpr
 callArityRHS e = lookup_expr (runFramework fw (Set.singleton (node, 0)))
   where
     (node, fw) = buildFramework $
-      registerTransferFunction $ \node -> do
+      registerTransferFunction (LowerThan (FrameworkNode 0)) $ \node -> do
         transfer <- callArityExpr emptyVarEnv e
         -- We only get away with using alwaysChangeDetector because this won't
         -- introduce a cycle.
@@ -478,17 +479,34 @@ buildFramework (FB state) = (res, DFF dff)
       Nothing -> pprPanic "CallArity.buildFramework" (ppr node)
       Just (transfer, detectChange) -> (transfer arity, detectChange)
 
+data RequestedPriority
+  = LowerThan FrameworkNode
+  | HighestAvailable
+
 registerTransferFunction
-  :: (FrameworkNode -> FrameworkBuilder (a, (Arity -> TransferFunction' AnalResult, ChangeDetector')))
+  :: RequestedPriority
+  -> (FrameworkNode -> FrameworkBuilder (a, (Arity -> TransferFunction' AnalResult, ChangeDetector')))
   -> FrameworkBuilder a
-registerTransferFunction f = FB $ do
-  node <- gets IntMap.size
+registerTransferFunction prio f = FB $ do
+  nodes <- get
+  let node = case prio of
+        HighestAvailable -> 2 * IntMap.size nodes
+        LowerThan (FrameworkNode node)
+          | not (IntMap.member (node - 1) nodes) -> node - 1
+          | otherwise -> pprPanic "registerTransferFunction" (text "There was already a node registered with priority" <+> ppr (node - 1))
   (result, _) <- mfix $ \ ~(_, entry) -> do
     -- Using mfix so that we can spare an unnecessary Int counter in the state
     modify' (IntMap.insert node entry)
     unFB (f (FrameworkNode node))
   return result
 
+dependOn' :: (FrameworkNode, Arity) -> TransferFunction' (Maybe AnalResult)
+dependOn' (node, arity) = do
+  --pprTrace "dependOn':before" (text "node:" <+> ppr node <+> text "arity:" <+> ppr arity) $ return ()
+  res <- dependOn (node, arity)
+  --pprTrace "dependOn':after" (vcat [text "node:" <+> ppr node, text "arity:" <+> ppr arity, text "res:" <+> ppr res]) $ return ()
+  return res
+
 -- | The main analysis function. See Note [Analysis type signature]
 callArityExpr
   :: VarEnv FrameworkNode
@@ -529,8 +547,8 @@ callArityExpr nodes e@(Var v) = return transfer
       | isInteresting v
       , Just node <- lookupVarEnv nodes v
       = do
-        (cat_callee, _) <- fromMaybe (unusedArgsArityType arity, e) <$> dependOn (node, arity)
-        return ((unitArityType v arity) { cat_args = cat_args cat_callee }, e)
+        (cat_callee, _) <- fromMaybe (unusedArgsArityType arity, e) <$> dependOn' (node, arity)
+        return ((unitArityType v arity) { cat_args = cat_args cat_callee }, e)
 
       | isInteresting v
       = return (unitArityType v arity, e) -- TODO: lookup sig if present
@@ -564,11 +582,13 @@ callArityExpr nodes (App f a) = do
   transfer_a <- callArityExpr nodes a
   return $ \arity -> do
     (cat_f, f') <- transfer_f (arity + 1)
+    --pprTrace "App:f'" (ppr (cat_f, f')) $ return ()
     -- peel off one argument from the type
     case peelCallArityType a cat_f of
       (Nothing, cat_f') -> return (cat_f', App f' a) -- TODO: Visit a, too? Seems unnecessary, wasn't called at all
       (Just (arg_arity, called_once), cat_f') -> do
         (cat_a, a') <- transfer_a arg_arity
+        --pprTrace "App:a'" (ppr (cat_a, a')) $ return ()
         let cat_a' | called_once    = cat_a
                    | arg_arity == 0 = cat_a
                    | otherwise      = calledMultipleTimes cat_a
@@ -583,9 +603,10 @@ callArityExpr nodes (Case scrut bndr ty alts) = do
   return $ \arity -> do
     (cat_scrut, scrut') <- transfer_scrut 0
     (cat_alts, alts') <- unzip <$> mapM ($ arity) transfer_alts
-    let cat = cat_scrut `both` lubTypes cat_alts
+    let cat = lubTypes cat_alts `both` cat_scrut
     -- pprTrace "callArityExpr:Case"
     --          (vcat [ppr scrut, ppr cat])
+    --pprTrace "Case" (vcat [text "cat_scrut:" <+> ppr cat_scrut, text "cat_alts:" <+> ppr cat_alts, text "cat:" <+> ppr cat]) (return ())
     return (cat, Case scrut' bndr ty alts')
 
 callArityExpr letdown_nodes (Let bind e) = do
@@ -594,7 +615,7 @@ callArityExpr letdown_nodes (Let bind e) = do
   -- the FP iteration will first stabilize bindings before analyzing the body.
   (letdown_nodes', letup_nodes) <- callArityBind letdown_nodes binds
   let transfer_rhs (id, rhs) arity =
-        fromMaybe (unusedArgsArityType arity, rhs) <$> dependOn (fromJust (lookupVarEnv letup_nodes id), arity)
+        fromMaybe (unusedArgsArityType arity, rhs) <$> dependOn' (fromJust (lookupVarEnv letup_nodes id), arity)
   let transfer_rhss = map transfer_rhs binds
   transfer_body <- callArityExpr letdown_nodes' e
 
@@ -612,12 +633,12 @@ callArityExpr letdown_nodes (Let bind e) = do
     Rec _ -> do
       -- This is a little more complicated, as we'll introduce a new FrameworkNode
       -- which we'll depend on ourselves.
-      node <- registerTransferFunction $ \node -> do
+      node <- registerTransferFunction (LowerThan (minimum (eltsUFM letup_nodes))) $ \node -> do
         let transfer arity = do
               (cat_body, e') <- transfer_body arity
               -- This is the actual fixed-point iteration: we depend on usage
               -- results from the previous iteration, defaulting to just the body.
-              (cat_usage, Let (Rec old_bind) _) <- fromMaybe (cat_body, Let bind e') <$> dependOn (node, arity)
+              (cat_usage, Let (Rec old_bind) _) <- fromMaybe (cat_body, Let bind e') <$> dependOn' (node, arity)
               let bind_with_transfer = zip213 old_bind transfer_rhss
               (cat, bind') <- unleashLet True bind_with_transfer cat_usage cat_body
               return (cat, Let (Rec bind') e')
@@ -625,6 +646,7 @@ callArityExpr letdown_nodes (Let bind e) = do
         let change_detector changed_refs (old, _) (new, _) =
               -- since we only care for arity and called once information of the
               -- previous iteration, we cann efficiently test for changes.
+              --pprTrace "change_detector" (vcat[ppr node, ppr changed_refs, ppr old, ppr new])
               map fst (Set.toList changed_refs) /= [node]
               || any (\id -> lookupCallArityType old id /= lookupCallArityType new id) (map fst binds)
 
@@ -632,7 +654,8 @@ callArityExpr letdown_nodes (Let bind e) = do
 
       -- Now for the actual TransferFunction of this expr...
       return $ \arity -> do
-        (cat, let') <- fromMaybe (emptyArityType, Let bind e) <$> dependOn (node, arity)
+        (cat, let') <- fromMaybe (emptyArityType, Let bind e) <$> dependOn' (node, arity)
+        --pprTrace "Let" (ppr (cat, let')) $ return ()
         return (typeDelList (bindersOf bind) cat, let')
 
 callArityBind
@@ -643,14 +666,19 @@ callArityBind letdown_nodes = go letdown_nodes emptyVarEnv
   where
     go letdown_nodes letup_nodes [] = return (letdown_nodes, letup_nodes)
     go letdown_nodes letup_nodes ((id, rhs):binds) =
-      registerTransferFunction $ \letup_node ->
-        registerTransferFunction $ \letdown_node -> do
+      registerTransferFunction HighestAvailable $ \letup_node ->
+        registerTransferFunction HighestAvailable $ \letdown_node -> do
           (letdown_nodes', letup_nodes') <- go
             (extendVarEnv letdown_nodes id letdown_node)
             (extendVarEnv letup_nodes id letup_node)
             binds
-          transfer_up <- callArityExpr letdown_nodes' rhs
-          let transfer_down arity = fromMaybe (unusedArgsArityType arity, rhs) <$> dependOn (letup_node, arity)
+          transfer_up' <- callArityExpr letdown_nodes' rhs
+          let transfer_up arity = do
+                --pprTrace "Bind:Before" (text "id:" <+> ppr id <+> text "arity:" <+> ppr arity) $ return ()
+                res <- transfer_up' arity
+                --pprTrace "Bind:Finished" (ppr res) $ return ()
+                return res
+          let transfer_down arity = fromMaybe (unusedArgsArityType arity, rhs) <$> dependOn' (letup_node, arity)
           let change_detector_down _ (old, _) (new, _) =
                 -- The only reason we split the transfer fuctions up is cheap
                 -- change detection for the LetDown case. This implies that
@@ -658,6 +686,7 @@ callArityBind letdown_nodes = go letdown_nodes emptyVarEnv
                 -- component!
                 -- FIXME: Encode this in the FrameworkNode type somehow, but I
                 -- don't think it's worth the trouble.
+                --pprTrace "change_detector_down" (ppr (cat_args old) <+> ppr (cat_args new) <+> ppr (cat_args old /= cat_args new)) $ 
                 cat_args old /= cat_args new
           let ret = (letdown_nodes', letup_nodes') -- What we return from callArityBind
           let letup = (transfer_up, alwaysChangeDetector) -- What we register for letup_node
@@ -759,7 +788,7 @@ callArityLetEnv cat_rhss cat_body
     -- which we have to handle, for the recursive case even any of cat_rhss may.
     -- This is why we have to union in appropriate cross_calls, which basically
     -- perform substitution of Id to CallArityType.
-    cat_combined = lubTypes (map snd cat_rhss) `lubType` cat_body
+    cat_combined = lubTypes (cat_body : map (unusedArgs . snd) cat_rhss)
 
     cross_calls
         -- Calculating cross_calls is expensive. Simply be conservative
@@ -779,7 +808,7 @@ callArityLetEnv cat_rhss cat_body
         --    If v doesn't recurse into itself, everything from all the _other_ variables
         --    If v is self-recursive, everything can happen.
         cat_before_v
-            | is_thunk  = lubTypes (map snd $ filter ((/= v) . fst) cat_rhss) `lubType` cat_body
+            | is_thunk  = lubTypes (cat_body : map (unusedArgs . snd) (filter ((/= v) . fst) cat_rhss))
             | otherwise = cat_combined
         -- What do we want to know from these?
         -- Which calls can happen next to any recursive call.
@@ -828,6 +857,9 @@ unitArityType v arity = emptyArityType { cat_arities = unitVarEnv v arity }
 unusedArgsArityType :: Int -> CallArityType
 unusedArgsArityType arity = emptyArityType { cat_args = replicate arity Nothing }
 
+unusedArgs :: CallArityType -> CallArityType
+unusedArgs cat = cat { cat_args = repeat Nothing }
+
 typeDelList :: [Var] -> CallArityType -> CallArityType
 typeDelList vs ae = foldr typeDel ae vs
 
@@ -870,15 +902,19 @@ calledMultipleTimes res = modifyCoCalls (const (completeGraph (domType res))) re
 
 -- Used for application and cases
 both :: CallArityType -> CallArityType -> CallArityType
-both r1 r2 = addCrossCoCalls (domType r1) (domType r2) (r1 `lubType` r2)
+both r1 r2 = addCrossCoCalls (domType r1) (domType r2) ((r1 `lubType` r2) { cat_args = cat_args r1 })
 
 -- Used when combining results from alternative cases; take the minimum
 lubType :: CallArityType -> CallArityType -> CallArityType
-lubType (CAT g1 ae1 args) (CAT g2 ae2 _) -- both args should really be the same
-  = CAT (g1 `unionUnVarGraph` g2) (ae1 `lubArityEnv` ae2) args
+lubType (CAT g1 ae1 args1) (CAT g2 ae2 args2) -- both args should really be the same
+  = CAT (g1 `unionUnVarGraph` g2) (ae1 `lubArityEnv` ae2) (zipWith lubArg args1 args2)
+  where
+    lubArg Nothing b = b
+    lubArg a Nothing = a
+    lubArg (Just (arity1, _)) (Just (arity2, _)) = Just (min arity1 arity2, False)
 
 lubArityEnv :: VarEnv Arity -> VarEnv Arity -> VarEnv Arity
 lubArityEnv = plusVarEnv_C min
 
 lubTypes :: [CallArityType] -> CallArityType
-lubTypes = foldl lubType emptyArityType
+lubTypes = foldl lubType (unusedArgs emptyArityType)
-- 
2.12.1


From 9b5cdbbad3a77771af52ac9ccbfd740c5df526b1 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 9 Jan 2017 22:49:29 +0100
Subject: [PATCH 018/117] Being more conservative about higher-order arity

---
 compiler/simplCore/CallArity.hs | 14 +++++++++++---
 1 file changed, 11 insertions(+), 3 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index b8248a53cc..232a342818 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -587,8 +587,16 @@ callArityExpr nodes (App f a) = do
     case peelCallArityType a cat_f of
       (Nothing, cat_f') -> return (cat_f', App f' a) -- TODO: Visit a, too? Seems unnecessary, wasn't called at all
       (Just (arg_arity, called_once), cat_f') -> do
-        (cat_a, a') <- transfer_a arg_arity
-        --pprTrace "App:a'" (ppr (cat_a, a')) $ return ()
+        -- a' might be a thunk, in which case we may only eta-expand if it's called once.
+        -- We could look at the called expression to tell if it returns a thunk...
+        -- But for now let's just assume it is.
+        -- So: TODO: recognize if a' is a thunk.
+        -- How? collectBinder? Do we actually win something?
+        -- This has some parallels to `let cache = f x in cache 1 + cache 2`, where
+        -- we also check if `cache` is a thunk (in which case we don't expand) or not.
+        let safe_arity = if called_once then arg_arity else 0
+        (cat_a, a') <- transfer_a safe_arity
+        --pprTrace "App:a'" (text "safe_arity:" <+> ppr safe_arity <+> ppr (cat_a, a')) $ return ()
         let cat_a' | called_once    = cat_a
                    | arg_arity == 0 = cat_a
                    | otherwise      = calledMultipleTimes cat_a
@@ -686,7 +694,7 @@ callArityBind letdown_nodes = go letdown_nodes emptyVarEnv
                 -- component!
                 -- FIXME: Encode this in the FrameworkNode type somehow, but I
                 -- don't think it's worth the trouble.
-                --pprTrace "change_detector_down" (ppr (cat_args old) <+> ppr (cat_args new) <+> ppr (cat_args old /= cat_args new)) $ 
+                --pprTrace "change_detector_down" (ppr (cat_args old) <+> ppr (cat_args new) <+> ppr (cat_args old /= cat_args new)) $
                 cat_args old /= cat_args new
           let ret = (letdown_nodes', letup_nodes') -- What we return from callArityBind
           let letup = (transfer_up, alwaysChangeDetector) -- What we register for letup_node
-- 
2.12.1


From d932e056b168b8b6d3242540740c68df14de60fa Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 10 Jan 2017 16:12:28 +0100
Subject: [PATCH 019/117] Now handling empty case bodies without diverging

---
 compiler/simplCore/CallArity.hs | 13 ++++++++++---
 1 file changed, 10 insertions(+), 3 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index 232a342818..c116564496 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -606,12 +606,16 @@ callArityExpr nodes (App f a) = do
 callArityExpr nodes (Case scrut bndr ty alts) = do
   transfer_scrut <- callArityExpr nodes scrut
     -- TODO: Do we have to do something special with bndr?
+    --       Don't think so, we can't make use of the information.
+    --       We also shouldn't track them to the co call graph (they are boring)
   transfer_alts <- forM alts $ \(dc, bndrs, e) ->
     callArityExprTransparent nodes (dc, bndrs,) e
   return $ \arity -> do
     (cat_scrut, scrut') <- transfer_scrut 0
     (cat_alts, alts') <- unzip <$> mapM ($ arity) transfer_alts
-    let cat = lubTypes cat_alts `both` cat_scrut
+    let cat = trimArgs arity (lubTypes cat_alts) `both` cat_scrut
+    -- TODO: Think harder about the diverging case (e.g. matching on `undefined`).
+    --       In that case we will declare all arguments as unused from the alts.
     -- pprTrace "callArityExpr:Case"
     --          (vcat [ppr scrut, ppr cat])
     --pprTrace "Case" (vcat [text "cat_scrut:" <+> ppr cat_scrut, text "cat_alts:" <+> ppr cat_alts, text "cat:" <+> ppr cat]) (return ())
@@ -863,11 +867,14 @@ unitArityType :: Var -> Arity -> CallArityType
 unitArityType v arity = emptyArityType { cat_arities = unitVarEnv v arity }
 
 unusedArgsArityType :: Int -> CallArityType
-unusedArgsArityType arity = emptyArityType { cat_args = replicate arity Nothing }
+unusedArgsArityType arity = trimArgs arity (unusedArgs emptyArityType)
 
 unusedArgs :: CallArityType -> CallArityType
 unusedArgs cat = cat { cat_args = repeat Nothing }
 
+trimArgs :: Int -> CallArityType -> CallArityType
+trimArgs arity cat = cat { cat_args = take arity (cat_args cat) }
+
 typeDelList :: [Var] -> CallArityType -> CallArityType
 typeDelList vs ae = foldr typeDel ae vs
 
@@ -925,4 +932,4 @@ lubArityEnv :: VarEnv Arity -> VarEnv Arity -> VarEnv Arity
 lubArityEnv = plusVarEnv_C min
 
 lubTypes :: [CallArityType] -> CallArityType
-lubTypes = foldl lubType (unusedArgs emptyArityType)
+lubTypes = foldl lubType (unusedArgs emptyArityType) -- note that this isn't safe for empty input, because of unusedArgs.
-- 
2.12.1


From 404625518b72426f47078977e7b3910bd2b1d04b Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 10 Jan 2017 17:43:05 +0100
Subject: [PATCH 020/117] Make better use of higher-order information

---
 compiler/simplCore/CallArity.hs | 5 +++--
 1 file changed, 3 insertions(+), 2 deletions(-)

diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index c116564496..c2110f4c5c 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -591,10 +591,10 @@ callArityExpr nodes (App f a) = do
         -- We could look at the called expression to tell if it returns a thunk...
         -- But for now let's just assume it is.
         -- So: TODO: recognize if a' is a thunk.
-        -- How? collectBinder? Do we actually win something?
+        -- How? collectBinder? Do we actually win something? Yes, foldr's higher-order argument
         -- This has some parallels to `let cache = f x in cache 1 + cache 2`, where
         -- we also check if `cache` is a thunk (in which case we don't expand) or not.
-        let safe_arity = if called_once then arg_arity else 0
+        let safe_arity = if called_once || exprIsCheap a then arg_arity else 0
         (cat_a, a') <- transfer_a safe_arity
         --pprTrace "App:a'" (text "safe_arity:" <+> ppr safe_arity <+> ppr (cat_a, a')) $ return ()
         let cat_a' | called_once    = cat_a
@@ -625,6 +625,7 @@ callArityExpr letdown_nodes (Let bind e) = do
   let binds = flattenBinds [bind]
   -- The order in which we call callArityExpr here is important: This makes sure
   -- the FP iteration will first stabilize bindings before analyzing the body.
+  -- Nope, in fact it does exactly the opposite!
   (letdown_nodes', letup_nodes) <- callArityBind letdown_nodes binds
   let transfer_rhs (id, rhs) arity =
         fromMaybe (unusedArgsArityType arity, rhs) <$> dependOn' (fromJust (lookupVarEnv letup_nodes id), arity)
-- 
2.12.1


From 929893328c906f5edeb8e1bd1f9485e15d9d1758 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 27 Mar 2017 11:43:43 +0200
Subject: [PATCH 021/117] Big refactoring + Sigs in Iface files

---
 compiler/basicTypes/Id.hs                        |   6 +-
 compiler/basicTypes/IdInfo.hs                    |  11 +-
 compiler/coreSyn/CoreUtils.hs                    |   5 +-
 compiler/iface/IfaceSyn.hs                       |  20 +-
 compiler/iface/TcIface.hs                        |   1 +
 compiler/iface/ToIface.hs                        |   9 +-
 compiler/simplCore/CallArity.hs                  | 929 +----------------------
 compiler/simplCore/CallArity/Analysis.hs         | 796 +++++++++++++++++++
 compiler/simplCore/CallArity/FrameworkBuilder.hs |  80 ++
 compiler/simplCore/CallArity/Types.hs            | 177 +++++
 10 files changed, 1087 insertions(+), 947 deletions(-)
 create mode 100644 compiler/simplCore/CallArity/Analysis.hs
 create mode 100644 compiler/simplCore/CallArity/FrameworkBuilder.hs
 create mode 100644 compiler/simplCore/CallArity/Types.hs

diff --git a/compiler/basicTypes/Id.hs b/compiler/basicTypes/Id.hs
index 8a5e28a235..13f3c219df 100644
--- a/compiler/basicTypes/Id.hs
+++ b/compiler/basicTypes/Id.hs
@@ -618,11 +618,11 @@ idArity id = arityInfo (idInfo id)
 setIdArity :: Id -> Arity -> Id
 setIdArity id arity = modifyIdInfo (`setArityInfo` arity) id
 
-idCallArity :: Id -> Arity
+idCallArity :: Id -> CardinalitySig
 idCallArity id = callArityInfo (idInfo id)
 
-setIdCallArity :: Id -> Arity -> Id
-setIdCallArity id arity = modifyIdInfo (`setCallArityInfo` arity) id
+setIdCallArity :: Id -> CardinalitySig -> Id
+setIdCallArity id sig = modifyIdInfo (`setCallArityInfo` sig) id
 
 idFunRepArity :: Id -> RepArity
 idFunRepArity x = countFunRepArgs (idArity x) (idType x)
diff --git a/compiler/basicTypes/IdInfo.hs b/compiler/basicTypes/IdInfo.hs
index bd6ec8f293..df21e8658e 100644
--- a/compiler/basicTypes/IdInfo.hs
+++ b/compiler/basicTypes/IdInfo.hs
@@ -98,6 +98,7 @@ import Outputable
 import Module
 import Demand
 import Util
+import CallArity.Types
 
 -- infixl so you can say (id `set` a `set` b)
 infixl  1 `setRuleInfo`,
@@ -247,8 +248,8 @@ data IdInfo
         strictnessInfo  :: StrictSig,      --  ^ A strictness signature
 
         demandInfo      :: Demand,       -- ^ ID demand information
-        callArityInfo   :: !ArityInfo,   -- ^ How this is called.
-                                         -- n <=> all calls have at least n arguments
+        callArityInfo   :: !CardinalitySig -- ^ How this is uses its arguments.
+                                           -- length of n <=> all calls have at least n arguments
 
         levityInfo      :: LevityInfo    -- ^ when applied, will this Id ever have a levity-polymorphic type?
     }
@@ -273,8 +274,8 @@ setUnfoldingInfo info uf
 
 setArityInfo :: IdInfo -> ArityInfo -> IdInfo
 setArityInfo      info ar  = info { arityInfo = ar  }
-setCallArityInfo :: IdInfo -> ArityInfo -> IdInfo
-setCallArityInfo info ar  = info { callArityInfo = ar  }
+setCallArityInfo :: IdInfo -> CardinalitySig -> IdInfo
+setCallArityInfo info sig  = info { callArityInfo = sig }
 setCafInfo :: IdInfo -> CafInfo -> IdInfo
 setCafInfo        info caf = info { cafInfo = caf }
 
@@ -300,7 +301,7 @@ vanillaIdInfo
             occInfo             = noOccInfo,
             demandInfo          = topDmd,
             strictnessInfo      = nopSig,
-            callArityInfo       = unknownArity,
+            callArityInfo       = topCardinalitySig,
             levityInfo          = NoLevityInfo
            }
 
diff --git a/compiler/coreSyn/CoreUtils.hs b/compiler/coreSyn/CoreUtils.hs
index e20fb872d6..4a83e90efb 100644
--- a/compiler/coreSyn/CoreUtils.hs
+++ b/compiler/coreSyn/CoreUtils.hs
@@ -1077,6 +1077,10 @@ Note that exprIsHNF does not imply exprIsCheap.  Eg
 This responds True to exprIsHNF (you can discard a seq), but
 False to exprIsCheap.
 
+Note [exprIsCheap and exprIsTrivial]
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+It is however the case that @exprIsTrivial@ implies @exprIsCheap@.
+
 Note [exprIsExpandable]
 ~~~~~~~~~~~~~~~~~~~~~~~
 An expression is "expandable" if we are willing to dupicate it, if doing
@@ -1099,7 +1103,6 @@ say that (q @ Float) expands to (Ptr a (a +# b)), and that will
 duplicate the (a +# b) primop, which we should not do lightly.
 (It's quite hard to trigger this bug, but T13155 does so for GHC 8.0.)
 
-
 Note [Arguments in exprIsOk]
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 What predicate should we apply to the argument of an application?  We
diff --git a/compiler/iface/IfaceSyn.hs b/compiler/iface/IfaceSyn.hs
index 6f8fcf4017..b023a46fb2 100644
--- a/compiler/iface/IfaceSyn.hs
+++ b/compiler/iface/IfaceSyn.hs
@@ -328,6 +328,7 @@ data IfaceIdInfo
 data IfaceInfoItem
   = HsArity         Arity
   | HsStrictness    StrictSig
+  | HsCardinality   CardinalitySig
   | HsInline        InlinePragma
   | HsUnfold        Bool             -- True <=> isStrongLoopBreaker is true
                     IfaceUnfolding   -- See Note [Expose recursive functions]
@@ -1222,7 +1223,8 @@ instance Outputable IfaceInfoItem where
                               <> colon <+> ppr unf
   ppr (HsInline prag)       = text "Inline:" <+> ppr prag
   ppr (HsArity arity)       = text "Arity:" <+> int arity
-  ppr (HsStrictness str) = text "Strictness:" <+> pprIfaceStrictSig str
+  ppr (HsStrictness str)    = text "Strictness:" <+> pprIfaceStrictSig str
+  ppr (HsCardinality card)  = text "Cardinality:" <+> pprIfaceCardinalitySig card
   ppr HsNoCafRefs           = text "HasNoCafRefs"
   ppr HsLevity              = text "Never levity-polymorphic"
 
@@ -1965,20 +1967,22 @@ instance Binary IfaceIdInfo where
 instance Binary IfaceInfoItem where
     put_ bh (HsArity aa)          = putByte bh 0 >> put_ bh aa
     put_ bh (HsStrictness ab)     = putByte bh 1 >> put_ bh ab
-    put_ bh (HsUnfold lb ad)      = putByte bh 2 >> put_ bh lb >> put_ bh ad
-    put_ bh (HsInline ad)         = putByte bh 3 >> put_ bh ad
-    put_ bh HsNoCafRefs           = putByte bh 4
-    put_ bh HsLevity              = putByte bh 5
+    put_ bh (HsCardinality ac)    = putByte bh 2 >> put_ bh ac
+    put_ bh (HsUnfold lb ad)      = putByte bh 3 >> put_ bh lb >> put_ bh ad
+    put_ bh (HsInline ad)         = putByte bh 4 >> put_ bh ad
+    put_ bh HsNoCafRefs           = putByte bh 5
+    put_ bh HsLevity              = putByte bh 6
     get bh = do
         h <- getByte bh
         case h of
             0 -> liftM HsArity $ get bh
             1 -> liftM HsStrictness $ get bh
-            2 -> do lb <- get bh
+            2 -> liftM HsCardinality $ get bh
+            3 -> do lb <- get bh
                     ad <- get bh
                     return (HsUnfold lb ad)
-            3 -> liftM HsInline $ get bh
-            4 -> return HsNoCafRefs
+            4 -> liftM HsInline $ get bh
+            5 -> return HsNoCafRefs
             _ -> return HsLevity
 
 instance Binary IfaceUnfolding where
diff --git a/compiler/iface/TcIface.hs b/compiler/iface/TcIface.hs
index 1477f462fc..07fd9cb6e8 100644
--- a/compiler/iface/TcIface.hs
+++ b/compiler/iface/TcIface.hs
@@ -1569,6 +1569,7 @@ tcIdInfo ignore_prags name ty info = do
     tcPrag info HsNoCafRefs        = return (info `setCafInfo`   NoCafRefs)
     tcPrag info (HsArity arity)    = return (info `setArityInfo` arity)
     tcPrag info (HsStrictness str) = return (info `setStrictnessInfo` str)
+    tcPrag info (HsCardinality card) = return (info `setCallArityInfo` card)
     tcPrag info (HsInline prag)    = return (info `setInlinePragInfo` prag)
     tcPrag info HsLevity           = return (info `setNeverLevPoly` ty)
 
diff --git a/compiler/iface/ToIface.hs b/compiler/iface/ToIface.hs
index 59184dcab0..fcda26c9da 100644
--- a/compiler/iface/ToIface.hs
+++ b/compiler/iface/ToIface.hs
@@ -389,10 +389,15 @@ toIfaceIdInfo id_info
 
     ------------  Strictness  --------------
         -- No point in explicitly exporting TopSig
-    sig_info = strictnessInfo id_info
-    strict_hsinfo | not (isTopSig sig_info) = Just (HsStrictness sig_info)
+    str_info = strictnessInfo id_info
+    strict_hsinfo | not (isTopSig str_info) = Just (HsStrictness str_info)
                   | otherwise               = Nothing
 
+    ------------  Cardinality --------------
+    sig_info = callArityInfo id_info
+    strict_hsinfo | card_info /= topCardinality = Just (HsCardinality card_info)
+                  | otherwise                   = Nothing
+
     ------------  Unfolding  --------------
     unfold_hsinfo = toIfUnfolding loop_breaker (unfoldingInfo id_info)
     loop_breaker  = isStrongLoopBreaker (occInfo id_info)
diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
index c2110f4c5c..1ca6d6092c 100644
--- a/compiler/simplCore/CallArity.hs
+++ b/compiler/simplCore/CallArity.hs
@@ -1,936 +1,9 @@
-{-# LANGUAGE GeneralizedNewtypeDeriving #-}
-{-# LANGUAGE TupleSections #-}
 --
 -- Copyright (c) 2014 Joachim Breitner
 --
 
 module CallArity
     ( callArityAnalProgram
-    , callArityRHS -- for testing
     ) where
 
-import DynFlags      (DynFlags)
-import VarEnv
-
-import Data.IntMap.Lazy (IntMap)
-import qualified Data.IntMap.Lazy as IntMap
-import Data.Map.Strict   (Map)
-import qualified Data.Map.Strict as Map
-import Data.Maybe
-import qualified Data.Set as Set
-
-import BasicTypes
-import CoreArity     (typeArity)
-import CoreSyn
-import CoreUtils     (exprIsHNF, exprIsTrivial)
-import MkCore
-import Id
-import Outputable
-import Demand
-import UniqFM
-import UnVarGraph
-import Worklist
-import Control.Monad
-import Control.Monad.Fix
-import Control.Monad.Trans.State.Strict
-
-
-{-
-%************************************************************************
-%*                                                                      *
-              Call Arity Analyis
-%*                                                                      *
-%************************************************************************
-
-Note [Call Arity: The goal]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-The goal of this analysis is to find out if we can eta-expand a local function,
-based on how it is being called. The motivating example is this code,
-which comes up when we implement foldl using foldr, and do list fusion:
-
-    let go = \x -> let d = case ... of
-                              False -> go (x+1)
-                              True  -> id
-                   in \z -> d (x + z)
-    in go 1 0
-
-If we do not eta-expand `go` to have arity 2, we are going to allocate a lot of
-partial function applications, which would be bad.
-
-The function `go` has a type of arity two, but only one lambda is manifest.
-Furthermore, an analysis that only looks at the RHS of go cannot be sufficient
-to eta-expand go: If `go` is ever called with one argument (and the result used
-multiple times), we would be doing the work in `...` multiple times.
-
-So `callArityAnalProgram` looks at the whole let expression to figure out if
-all calls are nice, i.e. have a high enough arity. It then stores the result in
-the `calledArity` field of the `IdInfo` of `go`, which the next simplifier
-phase will eta-expand.
-
-The specification of the `calledArity` field is:
-
-    No work will be lost if you eta-expand me to the arity in `calledArity`.
-
-What we want to know for a variable
------------------------------------
-
-For every let-bound variable we'd like to know:
-  1. A lower bound on the arity of all calls to the variable, and
-  2. whether the variable is being called at most once or possible multiple
-     times.
-
-It is always ok to lower the arity, or pretend that there are multiple calls.
-In particular, "Minimum arity 0 and possible called multiple times" is always
-correct.
-
-
-What we want to know from an expression
----------------------------------------
-
-In order to obtain that information for variables, we analyize expression and
-obtain bits of information:
-
- I.  The arity analysis:
-     For every variable, whether it is absent, or called,
-     and if called, which what arity.
-
- II. The Co-Called analysis:
-     For every two variables, whether there is a possibility that both are being
-     called.
-     We obtain as a special case: For every variables, whether there is a
-     possibility that it is being called twice.
-
-For efficiency reasons, we gather this information only for a set of
-*interesting variables*, to avoid spending time on, e.g., variables from pattern matches.
-
-The two analysis are not completely independent, as a higher arity can improve
-the information about what variables are being called once or multiple times.
-
-Note [Analysis I: The arity analyis]
-------------------------------------
-
-The arity analysis is quite straight forward: The information about an
-expression is an
-    VarEnv Arity
-where absent variables are bound to Nothing and otherwise to a lower bound to
-their arity.
-
-When we analyize an expression, we analyize it with a given context arity.
-Lambdas decrease and applications increase the incoming arity. Analysizing a
-variable will put that arity in the environment. In lets or cases all the
-results from the various subexpressions are lubed, which takes the point-wise
-minimum (considering Nothing an infinity).
-
-
-Note [Analysis II: The Co-Called analysis]
-------------------------------------------
-
-The second part is more sophisticated. For reasons explained below, it is not
-sufficient to simply know how often an expression evaluates a variable. Instead
-we need to know which variables are possibly called together.
-
-The data structure here is an undirected graph of variables, which is provided
-by the abstract
-    UnVarGraph
-
-It is safe to return a larger graph, i.e. one with more edges. The worst case
-(i.e. the least useful and always correct result) is the complete graph on all
-free variables, which means that anything can be called together with anything
-(including itself).
-
-Notation for the following:
-C(e)  is the co-called result for e.
-G₁∪G₂ is the union of two graphs
-fv    is the set of free variables (conveniently the domain of the arity analysis result)
-S₁×S₂ is the complete bipartite graph { {a,b} | a ∈ S₁, b ∈ S₂ }
-S²    is the complete graph on the set of variables S, S² = S×S
-C'(e) is a variant for bound expression:
-      If e is called at most once, or it is and stays a thunk (after the analysis),
-      it is simply C(e). Otherwise, the expression can be called multiple times
-      and we return (fv e)²
-
-The interesting cases of the analysis:
- * Var v:
-   No other variables are being called.
-   Return {} (the empty graph)
- * Lambda v e, under arity 0:
-   This means that e can be evaluated many times and we cannot get
-   any useful co-call information.
-   Return (fv e)²
- * Case alternatives alt₁,alt₂,...:
-   Only one can be execuded, so
-   Return (alt₁ ∪ alt₂ ∪...)
- * App e₁ e₂ (and analogously Case scrut alts), with non-trivial e₂:
-   We get the results from both sides, with the argument evaluated at most once.
-   Additionally, anything called by e₁ can possibly be called with anything
-   from e₂.
-   Return: C(e₁) ∪ C(e₂) ∪ (fv e₁) × (fv e₂)
- * App e₁ x:
-   As this is already in A-normal form, CorePrep will not separately lambda
-   bind (and hence share) x. So we conservatively assume multiple calls to x here
-   Return: C(e₁) ∪ (fv e₁) × {x} ∪ {(x,x)}
- * Let v = rhs in body:
-   In addition to the results from the subexpressions, add all co-calls from
-   everything that the body calls together with v to everthing that is called
-   by v.
-   Return: C'(rhs) ∪ C(body) ∪ (fv rhs) × {v'| {v,v'} ∈ C(body)}
- * Letrec v₁ = rhs₁ ... vₙ = rhsₙ in body
-   Tricky.
-   We assume that it is really mutually recursive, i.e. that every variable
-   calls one of the others, and that this is strongly connected (otherwise we
-   return an over-approximation, so that's ok), see note [Recursion and fixpointing].
-
-   Let V = {v₁,...vₙ}.
-   Assume that the vs have been analysed with an incoming demand and
-   cardinality consistent with the final result (this is the fixed-pointing).
-   Again we can use the results from all subexpressions.
-   In addition, for every variable vᵢ, we need to find out what it is called
-   with (call this set Sᵢ). There are two cases:
-    * If vᵢ is a function, we need to go through all right-hand-sides and bodies,
-      and collect every variable that is called together with any variable from V:
-      Sᵢ = {v' | j ∈ {1,...,n},      {v',vⱼ} ∈ C'(rhs₁) ∪ ... ∪ C'(rhsₙ) ∪ C(body) }
-    * If vᵢ is a thunk, then its rhs is evaluated only once, so we need to
-      exclude it from this set:
-      Sᵢ = {v' | j ∈ {1,...,n}, j≠i, {v',vⱼ} ∈ C'(rhs₁) ∪ ... ∪ C'(rhsₙ) ∪ C(body) }
-   Finally, combine all this:
-   Return: C(body) ∪
-           C'(rhs₁) ∪ ... ∪ C'(rhsₙ) ∪
-           (fv rhs₁) × S₁) ∪ ... ∪ (fv rhsₙ) × Sₙ)
-
-Using the result: Eta-Expansion
--------------------------------
-
-We use the result of these two analyses to decide whether we can eta-expand the
-rhs of a let-bound variable.
-
-If the variable is already a function (exprIsCheap), and all calls to the
-variables have a higher arity than the current manifest arity (i.e. the number
-of lambdas), expand.
-
-If the variable is a thunk we must be careful: Eta-Expansion will prevent
-sharing of work, so this is only safe if there is at most one call to the
-function. Therefore, we check whether {v,v} ∈ G.
-
-    Example:
-
-        let n = case .. of .. -- A thunk!
-        in n 0 + n 1
-
-    vs.
-
-        let n = case .. of ..
-        in case .. of T -> n 0
-                      F -> n 1
-
-    We are only allowed to eta-expand `n` if it is going to be called at most
-    once in the body of the outer let. So we need to know, for each variable
-    individually, that it is going to be called at most once.
-
-
-Why the co-call graph?
-----------------------
-
-Why is it not sufficient to simply remember which variables are called once and
-which are called multiple times? It would be in the previous example, but consider
-
-        let n = case .. of ..
-        in case .. of
-            True -> let go = \y -> case .. of
-                                     True -> go (y + n 1)
-                                     False > n
-                    in go 1
-            False -> n
-
-vs.
-
-        let n = case .. of ..
-        in case .. of
-            True -> let go = \y -> case .. of
-                                     True -> go (y+1)
-                                     False > n
-                    in go 1
-            False -> n
-
-In both cases, the body and the rhs of the inner let call n at most once.
-But only in the second case that holds for the whole expression! The
-crucial difference is that in the first case, the rhs of `go` can call
-*both* `go` and `n`, and hence can call `n` multiple times as it recurses,
-while in the second case find out that `go` and `n` are not called together.
-
-
-Why co-call information for functions?
---------------------------------------
-
-Although for eta-expansion we need the information only for thunks, we still
-need to know whether functions are being called once or multiple times, and
-together with what other functions.
-
-    Example:
-
-        let n = case .. of ..
-            f x = n (x+1)
-        in f 1 + f 2
-
-    vs.
-
-        let n = case .. of ..
-            f x = n (x+1)
-        in case .. of T -> f 0
-                      F -> f 1
-
-    Here, the body of f calls n exactly once, but f itself is being called
-    multiple times, so eta-expansion is not allowed.
-
-
-Note [Analysis type signature]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-The work-hourse of the analysis is the function `callArityAnal`, with the
-following type:
-
-    type CallArityType = (UnVarGraph, VarEnv Arity)
-    callArityAnal ::
-        Arity ->  -- The arity this expression is called with
-        VarSet -> -- The set of interesting variables
-        CoreExpr ->  -- The expression to analyse
-        (CallArityType, CoreExpr)
-
-and the following specification:
-
-  ((coCalls, callArityEnv), expr') = callArityEnv arity interestingIds expr
-
-                            <=>
-
-  Assume the expression `expr` is being passed `arity` arguments. Then it holds that
-    * The domain of `callArityEnv` is a subset of `interestingIds`.
-    * Any variable from `interestingIds` that is not mentioned in the `callArityEnv`
-      is absent, i.e. not called at all.
-    * Every call from `expr` to a variable bound to n in `callArityEnv` has at
-      least n value arguments.
-    * For two interesting variables `v1` and `v2`, they are not adjacent in `coCalls`,
-      then in no execution of `expr` both are being called.
-  Furthermore, expr' is expr with the callArity field of the `IdInfo` updated.
-
-
-Note [Which variables are interesting]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-The analysis would quickly become prohibitive expensive if we would analyse all
-variables; for most variables we simply do not care about how often they are
-called, i.e. variables bound in a pattern match. So interesting are variables that are
- * top-level or let bound
- * and possibly functions (typeArity > 0)
-
-Note [Taking boring variables into account]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-If we decide that the variable bound in `let x = e1 in e2` is not interesting,
-the analysis of `e2` will not report anything about `x`. To ensure that
-`callArityBind` does still do the right thing we have to take that into account
-everytime we look up up `x` in the analysis result of `e2`.
-  * Instead of calling lookupCallArityType, we return (0, True), indicating
-    that this variable might be called many times with no arguments.
-  * Instead of checking `calledWith x`, we assume that everything can be called
-    with it.
-  * In the recursive case, when calclulating the `cross_calls`, if there is
-    any boring variable in the recursive group, we ignore all co-call-results
-    and directly go to a very conservative assumption.
-
-The last point has the nice side effect that the relatively expensive
-integration of co-call results in a recursive groups is often skipped. This
-helped to avoid the compile time blowup in some real-world code with large
-recursive groups (#10293).
-
-Note [Recursion and fixpointing]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-For a mutually recursive let, we begin by
- 1. analysing the body, using the same incoming arity as for the whole expression.
- 2. Then we iterate, memoizing for each of the bound variables the last
-    analysis call, i.e. incoming arity, whether it is called once, and the CallArityType.
- 3. We combine the analysis result from the body and the memoized results for
-    the arguments (if already present).
- 4. For each variable, we find out the incoming arity and whether it is called
-    once, based on the the current analysis result. If this differs from the
-    memoized results, we re-analyse the rhs and update the memoized table.
- 5. If nothing had to be reanalyzed, we are done.
-    Otherwise, repeat from step 3.
-
-
-Note [Thunks in recursive groups]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-We never eta-expand a thunk in a recursive group, on the grounds that if it is
-part of a recursive group, then it will be called multipe times.
-
-This is not necessarily true, e.g.  it would be safe to eta-expand t2 (but not
-t1) in the following code:
-
-  let go x = t1
-      t1 = if ... then t2 else ...
-      t2 = if ... then go 1 else ...
-  in go 0
-
-Detecting this would require finding out what variables are only ever called
-from thunks. While this is certainly possible, we yet have to see this to be
-relevant in the wild.
-
-
-Note [Analysing top-level binds]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-We can eta-expand top-level-binds if they are not exported, as we see all calls
-to them. The plan is as follows: Treat the top-level binds as nested lets around
-a body representing “all external calls”, which returns a pessimistic
-CallArityType (the co-call graph is the complete graph, all arityies 0).
-
-Note [Trimming arity]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-In the Call Arity papers, we are working on an untyped lambda calculus with no
-other id annotations, where eta-expansion is always possible. But this is not
-the case for Core!
- 1. We need to ensure the invariant
-      callArity e <= typeArity (exprType e)
-    for the same reasons that exprArity needs this invariant (see Note
-    [exprArity invariant] in CoreArity).
-
-    If we are not doing that, a too-high arity annotation will be stored with
-    the id, confusing the simplifier later on.
-
- 2. Eta-expanding a right hand side might invalidate existing annotations. In
-    particular, if an id has a strictness annotation of <...><...>b, then
-    passing two arguments to it will definitely bottom out, so the simplifier
-    will throw away additional parameters. This conflicts with Call Arity! So
-    we ensure that we never eta-expand such a value beyond the number of
-    arguments mentioned in the strictness signature.
-    See #10176 for a real-world-example.
-
-Note [What is a thunk]
-~~~~~~~~~~~~~~~~~~~~~~
-
-Originally, everything that is not in WHNF (`exprIsWHNF`) is considered a
-thunk, not eta-expanded, to avoid losing any sharing. This is also how the
-published papers on Call Arity describe it.
-
-In practice, there are thunks that do a just little work, such as
-pattern-matching on a variable, and the benefits of eta-expansion likely
-oughtweigh the cost of doing that repeatedly. Therefore, this implementation of
-Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
--}
-
-
--- See Note [Analysing top-level-binds]
--- Represents the fact that a CoreProgram is like a sequence of
--- nested lets, where the exports are returned in the inner-most let
--- as a tuple. As a result, all exported identifiers are handled as called
--- with each other, with arity 0.
-moduleToExpr :: CoreProgram -> CoreExpr
-moduleToExpr = impl []
-  where
-    impl exported [] = mkBigCoreTup (map Var exported)
-    impl exported (bind:prog) = Let bind (impl (filter isExportedId (bindersOf bind) ++ exported) prog)
-
-exprToModule :: CoreExpr -> CoreProgram
-exprToModule (Let bind e) = bind : exprToModule e
-exprToModule _ = []
-
--- Main entry point
-callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
-callArityAnalProgram _dflags = exprToModule . callArityRHS . moduleToExpr
-
-callArityRHS :: CoreExpr -> CoreExpr
-callArityRHS e = lookup_expr (runFramework fw (Set.singleton (node, 0)))
-  where
-    (node, fw) = buildFramework $
-      registerTransferFunction (LowerThan (FrameworkNode 0)) $ \node -> do
-        transfer <- callArityExpr emptyVarEnv e
-        -- We only get away with using alwaysChangeDetector because this won't
-        -- introduce a cycle.
-        return (node, (transfer, alwaysChangeDetector))
-
-    lookup_expr :: Map (FrameworkNode, Arity) AnalResult -> CoreExpr
-    lookup_expr result_map = case Map.lookup (node, 0) result_map of
-      Nothing -> pprPanic "callArityRHS" empty
-      Just (_, e) -> e
-
--- | How an expression uses its interesting variables
--- and the expression with annotated Ids
-type AnalResult = (CallArityType, CoreExpr)
-
-newtype FrameworkNode
-  = FrameworkNode Int
-  deriving (Show, Eq, Ord, Outputable)
-
-type TransferFunction' a = TransferFunction (FrameworkNode, Arity) AnalResult a
-type ChangeDetector' = ChangeDetector (FrameworkNode, Arity) AnalResult
-type DataFlowFramework' = DataFlowFramework (FrameworkNode, Arity) AnalResult
-
-newtype FrameworkBuilder a
-  = FB { unFB :: State (IntMap (Arity -> TransferFunction' AnalResult, ChangeDetector')) a }
-  deriving (Functor, Applicative, Monad)
-
-buildFramework :: FrameworkBuilder a -> (a, DataFlowFramework')
-buildFramework (FB state) = (res, DFF dff)
-  where
-    (res, env) = runState state IntMap.empty
-    dff (FrameworkNode node, arity) = case IntMap.lookup node env of
-      Nothing -> pprPanic "CallArity.buildFramework" (ppr node)
-      Just (transfer, detectChange) -> (transfer arity, detectChange)
-
-data RequestedPriority
-  = LowerThan FrameworkNode
-  | HighestAvailable
-
-registerTransferFunction
-  :: RequestedPriority
-  -> (FrameworkNode -> FrameworkBuilder (a, (Arity -> TransferFunction' AnalResult, ChangeDetector')))
-  -> FrameworkBuilder a
-registerTransferFunction prio f = FB $ do
-  nodes <- get
-  let node = case prio of
-        HighestAvailable -> 2 * IntMap.size nodes
-        LowerThan (FrameworkNode node)
-          | not (IntMap.member (node - 1) nodes) -> node - 1
-          | otherwise -> pprPanic "registerTransferFunction" (text "There was already a node registered with priority" <+> ppr (node - 1))
-  (result, _) <- mfix $ \ ~(_, entry) -> do
-    -- Using mfix so that we can spare an unnecessary Int counter in the state
-    modify' (IntMap.insert node entry)
-    unFB (f (FrameworkNode node))
-  return result
-
-dependOn' :: (FrameworkNode, Arity) -> TransferFunction' (Maybe AnalResult)
-dependOn' (node, arity) = do
-  --pprTrace "dependOn':before" (text "node:" <+> ppr node <+> text "arity:" <+> ppr arity) $ return ()
-  res <- dependOn (node, arity)
-  --pprTrace "dependOn':after" (vcat [text "node:" <+> ppr node, text "arity:" <+> ppr arity, text "res:" <+> ppr res]) $ return ()
-  return res
-
--- | The main analysis function. See Note [Analysis type signature]
-callArityExpr
-  :: VarEnv FrameworkNode
-  -> CoreExpr
-  -> FrameworkBuilder (Arity -> TransferFunction' AnalResult)
-
-callArityExprTrivial
-  :: CoreExpr
-  -> FrameworkBuilder (Arity -> TransferFunction' AnalResult)
-callArityExprTrivial e
-  = return (\_ -> return (emptyArityType, e))
-
-callArityExprTransparent
-  :: VarEnv FrameworkNode
-  -> (CoreExpr -> a)
-  -> CoreExpr
-  -> FrameworkBuilder (Arity -> TransferFunction' (CallArityType, a))
-callArityExprTransparent nodes f e
-  = transfer' <$> callArityExpr nodes e
-  where
-    transfer' transfer arity = do
-      (cat, e') <- transfer arity
-      return (cat, f e')
-
--- The trivial base cases
-callArityExpr _ e@(Lit _) = callArityExprTrivial e
-callArityExpr _ e@(Type _) = callArityExprTrivial e
-callArityExpr _ e@(Coercion _) = callArityExprTrivial e
-
--- The transparent cases
-callArityExpr nodes (Tick t e) = callArityExprTransparent nodes (Tick t) e
-callArityExpr nodes (Cast e c) = callArityExprTransparent nodes (flip Cast c) e
-
--- The interesting cases: Variables, Lambdas, Lets, Applications, Cases
-callArityExpr nodes e@(Var v) = return transfer
-  where
-    transfer arity
-      | isInteresting v
-      , Just node <- lookupVarEnv nodes v
-      = do
-        (cat_callee, _) <- fromMaybe (unusedArgsArityType arity, e) <$> dependOn' (node, arity)
-        return ((unitArityType v arity) { cat_args = cat_args cat_callee }, e)
-
-      | isInteresting v
-      = return (unitArityType v arity, e) -- TODO: lookup sig if present
-
-      | otherwise
-      = return (emptyArityType, e)
-
--- Non-value lambdas are ignored
-callArityExpr nodes (Lam v e)
-  | not (isId v) = callArityExprTransparent nodes (Lam v) e
-  | otherwise    = transfer' <$> callArityExpr nodes e
-  where
-    -- We have a lambda that may be called multiple times, so its free variables
-    -- can all be co-called.
-    -- Also regardless of the variable not being interesting,
-    -- we have to add the var as an argument.
-    transfer' transfer 0 = do
-      (cat, e') <- transfer 0
-      return (makeIdArg v (calledMultipleTimes cat), Lam v e')
-    -- We have a lambda that we are calling. decrease arity.
-    transfer' transfer arity = do
-      (cat, e') <- transfer (arity - 1)
-      return (makeIdArg v cat, Lam v e')
-
-callArityExpr nodes (App f (Type t)) = callArityExprTransparent nodes (flip App (Type t)) f
-
--- Application. Increase arity for the called expression, nothing to know about
--- the second
-callArityExpr nodes (App f a) = do
-  transfer_f <- callArityExpr nodes f
-  transfer_a <- callArityExpr nodes a
-  return $ \arity -> do
-    (cat_f, f') <- transfer_f (arity + 1)
-    --pprTrace "App:f'" (ppr (cat_f, f')) $ return ()
-    -- peel off one argument from the type
-    case peelCallArityType a cat_f of
-      (Nothing, cat_f') -> return (cat_f', App f' a) -- TODO: Visit a, too? Seems unnecessary, wasn't called at all
-      (Just (arg_arity, called_once), cat_f') -> do
-        -- a' might be a thunk, in which case we may only eta-expand if it's called once.
-        -- We could look at the called expression to tell if it returns a thunk...
-        -- But for now let's just assume it is.
-        -- So: TODO: recognize if a' is a thunk.
-        -- How? collectBinder? Do we actually win something? Yes, foldr's higher-order argument
-        -- This has some parallels to `let cache = f x in cache 1 + cache 2`, where
-        -- we also check if `cache` is a thunk (in which case we don't expand) or not.
-        let safe_arity = if called_once || exprIsCheap a then arg_arity else 0
-        (cat_a, a') <- transfer_a safe_arity
-        --pprTrace "App:a'" (text "safe_arity:" <+> ppr safe_arity <+> ppr (cat_a, a')) $ return ()
-        let cat_a' | called_once    = cat_a
-                   | arg_arity == 0 = cat_a
-                   | otherwise      = calledMultipleTimes cat_a
-        return (cat_f' `both` cat_a', App f' a')
-
--- Case expression.
-callArityExpr nodes (Case scrut bndr ty alts) = do
-  transfer_scrut <- callArityExpr nodes scrut
-    -- TODO: Do we have to do something special with bndr?
-    --       Don't think so, we can't make use of the information.
-    --       We also shouldn't track them to the co call graph (they are boring)
-  transfer_alts <- forM alts $ \(dc, bndrs, e) ->
-    callArityExprTransparent nodes (dc, bndrs,) e
-  return $ \arity -> do
-    (cat_scrut, scrut') <- transfer_scrut 0
-    (cat_alts, alts') <- unzip <$> mapM ($ arity) transfer_alts
-    let cat = trimArgs arity (lubTypes cat_alts) `both` cat_scrut
-    -- TODO: Think harder about the diverging case (e.g. matching on `undefined`).
-    --       In that case we will declare all arguments as unused from the alts.
-    -- pprTrace "callArityExpr:Case"
-    --          (vcat [ppr scrut, ppr cat])
-    --pprTrace "Case" (vcat [text "cat_scrut:" <+> ppr cat_scrut, text "cat_alts:" <+> ppr cat_alts, text "cat:" <+> ppr cat]) (return ())
-    return (cat, Case scrut' bndr ty alts')
-
-callArityExpr letdown_nodes (Let bind e) = do
-  let binds = flattenBinds [bind]
-  -- The order in which we call callArityExpr here is important: This makes sure
-  -- the FP iteration will first stabilize bindings before analyzing the body.
-  -- Nope, in fact it does exactly the opposite!
-  (letdown_nodes', letup_nodes) <- callArityBind letdown_nodes binds
-  let transfer_rhs (id, rhs) arity =
-        fromMaybe (unusedArgsArityType arity, rhs) <$> dependOn' (fromJust (lookupVarEnv letup_nodes id), arity)
-  let transfer_rhss = map transfer_rhs binds
-  transfer_body <- callArityExpr letdown_nodes' e
-
-  let zip213 = zipWith (\(a, b) c -> (a, b, c))
-
-  case bind of
-    NonRec _ _ ->
-      -- We don't need to dependOn ourselves here, because only the let body can
-      -- call id.
-      return $ \arity -> do
-        (cat_body, e') <- transfer_body arity
-        let bind_with_transfer = zip213 binds transfer_rhss
-        (cat, [(id', rhs')]) <- unleashLet False bind_with_transfer cat_body cat_body
-        return (typeDelList (bindersOf bind) cat, Let (NonRec id' rhs') e')
-    Rec _ -> do
-      -- This is a little more complicated, as we'll introduce a new FrameworkNode
-      -- which we'll depend on ourselves.
-      node <- registerTransferFunction (LowerThan (minimum (eltsUFM letup_nodes))) $ \node -> do
-        let transfer arity = do
-              (cat_body, e') <- transfer_body arity
-              -- This is the actual fixed-point iteration: we depend on usage
-              -- results from the previous iteration, defaulting to just the body.
-              (cat_usage, Let (Rec old_bind) _) <- fromMaybe (cat_body, Let bind e') <$> dependOn' (node, arity)
-              let bind_with_transfer = zip213 old_bind transfer_rhss
-              (cat, bind') <- unleashLet True bind_with_transfer cat_usage cat_body
-              return (cat, Let (Rec bind') e')
-
-        let change_detector changed_refs (old, _) (new, _) =
-              -- since we only care for arity and called once information of the
-              -- previous iteration, we cann efficiently test for changes.
-              --pprTrace "change_detector" (vcat[ppr node, ppr changed_refs, ppr old, ppr new])
-              map fst (Set.toList changed_refs) /= [node]
-              || any (\id -> lookupCallArityType old id /= lookupCallArityType new id) (map fst binds)
-
-        return (node, (transfer, change_detector))
-
-      -- Now for the actual TransferFunction of this expr...
-      return $ \arity -> do
-        (cat, let') <- fromMaybe (emptyArityType, Let bind e) <$> dependOn' (node, arity)
-        --pprTrace "Let" (ppr (cat, let')) $ return ()
-        return (typeDelList (bindersOf bind) cat, let')
-
-callArityBind
-  :: VarEnv FrameworkNode
-  -> [(Id, CoreExpr)]
-  -> FrameworkBuilder (VarEnv FrameworkNode, VarEnv FrameworkNode)
-callArityBind letdown_nodes = go letdown_nodes emptyVarEnv
-  where
-    go letdown_nodes letup_nodes [] = return (letdown_nodes, letup_nodes)
-    go letdown_nodes letup_nodes ((id, rhs):binds) =
-      registerTransferFunction HighestAvailable $ \letup_node ->
-        registerTransferFunction HighestAvailable $ \letdown_node -> do
-          (letdown_nodes', letup_nodes') <- go
-            (extendVarEnv letdown_nodes id letdown_node)
-            (extendVarEnv letup_nodes id letup_node)
-            binds
-          transfer_up' <- callArityExpr letdown_nodes' rhs
-          let transfer_up arity = do
-                --pprTrace "Bind:Before" (text "id:" <+> ppr id <+> text "arity:" <+> ppr arity) $ return ()
-                res <- transfer_up' arity
-                --pprTrace "Bind:Finished" (ppr res) $ return ()
-                return res
-          let transfer_down arity = fromMaybe (unusedArgsArityType arity, rhs) <$> dependOn' (letup_node, arity)
-          let change_detector_down _ (old, _) (new, _) =
-                -- The only reason we split the transfer fuctions up is cheap
-                -- change detection for the LetDown case. This implies that
-                -- use sites of the LetDown component may only use the cat_args
-                -- component!
-                -- FIXME: Encode this in the FrameworkNode type somehow, but I
-                -- don't think it's worth the trouble.
-                --pprTrace "change_detector_down" (ppr (cat_args old) <+> ppr (cat_args new) <+> ppr (cat_args old /= cat_args new)) $
-                cat_args old /= cat_args new
-          let ret = (letdown_nodes', letup_nodes') -- What we return from callArityBind
-          let letup = (transfer_up, alwaysChangeDetector) -- What we register for letup_node
-          let letdown = (transfer_down, change_detector_down) -- What we register for letdown_node
-          return ((ret, letup), letdown) -- registerTransferFunction  will peel `snd`s away for registration
-
-unleashLet
-  :: Bool
-  -> [(Id, CoreExpr, Arity -> TransferFunction' AnalResult)]
-  -> CallArityType
-  -> CallArityType
-  -> TransferFunction' (CallArityType, [(Id, CoreExpr)])
-unleashLet is_recursive transferred_binds cat_usage cat_body = do
-  (cat_rhss, binds') <- unzip <$> mapM (unleashCall is_recursive cat_usage) transferred_binds
-  let ids = map fst binds'
-  let cat_final = callArityLetEnv (zip ids cat_rhss) cat_body
-  return (cat_final, binds')
-
-unleashCall
-  :: Bool
-  -> CallArityType
-  -> (Id, CoreExpr, Arity -> TransferFunction' AnalResult)
-  -> TransferFunction' (CallArityType, (Id, CoreExpr))
-unleashCall is_recursive cat_usage (id, rhs, transfer_rhs)
-  | isInteresting id && not (id `elemUnVarSet` domType cat_usage)
-  = return (emptyArityType, (id, rhs)) -- No call to `id` (yet)
-  | otherwise
-  = do
-    let boring = not (isInteresting id)
-        -- If v is boring, we will not find it in cat_usage, but always assume (0, False)
-        (arity, called_once)
-            | boring    = (0, False) -- See Note [Taking boring variables into account]
-            | otherwise = --pprTrace "CallArity.unleashCalls" (ppr id <+> ppr (lookupCallArityType cat_usage id)) $
-                          lookupCallArityType cat_usage id
-
-        -- See Note [Thunks in recursive groups]
-        safe_arity
-            | isThunk rhs && (is_recursive || not called_once) = 0 -- A thunk was called multiple times! Do not eta-expand
-            | otherwise = arity -- in the other cases it's safe to expand
-
-        -- See Note [Trimming arity]
-        trimmed_arity = trimArity id safe_arity
-
-    -- TODO: Find out if (where) we need the trimmed_arity here or not
-    -- We probably want to analyze with arity und annotate trimmed_arity.
-    -- Although CA analyzes with trimmed_arity, so we do that for now
-    (cat_rhs, rhs') <- transfer_rhs trimmed_arity
-    let cat_rhs' | called_once || safe_arity == 0 = cat_rhs
-                 | otherwise = calledMultipleTimes cat_rhs
-    return (cat_rhs', (id `setIdCallArity` trimmed_arity, rhs'))
-
-isThunk :: CoreExpr -> Bool
-isThunk = not . exprIsHNF
-
-peelCallArityType :: CoreExpr -> CallArityType -> (Maybe (Arity, Bool), CallArityType)
-peelCallArityType a ca_type = case cat_args ca_type of
-  arg:args -> (arg, ca_type { cat_args = args })
-  _ -> (Just (0, False), ca_type)
-  {- TODO: worry about this later
-  arg:args | isInteresting arg ->
-    -- TODO: not (exprIsTrivial a)?
-    -- TODO: called_once when arity = 0?
-    let (arity, called_once) = lookupCallArityType ca_type arg
-        ca_type' = typeDel arg ca_type
-    in  (arity, called_once, ca_type')
-  _:_ -> (0, False, ca_type) -- See Note [Taking boring variables into account]
-  [] -> (0, not (exprIsTrivial a), ca_type)
-    -- the called function had no signature or has not
-    -- been analysed with high enough incoming arity
-    -- (e.g. when loading the signature from an imported id).
-    -- ca_f is rather useless for analysing a, so
-    -- be consersative assume incoming arity 0.
-    --
-    -- Also, if the argument is trivial (e.g. a variable), then it will _not_ be
-    -- let-bound in the Core to STG transformation (CorePrep actually),
-    -- so no sharing will happen here, and we have to assume many calls.
-    -}
-
--- Which bindings should we look at?
--- See Note [Which variables are interesting]
-isInteresting :: Var -> Bool
-isInteresting v = not $ null (typeArity (idType v))
-
--- Combining the results from body and rhs of a let binding
--- See Note [Analysis II: The Co-Called analysis]
-callArityLetEnv
-  :: [(Var, CallArityType)]
-  -> CallArityType
-  -> CallArityType
-callArityLetEnv cat_rhss cat_body
-    = -- (if length ae_rhss > 300 then pprTrace "callArityLetEnv" (vcat [ppr ae_rhss, ppr ae_body, ppr ae_new]) else id) $
-      cat_new
-  where
-    vars = map fst cat_rhss
-
-    -- This is already the complete type, but with references from the current
-    -- binding group not resolved.
-    -- For the non-recursive case, at least cat_body may refer to some bound var
-    -- which we have to handle, for the recursive case even any of cat_rhss may.
-    -- This is why we have to union in appropriate cross_calls, which basically
-    -- perform substitution of Id to CallArityType.
-    cat_combined = lubTypes (cat_body : map (unusedArgs . snd) cat_rhss)
-
-    cross_calls
-        -- Calculating cross_calls is expensive. Simply be conservative
-        -- if the mutually recursive group becomes too large.
-        -- TODO: I *think* 5 is enough here, but this used to be 25.
-        | length cat_rhss > 5 = completeGraph (domType cat_combined)
-        | otherwise            = unionUnVarGraphs $ map cross_call cat_rhss
-    cross_call (v, cat_rhs) = completeBipartiteGraph called_by_v called_with_v
-      where
-        is_thunk = idCallArity v == 0 -- This is an old annotation, possibly from the last FP iteration
-        -- We only add self cross calls if we really can recurse into ourselves.
-        -- This is not the case for thunks (and non-recursive bindings, but
-        -- then there won't be any mention of v in the rhs).
-        -- A thunk is not evaluated more than once, so the only
-        -- relevant calls are from other bindings or the body.
-        -- What rhs are relevant as happening before (or after) calling v?
-        --    If v doesn't recurse into itself, everything from all the _other_ variables
-        --    If v is self-recursive, everything can happen.
-        cat_before_v
-            | is_thunk  = lubTypes (cat_body : map (unusedArgs . snd) (filter ((/= v) . fst) cat_rhss))
-            | otherwise = cat_combined
-        -- What do we want to know from these?
-        -- Which calls can happen next to any recursive call.
-        called_with_v = unionUnVarSets $ map (calledWith cat_before_v) vars
-        called_by_v = domType cat_rhs
-
-    cat_new = modifyCoCalls (cross_calls `unionUnVarGraph`) cat_combined
-
--- See Note [Trimming arity]
-trimArity :: Id -> Arity -> Arity
-trimArity v a = minimum [a, max_arity_by_type, max_arity_by_strsig]
-  where
-    max_arity_by_type = length (typeArity (idType v))
-    max_arity_by_strsig
-        | isBotRes result_info = length demands
-        | otherwise = a
-
-    (demands, result_info) = splitStrictSig (idStrictness v)
-
----------------------------------------
--- Functions related to CallArityType --
----------------------------------------
-
--- Result type for the two analyses.
--- See Note [Analysis I: The arity analyis]
--- and Note [Analysis II: The Co-Called analysis]
-data CallArityType
-  = CAT
-  { cat_cocalled :: UnVarGraph
-  , cat_arities :: VarEnv Arity
-  , cat_args :: [Maybe (Arity, Bool)]
-  }
-
-instance Outputable CallArityType where
-  ppr (CAT cocalled arities args) =
-    text "arg demands:" <+> ppr args
-    <+> text "co-calls:" <+> ppr cocalled
-    <+> text "arities:" <+> ppr arities
-
-emptyArityType :: CallArityType
-emptyArityType = CAT emptyUnVarGraph emptyVarEnv []
-
-unitArityType :: Var -> Arity -> CallArityType
-unitArityType v arity = emptyArityType { cat_arities = unitVarEnv v arity }
-
-unusedArgsArityType :: Int -> CallArityType
-unusedArgsArityType arity = trimArgs arity (unusedArgs emptyArityType)
-
-unusedArgs :: CallArityType -> CallArityType
-unusedArgs cat = cat { cat_args = repeat Nothing }
-
-trimArgs :: Int -> CallArityType -> CallArityType
-trimArgs arity cat = cat { cat_args = take arity (cat_args cat) }
-
-typeDelList :: [Var] -> CallArityType -> CallArityType
-typeDelList vs ae = foldr typeDel ae vs
-
-typeDel :: Var -> CallArityType -> CallArityType
-typeDel v (CAT g ae args) = CAT (g `delNode` v) (ae `delVarEnv` v) args
-
-domType :: CallArityType -> UnVarSet
-domType ca_type = varEnvDom (cat_arities ca_type)
-
-makeIdArg :: Id -> CallArityType -> CallArityType
-makeIdArg id ca_type = typeDel id ca_type
-  { cat_args = Just (lookupCallArityType ca_type id) : cat_args ca_type }
-
--- In the result, find out the minimum arity and whether the variable is called
--- at most once.
-lookupCallArityType :: CallArityType -> Var -> (Arity, Bool)
-lookupCallArityType (CAT g ae _) v
-    = case lookupVarEnv ae v of
-        Just a -> (a, not (v `elemUnVarSet` neighbors g v))
-        Nothing -> (0, False)
-
-calledWith :: CallArityType -> Var -> UnVarSet
-calledWith ca_type v
-  | isInteresting v
-  = neighbors (cat_cocalled ca_type) v
-  | otherwise
-  = domType ca_type
-
-modifyCoCalls :: (UnVarGraph -> UnVarGraph) -> CallArityType -> CallArityType
-modifyCoCalls modifier ca_type
-  = ca_type { cat_cocalled = modifier (cat_cocalled ca_type) }
-
-addCrossCoCalls :: UnVarSet -> UnVarSet -> CallArityType -> CallArityType
-addCrossCoCalls set1 set2
-  = modifyCoCalls (completeBipartiteGraph set1 set2 `unionUnVarGraph`)
-
--- Replaces the co-call graph by a complete graph (i.e. no information)
-calledMultipleTimes :: CallArityType -> CallArityType
-calledMultipleTimes res = modifyCoCalls (const (completeGraph (domType res))) res
-
--- Used for application and cases
-both :: CallArityType -> CallArityType -> CallArityType
-both r1 r2 = addCrossCoCalls (domType r1) (domType r2) ((r1 `lubType` r2) { cat_args = cat_args r1 })
-
--- Used when combining results from alternative cases; take the minimum
-lubType :: CallArityType -> CallArityType -> CallArityType
-lubType (CAT g1 ae1 args1) (CAT g2 ae2 args2) -- both args should really be the same
-  = CAT (g1 `unionUnVarGraph` g2) (ae1 `lubArityEnv` ae2) (zipWith lubArg args1 args2)
-  where
-    lubArg Nothing b = b
-    lubArg a Nothing = a
-    lubArg (Just (arity1, _)) (Just (arity2, _)) = Just (min arity1 arity2, False)
-
-lubArityEnv :: VarEnv Arity -> VarEnv Arity -> VarEnv Arity
-lubArityEnv = plusVarEnv_C min
-
-lubTypes :: [CallArityType] -> CallArityType
-lubTypes = foldl lubType (unusedArgs emptyArityType) -- note that this isn't safe for empty input, because of unusedArgs.
+import CallArity.Analysis ( callArityAnalProgram )
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
new file mode 100644
index 0000000000..9cd289877d
--- /dev/null
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -0,0 +1,796 @@
+{-# LANGUAGE TupleSections #-}
+--
+-- Copyright (c) 2014 Joachim Breitner
+--
+
+module CallArity.Analysis where
+
+import CallArity.Types
+import CallArity.FrameworkBuilder
+
+import DynFlags      (DynFlags)
+import Maybes
+import VarEnv
+
+import Data.Map.Strict   (Map)
+import qualified Data.Map.Strict as Map
+import Data.Maybe
+import qualified Data.Set as Set
+
+import BasicTypes
+import CoreSyn
+import CoreArity ( typeArity )
+import CoreUtils ( exprIsCheap )
+import MkCore
+import Id
+import Outputable
+import Demand
+import UniqFM
+import UnVarGraph
+
+
+{-
+%************************************************************************
+%*                                                                      *
+              Call Arity Analyis
+%*                                                                      *
+%************************************************************************
+
+Note [Call Arity: The goal]
+~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+The goal of this analysis is to find out if we can eta-expand a local function,
+based on how it is being called. The motivating example is this code,
+which comes up when we implement foldl using foldr, and do list fusion:
+
+    let go = \x -> let d = case ... of
+                              False -> go (x+1)
+                              True  -> id
+                   in \z -> d (x + z)
+    in go 1 0
+
+If we do not eta-expand `go` to have arity 2, we are going to allocate a lot of
+partial function applications, which would be bad.
+
+The function `go` has a type of arity two, but only one lambda is manifest.
+Furthermore, an analysis that only looks at the RHS of go cannot be sufficient
+to eta-expand go: If `go` is ever called with one argument (and the result used
+multiple times), we would be doing the work in `...` multiple times.
+
+So `callArityAnalProgram` looks at the whole let expression to figure out if
+all calls are nice, i.e. have a high enough arity. It then stores the result in
+the `calledArity` field of the `IdInfo` of `go`, which the next simplifier
+phase will eta-expand.
+
+The specification of the `calledArity` field is:
+
+    No work will be lost if you eta-expand me to the arity in `calledArity`.
+
+What we want to know for a variable
+-----------------------------------
+
+For every let-bound variable we'd like to know:
+  1. A lower bound on the arity of all calls to the variable, and
+  2. whether the variable is being called at most once or possible multiple
+     times.
+
+It is always ok to lower the arity, or pretend that there are multiple calls.
+In particular, "Minimum arity 0 and possible called multiple times" is always
+correct.
+
+
+What we want to know from an expression
+---------------------------------------
+
+In order to obtain that information for variables, we analyize expression and
+obtain bits of information:
+
+ I.  The arity analysis:
+     For every variable, whether it is absent, or called,
+     and if called, which what arity.
+
+ II. The Co-Called analysis:
+     For every two variables, whether there is a possibility that both are being
+     called.
+     We obtain as a special case: For every variables, whether there is a
+     possibility that it is being called twice.
+
+For efficiency reasons, we gather this information only for a set of
+*interesting variables*, to avoid spending time on, e.g., variables from pattern matches.
+
+The two analysis are not completely independent, as a higher arity can improve
+the information about what variables are being called once or multiple times.
+
+Note [Analysis I: The arity analyis]
+------------------------------------
+
+The arity analysis is quite straight forward: The information about an
+expression is an
+    VarEnv Arity
+where absent variables are bound to Nothing and otherwise to a lower bound to
+their arity.
+
+When we analyize an expression, we analyize it with a given context arity.
+Lambdas decrease and applications increase the incoming arity. Analysizing a
+variable will put that arity in the environment. In lets or cases all the
+results from the various subexpressions are lubed, which takes the point-wise
+minimum (considering Nothing an infinity).
+
+
+Note [Analysis II: The Co-Called analysis]
+------------------------------------------
+
+The second part is more sophisticated. For reasons explained below, it is not
+sufficient to simply know how often an expression evalutes a variable. Instead
+we need to know which variables are possibly called together.
+
+The data structure here is an undirected graph of variables, which is provided
+by the abstract
+    UnVarGraph
+
+It is safe to return a larger graph, i.e. one with more edges. The worst case
+(i.e. the least useful and always correct result) is the complete graph on all
+free variables, which means that anything can be called together with anything
+(including itself).
+
+Notation for the following:
+C(e)  is the co-called result for e.
+G₁∪G₂ is the union of two graphs
+fv    is the set of free variables (conveniently the domain of the arity analysis result)
+S₁×S₂ is the complete bipartite graph { {a,b} | a ∈ S₁, b ∈ S₂ }
+S²    is the complete graph on the set of variables S, S² = S×S
+C'(e) is a variant for bound expression:
+      If e is called at most once, or it is and stays a thunk (after the analysis),
+      it is simply C(e). Otherwise, the expression can be called multiple times
+      and we return (fv e)²
+
+The interesting cases of the analysis:
+ * Var v:
+   No other variables are being called.
+   Return {} (the empty graph)
+ * Lambda v e, under arity 0:
+   This means that e can be evaluated many times and we cannot get
+   any useful co-call information.
+   Return (fv e)²
+ * Case alternatives alt₁,alt₂,...:
+   Only one can be execuded, so
+   Return (alt₁ ∪ alt₂ ∪...)
+ * App e₁ e₂ (and analogously Case scrut alts), with non-trivial e₂:
+   We get the results from both sides, with the argument evaluated at most once.
+   Additionally, anything called by e₁ can possibly be called with anything
+   from e₂.
+   Return: C(e₁) ∪ C(e₂) ∪ (fv e₁) × (fv e₂)
+ * App e₁ x:
+   As this is already in A-normal form, CorePrep will not separately lambda
+   bind (and hence share) x. So we conservatively assume multiple calls to x here
+   Return: C(e₁) ∪ (fv e₁) × {x} ∪ {(x,x)}
+ * Let v = rhs in body:
+   In addition to the results from the subexpressions, add all co-calls from
+   everything that the body calls together with v to everthing that is called
+   by v.
+   Return: C'(rhs) ∪ C(body) ∪ (fv rhs) × {v'| {v,v'} ∈ C(body)}
+ * Letrec v₁ = rhs₁ ... vₙ = rhsₙ in body
+   Tricky.
+   We assume that it is really mutually recursive, i.e. that every variable
+   calls one of the others, and that this is strongly connected (otherwise we
+   return an over-approximation, so that's ok), see note [Recursion and fixpointing].
+
+   Let V = {v₁,...vₙ}.
+   Assume that the vs have been analysed with an incoming demand and
+   cardinality consistent with the final result (this is the fixed-pointing).
+   Again we can use the results from all subexpressions.
+   In addition, for every variable vᵢ, we need to find out what it is called
+   with (call this set Sᵢ). There are two cases:
+    * If vᵢ is a function, we need to go through all right-hand-sides and bodies,
+      and collect every variable that is called together with any variable from V:
+      Sᵢ = {v' | j ∈ {1,...,n},      {v',vⱼ} ∈ C'(rhs₁) ∪ ... ∪ C'(rhsₙ) ∪ C(body) }
+    * If vᵢ is a thunk, then its rhs is evaluated only once, so we need to
+      exclude it from this set:
+      Sᵢ = {v' | j ∈ {1,...,n}, j≠i, {v',vⱼ} ∈ C'(rhs₁) ∪ ... ∪ C'(rhsₙ) ∪ C(body) }
+   Finally, combine all this:
+   Return: C(body) ∪
+           C'(rhs₁) ∪ ... ∪ C'(rhsₙ) ∪
+           (fv rhs₁) × S₁) ∪ ... ∪ (fv rhsₙ) × Sₙ)
+
+Using the result: Eta-Expansion
+-------------------------------
+
+We use the result of these two analyses to decide whether we can eta-expand the
+rhs of a let-bound variable.
+
+If the variable is already a function (exprIsCheap), and all calls to the
+variables have a higher arity than the current manifest arity (i.e. the number
+of lambdas), expand.
+
+If the variable is a thunk we must be careful: Eta-Expansion will prevent
+sharing of work, so this is only safe if there is at most one call to the
+function. Therefore, we check whether {v,v} ∈ G.
+
+    Example:
+
+        let n = case .. of .. -- A thunk!
+        in n 0 + n 1
+
+    vs.
+
+        let n = case .. of ..
+        in case .. of T -> n 0
+                      F -> n 1
+
+    We are only allowed to eta-expand `n` if it is going to be called at most
+    once in the body of the outer let. So we need to know, for each variable
+    individually, that it is going to be called at most once.
+
+
+Why the co-call graph?
+----------------------
+
+Why is it not sufficient to simply remember which variables are called once and
+which are called multiple times? It would be in the previous example, but consider
+
+        let n = case .. of ..
+        in case .. of
+            True -> let go = \y -> case .. of
+                                     True -> go (y + n 1)
+                                     False > n
+                    in go 1
+            False -> n
+
+vs.
+
+        let n = case .. of ..
+        in case .. of
+            True -> let go = \y -> case .. of
+                                     True -> go (y+1)
+                                     False > n
+                    in go 1
+            False -> n
+
+In both cases, the body and the rhs of the inner let call n at most once.
+But only in the second case that holds for the whole expression! The
+crucial difference is that in the first case, the rhs of `go` can call
+*both* `go` and `n`, and hence can call `n` multiple times as it recurses,
+while in the second case find out that `go` and `n` are not called together.
+
+
+Why co-call information for functions?
+--------------------------------------
+
+Although for eta-expansion we need the information only for thunks, we still
+need to know whether functions are being called once or multiple times, and
+together with what other functions.
+
+    Example:
+
+        let n = case .. of ..
+            f x = n (x+1)
+        in f 1 + f 2
+
+    vs.
+
+        let n = case .. of ..
+            f x = n (x+1)
+        in case .. of T -> f 0
+                      F -> f 1
+
+    Here, the body of f calls n exactly once, but f itself is being called
+    multiple times, so eta-expansion is not allowed.
+
+
+Note [Analysis type signature]
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+The work-hourse of the analysis is the function `callArityAnal`, with the
+following type:
+
+    type CallArityType = (UnVarGraph, VarEnv Arity)
+    callArityAnal ::
+        Arity ->  -- The arity this expression is called with
+        VarSet -> -- The set of interesting variables
+        CoreExpr ->  -- The expression to analyse
+        (CallArityType, CoreExpr)
+
+and the following specification:
+
+  ((coCalls, callArityEnv), expr') = callArityEnv arity interestingIds expr
+
+                            <=>
+
+  Assume the expression `expr` is being passed `arity` arguments. Then it holds that
+    * The domain of `callArityEnv` is a subset of `interestingIds`.
+    * Any variable from `interestingIds` that is not mentioned in the `callArityEnv`
+      is absent, i.e. not called at all.
+    * Every call from `expr` to a variable bound to n in `callArityEnv` has at
+      least n value arguments.
+    * For two interesting variables `v1` and `v2`, they are not adjacent in `coCalls`,
+      then in no execution of `expr` both are being called.
+  Furthermore, expr' is expr with the callArity field of the `IdInfo` updated.
+
+
+Note [Which variables are interesting]
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+The analysis would quickly become prohibitive expensive if we would analyse all
+variables; for most variables we simply do not care about how often they are
+called, i.e. variables bound in a pattern match. So interesting are variables that are
+ * top-level or let bound
+ * and possibly functions (typeArity > 0)
+
+Note [Taking boring variables into account]
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+If we decide that the variable bound in `let x = e1 in e2` is not interesting,
+the analysis of `e2` will not report anything about `x`. To ensure that
+`callArityBind` does still do the right thing we have to take that into account
+everytime we look up up `x` in the analysis result of `e2`.
+  * Instead of calling lookupCallArityType, we return (0, True), indicating
+    that this variable might be called many times with no arguments.
+  * Instead of checking `calledWith x`, we assume that everything can be called
+    with it.
+  * In the recursive case, when calclulating the `cross_calls`, if there is
+    any boring variable in the recursive group, we ignore all co-call-results
+    and directly go to a very conservative assumption.
+
+The last point has the nice side effect that the relatively expensive
+integration of co-call results in a recursive groups is often skipped. This
+helped to avoid the compile time blowup in some real-world code with large
+recursive groups (#10293).
+
+Note [Recursion and fixpointing]
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+For a mutually recursive let, we begin by
+ 1. analysing the body, using the same incoming arity as for the whole expression.
+ 2. Then we iterate, memoizing for each of the bound variables the last
+    analysis call, i.e. incoming arity, whether it is called once, and the CallArityType.
+ 3. We combine the analysis result from the body and the memoized results for
+    the arguments (if already present).
+ 4. For each variable, we find out the incoming arity and whether it is called
+    once, based on the the current analysis result. If this differs from the
+    memoized results, we re-analyse the rhs and update the memoized table.
+ 5. If nothing had to be reanalyzed, we are done.
+    Otherwise, repeat from step 3.
+
+
+Note [Thunks in recursive groups]
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+We never eta-expand a thunk in a recursive group, on the grounds that if it is
+part of a recursive group, then it will be called multipe times.
+
+This is not necessarily true, e.g.  it would be safe to eta-expand t2 (but not
+t1) in the following code:
+
+  let go x = t1
+      t1 = if ... then t2 else ...
+      t2 = if ... then go 1 else ...
+  in go 0
+
+Detecting this would require finding out what variables are only ever called
+from thunks. While this is certainly possible, we yet have to see this to be
+relevant in the wild.
+
+
+Note [Analysing top-level binds]
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+We can eta-expand top-level-binds if they are not exported, as we see all calls
+to them. The plan is as follows: Treat the top-level binds as nested lets around
+a body representing “all external calls”, which returns a pessimistic
+CallArityType (the co-call graph is the complete graph, all arityies 0).
+
+Note [Trimming arity]
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+In the Call Arity papers, we are working on an untyped lambda calculus with no
+other id annotations, where eta-expansion is always possible. But this is not
+the case for Core!
+ 1. We need to ensure the invariant
+      callArity e <= typeArity (exprType e)
+    for the same reasons that exprArity needs this invariant (see Note
+    [exprArity invariant] in CoreArity).
+
+    If we are not doing that, a too-high arity annotation will be stored with
+    the id, confusing the simplifier later on.
+
+ 2. Eta-expanding a right hand side might invalidate existing annotations. In
+    particular, if an id has a strictness annotation of <...><...>b, then
+    passing two arguments to it will definitely bottom out, so the simplifier
+    will throw away additional parameters. This conflicts with Call Arity! So
+    we ensure that we never eta-expand such a value beyond the number of
+    arguments mentioned in the strictness signature.
+    See #10176 for a real-world-example.
+
+Note [What is a thunk]
+~~~~~~~~~~~~~~~~~~~~~~
+
+Originally, everything that is not in WHNF (`exprIsWHNF`) is considered a
+thunk, not eta-expanded, to avoid losing any sharing. This is also how the
+published papers on Call Arity describe it.
+
+In practice, there are thunks that do a just little work, such as
+pattern-matching on a variable, and the benefits of eta-expansion likely
+oughtweigh the cost of doing that repeatedly. Therefore, this implementation of
+Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
+-}
+
+
+-- | See Note [Analysing top-level-binds]
+-- Represents the fact that a CoreProgram is like a sequence of
+-- nested lets, where the exports are returned in the inner-most let
+-- as a tuple. As a result, all exported identifiers are handled as called
+-- with each other, with arity 0.
+moduleToExpr :: CoreProgram -> CoreExpr
+moduleToExpr = impl []
+  where
+    impl exported [] = mkBigCoreTup (map Var exported)
+    impl exported (bind:prog) = Let bind (impl (filter isExportedId (bindersOf bind) ++ exported) prog)
+
+-- | The left inverse to @moduleToExpr@: @exprToModule . moduleToExpr = id \@CoreProgram@
+exprToModule :: CoreExpr -> CoreProgram
+exprToModule (Let bind e) = bind : exprToModule e
+exprToModule _ = []
+
+-- Main entry point
+callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
+callArityAnalProgram _dflags = exprToModule . callArityRHS . moduleToExpr
+
+callArityRHS :: CoreExpr -> CoreExpr
+callArityRHS e = lookup_expr (runFramework fw (Set.singleton (node, 0)))
+  where
+    (node, fw) = buildFramework $
+      registerTransferFunction (LowerThan (FrameworkNode 0)) $ \node -> do
+        transfer <- callArityExpr emptyVarEnv e
+        -- We only get away with using alwaysChangeDetector because this won't
+        -- introduce a cycle.
+        return (node, (transfer, alwaysChangeDetector))
+
+    lookup_expr :: Map (FrameworkNode, Arity) AnalResult -> CoreExpr
+    lookup_expr result_map = case Map.lookup (node, 0) result_map of
+      Nothing -> pprPanic "callArityRHS" empty
+      Just (_, e) -> e
+
+-- | The main analysis function. See Note [Analysis type signature]
+callArityExpr
+  :: VarEnv FrameworkNode
+  -> CoreExpr
+  -> FrameworkBuilder (Arity -> TransferFunction AnalResult)
+
+callArityExprTrivial
+  :: CoreExpr
+  -> FrameworkBuilder (Arity -> TransferFunction AnalResult)
+callArityExprTrivial e
+  = return (\_ -> return (emptyArityType, e))
+
+callArityExprMap
+  :: VarEnv FrameworkNode
+  -> (CoreExpr -> a)
+  -> CoreExpr
+  -> FrameworkBuilder (Arity -> TransferFunction (CallArityType, a)) -- @a@ instead of @CoreExpr@
+callArityExprMap nodes f e
+  = transfer' <$> callArityExpr nodes e
+  where
+    transfer' transfer arity = do
+      (cat, e') <- transfer arity
+      return (cat, f e')
+
+-- The trivial base cases
+callArityExpr _ e@(Lit _) = callArityExprTrivial e
+callArityExpr _ e@(Type _) = callArityExprTrivial e
+callArityExpr _ e@(Coercion _) = callArityExprTrivial e
+
+-- The transparent cases
+callArityExpr nodes (Tick t e) = callArityExprMap nodes (Tick t) e
+callArityExpr nodes (Cast e c) = callArityExprMap nodes (flip Cast c) e
+
+-- The interesting cases: Variables, Lambdas, Lets, Applications, Cases
+callArityExpr nodes e@(Var v) = return transfer
+  where
+    transfer arity
+      | isInteresting v
+      , Just node <- lookupVarEnv nodes v
+      = do
+        (cat_callee, _) <- dependOnWithDefault (unusedArgsArityType arity, e) (node, arity)
+        -- It is crucial that we only use cat_args here, as every other field
+        -- might be unstable and thus too optimistic.
+        return ((unitArityType v arity) { cat_args = cat_args cat_callee }, e)
+
+      | isInteresting v
+      --, isGlobalId v -- TODO: lookup sig if present
+      = return (unitArityType v arity, e)
+
+      | otherwise
+      -- We don't track uninteresting vars and implicitly assume they are called
+      -- multiple times with every other variable.
+      -- See Note [Taking boring variables into account]
+      = return (emptyArityType, e)
+
+callArityExpr nodes (Lam v e)
+  | isTyVar v = callArityExprMap nodes (Lam v) e -- Non-value lambdas are ignored
+  | otherwise = transfer' <$> callArityExpr nodes e
+  where
+    transfer' transfer 0 = do
+      -- We have a lambda that may be called multiple times, so its free variables
+      -- can all be co-called.
+      -- Also regardless of the variable not being interesting,
+      -- we have to add the var as an argument.
+      (cat, e') <- transfer 0
+      return (makeIdArg v (calledMultipleTimes cat), Lam v e')
+
+    transfer' transfer arity = do
+      -- We have a lambda that we are applying to. decrease arity.
+      (cat, e') <- transfer (arity - 1)
+      return (makeIdArg v cat, Lam v e')
+
+callArityExpr nodes (App f (Type t)) = callArityExprMap nodes (flip App (Type t)) f
+
+-- Application. Increase arity for the called expression, nothing to know about
+-- the second
+callArityExpr nodes (App f a) = do
+  transfer_f <- callArityExpr nodes f
+  transfer_a <- callArityExpr nodes a
+  return $ \arity -> do
+    (cat_f, f') <- transfer_f (arity + 1)
+    --pprTrace "App:f'" (ppr (cat_f, f')) $ return ()
+    -- peel off one argument from the type
+    let (arg_usage, cat_f') = peelCallArityType cat_f
+    -- In call-by-need, arguments are evaluated at most once, so they qualify as
+    -- thunk.
+    case oneifyCardinalityIfThunk a arg_usage of
+      Zero -> return (cat_f', App f' a) -- TODO: Visit a, too? Seems unnecessary, wasn't called at all
+      One arity -> analyse calledOnce arity
+      Many arity -> analyse calledMultipleTimes arity
+        where
+          calledOnce = id
+          analyse finish_cat_a arity = do
+            (cat_a, a') <- transfer_a arity
+            --pprTrace "App:a'" (text "safe_arity:" <+> ppr safe_arity <+> ppr (cat_a, a')) $ return ()
+            let cat_a' = finish_cat_a cat_a
+            return (cat_f' `both` cat_a', App f' a')
+
+-- Case expression.
+callArityExpr nodes (Case scrut bndr ty alts) = do
+  transfer_scrut <- callArityExpr nodes scrut
+    -- TODO: Do we have to do something special with bndr?
+    --       Don't think so, we can't make use of the information.
+    --       We also shouldn't track them in the co call graph (they are boring)
+  transfer_alts <- forM alts $ \(dc, bndrs, e) ->
+    callArityExprMap nodes (dc, bndrs,) e
+  return $ \arity -> do
+    (cat_scrut, scrut') <- transfer_scrut 0
+    (cat_alts, alts') <- unzip <$> mapM ($ arity) transfer_alts
+    let cat = trimArgs arity (lubTypes cat_alts) `both` cat_scrut
+    -- TODO: Think harder about the diverging case (e.g. matching on `undefined`).
+    --       In that case we will declare all arguments as unused from the alts.
+    -- pprTrace "callArityExpr:Case"
+    --          (vcat [ppr scrut, ppr cat])
+    --pprTrace "Case" (vcat [text "cat_scrut:" <+> ppr cat_scrut, text "cat_alts:" <+> ppr cat_alts, text "cat:" <+> ppr cat]) (return ())
+    return (cat, Case scrut' bndr ty alts')
+
+callArityExpr letdown_nodes (Let bind e) = do
+  let initial_binds = flattenBinds [bind]
+  -- The order in which we call callArityExpr here is important: This makes sure
+  -- the FP iteration will first stabilize bindings before analyzing the body.
+  -- Nope, in fact it does exactly the opposite!
+  (letdown_nodes', letup_nodes) <- callArityBind letdown_nodes binds
+  let lookup_letup_node id = expectJust ": the RHS of id wasn't registered" (lookupVarEnv letup_nodes id)
+  let transfer_rhs (id, rhs) arity =
+        dependOnWithDefault (unusedArgsArityType arity, rhs) (lookup_letup_node id, arity)
+  transfer_body <- callArityExpr letdown_nodes' e
+
+  case bind of
+    NonRec _ _ ->
+      -- We don't need to dependOn ourselves here, because only the let body can't
+      -- call id. Thus we also can spare to allocate a new @FrameworkNode@.
+      return $ \arity -> do
+        (cat_body, e') <- transfer_body arity
+        (cat, [(id', rhs')]) <- unleashLet False initial_binds transfer_rhs cat_body cat_body
+        return (typeDelList (bindersOf bind) cat, Let (NonRec id' rhs') e')
+    Rec _ -> do -- The binding group stored in the @Rec@ constructor is always the initial one!
+      -- This is a little more complicated, as we'll introduce a new FrameworkNode
+      -- which we'll depend on ourselves.
+      node <- registerTransferFunction (LowerThan (minimum (eltsUFM letup_nodes))) $ \node -> do
+        let transfer arity = do
+              (cat_body, e') <- transfer_body arity
+              -- This is the actual fixed-point iteration: we depend on usage
+              -- results from the previous iteration, defaulting to just the body.
+              (cat_usage, Let (Rec old_bind) _) <- dependOnWithDefault (cat_body, Let bind e') (node, arity)
+              (cat, bind') <- unleashLet True old_bind transfer_rhs cat_usage cat_body
+              return (cat, Let (Rec bind') e')
+
+        let change_detector changed_refs (old, _) (new, _) =
+              -- since we only care for arity and called once information of the
+              -- previous iteration, we can efficiently test for changes.
+              --pprTrace "change_detector" (vcat[ppr node, ppr changed_refs, ppr old, ppr new])
+              map fst (Set.toList changed_refs) /= [node]
+              || any (\id -> lookupCallArityType old id /= lookupCallArityType new id) (map fst binds)
+
+        return (node, (transfer, change_detector))
+
+      -- Now for the actual TransferFunction of this expr...
+      return $ \arity -> do
+        (cat, let') <- dependOnWithDefault (emptyArityType, Let bind e) (node, arity)
+        --pprTrace "Let" (ppr (cat, let')) $ return ()
+        return (typeDelList (bindersOf bind) cat, let')
+
+callArityBind
+  :: VarEnv FrameworkNode
+  -> [(Id, CoreExpr)]
+  -> FrameworkBuilder (VarEnv FrameworkNode, VarEnv FrameworkNode)
+callArityBind letdown_nodes = go letdown_nodes emptyVarEnv
+  where
+    go letdown_nodes letup_nodes [] = return (letdown_nodes, letup_nodes)
+    go letdown_nodes letup_nodes ((id, rhs):binds) =
+      registerTransferFunction HighestAvailable $ \letup_node ->
+        registerTransferFunction HighestAvailable $ \letdown_node -> do
+          (letdown_nodes', letup_nodes') <- go
+            (extendVarEnv letdown_nodes id letdown_node)
+            (extendVarEnv letup_nodes id letup_node)
+            binds
+          transfer_up' <- callArityExpr letdown_nodes' rhs
+          let transfer_up arity = do
+                --pprTrace "Bind:Before" (text "id:" <+> ppr id <+> text "arity:" <+> ppr arity) $ return ()
+                res <- transfer_up' arity
+                --pprTrace "Bind:Finished" (ppr res) $ return ()
+                return res
+          let transfer_down arity = dependOnWithDefault (unusedArgsArityType arity, rhs) (letup_node, arity)
+          let change_detector_down _ (old, _) (new, _) =
+                -- The only reason we split the transfer fuctions up is cheap
+                -- change detection for the LetDown case. This implies that
+                -- use sites of the LetDown component may only use the cat_args
+                -- component!
+                -- FIXME: Encode this in the FrameworkNode type somehow, but I
+                -- don't think it's worth the trouble.
+                --pprTrace "change_detector_down" (ppr (cat_args old) <+> ppr (cat_args new) <+> ppr (cat_args old /= cat_args new)) $
+                cat_args old /= cat_args new
+          let ret = (letdown_nodes', letup_nodes') -- What we return from callArityBind
+          let letup = (transfer_up, alwaysChangeDetector) -- What we register for letup_node
+          let letdown = (transfer_down, change_detector_down) -- What we register for letdown_node
+          return ((ret, letup), letdown) -- registerTransferFunction  will peel `snd`s away for registration
+
+{-|
+-}
+unleashLet
+  :: Bool
+  -> [(Id, CoreExpr)]
+  -> (Id, CoreExpr) -> Arity -> TransferFunction AnalResult
+  -> CallArityType
+  -> CallArityType
+  -> TransferFunction (CallArityType, [(Id, CoreExpr)])
+unleashLet is_recursive binds transfer_rhs cat_usage cat_body = do
+  (cat_rhss, binds') <- unzip <$> forM binds $ \bind ->
+    unleashCall is_recursive cat_usage bind (transfer_rhs bind)
+  let ids = map fst binds'
+  let cat_final = callArityLetEnv (zip ids cat_rhss) cat_body
+  return (cat_final, binds')
+
+unleashCall
+  :: Bool
+  -> CallArityType
+  -> (Id, CoreExpr)
+  -> Arity -> TransferFunction AnalResult
+  -> TransferFunction (CallArityType, (Id, CoreExpr))
+unleashCall is_recursive cat_usage (id, rhs) transfer_rhs
+  | Zero <- usage
+  = return (emptyArityType, (id, rhs)) -- No call to @id@ (yet)
+  | One arity <- usage
+  = analyse calledOnce arity
+  | Many arity <- usage
+  = analyse calledMultipleTimes arity
+  where
+    usage =
+      oneifyCardinalityIfThunk rhs
+      -- See Note [Thunks in recursive groups]
+      -- @is_recursive@ implies @not called_once@ (otherwise, why would it be
+      -- recursive?), although the co-call graph doesn't model it that way.
+      -- Self-edges in the co-call graph correspond to non-linear recursion.
+      . if is_recursive then manifyCardinality else id
+      . lookupCallArityType cat_usage
+      $ id
+    calledOnce u = u
+    analyse finish_cat_rhs arity = do
+      -- See Note [Trimming arity]
+      let trimmed_arity = trimArity id arity
+      -- TODO: Find out if (where) we need the trimmed_arity here or not
+      -- We probably want to analyze with arity und annotate trimmed_arity.
+      -- Although CA analyzes with trimmed_arity, so we do that for now
+      -- Also if we analysed with arity, we would need to analyze again with
+      -- trimmed_arity nonetheless for the signature!
+      (cat_rhs, rhs') <- transfer_rhs trimmed_arity
+      let cat_rhs' = finish_cat_rhs cat_rhs
+      return (cat_rhs', (id `setIdCallArity` cat_args cat_rhs', rhs'))
+
+-- | See Note [What is a thunk].
+isThunk :: CoreExpr -> Bool
+isThunk = not . exprIsCheap
+
+{-| If a (future, in the case of arguments) let-bound expression is a thunk, we
+    need to make sure that we don't accidentally duplicate work by eta-expansion.
+    Which we do if we expand a thunk which we use multiple times.
+
+    So: If we use a thunk @Many 2@, we must be sure that we are OK with
+    losing shared work by eta-expansion (@exprIsCheap@). Otherwise we have to
+    fall back to @One 0@.
+
+    This function should be used anywhere expressions are to be let-bound.
+-}
+oneifyCardinalityIfThunk :: -> CoreExpr -> Cardinality -> Cardinality
+oneifyCardinalityIfThunk e (Many arity)
+  -- A thunk was called multiple times! Do not eta-expand
+  | isThunk e = One 0
+  -- In case e is cheap and we use the let-bound var of e with @Many 0@, this
+  -- allows us to at least analyze the cheap RHS with cardinality 1 before we
+  -- potentially hit a lambda binder, were we proceed normally with @Many 0@.
+  -- I'm not sure if this actually buys us anything, @e@ is cheap after all.
+  -- But it may still be non-@exprIsTrivial@, so just leaving it here for the
+  -- time being.
+  | arity == 0 = One 0
+oneifyCardinalityIfThunk _ u = u
+
+-- | Multiplies with @Many@; $\omega*_$ formally. @manifyCardinality Zero = Zero@ still!
+manifyCardinality :: Cardinality -> Cardinality
+manifyCardinality (One arity) = Many arity
+manifyCardinality u = u
+
+-- Which bindings should we look at?
+-- See Note [Which variables are interesting]
+isInteresting :: Var -> Bool
+isInteresting v = not $ null (typeArity (idType v))
+
+-- Combining the results from body and rhs of a let binding
+-- See Note [Analysis II: The Co-Called analysis]
+callArityLetEnv
+  :: [(Id, CallArityType)]
+  -> CallArityType
+  -> CallArityType
+callArityLetEnv cat_rhss cat_body
+    = -- (if length ae_rhss > 300 then pprTrace "callArityLetEnv" (vcat [ppr ae_rhss, ppr ae_body, ppr ae_new]) else id) $
+      cat_new
+  where
+    ids = map fst cat_rhss
+
+    -- This is already the complete type, but with references from the current
+    -- binding group not resolved.
+    -- For the non-recursive case, at least cat_body may refer to some bound var
+    -- which we have to handle, for the recursive case even any of cat_rhss may.
+    -- This is why we have to union in appropriate cross_calls, which basically
+    -- perform substitution of Id to CallArityType.
+    cat_combined = lubTypes (cat_body : map (unusedArgs . snd) cat_rhss)
+
+    cross_calls
+        -- Calculating cross_calls is expensive. Simply be conservative
+        -- if the mutually recursive group becomes too large.
+        -- TODO: I *think* 5 is enough here, but this used to be 25.
+        | length cat_rhss > 5 = completeGraph (domType cat_combined)
+        | otherwise            = unionUnVarGraphs $ map cross_call cat_rhss
+    cross_call (id, cat_rhs) = completeBipartiteGraph called_by_id called_with_id
+      where
+        is_thunk = length (idCallArity id) == 0 -- This is a new annotation, from this FP iteration!
+        -- We only add self cross calls if we really can recurse into ourselves.
+        -- This is not the case for thunks (and non-recursive bindings, but
+        -- then there won't be any mention of id in the rhs).
+        -- A thunk is not evaluated more than once, so the only
+        -- relevant calls are from other bindings or the body.
+        -- What rhs are relevant as happening before (or after) calling id?
+        --    If id doesn't recurse into itself, everything from all the _other_ variables
+        --    If id is self-recursive, everything can happen.
+        cat_before_id
+            | is_thunk  = lubTypes (cat_body : map (unusedArgs . snd) (filter ((/= id) . fst) cat_rhss))
+            | otherwise = cat_combined
+        -- What do we want to know from these?
+        -- Which calls can happen next to any recursive call.
+        called_with_id = unionUnVarSets $ map (calledWith cat_before_id) vars
+        called_by_id = domType cat_rhs
+
+    cat_new = modifyCoCalls (cross_calls `unionUnVarGraph`) cat_combined
+
+-- See Note [Trimming arity]
+trimArity :: Id -> Arity -> Arity
+trimArity id a = minimum [a, max_arity_by_type, max_arity_by_strsig]
+  where
+    max_arity_by_type = length (typeArity (idType id))
+    max_arity_by_strsig
+        | isBotRes result_info = length demands
+        | otherwise = a
+
+    (demands, result_info) = splitStrictSig (idStrictness id)
diff --git a/compiler/simplCore/CallArity/FrameworkBuilder.hs b/compiler/simplCore/CallArity/FrameworkBuilder.hs
new file mode 100644
index 0000000000..3553822e25
--- /dev/null
+++ b/compiler/simplCore/CallArity/FrameworkBuilder.hs
@@ -0,0 +1,80 @@
+{-# LANGUAGE GeneralizedNewtypeDeriving #-}
+
+module CallArity.FrameworkBuilder
+  ( FrameworkNode
+  , TransferFunction
+  , ChangeDetector
+  , Worklist.alwaysChangeDetector
+  , DataFlowFramework
+  , buildFramework
+  , Worklist.runFramework
+  , RequestedPriority (..)
+  , registerTransferFunction
+  , dependOnWithDefault
+  ) where
+
+import CallArity.Types
+import qualified Worklist
+
+import Data.IntMap.Lazy (IntMap)
+import qualified Data.IntMap.Lazy as IntMap
+import Data.Map.Strict   (Map)
+import qualified Data.Map.Strict as Map
+import Data.Maybe
+import qualified Data.Set as Set
+import VarEnv
+import Control.Monad
+import Control.Monad.Fix
+import Control.Monad.Trans.State.Strict
+
+newtype FrameworkNode
+  = FrameworkNode Int
+  deriving (Show, Eq, Ord, Outputable)
+
+type TransferFunction a = Worklist.TransferFunction (FrameworkNode, Arity) AnalResult a
+type ChangeDetector = Worklist.ChangeDetector (FrameworkNode, Arity) AnalResult
+type DataFlowFramework = Worklist.DataFlowFramework (FrameworkNode, Arity) AnalResult
+-- | Maps @FrameworkNode@ to incoming usage dependent @TransferFunction'@s
+type NodeTransferEnv = IntMap (Arity -> TransferFunction AnalResult, ChangeDetector)
+
+newtype FrameworkBuilder a
+  = FB { unFB :: State NodeTransferEnv a }
+  deriving (Functor, Applicative, Monad)
+
+buildFramework :: FrameworkBuilder a -> (a, DataFlowFramework)
+buildFramework (FB state) = (res, DFF dff)
+  where
+    (res, env) = runState state IntMap.empty -- NodeTransferEnv
+    dff (FrameworkNode node, arity) = case IntMap.lookup node env of
+      Nothing -> pprPanic "CallArity.buildFramework" (ppr node)
+      Just (transfer, detectChange) -> (transfer arity, detectChange)
+
+data RequestedPriority
+  = LowerThan FrameworkNode
+  | HighestAvailable
+
+registerTransferFunction
+  :: RequestedPriority
+  -> (FrameworkNode -> FrameworkBuilder (a, (Arity -> TransferFunction' AnalResult, ChangeDetector')))
+  -> FrameworkBuilder a
+registerTransferFunction prio f = FB $ do
+  nodes <- get
+  let node = case prio of
+        HighestAvailable -> 2 * IntMap.size nodes
+        LowerThan (FrameworkNode node)
+          | not (IntMap.member (node - 1) nodes) -> node - 1
+          | otherwise -> pprPanic "registerTransferFunction" (text "There was already a node registered with priority" <+> ppr (node - 1))
+  (result, _) <- mfix $ \~(_, entry) -> do
+    -- Using mfix so that we can spare an unnecessary Int counter in the state.
+    -- Also because @f@ needs to see its own node in order to define its
+    -- transfer function in case of letrec.
+    modify' (IntMap.insert node entry)
+    unFB (f (FrameworkNode node))
+  return result
+
+dependOnWithDefault :: AnalResult -> (FrameworkNode, Arity) -> TransferFunction AnalResult
+dependOnWithDefault def which = do
+  --pprTrace "dependOnWithDefault:before" (text "node:" <+> ppr node <+> text "arity:" <+> ppr arity) $ return ()
+  res <- fromMaybe def <$> Worklist.dependOn which
+  --pprTrace "dependOnWithDefault:after" (vcat [text "node:" <+> ppr node, text "arity:" <+> ppr arity, text "res:" <+> ppr res]) $ return ()
+  return res
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
new file mode 100644
index 0000000000..74725eeffc
--- /dev/null
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -0,0 +1,177 @@
+module CallArity.Types where
+
+import Maybes
+import Outputable
+import Binary
+
+---------------------------------------
+-- Functions related to CallArityType --
+---------------------------------------
+
+-- Result type for the two analyses.
+-- See Note [Analysis I: The arity analyis]
+-- and Note [Analysis II: The Co-Called analysis]
+data Cardinality
+  = Zero
+  | One {-# UNPACK #-} !Arity
+  | Many {-# UNPACK #-} !Arity
+  deriving (Eq, Show)
+
+arity :: Cardinality -> Maybe Arity
+arity (One a) = Just a
+arity (Many a) = Just a
+arity _ = Nothing
+
+lubCardinality :: Cardinality -> Cardinality -> Cardinality
+lubCardinality Zero u = u
+lubCardinality u Zero = u
+lubCardinality (One arity1) (One arity2) = One (min arity1 arity2)
+lubCardinality = Many . min `on` expectJust ": Zero has no arity" . arity
+
+botCardinality :: Cardinality
+botCardinality = Zero
+
+topCardinality :: Cardinality
+topCardinality = Many 0
+
+type CardinalitySig = [Cardinality]
+
+topCardinalitySig :: CardinalitySig
+topCardinalitySig = []
+
+data CallArityType
+  = CAT
+  { cat_cocalled :: UnVarGraph -- ^ Models cardinality, e.g. 1, many via the co-call relation for _interesting_ variables
+  , cat_arities :: VarEnv Arity -- ^ Models per var usage and absence (card 0)
+  , cat_args :: CardinalitySig -- ^ Collects the signature for captured lambda binders
+  }
+
+-- | How an expression uses its interesting variables
+-- and the elaborated expression with annotated Ids
+type AnalResult = (CallArityType, CoreExpr)
+
+emptyArityType :: CallArityType
+emptyArityType = CAT emptyUnVarGraph emptyVarEnv topCardinalitySig
+
+unitArityType :: Var -> Arity -> CallArityType
+unitArityType v arity = emptyArityType { cat_arities = unitVarEnv v arity }
+
+unusedArgsArityType :: Int -> CallArityType
+unusedArgsArityType arity = trimArgs arity (unusedArgs emptyArityType)
+
+unusedArgs :: CallArityType -> CallArityType
+unusedArgs cat = cat { cat_args = repeat Zero }
+
+trimArgs :: Int -> CallArityType -> CallArityType
+trimArgs arity cat = cat { cat_args = take arity (cat_args cat) }
+
+typeDelList :: [Var] -> CallArityType -> CallArityType
+typeDelList vs ae = foldr typeDel ae vs
+
+typeDel :: Var -> CallArityType -> CallArityType
+typeDel v (CAT g ae args) = CAT (g `delNode` v) (ae `delVarEnv` v) args
+
+domType :: CallArityType -> UnVarSet
+domType ca_type = varEnvDom (cat_arities ca_type)
+
+makeIdArg :: Id -> CallArityType -> CallArityType
+makeIdArg id ca_type = typeDel id ca_type
+  { cat_args = lookupCallArityType ca_type id : cat_args ca_type }
+
+-- In the result, find out the minimum arity and whether the variable is called
+-- at most once.
+lookupCallArityType :: CallArityType -> Var -> Cardinality
+lookupCallArityType (CAT g ae _) v = case lookupVarEnv ae v of
+  Just a
+    | v `elemUnVarSet` neighbors g v -> Many a
+    | otherwise -> One a
+  Nothing
+    | isInteresting v -> botCardinality
+    -- If v is boring, we will not find it in cat_usage, but always assume topCardinality.
+    -- See Note [Taking boring variables into account]
+    | otherwise -> topCardinality
+
+calledWith :: CallArityType -> Var -> UnVarSet
+calledWith ca_type v
+  | isInteresting v
+  = neighbors (cat_cocalled ca_type) v
+  | otherwise
+  = domType ca_type
+
+modifyCoCalls :: (UnVarGraph -> UnVarGraph) -> CallArityType -> CallArityType
+modifyCoCalls modifier ca_type
+  = ca_type { cat_cocalled = modifier (cat_cocalled ca_type) }
+
+addCrossCoCalls :: UnVarSet -> UnVarSet -> CallArityType -> CallArityType
+addCrossCoCalls set1 set2
+  = modifyCoCalls (completeBipartiteGraph set1 set2 `unionUnVarGraph`)
+
+-- Replaces the co-call graph by a complete graph (i.e. no information)
+calledMultipleTimes :: CallArityType -> CallArityType
+calledMultipleTimes res = modifyCoCalls (const (completeGraph (domType res))) res
+
+-- Used for application and cases
+both :: CallArityType -> CallArityType -> CallArityType
+both r1 r2 = addCrossCoCalls (domType r1) (domType r2) ((r1 `lubType` r2) { cat_args = cat_args r1 })
+
+-- Used when combining results from alternative cases; take the minimum
+lubType :: CallArityType -> CallArityType -> CallArityType
+lubType (CAT g1 ae1 args1) (CAT g2 ae2 args2) -- both args should really be the same
+  = CAT (g1 `unionUnVarGraph` g2) (ae1 `lubArityEnv` ae2) (zipWith lubCardinality args1 args2)
+
+lubArityEnv :: VarEnv Arity -> VarEnv Arity -> VarEnv Arity
+lubArityEnv = plusVarEnv_C min
+
+lubTypes :: [CallArityType] -> CallArityType
+lubTypes = foldl lubType (unusedArgs emptyArityType) -- note that this isn't safe for empty input, because of unusedArgs.
+
+-- | Peels off a single argument usage from the signature, corresponding to how
+-- @App f a@ uses @a@ under the given incoming arity.
+peelCallArityType :: CallArityType -> (Cardinality, CallArityType)
+peelCallArityType ca_f
+  | arg:args <- cat_args ca_f
+  -- The called expression had a signature we can return.
+  = (arg, ca_f { cat_args = args })
+
+  | otherwise
+  -- The called function had no signature or has not
+  -- been analysed with high enough incoming arity
+  -- (e.g. when loading the signature from an imported id).
+  -- ca_f is rather useless for analysing a, so we conservatively
+  -- assume topCardinality here.
+  = (topCardinality, ca_f)
+
+-- * Pretty-printing
+
+-- | Formats incoming arity like a Call demand.
+pprArity :: Arity -> SDoc
+pprArity 0 = text "U"
+pprArity arity = text "C" <> parens (pprArity (arity - 1))
+
+instance Outputable Cardinality where
+  ppr Zero = text "A"
+  ppr (One arity) = text "1*" <> pprArity arity
+  ppr (Many arity) = pprArity arity
+
+instance Outputable CallArityType where
+  ppr (CAT cocalled arities args) =
+    text "arg usages:" <+> ppr args
+    <+> text "co-calls:" <+> ppr cocalled
+    <+> text "arities:" <+> ppr arities
+
+-- | Used for printing top-level cardinality pragmas in interface files
+pprIfaceStrictSig :: CardinalitySig -> SDoc
+pprIfaceStrictSig = hcat . map ppr
+
+-- * Serialization
+
+instance Binary Cardinality where
+  put_ bh Zero = putByte bh 0
+  put_ bh (One arity) = putByte bh 1 >> put bh arity
+  put_ bh (Many arity) = putByte bh 2 >> put bh arity
+  get  bh = do
+    h <- getByte bh
+    case h of
+      0 -> return Zero
+      1 -> One <$> get bh
+      _ -> Many <$> get bh
-- 
2.12.1


From df37b3dffc554742c613cc80b1e3af6d3c02c26b Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 27 Mar 2017 14:07:44 +0200
Subject: [PATCH 022/117] Making use of signature annotation in global ids

---
 compiler/simplCore/CallArity/Analysis.hs | 9 ++++++---
 1 file changed, 6 insertions(+), 3 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 9cd289877d..6008c0d97f 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -496,7 +496,12 @@ callArityExpr nodes e@(Var v) = return transfer
         return ((unitArityType v arity) { cat_args = cat_args cat_callee }, e)
 
       | isInteresting v
-      --, isGlobalId v -- TODO: lookup sig if present
+      , isGlobalId v
+      = return (unitArityType v arity { cat_args = idCallArity v }, e)
+
+      | isInteresting v
+      -- LocalId, not present in @nodes@, e.g. a lambda-bound variable.
+      -- We are only second-order, so we don't model signatures for parameters!
       = return (unitArityType v arity, e)
 
       | otherwise
@@ -648,8 +653,6 @@ callArityBind letdown_nodes = go letdown_nodes emptyVarEnv
           let letdown = (transfer_down, change_detector_down) -- What we register for letdown_node
           return ((ret, letup), letdown) -- registerTransferFunction  will peel `snd`s away for registration
 
-{-|
--}
 unleashLet
   :: Bool
   -> [(Id, CoreExpr)]
-- 
2.12.1


From af54f8653e384ae23c7857cd97c0307e78a26dc2 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 30 Mar 2017 13:39:19 +0200
Subject: [PATCH 023/117] Separate Usage type + fixing all compilation errors

---
 compiler/basicTypes/Id.hs                        |  31 ++-
 compiler/basicTypes/IdInfo.hs                    |  73 +++++-
 compiler/basicTypes/Usage.hs                     | 139 +++++++++++
 compiler/coreSyn/PprCore.hs                      |   9 +-
 compiler/ghc.cabal.in                            |   4 +
 compiler/iface/IfaceSyn.hs                       |   9 +-
 compiler/iface/TcIface.hs                        |   2 +-
 compiler/iface/ToIface.hs                        |  11 +-
 compiler/simplCore/CallArity/Analysis.hs         | 303 +++++++++++------------
 compiler/simplCore/CallArity/FrameworkBuilder.hs |  59 +++--
 compiler/simplCore/CallArity/Types.hs            | 206 ++++++---------
 compiler/simplCore/SimplUtils.hs                 |   4 +-
 compiler/utils/Worklist.hs                       |   1 -
 13 files changed, 510 insertions(+), 341 deletions(-)
 create mode 100644 compiler/basicTypes/Usage.hs

diff --git a/compiler/basicTypes/Id.hs b/compiler/basicTypes/Id.hs
index 13f3c219df..3f118835ee 100644
--- a/compiler/basicTypes/Id.hs
+++ b/compiler/basicTypes/Id.hs
@@ -89,29 +89,31 @@ module Id (
 
         -- ** Reading 'IdInfo' fields
         idArity,
-        idCallArity, idFunRepArity,
+        idFunRepArity,
         idUnfolding, realIdUnfolding,
         idSpecialisation, idCoreRules, idHasRules,
         idCafInfo,
         idOneShotInfo, idStateHackOneShotInfo,
         idOccInfo,
         isNeverLevPolyId,
+        idCallArity,
+        idArgUsage,
+        idDemandInfo,
+        idStrictness,
 
         -- ** Writing 'IdInfo' fields
         setIdUnfolding, setCaseBndrEvald,
         setIdArity,
-        setIdCallArity,
 
         setIdSpecialisation,
         setIdCafInfo,
         setIdOccInfo, zapIdOccInfo,
 
+        setIdCallArity,
+        setIdArgUsage,
         setIdDemandInfo,
         setIdStrictness,
 
-        idDemandInfo,
-        idStrictness,
-
     ) where
 
 #include "HsVersions.h"
@@ -135,6 +137,7 @@ import RepType
 import TysPrim
 import DataCon
 import Demand
+import Usage
 import Name
 import Module
 import Class
@@ -151,7 +154,6 @@ import Util
 -- infixl so you can say (id `set` a `set` b)
 infixl  1 `setIdUnfolding`,
           `setIdArity`,
-          `setIdCallArity`,
           `setIdOccInfo`,
           `setIdOneShotInfo`,
 
@@ -164,7 +166,10 @@ infixl  1 `setIdUnfolding`,
           `setIdStrictness`,
 
           `asJoinId`,
-          `asJoinId_maybe`
+          `asJoinId_maybe`,
+
+          `setIdCallArity`,
+          `setIdArgUsage`
 
 {-
 ************************************************************************
@@ -618,11 +623,17 @@ idArity id = arityInfo (idInfo id)
 setIdArity :: Id -> Arity -> Id
 setIdArity id arity = modifyIdInfo (`setArityInfo` arity) id
 
-idCallArity :: Id -> CardinalitySig
+idCallArity :: Id -> Usage
 idCallArity id = callArityInfo (idInfo id)
 
-setIdCallArity :: Id -> CardinalitySig -> Id
-setIdCallArity id sig = modifyIdInfo (`setCallArityInfo` sig) id
+setIdCallArity :: Id -> Usage -> Id
+setIdCallArity id used = modifyIdInfo (`setCallArityInfo` used) id
+
+idArgUsage :: Id -> UsageSig
+idArgUsage id = argUsageInfo (idInfo id)
+
+setIdArgUsage :: Id -> UsageSig -> Id
+setIdArgUsage id sig = modifyIdInfo (`setArgUsageInfo` sig) id
 
 idFunRepArity :: Id -> RepArity
 idFunRepArity x = countFunRepArgs (idArity x) (idType x)
diff --git a/compiler/basicTypes/IdInfo.hs b/compiler/basicTypes/IdInfo.hs
index df21e8658e..ca9ff1f121 100644
--- a/compiler/basicTypes/IdInfo.hs
+++ b/compiler/basicTypes/IdInfo.hs
@@ -36,6 +36,8 @@ module IdInfo (
         unknownArity,
         arityInfo, setArityInfo, ppArityInfo,
 
+        -- ** Usage info
+        argUsageInfo, setArgUsageInfo,
         callArityInfo, setCallArityInfo,
 
         -- ** Demand and strictness Info
@@ -98,7 +100,7 @@ import Outputable
 import Module
 import Demand
 import Util
-import CallArity.Types
+import Usage
 
 -- infixl so you can say (id `set` a `set` b)
 infixl  1 `setRuleInfo`,
@@ -112,6 +114,8 @@ infixl  1 `setRuleInfo`,
           `setDemandInfo`,
           `setNeverLevPoly`,
           `setLevityInfoWithType`
+          `setCallArityInfo`,
+          `setArgUsageInfo`
 
 {-
 ************************************************************************
@@ -245,15 +249,53 @@ data IdInfo
         inlinePragInfo  :: InlinePragma,        -- ^ Any inline pragma atached to the 'Id'
         occInfo         :: OccInfo,             -- ^ How the 'Id' occurs in the program
 
-        strictnessInfo  :: StrictSig,      --  ^ A strictness signature
-
-        demandInfo      :: Demand,       -- ^ ID demand information
-        callArityInfo   :: !CardinalitySig -- ^ How this is uses its arguments.
-                                           -- length of n <=> all calls have at least n arguments
+        strictnessInfo  :: !StrictSig,
+        demandInfo      :: !Demand,
+        argUsageInfo    :: !UsageSig,
+        callArityInfo   :: !Usage
 
         levityInfo      :: LevityInfo    -- ^ when applied, will this Id ever have a levity-polymorphic type?
+        --cardinalityInfo :: CardinalityInfo      -- ^ Evaluation cardinality of the binder and its arguments
     }
 
+-- | Cardinality information about a binder.
+--
+-- The cardinality of a binder represents how often it is evaluated/called.
+-- Interesting cardinalities are {0, 1, $\omega$}, where $\omega$ means
+-- multiple times.
+--
+-- Strictness and usage analysis compute approximations to the
+-- actual runtime cardinality: Strictness analysis will compute a *lower* bound
+-- for the cadinality (e.g. 'is this evaluated at least once?'), whereas
+-- usage analysis computes upper bounds for cardinality (e.g. 'not used at all',
+-- 'used at most once'). The results are saved in @ci_demanded@ and @ci_used@.
+--
+-- For second-order strictness and usage analysis, we also store signatures of
+-- how the binder evaluates *its arguments* on evaluation. These signatures are
+-- stored in @ci_argStrictness@ and @ci_argUsage@ and persisted in interface
+-- files for analysis information flow across module boundaries.
+data CardinalityInfo
+  = CardinalityInfo {
+        ci_argStrictness :: !StrictSig,
+        -- ^ What strictness is unleashed upon *arguments* if this @Id@ is called
+        ci_argUsage      :: !UsageSig,
+        -- ^ What usage is unleashed upon *arguments* if this @Id@ is called
+        ci_demanded      :: !Demand,
+        -- ^ Is this binding used *at least* once (e.g. strict)?
+        ci_used          :: !Usage
+        -- ^ Is this binding used *at most* never, once or multiple times?
+        -- What is the minimum number of arguments it was called with?
+  }
+
+emptyCardinalityInfo :: CardinalityInfo
+emptyCardinalityInfo
+  = CardinalityInfo {
+        ci_argStrictness = nopSig,
+        ci_argUsage      = topUsageSig,
+        ci_demanded      = topDmd,
+        ci_used          = topUsage
+  }
+
 -- Setters
 
 setRuleInfo :: IdInfo -> RuleInfo -> IdInfo
@@ -274,8 +316,7 @@ setUnfoldingInfo info uf
 
 setArityInfo :: IdInfo -> ArityInfo -> IdInfo
 setArityInfo      info ar  = info { arityInfo = ar  }
-setCallArityInfo :: IdInfo -> CardinalitySig -> IdInfo
-setCallArityInfo info sig  = info { callArityInfo = sig }
+
 setCafInfo :: IdInfo -> CafInfo -> IdInfo
 setCafInfo        info caf = info { cafInfo = caf }
 
@@ -283,10 +324,16 @@ setOneShotInfo :: IdInfo -> OneShotInfo -> IdInfo
 setOneShotInfo      info lb = {-lb `seq`-} info { oneShotInfo = lb }
 
 setDemandInfo :: IdInfo -> Demand -> IdInfo
-setDemandInfo info dd = dd `seq` info { demandInfo = dd }
+setDemandInfo info dd = info { demandInfo = dd }
 
 setStrictnessInfo :: IdInfo -> StrictSig -> IdInfo
-setStrictnessInfo info dd = dd `seq` info { strictnessInfo = dd }
+setStrictnessInfo info dd = info { strictnessInfo = dd }
+
+setArgUsageInfo :: IdInfo -> UsageSig -> IdInfo
+setArgUsageInfo info sig = info { argUsageInfo = sig }
+
+setCallArityInfo :: IdInfo -> Usage -> IdInfo
+setCallArityInfo info used = info { callArityInfo = used }
 
 -- | Basic 'IdInfo' that carries no useful information whatsoever
 vanillaIdInfo :: IdInfo
@@ -299,10 +346,12 @@ vanillaIdInfo
             oneShotInfo         = NoOneShotInfo,
             inlinePragInfo      = defaultInlinePragma,
             occInfo             = noOccInfo,
-            demandInfo          = topDmd,
             strictnessInfo      = nopSig,
-            callArityInfo       = topCardinalitySig,
+            demandInfo          = topDmd,
+            argUsageInfo        = topUsageSig,
+            callArityInfo       = topUsage
             levityInfo          = NoLevityInfo
+            --cardinalityInfo     = emptyCardinalityInfo
            }
 
 -- | More informative 'IdInfo' we can use when we know the 'Id' has no CAF references
diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
new file mode 100644
index 0000000000..9aff5de369
--- /dev/null
+++ b/compiler/basicTypes/Usage.hs
@@ -0,0 +1,139 @@
+module Usage where
+
+import BasicTypes
+import Binary
+import Maybes ( expectJust )
+import Outputable
+
+import Data.Function ( on )
+
+-- * Types
+
+type Use = Arity
+
+data Usage
+  = Zero
+  | One {-# UNPACK #-} !Use
+  | Many {-# UNPACK #-} !Use
+  deriving (Eq, Show)
+
+use :: Usage -> Maybe Use
+use (One u) = Just u
+use (Many u) = Just u
+use _ = Nothing
+
+data UsageSig
+  = BotUsageSig -- ^ All further args absent
+  | TopUsageSig -- ^ All further args used many times
+  | ArgUsage !Usage !UsageSig -- ^ Specific arg use
+  deriving (Eq, Show)
+
+-- * Lattice operations
+
+topUse :: Use
+topUse = 0
+
+-- TODO: decide if botUse would be valuable, and if so, change @Use@ to an
+-- appropriate integer type with pos. Inf.
+
+lubUse :: Use -> Use -> Use
+lubUse = min
+
+botUsage :: Usage
+botUsage = Zero
+
+topUsage :: Usage
+topUsage = Many topUse
+
+lubUsage :: Usage -> Usage -> Usage
+lubUsage Zero u = u
+lubUsage u Zero = u
+lubUsage (One u1) (One u2) = One (lubUse u1 u2)
+lubUsage u1 u2 = Many (extractAndLubUse u1 u2)
+  where
+    extractAndLubUse = lubUse `on` expectJust ": Zero has no use" . use
+
+botUsageSig :: UsageSig
+botUsageSig = BotUsageSig
+
+topUsageSig :: UsageSig
+topUsageSig = TopUsageSig
+
+lubUsageSig :: UsageSig -> UsageSig -> UsageSig
+lubUsageSig BotUsageSig s = s
+lubUsageSig s BotUsageSig = s
+lubUsageSig TopUsageSig _ = TopUsageSig
+lubUsageSig _ TopUsageSig = TopUsageSig
+lubUsageSig (ArgUsage u1 s1) (ArgUsage u2 s2) = ArgUsage (lubUsage u1 u2) (lubUsageSig s1 s2)
+
+-- * Working with @Use@, @Usage@ and @UsageSig@
+
+mapUseArity :: (Arity -> Arity) -> Use -> Use
+mapUseArity f use = f use
+
+consUsageSig :: Usage -> UsageSig -> UsageSig
+consUsageSig u s
+  | u == botUsage
+  , s == botUsageSig
+  = botUsageSig
+
+  | u == topUsage
+  , s == topUsageSig
+  = topUsageSig
+
+  | otherwise
+  = ArgUsage u s
+
+unconsUsageSig :: UsageSig -> (Usage, UsageSig)
+unconsUsageSig BotUsageSig = (botUsage, BotUsageSig)
+unconsUsageSig TopUsageSig = (topUsage, TopUsageSig)
+unconsUsageSig (ArgUsage u s) = (u, s)
+
+trimUsageSig :: Arity -> UsageSig -> UsageSig
+trimUsageSig 0 _ = topUsageSig
+trimUsageSig _ TopUsageSig = topUsageSig
+trimUsageSig arity sig = consUsageSig headUsage (trimUsageSig (arity - 1) tailUsage)
+  where
+    (headUsage, tailUsage) = unconsUsageSig sig
+
+-- * Pretty-printing
+
+-- | Formats use like a Call demand.
+pprUse :: Use -> SDoc
+pprUse 0 = text "U"
+pprUse u = text "C" <> parens (pprUse (u - 1))
+
+instance Outputable Usage where
+  ppr Zero = text "A"
+  ppr (One u) = text "1*" <> pprUse u
+  ppr (Many u) = pprUse u
+
+instance Outputable UsageSig where
+  ppr BotUsageSig = text "AA.."
+  ppr TopUsageSig = text "UU.."
+  ppr (ArgUsage u sig) = ppr u <> ppr sig
+
+-- * Serialization
+
+-- | Mostly important for serializing @UsageSig@ in interface files.
+instance Binary Usage where
+  put_ bh Zero = putByte bh 0
+  put_ bh (One use) = putByte bh 1 >> put_ bh use
+  put_ bh (Many use) = putByte bh 2 >> put_ bh use
+  get  bh = do
+    h <- getByte bh
+    case h of
+      0 -> return Zero
+      1 -> One <$> get bh
+      _ -> Many <$> get bh
+
+instance Binary UsageSig where
+  put_ bh BotUsageSig = putByte bh 0
+  put_ bh TopUsageSig = putByte bh 1
+  put_ bh (ArgUsage u sig) = putByte bh 2 >> put_ bh u >> put_ bh sig
+  get  bh = do
+    h <- getByte bh
+    case h of
+      0 -> return BotUsageSig
+      1 -> return TopUsageSig
+      _ -> ArgUsage <$> get bh <*> get bh
diff --git a/compiler/coreSyn/PprCore.hs b/compiler/coreSyn/PprCore.hs
index 28d35528fe..5889fff949 100644
--- a/compiler/coreSyn/PprCore.hs
+++ b/compiler/coreSyn/PprCore.hs
@@ -23,6 +23,7 @@ import Var
 import Id
 import IdInfo
 import Demand
+import Usage
 import DataCon
 import TyCon
 import Type
@@ -458,7 +459,8 @@ ppIdInfo id info
     showAttributes
     [ (True, pp_scope <> ppr (idDetails id))
     , (has_arity,        text "Arity=" <> int arity)
-    , (has_called_arity, text "CallArity=" <> int called_arity)
+    , (has_arg_usage,    text "Usg=" <> ppr called_arity)
+    , (has_called_arity, text "CallArity=" <> ppr called_arity)
     , (has_caf_info,     text "Caf=" <> ppr caf_info)
     , (has_str_info,     text "Str=" <> pprStrictness str_info)
     , (has_unf,          text "Unf=" <> ppr unf_info)
@@ -475,7 +477,10 @@ ppIdInfo id info
     has_arity = arity /= 0
 
     called_arity = callArityInfo info
-    has_called_arity = called_arity /= 0
+    has_called_arity = called_arity /= topUsage
+
+    arg_usage = argUsageInfo info
+    has_arg_usage = arg_usage /= topUsageSig
 
     caf_info = cafInfo info
     has_caf_info = not (mayHaveCafRefs caf_info)
diff --git a/compiler/ghc.cabal.in b/compiler/ghc.cabal.in
index 4849c56443..3aba59ad17 100644
--- a/compiler/ghc.cabal.in
+++ b/compiler/ghc.cabal.in
@@ -207,6 +207,7 @@ Library
         SrcLoc
         UniqSupply
         Unique
+        Usage
         Var
         VarEnv
         VarSet
@@ -412,6 +413,9 @@ Library
         StgLint
         StgSyn
         CallArity
+        CallArity.Types
+        CallArity.FrameworkBuilder
+        CallArity.Analysis
         DmdAnal
         WorkWrap
         WwLib
diff --git a/compiler/iface/IfaceSyn.hs b/compiler/iface/IfaceSyn.hs
index b023a46fb2..9fc1d780d3 100644
--- a/compiler/iface/IfaceSyn.hs
+++ b/compiler/iface/IfaceSyn.hs
@@ -46,6 +46,7 @@ import BinFingerprint
 import CoreSyn( IsOrphan, isOrphan )
 import PprCore()            -- Printing DFunArgs
 import Demand
+import Usage
 import Class
 import FieldLabel
 import NameSet
@@ -328,7 +329,7 @@ data IfaceIdInfo
 data IfaceInfoItem
   = HsArity         Arity
   | HsStrictness    StrictSig
-  | HsCardinality   CardinalitySig
+  | HsUsage         UsageSig
   | HsInline        InlinePragma
   | HsUnfold        Bool             -- True <=> isStrongLoopBreaker is true
                     IfaceUnfolding   -- See Note [Expose recursive functions]
@@ -1224,7 +1225,7 @@ instance Outputable IfaceInfoItem where
   ppr (HsInline prag)       = text "Inline:" <+> ppr prag
   ppr (HsArity arity)       = text "Arity:" <+> int arity
   ppr (HsStrictness str)    = text "Strictness:" <+> pprIfaceStrictSig str
-  ppr (HsCardinality card)  = text "Cardinality:" <+> pprIfaceCardinalitySig card
+  ppr (HsUsage usg)         = text "Usage:" <+> ppr usg
   ppr HsNoCafRefs           = text "HasNoCafRefs"
   ppr HsLevity              = text "Never levity-polymorphic"
 
@@ -1967,7 +1968,7 @@ instance Binary IfaceIdInfo where
 instance Binary IfaceInfoItem where
     put_ bh (HsArity aa)          = putByte bh 0 >> put_ bh aa
     put_ bh (HsStrictness ab)     = putByte bh 1 >> put_ bh ab
-    put_ bh (HsCardinality ac)    = putByte bh 2 >> put_ bh ac
+    put_ bh (HsUsage ac)          = putByte bh 2 >> put_ bh ac
     put_ bh (HsUnfold lb ad)      = putByte bh 3 >> put_ bh lb >> put_ bh ad
     put_ bh (HsInline ad)         = putByte bh 4 >> put_ bh ad
     put_ bh HsNoCafRefs           = putByte bh 5
@@ -1977,7 +1978,7 @@ instance Binary IfaceInfoItem where
         case h of
             0 -> liftM HsArity $ get bh
             1 -> liftM HsStrictness $ get bh
-            2 -> liftM HsCardinality $ get bh
+            2 -> liftM HsUsage $ get bh
             3 -> do lb <- get bh
                     ad <- get bh
                     return (HsUnfold lb ad)
diff --git a/compiler/iface/TcIface.hs b/compiler/iface/TcIface.hs
index 07fd9cb6e8..89b5d7b81f 100644
--- a/compiler/iface/TcIface.hs
+++ b/compiler/iface/TcIface.hs
@@ -1569,7 +1569,7 @@ tcIdInfo ignore_prags name ty info = do
     tcPrag info HsNoCafRefs        = return (info `setCafInfo`   NoCafRefs)
     tcPrag info (HsArity arity)    = return (info `setArityInfo` arity)
     tcPrag info (HsStrictness str) = return (info `setStrictnessInfo` str)
-    tcPrag info (HsCardinality card) = return (info `setCallArityInfo` card)
+    tcPrag info (HsUsage usg)      = return (info `setArgUsageInfo` usg)
     tcPrag info (HsInline prag)    = return (info `setInlinePragInfo` prag)
     tcPrag info HsLevity           = return (info `setNeverLevPoly` ty)
 
diff --git a/compiler/iface/ToIface.hs b/compiler/iface/ToIface.hs
index fcda26c9da..eed6138f84 100644
--- a/compiler/iface/ToIface.hs
+++ b/compiler/iface/ToIface.hs
@@ -67,6 +67,7 @@ import VarEnv
 import VarSet
 import TyCoRep
 import Demand ( isTopSig )
+import Usage ( topUsageSig )
 
 import Data.Maybe ( catMaybes )
 
@@ -370,7 +371,7 @@ toIfaceIdDetails other = pprTrace "toIfaceIdDetails" (ppr other)
 toIfaceIdInfo :: IdInfo -> IfaceIdInfo
 toIfaceIdInfo id_info
   = case catMaybes [arity_hsinfo, caf_hsinfo, strict_hsinfo,
-                    inline_hsinfo,  unfold_hsinfo, levity_hsinfo] of
+                    usage_hsinfo, inline_hsinfo,  unfold_hsinfo, levity_hsinfo] of
        []    -> NoInfo
        infos -> HasInfo infos
                -- NB: strictness and arity must appear in the list before unfolding
@@ -393,10 +394,10 @@ toIfaceIdInfo id_info
     strict_hsinfo | not (isTopSig str_info) = Just (HsStrictness str_info)
                   | otherwise               = Nothing
 
-    ------------  Cardinality --------------
-    sig_info = callArityInfo id_info
-    strict_hsinfo | card_info /= topCardinality = Just (HsCardinality card_info)
-                  | otherwise                   = Nothing
+    ------------  Usage --------------
+    usg_info = argUsageInfo id_info
+    usage_hsinfo | usg_info /= topUsageSig = Just (HsUsage usg_info)
+                 | otherwise               = Nothing
 
     ------------  Unfolding  --------------
     unfold_hsinfo = toIfUnfolding loop_breaker (unfoldingInfo id_info)
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 6008c0d97f..9a963fb8d8 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -8,25 +8,24 @@ module CallArity.Analysis where
 import CallArity.Types
 import CallArity.FrameworkBuilder
 
-import DynFlags      (DynFlags)
+import DynFlags      ( DynFlags )
 import Maybes
 import VarEnv
 
-import Data.Map.Strict   (Map)
-import qualified Data.Map.Strict as Map
-import Data.Maybe
+import Control.Monad ( forM )
 import qualified Data.Set as Set
 
 import BasicTypes
 import CoreSyn
 import CoreArity ( typeArity )
 import CoreUtils ( exprIsCheap )
+import Demand
 import MkCore
 import Id
-import Outputable
-import Demand
 import UniqFM
 import UnVarGraph
+import Usage
+import Var ( isTyVar )
 
 
 {-
@@ -283,12 +282,12 @@ Note [Analysis type signature]
 The work-hourse of the analysis is the function `callArityAnal`, with the
 following type:
 
-    type CallArityType = (UnVarGraph, VarEnv Arity)
+    type UsageType = (UnVarGraph, VarEnv Arity)
     callArityAnal ::
         Arity ->  -- The arity this expression is called with
         VarSet -> -- The set of interesting variables
         CoreExpr ->  -- The expression to analyse
-        (CallArityType, CoreExpr)
+        (UsageType, CoreExpr)
 
 and the following specification:
 
@@ -323,7 +322,7 @@ If we decide that the variable bound in `let x = e1 in e2` is not interesting,
 the analysis of `e2` will not report anything about `x`. To ensure that
 `callArityBind` does still do the right thing we have to take that into account
 everytime we look up up `x` in the analysis result of `e2`.
-  * Instead of calling lookupCallArityType, we return (0, True), indicating
+  * Instead of calling lookupUsage, we return (0, True), indicating
     that this variable might be called many times with no arguments.
   * Instead of checking `calledWith x`, we assume that everything can be called
     with it.
@@ -342,7 +341,7 @@ Note [Recursion and fixpointing]
 For a mutually recursive let, we begin by
  1. analysing the body, using the same incoming arity as for the whole expression.
  2. Then we iterate, memoizing for each of the bound variables the last
-    analysis call, i.e. incoming arity, whether it is called once, and the CallArityType.
+    analysis call, i.e. incoming arity, whether it is called once, and the UsageType.
  3. We combine the analysis result from the body and the memoized results for
     the arguments (if already present).
  4. For each variable, we find out the incoming arity and whether it is called
@@ -377,7 +376,7 @@ Note [Analysing top-level binds]
 We can eta-expand top-level-binds if they are not exported, as we see all calls
 to them. The plan is as follows: Treat the top-level binds as nested lets around
 a body representing “all external calls”, which returns a pessimistic
-CallArityType (the co-call graph is the complete graph, all arityies 0).
+UsageType (the co-call graph is the complete graph, all arityies 0).
 
 Note [Trimming arity]
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
@@ -436,42 +435,30 @@ callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
 callArityAnalProgram _dflags = exprToModule . callArityRHS . moduleToExpr
 
 callArityRHS :: CoreExpr -> CoreExpr
-callArityRHS e = lookup_expr (runFramework fw (Set.singleton (node, 0)))
-  where
-    (node, fw) = buildFramework $
-      registerTransferFunction (LowerThan (FrameworkNode 0)) $ \node -> do
-        transfer <- callArityExpr emptyVarEnv e
-        -- We only get away with using alwaysChangeDetector because this won't
-        -- introduce a cycle.
-        return (node, (transfer, alwaysChangeDetector))
-
-    lookup_expr :: Map (FrameworkNode, Arity) AnalResult -> CoreExpr
-    lookup_expr result_map = case Map.lookup (node, 0) result_map of
-      Nothing -> pprPanic "callArityRHS" empty
-      Just (_, e) -> e
+callArityRHS e = snd (buildAndRun (callArityExpr emptyVarEnv e) topUse)
 
 -- | The main analysis function. See Note [Analysis type signature]
 callArityExpr
   :: VarEnv FrameworkNode
   -> CoreExpr
-  -> FrameworkBuilder (Arity -> TransferFunction AnalResult)
+  -> FrameworkBuilder (Use -> TransferFunction AnalResult)
 
 callArityExprTrivial
   :: CoreExpr
-  -> FrameworkBuilder (Arity -> TransferFunction AnalResult)
+  -> FrameworkBuilder (Use -> TransferFunction AnalResult)
 callArityExprTrivial e
-  = return (\_ -> return (emptyArityType, e))
+  = return (\_ -> return (emptyUsageType, e))
 
 callArityExprMap
   :: VarEnv FrameworkNode
   -> (CoreExpr -> a)
   -> CoreExpr
-  -> FrameworkBuilder (Arity -> TransferFunction (CallArityType, a)) -- @a@ instead of @CoreExpr@
+  -> FrameworkBuilder (Use -> TransferFunction (UsageType, a)) -- @a@ instead of @CoreExpr@
 callArityExprMap nodes f e
   = transfer' <$> callArityExpr nodes e
   where
-    transfer' transfer arity = do
-      (cat, e') <- transfer arity
+    transfer' transfer use = do
+      (cat, e') <- transfer use
       return (cat, f e')
 
 -- The trivial base cases
@@ -484,35 +471,35 @@ callArityExpr nodes (Tick t e) = callArityExprMap nodes (Tick t) e
 callArityExpr nodes (Cast e c) = callArityExprMap nodes (flip Cast c) e
 
 -- The interesting cases: Variables, Lambdas, Lets, Applications, Cases
-callArityExpr nodes e@(Var v) = return transfer
+callArityExpr nodes e@(Var id) = return transfer
   where
-    transfer arity
-      | isInteresting v
-      , Just node <- lookupVarEnv nodes v
+    transfer use
+      | isInteresting id
+      , Just node <- lookupVarEnv nodes id
       = do
-        (cat_callee, _) <- dependOnWithDefault (unusedArgsArityType arity, e) (node, arity)
-        -- It is crucial that we only use cat_args here, as every other field
+        (ut_callee, _) <- dependOnWithDefault (unusedArgsUsageType use, e) (node, use)
+        -- It is crucial that we only use ut_args here, as every other field
         -- might be unstable and thus too optimistic.
-        return ((unitArityType v arity) { cat_args = cat_args cat_callee }, e)
+        return ((unitUsageType id use) { ut_args = ut_args ut_callee }, e)
 
-      | isInteresting v
-      , isGlobalId v
-      = return (unitArityType v arity { cat_args = idCallArity v }, e)
+      | isInteresting id
+      , isGlobalId id
+      = return ((unitUsageType id use) { ut_args = idArgUsage id }, e)
 
-      | isInteresting v
+      | isInteresting id
       -- LocalId, not present in @nodes@, e.g. a lambda-bound variable.
       -- We are only second-order, so we don't model signatures for parameters!
-      = return (unitArityType v arity, e)
+      = return (unitUsageType id use, e)
 
       | otherwise
       -- We don't track uninteresting vars and implicitly assume they are called
       -- multiple times with every other variable.
       -- See Note [Taking boring variables into account]
-      = return (emptyArityType, e)
+      = return (emptyUsageType, e)
 
-callArityExpr nodes (Lam v e)
-  | isTyVar v = callArityExprMap nodes (Lam v) e -- Non-value lambdas are ignored
-  | otherwise = transfer' <$> callArityExpr nodes e
+callArityExpr nodes (Lam id e)
+  | isTyVar id = callArityExprMap nodes (Lam id) e -- Non-value lambdas are ignored
+  | otherwise  = transfer' <$> callArityExpr nodes e
   where
     transfer' transfer 0 = do
       -- We have a lambda that may be called multiple times, so its free variables
@@ -520,12 +507,13 @@ callArityExpr nodes (Lam v e)
       -- Also regardless of the variable not being interesting,
       -- we have to add the var as an argument.
       (cat, e') <- transfer 0
-      return (makeIdArg v (calledMultipleTimes cat), Lam v e')
+      return (makeIdArg id (calledMultipleTimes cat), Lam id e')
 
-    transfer' transfer arity = do
+    transfer' transfer use = do
       -- We have a lambda that we are applying to. decrease arity.
-      (cat, e') <- transfer (arity - 1)
-      return (makeIdArg v cat, Lam v e')
+      (cat, e') <- transfer (use - 1)
+      -- TODO: annotate id
+      return (makeIdArg id cat, Lam id e')
 
 callArityExpr nodes (App f (Type t)) = callArityExprMap nodes (flip App (Type t)) f
 
@@ -534,24 +522,23 @@ callArityExpr nodes (App f (Type t)) = callArityExprMap nodes (flip App (Type t)
 callArityExpr nodes (App f a) = do
   transfer_f <- callArityExpr nodes f
   transfer_a <- callArityExpr nodes a
-  return $ \arity -> do
-    (cat_f, f') <- transfer_f (arity + 1)
-    --pprTrace "App:f'" (ppr (cat_f, f')) $ return ()
+  return $ \use -> do
+    (ut_f, f') <- transfer_f (use + 1)
+    --pprTrace "App:f'" (ppr (ut_f, f')) $ return ()
     -- peel off one argument from the type
-    let (arg_usage, cat_f') = peelCallArityType cat_f
+    let (arg_usage, ut_f') = peelUsageType ut_f
+    let called_once = id
+    let analyse finish_ut_a use = do
+          (ut_a, a') <- transfer_a use
+          --pprTrace "App:a'" (text "safe_arity:" <+> ppr safe_arity <+> ppr (ut_a, a')) $ return ()
+          let ut_a' = finish_ut_a ut_a
+          return (ut_f' `both` ut_a', App f' a')
     -- In call-by-need, arguments are evaluated at most once, so they qualify as
     -- thunk.
-    case oneifyCardinalityIfThunk a arg_usage of
-      Zero -> return (cat_f', App f' a) -- TODO: Visit a, too? Seems unnecessary, wasn't called at all
-      One arity -> analyse calledOnce arity
-      Many arity -> analyse calledMultipleTimes arity
-        where
-          calledOnce = id
-          analyse finish_cat_a arity = do
-            (cat_a, a') <- transfer_a arity
-            --pprTrace "App:a'" (text "safe_arity:" <+> ppr safe_arity <+> ppr (cat_a, a')) $ return ()
-            let cat_a' = finish_cat_a cat_a
-            return (cat_f' `both` cat_a', App f' a')
+    case oneifyUsageIfThunk a arg_usage of
+      Zero -> return (ut_f', App f' a) -- TODO: Visit a, too? Seems unnecessary, wasn't called at all
+      One use -> analyse called_once use
+      Many use -> analyse calledMultipleTimes use
 
 -- Case expression.
 callArityExpr nodes (Case scrut bndr ty alts) = do
@@ -561,60 +548,63 @@ callArityExpr nodes (Case scrut bndr ty alts) = do
     --       We also shouldn't track them in the co call graph (they are boring)
   transfer_alts <- forM alts $ \(dc, bndrs, e) ->
     callArityExprMap nodes (dc, bndrs,) e
-  return $ \arity -> do
-    (cat_scrut, scrut') <- transfer_scrut 0
-    (cat_alts, alts') <- unzip <$> mapM ($ arity) transfer_alts
-    let cat = trimArgs arity (lubTypes cat_alts) `both` cat_scrut
+  return $ \use -> do
+    (ut_scrut, scrut') <- transfer_scrut 0
+    (ut_alts, alts') <- unzip <$> mapM ($ use) transfer_alts
+    let cat = trimArgs use (lubTypes ut_alts) `both` ut_scrut
     -- TODO: Think harder about the diverging case (e.g. matching on `undefined`).
     --       In that case we will declare all arguments as unused from the alts.
     -- pprTrace "callArityExpr:Case"
     --          (vcat [ppr scrut, ppr cat])
-    --pprTrace "Case" (vcat [text "cat_scrut:" <+> ppr cat_scrut, text "cat_alts:" <+> ppr cat_alts, text "cat:" <+> ppr cat]) (return ())
+    --pprTrace "Case" (vcat [text "ut_scrut:" <+> ppr ut_scrut, text "ut_alts:" <+> ppr ut_alts, text "cat:" <+> ppr cat]) (return ())
     return (cat, Case scrut' bndr ty alts')
 
 callArityExpr letdown_nodes (Let bind e) = do
   let initial_binds = flattenBinds [bind]
+  let ids = map fst initial_binds
   -- The order in which we call callArityExpr here is important: This makes sure
   -- the FP iteration will first stabilize bindings before analyzing the body.
   -- Nope, in fact it does exactly the opposite!
-  (letdown_nodes', letup_nodes) <- callArityBind letdown_nodes binds
+  (letdown_nodes', letup_nodes) <- callArityBind letdown_nodes initial_binds
   let lookup_letup_node id = expectJust ": the RHS of id wasn't registered" (lookupVarEnv letup_nodes id)
-  let transfer_rhs (id, rhs) arity =
-        dependOnWithDefault (unusedArgsArityType arity, rhs) (lookup_letup_node id, arity)
+  let transfer_rhs (id, rhs) use =
+        dependOnWithDefault (unusedArgsUsageType use, rhs) (lookup_letup_node id, use)
   transfer_body <- callArityExpr letdown_nodes' e
 
   case bind of
     NonRec _ _ ->
       -- We don't need to dependOn ourselves here, because only the let body can't
       -- call id. Thus we also can spare to allocate a new @FrameworkNode@.
-      return $ \arity -> do
-        (cat_body, e') <- transfer_body arity
-        (cat, [(id', rhs')]) <- unleashLet False initial_binds transfer_rhs cat_body cat_body
-        return (typeDelList (bindersOf bind) cat, Let (NonRec id' rhs') e')
+      return $ \use -> do
+        (ut_body, e') <- transfer_body use
+        (ut, [(id', rhs')]) <- unleashLet False initial_binds transfer_rhs ut_body ut_body
+        return (typeDelList (bindersOf bind) ut, Let (NonRec id' rhs') e')
     Rec _ -> do -- The binding group stored in the @Rec@ constructor is always the initial one!
       -- This is a little more complicated, as we'll introduce a new FrameworkNode
       -- which we'll depend on ourselves.
       node <- registerTransferFunction (LowerThan (minimum (eltsUFM letup_nodes))) $ \node -> do
-        let transfer arity = do
-              (cat_body, e') <- transfer_body arity
+        let transfer :: Use -> TransferFunction AnalResult
+            transfer use = do
+              (ut_body, e') <- transfer_body use
               -- This is the actual fixed-point iteration: we depend on usage
               -- results from the previous iteration, defaulting to just the body.
-              (cat_usage, Let (Rec old_bind) _) <- dependOnWithDefault (cat_body, Let bind e') (node, arity)
-              (cat, bind') <- unleashLet True old_bind transfer_rhs cat_usage cat_body
-              return (cat, Let (Rec bind') e')
+              (ut_usage, Let (Rec old_bind) _) <- dependOnWithDefault (ut_body, Let bind e') (node, use)
+              (ut, bind') <- unleashLet True old_bind transfer_rhs ut_usage ut_body
+              return (ut, Let (Rec bind') e')
 
-        let change_detector changed_refs (old, _) (new, _) =
+        let change_detector :: ChangeDetector
+            change_detector changed_refs (old, _) (new, _) =
               -- since we only care for arity and called once information of the
               -- previous iteration, we can efficiently test for changes.
               --pprTrace "change_detector" (vcat[ppr node, ppr changed_refs, ppr old, ppr new])
               map fst (Set.toList changed_refs) /= [node]
-              || any (\id -> lookupCallArityType old id /= lookupCallArityType new id) (map fst binds)
+              || any (\id -> lookupUsage old id /= lookupUsage new id) ids
 
         return (node, (transfer, change_detector))
 
       -- Now for the actual TransferFunction of this expr...
-      return $ \arity -> do
-        (cat, let') <- dependOnWithDefault (emptyArityType, Let bind e) (node, arity)
+      return $ \use -> do
+        (cat, let') <- dependOnWithDefault (emptyUsageType, Let bind e) (node, use)
         --pprTrace "Let" (ppr (cat, let')) $ return ()
         return (typeDelList (bindersOf bind) cat, let')
 
@@ -633,21 +623,21 @@ callArityBind letdown_nodes = go letdown_nodes emptyVarEnv
             (extendVarEnv letup_nodes id letup_node)
             binds
           transfer_up' <- callArityExpr letdown_nodes' rhs
-          let transfer_up arity = do
-                --pprTrace "Bind:Before" (text "id:" <+> ppr id <+> text "arity:" <+> ppr arity) $ return ()
-                res <- transfer_up' arity
+          let transfer_up use = do
+                --pprTrace "Bind:Before" (text "id:" <+> ppr id <+> text "use:" <+> ppr use) $ return ()
+                res <- transfer_up' use
                 --pprTrace "Bind:Finished" (ppr res) $ return ()
                 return res
-          let transfer_down arity = dependOnWithDefault (unusedArgsArityType arity, rhs) (letup_node, arity)
+          let transfer_down use = dependOnWithDefault (unusedArgsUsageType use, rhs) (letup_node, use)
           let change_detector_down _ (old, _) (new, _) =
                 -- The only reason we split the transfer fuctions up is cheap
                 -- change detection for the LetDown case. This implies that
-                -- use sites of the LetDown component may only use the cat_args
+                -- use sites of the LetDown component may only use the ut_args
                 -- component!
                 -- FIXME: Encode this in the FrameworkNode type somehow, but I
                 -- don't think it's worth the trouble.
-                --pprTrace "change_detector_down" (ppr (cat_args old) <+> ppr (cat_args new) <+> ppr (cat_args old /= cat_args new)) $
-                cat_args old /= cat_args new
+                --pprTrace "change_detector_down" (ppr (ut_args old) <+> ppr (ut_args new) <+> ppr (ut_args old /= ut_args new)) $
+                ut_args old /= ut_args new
           let ret = (letdown_nodes', letup_nodes') -- What we return from callArityBind
           let letup = (transfer_up, alwaysChangeDetector) -- What we register for letup_node
           let letdown = (transfer_down, change_detector_down) -- What we register for letdown_node
@@ -656,52 +646,56 @@ callArityBind letdown_nodes = go letdown_nodes emptyVarEnv
 unleashLet
   :: Bool
   -> [(Id, CoreExpr)]
-  -> (Id, CoreExpr) -> Arity -> TransferFunction AnalResult
-  -> CallArityType
-  -> CallArityType
-  -> TransferFunction (CallArityType, [(Id, CoreExpr)])
-unleashLet is_recursive binds transfer_rhs cat_usage cat_body = do
-  (cat_rhss, binds') <- unzip <$> forM binds $ \bind ->
-    unleashCall is_recursive cat_usage bind (transfer_rhs bind)
+  -> ((Id, CoreExpr) -> Use -> TransferFunction AnalResult)
+  -> UsageType
+  -> UsageType
+  -> TransferFunction (UsageType, [(Id, CoreExpr)])
+unleashLet is_recursive binds transfer_rhs ut_usage ut_body = do
+  (ut_rhss, binds') <- fmap unzip $ forM binds $ \bind ->
+    unleashCall is_recursive ut_usage bind (transfer_rhs bind)
   let ids = map fst binds'
-  let cat_final = callArityLetEnv (zip ids cat_rhss) cat_body
-  return (cat_final, binds')
+  let ut_final = callArityLetEnv (zip ids ut_rhss) ut_body
+  return (ut_final, binds')
 
 unleashCall
   :: Bool
-  -> CallArityType
+  -> UsageType
   -> (Id, CoreExpr)
-  -> Arity -> TransferFunction AnalResult
-  -> TransferFunction (CallArityType, (Id, CoreExpr))
-unleashCall is_recursive cat_usage (id, rhs) transfer_rhs
+  -> (Use -> TransferFunction AnalResult)
+  -> TransferFunction (UsageType, (Id, CoreExpr))
+unleashCall is_recursive ut_usage (id, rhs) transfer_rhs
   | Zero <- usage
-  = return (emptyArityType, (id, rhs)) -- No call to @id@ (yet)
-  | One arity <- usage
-  = analyse calledOnce arity
-  | Many arity <- usage
-  = analyse calledMultipleTimes arity
+  = return (emptyUsageType, (id, rhs)) -- No call to @id@ (yet)
+  | One use <- usage
+  = analyse called_once use
+  | Many use <- usage
+  = analyse calledMultipleTimes use
   where
     usage =
-      oneifyCardinalityIfThunk rhs
+      oneifyUsageIfThunk rhs
       -- See Note [Thunks in recursive groups]
       -- @is_recursive@ implies @not called_once@ (otherwise, why would it be
       -- recursive?), although the co-call graph doesn't model it that way.
       -- Self-edges in the co-call graph correspond to non-linear recursion.
-      . if is_recursive then manifyCardinality else id
-      . lookupCallArityType cat_usage
+      . apply_when is_recursive manifyUsage
+      . lookupUsage ut_usage
       $ id
-    calledOnce u = u
-    analyse finish_cat_rhs arity = do
+    apply_when b f = if b then f else Prelude.id
+    called_once u = u
+    analyse finish_ut_rhs use = do
       -- See Note [Trimming arity]
-      let trimmed_arity = trimArity id arity
-      -- TODO: Find out if (where) we need the trimmed_arity here or not
-      -- We probably want to analyze with arity und annotate trimmed_arity.
-      -- Although CA analyzes with trimmed_arity, so we do that for now
+      let trimmed_use = mapUseArity (trimArity id) use
+      -- TODO: Find out if (where) we need the trimmed_use here or not
+      -- We probably want to analyze with arity und annotate trimmed_use.
+      -- Although CA analyzes with trimmed_use, so we do that for now
       -- Also if we analysed with arity, we would need to analyze again with
-      -- trimmed_arity nonetheless for the signature!
-      (cat_rhs, rhs') <- transfer_rhs trimmed_arity
-      let cat_rhs' = finish_cat_rhs cat_rhs
-      return (cat_rhs', (id `setIdCallArity` cat_args cat_rhs', rhs'))
+      -- trimmed_use nonetheless for the signature!
+      (ut_rhs, rhs') <- transfer_rhs trimmed_use
+      let ut_rhs' = finish_ut_rhs ut_rhs
+      let id' = id
+            `setIdArgUsage` ut_args ut_rhs'
+            `setIdCallArity` lookupUsage ut_rhs' id
+      return (ut_rhs', (id', rhs'))
 
 -- | See Note [What is a thunk].
 isThunk :: CoreExpr -> Bool
@@ -717,8 +711,8 @@ isThunk = not . exprIsCheap
 
     This function should be used anywhere expressions are to be let-bound.
 -}
-oneifyCardinalityIfThunk :: -> CoreExpr -> Cardinality -> Cardinality
-oneifyCardinalityIfThunk e (Many arity)
+oneifyUsageIfThunk :: CoreExpr -> Usage -> Usage
+oneifyUsageIfThunk e (Many use)
   -- A thunk was called multiple times! Do not eta-expand
   | isThunk e = One 0
   -- In case e is cheap and we use the let-bound var of e with @Many 0@, this
@@ -727,48 +721,43 @@ oneifyCardinalityIfThunk e (Many arity)
   -- I'm not sure if this actually buys us anything, @e@ is cheap after all.
   -- But it may still be non-@exprIsTrivial@, so just leaving it here for the
   -- time being.
-  | arity == 0 = One 0
-oneifyCardinalityIfThunk _ u = u
-
--- | Multiplies with @Many@; $\omega*_$ formally. @manifyCardinality Zero = Zero@ still!
-manifyCardinality :: Cardinality -> Cardinality
-manifyCardinality (One arity) = Many arity
-manifyCardinality u = u
+  | use == 0 = One 0
+oneifyUsageIfThunk _ u = u
 
--- Which bindings should we look at?
--- See Note [Which variables are interesting]
-isInteresting :: Var -> Bool
-isInteresting v = not $ null (typeArity (idType v))
+-- | Multiplies with @Many@; $\omega*_$ formally. @manifyUsage Zero = Zero@ still!
+manifyUsage :: Usage -> Usage
+manifyUsage (One use) = Many use
+manifyUsage u = u
 
 -- Combining the results from body and rhs of a let binding
 -- See Note [Analysis II: The Co-Called analysis]
 callArityLetEnv
-  :: [(Id, CallArityType)]
-  -> CallArityType
-  -> CallArityType
-callArityLetEnv cat_rhss cat_body
+  :: [(Id, UsageType)]
+  -> UsageType
+  -> UsageType
+callArityLetEnv ut_rhss ut_body
     = -- (if length ae_rhss > 300 then pprTrace "callArityLetEnv" (vcat [ppr ae_rhss, ppr ae_body, ppr ae_new]) else id) $
-      cat_new
+      ut_new
   where
-    ids = map fst cat_rhss
+    ids = map fst ut_rhss
 
     -- This is already the complete type, but with references from the current
     -- binding group not resolved.
-    -- For the non-recursive case, at least cat_body may refer to some bound var
-    -- which we have to handle, for the recursive case even any of cat_rhss may.
+    -- For the non-recursive case, at least ut_body may refer to some bound var
+    -- which we have to handle, for the recursive case even any of ut_rhss may.
     -- This is why we have to union in appropriate cross_calls, which basically
-    -- perform substitution of Id to CallArityType.
-    cat_combined = lubTypes (cat_body : map (unusedArgs . snd) cat_rhss)
+    -- perform substitution of Id to UsageType.
+    ut_combined = lubTypes (ut_body : map (unusedArgs . snd) ut_rhss)
 
     cross_calls
         -- Calculating cross_calls is expensive. Simply be conservative
         -- if the mutually recursive group becomes too large.
         -- TODO: I *think* 5 is enough here, but this used to be 25.
-        | length cat_rhss > 5 = completeGraph (domType cat_combined)
-        | otherwise            = unionUnVarGraphs $ map cross_call cat_rhss
-    cross_call (id, cat_rhs) = completeBipartiteGraph called_by_id called_with_id
+        | length ut_rhss > 5 = completeGraph (domType ut_combined)
+        | otherwise            = unionUnVarGraphs $ map cross_call ut_rhss
+    cross_call (id, ut_rhs) = completeBipartiteGraph called_by_id called_with_id
       where
-        is_thunk = length (idCallArity id) == 0 -- This is a new annotation, from this FP iteration!
+        is_thunk = use (idCallArity id) == Just 0 -- This is a new annotation, from this FP iteration!
         -- We only add self cross calls if we really can recurse into ourselves.
         -- This is not the case for thunks (and non-recursive bindings, but
         -- then there won't be any mention of id in the rhs).
@@ -777,15 +766,15 @@ callArityLetEnv cat_rhss cat_body
         -- What rhs are relevant as happening before (or after) calling id?
         --    If id doesn't recurse into itself, everything from all the _other_ variables
         --    If id is self-recursive, everything can happen.
-        cat_before_id
-            | is_thunk  = lubTypes (cat_body : map (unusedArgs . snd) (filter ((/= id) . fst) cat_rhss))
-            | otherwise = cat_combined
+        ut_before_id
+            | is_thunk  = lubTypes (ut_body : map (unusedArgs . snd) (filter ((/= id) . fst) ut_rhss))
+            | otherwise = ut_combined
         -- What do we want to know from these?
         -- Which calls can happen next to any recursive call.
-        called_with_id = unionUnVarSets $ map (calledWith cat_before_id) vars
-        called_by_id = domType cat_rhs
+        called_with_id = unionUnVarSets $ map (calledWith ut_before_id) ids
+        called_by_id = domType ut_rhs
 
-    cat_new = modifyCoCalls (cross_calls `unionUnVarGraph`) cat_combined
+    ut_new = modifyCoCalls (cross_calls `unionUnVarGraph`) ut_combined
 
 -- See Note [Trimming arity]
 trimArity :: Id -> Arity -> Arity
diff --git a/compiler/simplCore/CallArity/FrameworkBuilder.hs b/compiler/simplCore/CallArity/FrameworkBuilder.hs
index 3553822e25..00d7254bd5 100644
--- a/compiler/simplCore/CallArity/FrameworkBuilder.hs
+++ b/compiler/simplCore/CallArity/FrameworkBuilder.hs
@@ -6,24 +6,24 @@ module CallArity.FrameworkBuilder
   , ChangeDetector
   , Worklist.alwaysChangeDetector
   , DataFlowFramework
-  , buildFramework
-  , Worklist.runFramework
+  , FrameworkBuilder
   , RequestedPriority (..)
   , registerTransferFunction
   , dependOnWithDefault
+  , buildAndRun
   ) where
 
 import CallArity.Types
+import Outputable
+import Usage
 import qualified Worklist
 
 import Data.IntMap.Lazy (IntMap)
 import qualified Data.IntMap.Lazy as IntMap
 import Data.Map.Strict   (Map)
 import qualified Data.Map.Strict as Map
-import Data.Maybe
 import qualified Data.Set as Set
-import VarEnv
-import Control.Monad
+import Data.Maybe
 import Control.Monad.Fix
 import Control.Monad.Trans.State.Strict
 
@@ -31,31 +31,31 @@ newtype FrameworkNode
   = FrameworkNode Int
   deriving (Show, Eq, Ord, Outputable)
 
-type TransferFunction a = Worklist.TransferFunction (FrameworkNode, Arity) AnalResult a
-type ChangeDetector = Worklist.ChangeDetector (FrameworkNode, Arity) AnalResult
-type DataFlowFramework = Worklist.DataFlowFramework (FrameworkNode, Arity) AnalResult
--- | Maps @FrameworkNode@ to incoming usage dependent @TransferFunction'@s
-type NodeTransferEnv = IntMap (Arity -> TransferFunction AnalResult, ChangeDetector)
+type TransferFunction a = Worklist.TransferFunction (FrameworkNode, Use) AnalResult a
+type ChangeDetector = Worklist.ChangeDetector (FrameworkNode, Use) AnalResult
+type DataFlowFramework = Worklist.DataFlowFramework (FrameworkNode, Use) AnalResult
+-- | Maps @FrameworkNode@ to incoming usage dependent @TransferFunction@s
+type NodeTransferEnv = IntMap (Use -> TransferFunction AnalResult, ChangeDetector)
 
 newtype FrameworkBuilder a
   = FB { unFB :: State NodeTransferEnv a }
   deriving (Functor, Applicative, Monad)
 
 buildFramework :: FrameworkBuilder a -> (a, DataFlowFramework)
-buildFramework (FB state) = (res, DFF dff)
+buildFramework (FB state) = (res, Worklist.DFF dff)
   where
     (res, env) = runState state IntMap.empty -- NodeTransferEnv
-    dff (FrameworkNode node, arity) = case IntMap.lookup node env of
-      Nothing -> pprPanic "CallArity.buildFramework" (ppr node)
-      Just (transfer, detectChange) -> (transfer arity, detectChange)
+    dff (FrameworkNode node, use) = case IntMap.lookup node env of
+      Nothing -> pprPanic "CallArity.FrameworkBuilder.buildFramework" (ppr node)
+      Just (transfer, detectChange) -> (transfer use, detectChange)
 
 data RequestedPriority
-  = LowerThan FrameworkNode
+  = LowerThan !FrameworkNode
   | HighestAvailable
 
 registerTransferFunction
   :: RequestedPriority
-  -> (FrameworkNode -> FrameworkBuilder (a, (Arity -> TransferFunction' AnalResult, ChangeDetector')))
+  -> (FrameworkNode -> FrameworkBuilder (a, (Use -> TransferFunction AnalResult, ChangeDetector)))
   -> FrameworkBuilder a
 registerTransferFunction prio f = FB $ do
   nodes <- get
@@ -63,8 +63,10 @@ registerTransferFunction prio f = FB $ do
         HighestAvailable -> 2 * IntMap.size nodes
         LowerThan (FrameworkNode node)
           | not (IntMap.member (node - 1) nodes) -> node - 1
-          | otherwise -> pprPanic "registerTransferFunction" (text "There was already a node registered with priority" <+> ppr (node - 1))
-  (result, _) <- mfix $ \~(_, entry) -> do
+          | otherwise -> pprPanic
+            "CallArity.FrameworkBuilder.registerTransferFunction"
+            (text "There was already a node registered with priority" <+> ppr (node - 1))
+  (result, _) <- mfix $ \ ~(_, entry) -> do
     -- Using mfix so that we can spare an unnecessary Int counter in the state.
     -- Also because @f@ needs to see its own node in order to define its
     -- transfer function in case of letrec.
@@ -72,9 +74,24 @@ registerTransferFunction prio f = FB $ do
     unFB (f (FrameworkNode node))
   return result
 
-dependOnWithDefault :: AnalResult -> (FrameworkNode, Arity) -> TransferFunction AnalResult
+dependOnWithDefault :: AnalResult -> (FrameworkNode, Use) -> TransferFunction AnalResult
 dependOnWithDefault def which = do
-  --pprTrace "dependOnWithDefault:before" (text "node:" <+> ppr node <+> text "arity:" <+> ppr arity) $ return ()
+  --pprTrace "dependOnWithDefault:before" (text "node:" <+> ppr node <+> text "use:" <+> ppr use) $ return ()
   res <- fromMaybe def <$> Worklist.dependOn which
-  --pprTrace "dependOnWithDefault:after" (vcat [text "node:" <+> ppr node, text "arity:" <+> ppr arity, text "res:" <+> ppr res]) $ return ()
+  --pprTrace "dependOnWithDefault:after" (vcat [text "node:" <+> ppr node, text "use:" <+> ppr use, text "res:" <+> ppr res]) $ return ()
   return res
+
+buildAndRun :: FrameworkBuilder (Use -> TransferFunction AnalResult) -> Use -> AnalResult
+buildAndRun buildTransfer use = lookup_result (Worklist.runFramework fw (Set.singleton (node, use)))
+  where
+    (node, fw) = buildFramework $
+      registerTransferFunction (LowerThan (FrameworkNode 0)) $ \node -> do
+        transfer <- buildTransfer
+        -- We only get away with using alwaysChangeDetector because this won't
+        -- introduce a cycle.
+        return (node, (transfer, Worklist.alwaysChangeDetector))
+
+    lookup_result :: Map (FrameworkNode, Use) AnalResult -> AnalResult
+    lookup_result result_map = case Map.lookup (node, use) result_map of
+      Nothing -> pprPanic "CallArity.FrameworkBuilder.buildAndRun" empty
+      Just res -> res
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index 74725eeffc..56b948ace7 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -1,177 +1,129 @@
 module CallArity.Types where
 
-import Maybes
+import BasicTypes
+import CoreArity ( typeArity )
+import CoreSyn
+import Id
 import Outputable
-import Binary
+import UnVarGraph
+import Usage
+import VarEnv
 
 ---------------------------------------
--- Functions related to CallArityType --
+-- Functions related to UsageType --
 ---------------------------------------
 
 -- Result type for the two analyses.
 -- See Note [Analysis I: The arity analyis]
 -- and Note [Analysis II: The Co-Called analysis]
-data Cardinality
-  = Zero
-  | One {-# UNPACK #-} !Arity
-  | Many {-# UNPACK #-} !Arity
-  deriving (Eq, Show)
-
-arity :: Cardinality -> Maybe Arity
-arity (One a) = Just a
-arity (Many a) = Just a
-arity _ = Nothing
-
-lubCardinality :: Cardinality -> Cardinality -> Cardinality
-lubCardinality Zero u = u
-lubCardinality u Zero = u
-lubCardinality (One arity1) (One arity2) = One (min arity1 arity2)
-lubCardinality = Many . min `on` expectJust ": Zero has no arity" . arity
-
-botCardinality :: Cardinality
-botCardinality = Zero
-
-topCardinality :: Cardinality
-topCardinality = Many 0
-
-type CardinalitySig = [Cardinality]
-
-topCardinalitySig :: CardinalitySig
-topCardinalitySig = []
-
-data CallArityType
-  = CAT
-  { cat_cocalled :: UnVarGraph -- ^ Models cardinality, e.g. 1, many via the co-call relation for _interesting_ variables
-  , cat_arities :: VarEnv Arity -- ^ Models per var usage and absence (card 0)
-  , cat_args :: CardinalitySig -- ^ Collects the signature for captured lambda binders
+data UsageType
+  = UT
+  { ut_cocalled :: !UnVarGraph
+  -- ^ Models cardinality, e.g. at most {1, many} via the co-call relation for
+  -- _interesting_ variables
+  , ut_uses :: !(VarEnv Use)
+  -- ^ Models per var usage and absence (card 0)
+  , ut_args :: !UsageSig
+  -- ^ Collects the signature for captured lambda binders
   }
 
+modifyArgs :: (UsageSig -> UsageSig) -> UsageType -> UsageType
+modifyArgs modifier ut = ut { ut_args = modifier (ut_args ut) }
+
+modifyCoCalls :: (UnVarGraph -> UnVarGraph) -> UsageType -> UsageType
+modifyCoCalls modifier ut = ut { ut_cocalled = modifier (ut_cocalled ut) }
+
 -- | How an expression uses its interesting variables
 -- and the elaborated expression with annotated Ids
-type AnalResult = (CallArityType, CoreExpr)
+type AnalResult = (UsageType, CoreExpr)
+
+-- Which bindings should we look at?
+-- See Note [Which variables are interesting]
+isInteresting :: Var -> Bool
+isInteresting v = not $ null (typeArity (idType v))
 
-emptyArityType :: CallArityType
-emptyArityType = CAT emptyUnVarGraph emptyVarEnv topCardinalitySig
+emptyUsageType :: UsageType
+emptyUsageType = UT emptyUnVarGraph emptyVarEnv topUsageSig
 
-unitArityType :: Var -> Arity -> CallArityType
-unitArityType v arity = emptyArityType { cat_arities = unitVarEnv v arity }
+unitUsageType :: Id -> Use -> UsageType
+unitUsageType id use = emptyUsageType { ut_uses = unitVarEnv id use }
 
-unusedArgsArityType :: Int -> CallArityType
-unusedArgsArityType arity = trimArgs arity (unusedArgs emptyArityType)
+unusedArgsUsageType :: Arity -> UsageType
+unusedArgsUsageType arity = trimArgs arity (unusedArgs emptyUsageType)
 
-unusedArgs :: CallArityType -> CallArityType
-unusedArgs cat = cat { cat_args = repeat Zero }
+unusedArgs :: UsageType -> UsageType
+unusedArgs ut = ut { ut_args = botUsageSig }
 
-trimArgs :: Int -> CallArityType -> CallArityType
-trimArgs arity cat = cat { cat_args = take arity (cat_args cat) }
+trimArgs :: Int -> UsageType -> UsageType
+trimArgs arity = modifyArgs (trimUsageSig arity)
 
-typeDelList :: [Var] -> CallArityType -> CallArityType
-typeDelList vs ae = foldr typeDel ae vs
+typeDelList :: [Id] -> UsageType -> UsageType
+typeDelList ids ae = foldr typeDel ae ids
 
-typeDel :: Var -> CallArityType -> CallArityType
-typeDel v (CAT g ae args) = CAT (g `delNode` v) (ae `delVarEnv` v) args
+typeDel :: Id -> UsageType -> UsageType
+typeDel id (UT g ae args) = UT (g `delNode` id) (ae `delVarEnv` id) args
 
-domType :: CallArityType -> UnVarSet
-domType ca_type = varEnvDom (cat_arities ca_type)
+domType :: UsageType -> UnVarSet
+domType ca_type = varEnvDom (ut_uses ca_type)
 
-makeIdArg :: Id -> CallArityType -> CallArityType
-makeIdArg id ca_type = typeDel id ca_type
-  { cat_args = lookupCallArityType ca_type id : cat_args ca_type }
+makeIdArg :: Id -> UsageType -> UsageType
+makeIdArg id ut = typeDel id (modifyArgs (consUsageSig (lookupUsage ut id)) ut)
 
 -- In the result, find out the minimum arity and whether the variable is called
 -- at most once.
-lookupCallArityType :: CallArityType -> Var -> Cardinality
-lookupCallArityType (CAT g ae _) v = case lookupVarEnv ae v of
+lookupUsage :: UsageType -> Id -> Usage
+lookupUsage (UT g ae _) id = case lookupVarEnv ae id of
   Just a
-    | v `elemUnVarSet` neighbors g v -> Many a
+    | id `elemUnVarSet` neighbors g id -> Many a
     | otherwise -> One a
   Nothing
-    | isInteresting v -> botCardinality
-    -- If v is boring, we will not find it in cat_usage, but always assume topCardinality.
+    | isInteresting id -> botUsage
+    -- If v is boring, we will not find it in ut_usage, but always assume topUsage.
     -- See Note [Taking boring variables into account]
-    | otherwise -> topCardinality
+    | otherwise -> topUsage
 
-calledWith :: CallArityType -> Var -> UnVarSet
-calledWith ca_type v
-  | isInteresting v
-  = neighbors (cat_cocalled ca_type) v
+calledWith :: UsageType -> Id -> UnVarSet
+calledWith ut id
+  | isInteresting id
+  = neighbors (ut_cocalled ut) id
   | otherwise
-  = domType ca_type
+  = domType ut
 
-modifyCoCalls :: (UnVarGraph -> UnVarGraph) -> CallArityType -> CallArityType
-modifyCoCalls modifier ca_type
-  = ca_type { cat_cocalled = modifier (cat_cocalled ca_type) }
-
-addCrossCoCalls :: UnVarSet -> UnVarSet -> CallArityType -> CallArityType
+addCrossCoCalls :: UnVarSet -> UnVarSet -> UsageType -> UsageType
 addCrossCoCalls set1 set2
   = modifyCoCalls (completeBipartiteGraph set1 set2 `unionUnVarGraph`)
 
 -- Replaces the co-call graph by a complete graph (i.e. no information)
-calledMultipleTimes :: CallArityType -> CallArityType
+calledMultipleTimes :: UsageType -> UsageType
 calledMultipleTimes res = modifyCoCalls (const (completeGraph (domType res))) res
 
 -- Used for application and cases
-both :: CallArityType -> CallArityType -> CallArityType
-both r1 r2 = addCrossCoCalls (domType r1) (domType r2) ((r1 `lubType` r2) { cat_args = cat_args r1 })
+both :: UsageType -> UsageType -> UsageType
+both r1 r2 = addCrossCoCalls (domType r1) (domType r2) ((r1 `lubType` r2) { ut_args = ut_args r1 })
 
 -- Used when combining results from alternative cases; take the minimum
-lubType :: CallArityType -> CallArityType -> CallArityType
-lubType (CAT g1 ae1 args1) (CAT g2 ae2 args2) -- both args should really be the same
-  = CAT (g1 `unionUnVarGraph` g2) (ae1 `lubArityEnv` ae2) (zipWith lubCardinality args1 args2)
+lubType :: UsageType -> UsageType -> UsageType
+lubType (UT g1 ae1 args1) (UT g2 ae2 args2)
+  = UT (g1 `unionUnVarGraph` g2) (ae1 `lubUseEnv` ae2) (lubUsageSig args1 args2)
 
-lubArityEnv :: VarEnv Arity -> VarEnv Arity -> VarEnv Arity
-lubArityEnv = plusVarEnv_C min
+lubUseEnv :: VarEnv Use -> VarEnv Use -> VarEnv Use
+lubUseEnv = plusVarEnv_C lubUse
 
-lubTypes :: [CallArityType] -> CallArityType
-lubTypes = foldl lubType (unusedArgs emptyArityType) -- note that this isn't safe for empty input, because of unusedArgs.
+lubTypes :: [UsageType] -> UsageType
+lubTypes = foldl lubType (unusedArgs emptyUsageType)
 
 -- | Peels off a single argument usage from the signature, corresponding to how
 -- @App f a@ uses @a@ under the given incoming arity.
-peelCallArityType :: CallArityType -> (Cardinality, CallArityType)
-peelCallArityType ca_f
-  | arg:args <- cat_args ca_f
-  -- The called expression had a signature we can return.
-  = (arg, ca_f { cat_args = args })
-
-  | otherwise
-  -- The called function had no signature or has not
-  -- been analysed with high enough incoming arity
-  -- (e.g. when loading the signature from an imported id).
-  -- ca_f is rather useless for analysing a, so we conservatively
-  -- assume topCardinality here.
-  = (topCardinality, ca_f)
+peelUsageType :: UsageType -> (Usage, UsageType)
+peelUsageType ut = (usg, ut { ut_args = args' })
+  where
+    (usg, args') = unconsUsageSig (ut_args ut)
 
 -- * Pretty-printing
 
--- | Formats incoming arity like a Call demand.
-pprArity :: Arity -> SDoc
-pprArity 0 = text "U"
-pprArity arity = text "C" <> parens (pprArity (arity - 1))
-
-instance Outputable Cardinality where
-  ppr Zero = text "A"
-  ppr (One arity) = text "1*" <> pprArity arity
-  ppr (Many arity) = pprArity arity
-
-instance Outputable CallArityType where
-  ppr (CAT cocalled arities args) =
-    text "arg usages:" <+> ppr args
-    <+> text "co-calls:" <+> ppr cocalled
-    <+> text "arities:" <+> ppr arities
-
--- | Used for printing top-level cardinality pragmas in interface files
-pprIfaceStrictSig :: CardinalitySig -> SDoc
-pprIfaceStrictSig = hcat . map ppr
-
--- * Serialization
-
-instance Binary Cardinality where
-  put_ bh Zero = putByte bh 0
-  put_ bh (One arity) = putByte bh 1 >> put bh arity
-  put_ bh (Many arity) = putByte bh 2 >> put bh arity
-  get  bh = do
-    h <- getByte bh
-    case h of
-      0 -> return Zero
-      1 -> One <$> get bh
-      _ -> Many <$> get bh
+instance Outputable UsageType where
+  ppr (UT cocalled arities args) = vcat
+    [ text "arg usages:" <+> ppr args
+    , text "co-calls:" <+> ppr cocalled
+    , text "arities:" <+> ppr arities
+    ]
diff --git a/compiler/simplCore/SimplUtils.hs b/compiler/simplCore/SimplUtils.hs
index a2c7b8b855..16dce71402 100644
--- a/compiler/simplCore/SimplUtils.hs
+++ b/compiler/simplCore/SimplUtils.hs
@@ -50,6 +50,7 @@ import Id
 import IdInfo
 import Var
 import Demand
+import Usage
 import SimplMonad
 import Type     hiding( substTy )
 import Coercion hiding( substCo )
@@ -66,6 +67,7 @@ import Literal
 
 import Control.Monad    ( when )
 import Data.List        ( sortBy )
+import Data.Maybe ( fromMaybe )
 
 {-
 ************************************************************************
@@ -1428,7 +1430,7 @@ tryEtaExpandRhs env is_rec bndr rhs
 
       | sm_eta_expand (getMode env)      -- Provided eta-expansion is on
       , let new_arity1 = findRhsArity dflags bndr rhs old_arity
-            new_arity2 = idCallArity bndr
+            new_arity2 = fromMaybe new_arity1 (use (idCallArity bndr))
             new_arity  = max new_arity1 new_arity2
       , new_arity > old_arity      -- And the current manifest arity isn't enough
       = if is_rec == Recursive && isJoinId bndr
diff --git a/compiler/utils/Worklist.hs b/compiler/utils/Worklist.hs
index 693f2a7508..7282fe0946 100644
--- a/compiler/utils/Worklist.hs
+++ b/compiler/utils/Worklist.hs
@@ -10,7 +10,6 @@ import Data.Set (Set)
 import qualified Data.Set as Set
 import Data.Maybe (fromMaybe)
 import Control.Monad (forM_)
-import Debug.Trace
 
 newtype TransferFunction node lattice a
   = TFM (State (WorklistState node lattice) a)
-- 
2.12.1


From 5d96b749f2bac3fdf19698a4a7633a6570064aa7 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 30 Mar 2017 14:02:38 +0000
Subject: [PATCH 024/117] Added Usage to the set reachable from DynFlags in
 compiler/ghc.mk

---
 compiler/ghc.mk | 9 +++++----
 1 file changed, 5 insertions(+), 4 deletions(-)

diff --git a/compiler/ghc.mk b/compiler/ghc.mk
index 614d193d94..047055f577 100644
--- a/compiler/ghc.mk
+++ b/compiler/ghc.mk
@@ -486,20 +486,17 @@ compiler_stage2_dll0_MODULES = \
 	HsExpr \
 	HsImpExp \
 	HsLit \
-	PlaceHolder \
-	PmExpr \
 	HsPat \
 	HsSyn \
 	HsTypes \
 	HsUtils \
 	HscTypes \
-	IOEnv \
-	NameCache \
 	Id \
 	IdInfo \
 	IfaceSyn \
 	IfaceType \
 	InteractiveEvalTypes \
+	IOEnv \
 	Json \
 	ToIface \
 	InstEnv \
@@ -514,6 +511,7 @@ compiler_stage2_dll0_MODULES = \
 	Module \
 	MonadUtils \
 	Name \
+	NameCache \
 	NameEnv \
 	NameSet \
 	OccName \
@@ -527,9 +525,11 @@ compiler_stage2_dll0_MODULES = \
 	Panic \
 	PatSyn \
 	PipelineMonad \
+	PlaceHolder \
 	Platform \
 	PlatformConstants \
 	PprColour \
+	PmExpr \
 	PprCore \
 	PrelNames \
 	PrelRules \
@@ -557,6 +557,7 @@ compiler_stage2_dll0_MODULES = \
 	UniqSet \
 	UniqSupply \
 	Unique \
+	Usage \
 	Util \
 	Var \
 	VarEnv \
-- 
2.12.1


From 69b90c288fc5407786326229a5b558772c75c8a9 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 30 Mar 2017 15:25:31 +0000
Subject: [PATCH 025/117] Propagating changes to CallArity1 unittests

---
 testsuite/tests/callarity/unittest/CallArity1.hs   |   4 +-
 .../tests/callarity/unittest/CallArity1.stderr     | 108 ++++++++++-----------
 2 files changed, 56 insertions(+), 56 deletions(-)

diff --git a/testsuite/tests/callarity/unittest/CallArity1.hs b/testsuite/tests/callarity/unittest/CallArity1.hs
index 048f6ab02a..0c5f0d1354 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.hs
+++ b/testsuite/tests/callarity/unittest/CallArity1.hs
@@ -4,7 +4,7 @@ import CoreUtils
 import Id
 import Type
 import MkCore
-import CallArity (callArityRHS)
+import CallArity.Analysis (callArityRHS)
 import MkId
 import SysTools
 import DynFlags
@@ -41,7 +41,7 @@ go, go2, x, d, n, y, z, scrutf, scruta :: Id
 
 exprs :: [(String, CoreExpr)]
 exprs =
-  [ ("go2",) $ -- pprTraceIt "go2" $
+  [ ("go2",) $ pprTraceIt "go2" $
      mkRFun go [x]
         (mkNrLet d (mkACase (Var go `mkVarApps` [x])
                           (mkLams [y] $ Var y)
diff --git a/testsuite/tests/callarity/unittest/CallArity1.stderr b/testsuite/tests/callarity/unittest/CallArity1.stderr
index 010e516ed2..eace81b095 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.stderr
+++ b/testsuite/tests/callarity/unittest/CallArity1.stderr
@@ -1,77 +1,77 @@
 go2:
-    go 2
-    d 1
+    go C(C(A))
+    d C(U)
 nested_go2:
-    go 2
-    go2 2
-    d 1
-    n 1
+    go C(C(U))
+    go2 C(C(U))
+    d C(U)
+    n C(U)
 d0 (go 2 would be bad):
-    go 1
-    d 0
+    go C(U)
+    d U
 go2 (in case crut):
-    go 2
-    d 1
+    go C(C(U))
+    d C(U)
 go2 (in function call):
-    go 2
-    d 1
+    go C(C(U))
+    d C(U)
 go2 (using surrounding interesting let):
-    go 2
-    d 1
-    n 1
+    go C(C(U))
+    d C(U)
+    n C(U)
 go2 (using surrounding boring let):
-    go 2
-    d 1
-    z 0
+    go C(C(U))
+    d C(U)
+    z U
 two calls, one from let and from body (d 1 would be bad):
-    go 2
-    d 0
+    go C(C(U))
+    d U
 a thunk in a recursion (d 1 would be bad):
-    d 0
-    n 0
+    d U
+    n U
 two thunks, one called multiple times (both arity 1 would be bad!):
-    d 0
-    n 1
+    d U
+    n C(U)
 two functions, not thunks:
-    go 2
-    go2 2
+    go C(C(U))
+    go2 C(C(U))
 a thunk, called multiple times via a forking recursion (d 1 would be bad!):
-    go2 2
-    d 0
+    go2 C(C(U))
+    d U
 a function, one called multiple times via a forking recursion:
-    go 2
-    go2 2
+    go C(C(U))
+    go2 C(C(U))
 two functions (recursive):
-    go 2
-    go2 2
+    go C(C(U))
+    go2 C(C(U))
 mutual recursion (thunks), called mutiple times (both arity 1 would be bad!):
-    d 0
-    n 0
+    d U
+    n U
 mutual recursion (functions), but no thunks:
-    go 2
-    go2 2
+    go C(C(U))
+    go2 C(C(U))
 mutual recursion (functions), one boring (d 1 would be bad):
-    go 2
-    go2 2
-    d 0
+    go C(C(U))
+    go2 C(C(U))
+    d U
 a thunk (non-function-type), called twice, still calls once:
-    x 0
-    d 1
+    x U
+    d C(U)
 a thunk (function type), called multiple times, still calls once:
-    d 1
-    n 0
+    d C(U)
+    n U
 a thunk (non-function-type), in mutual recursion, still calls once (d 0 would be bad):
-    go 2
-    x 0
-    d 1
+    go C(C(U))
+    x U
+    d C(U)
 a thunk (non-function-type), in mutual recursion, causes many calls (d 1 would be bad):
-    go 2
-    x 0
-    d 0
+    go C(C(U))
+    x U
+    d U
 a thunk (function type), in mutual recursion, still calls once (d 1 would be good):
-    go 1
-    d 1
-    n 0
+    go C(U)
+    d C(U)
+    n U
 a thunk (non-function-type) co-calls with the body (d 1 would be bad):
-    x 0
-    d 0
+    x U
+    d U
-- 
2.12.1


From 08081178493ef38fb0b6f95ef380df726c453bce Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 30 Mar 2017 18:51:32 +0200
Subject: [PATCH 026/117] Annotated the wrong use

---
 compiler/simplCore/CallArity/Analysis.hs | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 9a963fb8d8..db48d3be29 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -694,7 +694,7 @@ unleashCall is_recursive ut_usage (id, rhs) transfer_rhs
       let ut_rhs' = finish_ut_rhs ut_rhs
       let id' = id
             `setIdArgUsage` ut_args ut_rhs'
-            `setIdCallArity` lookupUsage ut_rhs' id
+            `setIdCallArity` trimmed_use
       return (ut_rhs', (id', rhs'))
 
 -- | See Note [What is a thunk].
-- 
2.12.1


From 9ba36ea5f28b795ceba5910c4c5864643c5725b5 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <Sebastian Graf>
Date: Fri, 31 Mar 2017 18:14:31 +0200
Subject: [PATCH 027/117] Factored out Multiplicity. That's pretty much ArgUse

---
 compiler/basicTypes/Usage.hs             | 78 ++++++++++++++++++++------------
 compiler/simplCore/CallArity/Analysis.hs | 62 +++++++++++++------------
 compiler/simplCore/CallArity/Types.hs    | 11 +++--
 3 files changed, 89 insertions(+), 62 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 9aff5de369..92eeb7bf7c 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -11,15 +11,18 @@ import Data.Function ( on )
 
 type Use = Arity
 
+data Multiplicity
+  = Once
+  | Many
+  deriving (Eq, Ord, Show)
+
 data Usage
-  = Zero
-  | One {-# UNPACK #-} !Use
-  | Many {-# UNPACK #-} !Use
+  = Absent
+  | Used Multiplicity {-# UNPACK #-} !Use
   deriving (Eq, Show)
 
 use :: Usage -> Maybe Use
-use (One u) = Just u
-use (Many u) = Just u
+use (Used _ u) = Just u
 use _ = Nothing
 
 data UsageSig
@@ -30,28 +33,36 @@ data UsageSig
 
 -- * Lattice operations
 
-topUse :: Use
-topUse = 0
-
 -- TODO: decide if botUse would be valuable, and if so, change @Use@ to an
 -- appropriate integer type with pos. Inf.
 
+topUse :: Use
+topUse = 0
+
 lubUse :: Use -> Use -> Use
 lubUse = min
 
+botMultiplicity :: Multiplicity
+botMultiplicity = Once
+
+topMultiplicity :: Multiplicity
+topMultiplicity = Many
+
+lubMultiplicity :: Multiplicity -> Multiplicity -> Multiplicity
+lubMultiplicity Once m = m
+lubMultiplicity m Once = m
+lubMultiplicity _ _    = Many
+
 botUsage :: Usage
-botUsage = Zero
+botUsage = Absent
 
 topUsage :: Usage
-topUsage = Many topUse
+topUsage = Used topMultiplicity topUse
 
 lubUsage :: Usage -> Usage -> Usage
-lubUsage Zero u = u
-lubUsage u Zero = u
-lubUsage (One u1) (One u2) = One (lubUse u1 u2)
-lubUsage u1 u2 = Many (extractAndLubUse u1 u2)
-  where
-    extractAndLubUse = lubUse `on` expectJust ": Zero has no use" . use
+lubUsage Absent u = u
+lubUsage u Absent = u
+lubUsage (Used m1 u1) (Used m2 u2) = Used (lubMultiplicity m1 m2) (lubUse u1 u2)
 
 botUsageSig :: UsageSig
 botUsageSig = BotUsageSig
@@ -103,29 +114,40 @@ pprUse :: Use -> SDoc
 pprUse 0 = text "U"
 pprUse u = text "C" <> parens (pprUse (u - 1))
 
+instance Outputable Multiplicity where
+  ppr Once = text "1"
+  ppr Many = text "ω"
+
 instance Outputable Usage where
-  ppr Zero = text "A"
-  ppr (One u) = text "1*" <> pprUse u
-  ppr (Many u) = pprUse u
+  ppr Absent = text "A"
+  ppr (Used multi use) = ppr multi <> char '*' <> pprUse use
 
 instance Outputable UsageSig where
-  ppr BotUsageSig = text "AA.."
-  ppr TopUsageSig = text "UU.."
-  ppr (ArgUsage u sig) = ppr u <> ppr sig
+  ppr BotUsageSig = text "A,A.."
+  ppr TopUsageSig = text "U,U.."
+  ppr (ArgUsage u sig) = ppr u <> char ',' <> ppr sig
 
 -- * Serialization
 
 -- | Mostly important for serializing @UsageSig@ in interface files.
+instance Binary Multiplicity where
+  put_ bh Once = putByte bh 0
+  put_ bh Many = putByte bh 1
+  get  bh = do
+    h <- getByte bh
+    case h of
+      0 -> return Once
+      _ -> return Many
+
+-- | Mostly important for serializing @UsageSig@ in interface files.
 instance Binary Usage where
-  put_ bh Zero = putByte bh 0
-  put_ bh (One use) = putByte bh 1 >> put_ bh use
-  put_ bh (Many use) = putByte bh 2 >> put_ bh use
+  put_ bh Absent = putByte bh 0
+  put_ bh (Used multi use) = putByte bh 1 >> put_ bh multi >> put_ bh use
   get  bh = do
     h <- getByte bh
     case h of
-      0 -> return Zero
-      1 -> One <$> get bh
-      _ -> Many <$> get bh
+      0 -> return Absent
+      _ -> Used <$> get bh <*> get bh
 
 instance Binary UsageSig where
   put_ bh BotUsageSig = putByte bh 0
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index db48d3be29..fe8fc552e3 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -19,7 +19,7 @@ import BasicTypes
 import CoreSyn
 import CoreArity ( typeArity )
 import CoreUtils ( exprIsCheap )
-import Demand
+import Demand ( isBotRes, splitStrictSig )
 import MkCore
 import Id
 import UniqFM
@@ -507,7 +507,7 @@ callArityExpr nodes (Lam id e)
       -- Also regardless of the variable not being interesting,
       -- we have to add the var as an argument.
       (cat, e') <- transfer 0
-      return (makeIdArg id (calledMultipleTimes cat), Lam id e')
+      return (makeIdArg id (multiplyFreeVarUsages Many cat), Lam id e')
 
     transfer' transfer use = do
       -- We have a lambda that we are applying to. decrease arity.
@@ -527,7 +527,6 @@ callArityExpr nodes (App f a) = do
     --pprTrace "App:f'" (ppr (ut_f, f')) $ return ()
     -- peel off one argument from the type
     let (arg_usage, ut_f') = peelUsageType ut_f
-    let called_once = id
     let analyse finish_ut_a use = do
           (ut_a, a') <- transfer_a use
           --pprTrace "App:a'" (text "safe_arity:" <+> ppr safe_arity <+> ppr (ut_a, a')) $ return ()
@@ -536,9 +535,8 @@ callArityExpr nodes (App f a) = do
     -- In call-by-need, arguments are evaluated at most once, so they qualify as
     -- thunk.
     case oneifyUsageIfThunk a arg_usage of
-      Zero -> return (ut_f', App f' a) -- TODO: Visit a, too? Seems unnecessary, wasn't called at all
-      One use -> analyse called_once use
-      Many use -> analyse calledMultipleTimes use
+      Absent -> return (ut_f', App f' a) -- TODO: Visit a, too? Seems unnecessary, wasn't called at all
+      Used multi use -> analyse (multiplyFreeVarUsages multi) use
 
 -- Case expression.
 callArityExpr nodes (Case scrut bndr ty alts) = do
@@ -664,25 +662,30 @@ unleashCall
   -> (Use -> TransferFunction AnalResult)
   -> TransferFunction (UsageType, (Id, CoreExpr))
 unleashCall is_recursive ut_usage (id, rhs) transfer_rhs
-  | Zero <- usage
-  = return (emptyUsageType, (id, rhs)) -- No call to @id@ (yet)
-  | One use <- usage
-  = analyse called_once use
-  | Many use <- usage
-  = analyse calledMultipleTimes use
+  | Absent <- usage_rhs
+  = return (emptyUsageType, (id `setIdCallArity` Absent, rhs)) -- No call to @id@ (yet)
+  | Used multi use <- usage_rhs
+  = analyse multi use
   where
-    usage =
-      oneifyUsageIfThunk rhs
+    usage_id =
+      -- How @id@ was used in its scope.
+      --
       -- See Note [Thunks in recursive groups]
-      -- @is_recursive@ implies @not called_once@ (otherwise, why would it be
+      -- @is_recursive@ implies multiplicity @Many@ (otherwise, why would it be
       -- recursive?), although the co-call graph doesn't model it that way.
       -- Self-edges in the co-call graph correspond to non-linear recursion.
-      . apply_when is_recursive manifyUsage
+      -- Kind-of a leaky abstraction, maybe we could somehow merge the
+      -- @is_recursive@ flag into the analysis environment.
+      apply_when is_recursive manifyUsage
       . lookupUsage ut_usage
       $ id
     apply_when b f = if b then f else Prelude.id
-    called_once u = u
-    analyse finish_ut_rhs use = do
+    -- The usage propagated to the let-binding is another one, as we might
+    -- decide to share the work needed to get the RHS to WHNF. See
+    -- @oneifyUsageIfThunk@. We use this usage to analyse the RHS, but annotate
+    -- with @usage_id@, which represents how the binder was used in its scope.
+    usage_rhs = oneifyUsageIfThunk rhs usage_id
+    analyse multi use = do
       -- See Note [Trimming arity]
       let trimmed_use = mapUseArity (trimArity id) use
       -- TODO: Find out if (where) we need the trimmed_use here or not
@@ -691,10 +694,10 @@ unleashCall is_recursive ut_usage (id, rhs) transfer_rhs
       -- Also if we analysed with arity, we would need to analyze again with
       -- trimmed_use nonetheless for the signature!
       (ut_rhs, rhs') <- transfer_rhs trimmed_use
-      let ut_rhs' = finish_ut_rhs ut_rhs
+      let ut_rhs' = multiplyFreeVarUsages multi ut_rhs
       let id' = id
-            `setIdArgUsage` ut_args ut_rhs'
-            `setIdCallArity` trimmed_use
+            `setIdCallArity` usage_id -- How the *binder* was used
+            `setIdArgUsage` ut_args ut_rhs' -- How the *rhs* uses its args
       return (ut_rhs', (id', rhs'))
 
 -- | See Note [What is a thunk].
@@ -712,21 +715,22 @@ isThunk = not . exprIsCheap
     This function should be used anywhere expressions are to be let-bound.
 -}
 oneifyUsageIfThunk :: CoreExpr -> Usage -> Usage
-oneifyUsageIfThunk e (Many use)
+oneifyUsageIfThunk e (Used Many use)
   -- A thunk was called multiple times! Do not eta-expand
-  | isThunk e = One 0
-  -- In case e is cheap and we use the let-bound var of e with @Many 0@, this
-  -- allows us to at least analyze the cheap RHS with cardinality 1 before we
-  -- potentially hit a lambda binder, were we proceed normally with @Many 0@.
+  | isThunk e = Used Once 0
+  -- In case e is cheap and we use the let-bound var of e with @Used Many 0@, this
+  -- allows us to at least analyze the cheap RHS with multiplicity @Once@ before we
+  -- potentially hit a lambda binder, where we proceed normally with @Used Many 0@.
   -- I'm not sure if this actually buys us anything, @e@ is cheap after all.
   -- But it may still be non-@exprIsTrivial@, so just leaving it here for the
   -- time being.
-  | use == 0 = One 0
+  | use == 0 = Used Once 0
 oneifyUsageIfThunk _ u = u
 
--- | Multiplies with @Many@; $\omega*_$ formally. @manifyUsage Zero = Zero@ still!
+-- | Multiplies with @Many@; $\omega*_$ formally. @manifyUsage Absent = Absent@
+-- still!
 manifyUsage :: Usage -> Usage
-manifyUsage (One use) = Many use
+manifyUsage (Used Once use) = Used Many use
 manifyUsage u = u
 
 -- Combining the results from body and rhs of a let binding
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index 56b948ace7..dd6a709f74 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -73,9 +73,9 @@ makeIdArg id ut = typeDel id (modifyArgs (consUsageSig (lookupUsage ut id)) ut)
 -- at most once.
 lookupUsage :: UsageType -> Id -> Usage
 lookupUsage (UT g ae _) id = case lookupVarEnv ae id of
-  Just a
-    | id `elemUnVarSet` neighbors g id -> Many a
-    | otherwise -> One a
+  Just use
+    | id `elemUnVarSet` neighbors g id -> Used Many use
+    | otherwise -> Used Once use
   Nothing
     | isInteresting id -> botUsage
     -- If v is boring, we will not find it in ut_usage, but always assume topUsage.
@@ -94,8 +94,9 @@ addCrossCoCalls set1 set2
   = modifyCoCalls (completeBipartiteGraph set1 set2 `unionUnVarGraph`)
 
 -- Replaces the co-call graph by a complete graph (i.e. no information)
-calledMultipleTimes :: UsageType -> UsageType
-calledMultipleTimes res = modifyCoCalls (const (completeGraph (domType res))) res
+multiplyFreeVarUsages :: Multiplicity -> UsageType -> UsageType
+multiplyFreeVarUsages Once res = res
+multiplyFreeVarUsages Many res = modifyCoCalls (const (completeGraph (domType res))) res
 
 -- Used for application and cases
 both :: UsageType -> UsageType -> UsageType
-- 
2.12.1


From b7b1c9edb36dc7629220a9363dfd4e98cd154347 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sat, 1 Apr 2017 19:17:22 +0200
Subject: [PATCH 028/117] Split One and Many into Multiplicity, plus test fixes

---
 compiler/basicTypes/Usage.hs                       |   9 +-
 compiler/simplCore/CallArity/Analysis.hs           |  91 ++++++++-------
 compiler/simplCore/SimplUtils.hs                   |  11 +-
 testsuite/tests/callarity/unittest/CallArity1.hs   |  26 ++---
 .../tests/callarity/unittest/CallArity1.stderr     | 130 ++++++++++-----------
 5 files changed, 141 insertions(+), 126 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 92eeb7bf7c..057a59e996 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -21,6 +21,10 @@ data Usage
   | Used Multiplicity {-# UNPACK #-} !Use
   deriving (Eq, Show)
 
+multiplicity :: Usage -> Maybe Multiplicity
+multiplicity (Used m _) = Just m
+multiplicity _ = Nothing
+
 use :: Usage -> Maybe Use
 use (Used _ u) = Just u
 use _ = Nothing
@@ -79,8 +83,9 @@ lubUsageSig (ArgUsage u1 s1) (ArgUsage u2 s2) = ArgUsage (lubUsage u1 u2) (lubUs
 
 -- * Working with @Use@, @Usage@ and @UsageSig@
 
-mapUseArity :: (Arity -> Arity) -> Use -> Use
-mapUseArity f use = f use
+mapUsageArity :: (Arity -> Arity) -> Usage -> Usage
+mapUsageArity f (Used multi use) = Used multi (f use)
+mapUsageArity f u = u
 
 consUsageSig :: Usage -> UsageSig -> UsageSig
 consUsageSig u s
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index fe8fc552e3..ef4bc3f3ef 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -458,8 +458,8 @@ callArityExprMap nodes f e
   = transfer' <$> callArityExpr nodes e
   where
     transfer' transfer use = do
-      (cat, e') <- transfer use
-      return (cat, f e')
+      (ut, e') <- transfer use
+      return (ut, f e')
 
 -- The trivial base cases
 callArityExpr _ e@(Lit _) = callArityExprTrivial e
@@ -467,6 +467,7 @@ callArityExpr _ e@(Type _) = callArityExprTrivial e
 callArityExpr _ e@(Coercion _) = callArityExprTrivial e
 
 -- The transparent cases
+-- TODO: What if @tickishIsCode@? See CoreArity
 callArityExpr nodes (Tick t e) = callArityExprMap nodes (Tick t) e
 callArityExpr nodes (Cast e c) = callArityExprMap nodes (flip Cast c) e
 
@@ -474,29 +475,31 @@ callArityExpr nodes (Cast e c) = callArityExprMap nodes (flip Cast c) e
 callArityExpr nodes e@(Var id) = return transfer
   where
     transfer use
-      | isInteresting id
-      , Just node <- lookupVarEnv nodes id
+      | not (isInteresting id)
+      -- We don't track uninteresting vars and implicitly assume they are called
+      -- multiple times with every other variable.
+      -- See Note [Taking boring variables into account]
+      = return (emptyUsageType, e)
+
+      | Just node <- lookupVarEnv nodes id
+      -- A local let-binding.
       = do
         (ut_callee, _) <- dependOnWithDefault (unusedArgsUsageType use, e) (node, use)
         -- It is crucial that we only use ut_args here, as every other field
         -- might be unstable and thus too optimistic.
         return ((unitUsageType id use) { ut_args = ut_args ut_callee }, e)
 
-      | isInteresting id
-      , isGlobalId id
+      | isGlobalId id
+      -- A global id from another module which has a usage signature.
       = return ((unitUsageType id use) { ut_args = idArgUsage id }, e)
 
-      | isInteresting id
-      -- LocalId, not present in @nodes@, e.g. a lambda-bound variable.
+      | otherwise
+      -- interesting LocalId, not present in @nodes@, e.g. a lambda-bound variable.
       -- We are only second-order, so we don't model signatures for parameters!
+      -- Their usage is interesting to note nonetheless for annotating lambda
+      -- binders.
       = return (unitUsageType id use, e)
 
-      | otherwise
-      -- We don't track uninteresting vars and implicitly assume they are called
-      -- multiple times with every other variable.
-      -- See Note [Taking boring variables into account]
-      = return (emptyUsageType, e)
-
 callArityExpr nodes (Lam id e)
   | isTyVar id = callArityExprMap nodes (Lam id) e -- Non-value lambdas are ignored
   | otherwise  = transfer' <$> callArityExpr nodes e
@@ -506,14 +509,14 @@ callArityExpr nodes (Lam id e)
       -- can all be co-called.
       -- Also regardless of the variable not being interesting,
       -- we have to add the var as an argument.
-      (cat, e') <- transfer 0
-      return (makeIdArg id (multiplyFreeVarUsages Many cat), Lam id e')
+      (ut, e') <- transfer 0
+      return (makeIdArg id (multiplyFreeVarUsages Many ut), Lam id e')
 
     transfer' transfer use = do
       -- We have a lambda that we are applying to. decrease arity.
-      (cat, e') <- transfer (use - 1)
+      (ut, e') <- transfer (use - 1)
       -- TODO: annotate id
-      return (makeIdArg id cat, Lam id e')
+      return (makeIdArg id ut, Lam id e')
 
 callArityExpr nodes (App f (Type t)) = callArityExprMap nodes (flip App (Type t)) f
 
@@ -527,16 +530,18 @@ callArityExpr nodes (App f a) = do
     --pprTrace "App:f'" (ppr (ut_f, f')) $ return ()
     -- peel off one argument from the type
     let (arg_usage, ut_f') = peelUsageType ut_f
-    let analyse finish_ut_a use = do
-          (ut_a, a') <- transfer_a use
-          --pprTrace "App:a'" (text "safe_arity:" <+> ppr safe_arity <+> ppr (ut_a, a')) $ return ()
-          let ut_a' = finish_ut_a ut_a
-          return (ut_f' `both` ut_a', App f' a')
     -- In call-by-need, arguments are evaluated at most once, so they qualify as
     -- thunk.
+    -- This 'lifts' the transfer function of @a@ into one taking a @Usage@ instead
+    -- of just a single @Use@ by multipliying the analysis result with the
+    -- @Usage@s inherent @Multiplicity@.
     case oneifyUsageIfThunk a arg_usage of
       Absent -> return (ut_f', App f' a) -- TODO: Visit a, too? Seems unnecessary, wasn't called at all
-      Used multi use -> analyse (multiplyFreeVarUsages multi) use
+      Used multi use -> do
+          (ut_a, a') <- transfer_a use
+          --pprTrace "App:a'" (text "safe_arity:" <+> ppr safe_arity <+> ppr (ut_a, a')) $ return ()
+          let ut_a' = multiplyFreeVarUsages multi ut_a
+          return (ut_f' `both` ut_a', App f' a')
 
 -- Case expression.
 callArityExpr nodes (Case scrut bndr ty alts) = do
@@ -549,13 +554,13 @@ callArityExpr nodes (Case scrut bndr ty alts) = do
   return $ \use -> do
     (ut_scrut, scrut') <- transfer_scrut 0
     (ut_alts, alts') <- unzip <$> mapM ($ use) transfer_alts
-    let cat = trimArgs use (lubTypes ut_alts) `both` ut_scrut
+    let ut = trimArgs use (lubTypes ut_alts) `both` ut_scrut
     -- TODO: Think harder about the diverging case (e.g. matching on `undefined`).
     --       In that case we will declare all arguments as unused from the alts.
     -- pprTrace "callArityExpr:Case"
-    --          (vcat [ppr scrut, ppr cat])
+    --          (vcat [ppr scrut, ppr ut])
     --pprTrace "Case" (vcat [text "ut_scrut:" <+> ppr ut_scrut, text "ut_alts:" <+> ppr ut_alts, text "cat:" <+> ppr cat]) (return ())
-    return (cat, Case scrut' bndr ty alts')
+    return (ut, Case scrut' bndr ty alts')
 
 callArityExpr letdown_nodes (Let bind e) = do
   let initial_binds = flattenBinds [bind]
@@ -602,9 +607,9 @@ callArityExpr letdown_nodes (Let bind e) = do
 
       -- Now for the actual TransferFunction of this expr...
       return $ \use -> do
-        (cat, let') <- dependOnWithDefault (emptyUsageType, Let bind e) (node, use)
-        --pprTrace "Let" (ppr (cat, let')) $ return ()
-        return (typeDelList (bindersOf bind) cat, let')
+        (ut, let') <- dependOnWithDefault (emptyUsageType, Let bind e) (node, use)
+        --pprTrace "Let" (ppr (ut, let')) $ return ()
+        return (typeDelList (bindersOf bind) ut, let')
 
 callArityBind
   :: VarEnv FrameworkNode
@@ -661,23 +666,24 @@ unleashCall
   -> (Id, CoreExpr)
   -> (Use -> TransferFunction AnalResult)
   -> TransferFunction (UsageType, (Id, CoreExpr))
-unleashCall is_recursive ut_usage (id, rhs) transfer_rhs
+unleashCall is_recursive ut_scope (id, rhs) transfer_rhs
   | Absent <- usage_rhs
   = return (emptyUsageType, (id `setIdCallArity` Absent, rhs)) -- No call to @id@ (yet)
   | Used multi use <- usage_rhs
   = analyse multi use
   where
-    usage_id =
-      -- How @id@ was used in its scope.
-      --
+    usage_id = -- How @id@ was used in its scope.
+      -- ... except for bottoms, where we can't eta-expand.
+      -- See Note [Trimming arity]
+      mapUsageArity (trimArity id)
       -- See Note [Thunks in recursive groups]
       -- @is_recursive@ implies multiplicity @Many@ (otherwise, why would it be
       -- recursive?), although the co-call graph doesn't model it that way.
       -- Self-edges in the co-call graph correspond to non-linear recursion.
       -- Kind-of a leaky abstraction, maybe we could somehow merge the
       -- @is_recursive@ flag into the analysis environment.
-      apply_when is_recursive manifyUsage
-      . lookupUsage ut_usage
+      . apply_when is_recursive manifyUsage
+      . lookupUsage ut_scope
       $ id
     apply_when b f = if b then f else Prelude.id
     -- The usage propagated to the let-binding is another one, as we might
@@ -686,21 +692,16 @@ unleashCall is_recursive ut_usage (id, rhs) transfer_rhs
     -- with @usage_id@, which represents how the binder was used in its scope.
     usage_rhs = oneifyUsageIfThunk rhs usage_id
     analyse multi use = do
-      -- See Note [Trimming arity]
-      let trimmed_use = mapUseArity (trimArity id) use
-      -- TODO: Find out if (where) we need the trimmed_use here or not
-      -- We probably want to analyze with arity und annotate trimmed_use.
-      -- Although CA analyzes with trimmed_use, so we do that for now
-      -- Also if we analysed with arity, we would need to analyze again with
-      -- trimmed_use nonetheless for the signature!
-      (ut_rhs, rhs') <- transfer_rhs trimmed_use
+      (ut_rhs, rhs') <- transfer_rhs use
       let ut_rhs' = multiplyFreeVarUsages multi ut_rhs
       let id' = id
             `setIdCallArity` usage_id -- How the *binder* was used
-            `setIdArgUsage` ut_args ut_rhs' -- How the *rhs* uses its args
+            `setIdArgUsage` ut_args ut_rhs' -- How the *RHS* uses its args
       return (ut_rhs', (id', rhs'))
 
 -- | See Note [What is a thunk].
+-- This should always be in sync with @SimplUtils.tryEtaExpandRhs@.
+-- TODO: Factor out @exprIsCheap@ into the environment, like in CoreArity.
 isThunk :: CoreExpr -> Bool
 isThunk = not . exprIsCheap
 
diff --git a/compiler/simplCore/SimplUtils.hs b/compiler/simplCore/SimplUtils.hs
index 16dce71402..9e009b9751 100644
--- a/compiler/simplCore/SimplUtils.hs
+++ b/compiler/simplCore/SimplUtils.hs
@@ -1430,7 +1430,16 @@ tryEtaExpandRhs env is_rec bndr rhs
 
       | sm_eta_expand (getMode env)      -- Provided eta-expansion is on
       , let new_arity1 = findRhsArity dflags bndr rhs old_arity
-            new_arity2 = fromMaybe new_arity1 (use (idCallArity bndr))
+            usage = idCallArity bndr
+            -- This should always be in sync with @CallArity.Analysis.isThunk@
+            -- and @CallArity.Analysis.oneifyUsageIfThunk@.
+            -- TODO: Also figure out if CoreArity yields better results at all.
+            new_arity2
+              | Just arity <- use usage
+              , exprIsCheap rhs || Just Once == multiplicity usage
+              = arity
+              | otherwise
+              = 0
             new_arity  = max new_arity1 new_arity2
       , new_arity > old_arity      -- And the current manifest arity isn't enough
       = if is_rec == Recursive && isJoinId bndr
diff --git a/testsuite/tests/callarity/unittest/CallArity1.hs b/testsuite/tests/callarity/unittest/CallArity1.hs
index 0c5f0d1354..81dc1db940 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.hs
+++ b/testsuite/tests/callarity/unittest/CallArity1.hs
@@ -41,7 +41,7 @@ go, go2, x, d, n, y, z, scrutf, scruta :: Id
 
 exprs :: [(String, CoreExpr)]
 exprs =
-  [ ("go2",) $ pprTraceIt "go2" $
+  [ ("go2",) $ --pprTraceIt "go2" $
      mkRFun go [x]
         (mkNrLet d (mkACase (Var go `mkVarApps` [x])
                           (mkLams [y] $ Var y)
@@ -59,7 +59,7 @@ exprs =
                         mkLams [z] $ Var d `mkVarApps` [x] )$
                     Var go2 `mkApps` [mkLit 1] ) $
         go `mkLApps` [0, 0]
-  , ("d0 (go 2 would be bad)",) $
+  , ("d0 (go _*C(C(U)) would be bad)",) $
      mkRFun go [x]
         (mkNrLet d (mkACase (Var go `mkVarApps` [x])
                           (mkLams [y] $ Var y)
@@ -93,15 +93,15 @@ exprs =
                               (mkLams [y] $ Var y)
                       ) $ mkLams [z] $ Var d `mkVarApps` [x]) $
             Var f `mkApps` [Var z,  go `mkLApps` [0, 0]]
-  , ("two calls, one from let and from body (d 1 would be bad)",) $
+  , ("two calls, one from let and from body (d 1*_ would be bad)",) $
      mkNrLet  d (mkACase (mkLams [y] $ mkLit 0) (mkLams [y] $ mkLit 0)) $
      mkFun go [x,y] (mkVarApps (Var d) [x]) $
      mkApps (Var d) [mkLApps go [1,2]]
-  , ("a thunk in a recursion (d 1 would be bad)",) $
+  , ("a thunk in a recursion (d 1*_ would be bad)",) $
      mkRLet n (mkACase (mkLams [y] $ mkLit 0) (Var n)) $
      mkRLet d (mkACase (mkLams [y] $ mkLit 0) (Var d)) $
          Var n `mkApps` [d `mkLApps` [0]]
-  , ("two thunks, one called multiple times (both arity 1 would be bad!)",) $
+  , ("two thunks, one called multiple times (both 1*_ would be bad!)",) $
      mkNrLet n (mkACase (mkLams [y] $ mkLit 0) (f `mkLApps` [0])) $
      mkNrLet d (mkACase (mkLams [y] $ mkLit 0) (f `mkLApps` [0])) $
          Var n `mkApps` [Var d `mkApps` [Var d `mkApps` [mkLit 0]]]
@@ -109,7 +109,7 @@ exprs =
      mkNrLet go  (mkLams [x] (mkACase (mkLams [y] $ mkLit 0) (Var f `mkVarApps` [x]))) $
      mkNrLet go2 (mkLams [x] (mkACase (mkLams [y] $ mkLit 0) (Var f `mkVarApps` [x]))) $
          Var go `mkApps` [go2 `mkLApps` [0,1], mkLit 0]
-  , ("a thunk, called multiple times via a forking recursion (d 1 would be bad!)",) $
+  , ("a thunk, called multiple times via a forking recursion (d 1*_ would be bad!)",) $
      mkNrLet  d   (mkACase (mkLams [y] $ mkLit 0) (f `mkLApps` [0])) $
      mkRLet go2 (mkLams [x] (mkACase (Var go2 `mkApps` [Var go2 `mkApps` [mkLit 0, mkLit 0]]) (Var d))) $
          go2 `mkLApps` [0,1]
@@ -121,7 +121,7 @@ exprs =
      mkRLet go  (mkLams [x] (mkACase (mkLams [y] $ mkLit 0) (Var go `mkVarApps` [x]))) $
      mkRLet go2 (mkLams [x] (mkACase (mkLams [y] $ mkLit 0) (Var go2 `mkVarApps` [x]))) $
          Var go `mkApps` [go2 `mkLApps` [0,1], mkLit 0]
-  , ("mutual recursion (thunks), called mutiple times (both arity 1 would be bad!)",) $
+  , ("mutual recursion (thunks), called mutiple times (both 1*_ would be bad!)",) $
      Let (Rec [ (n, mkACase (mkLams [y] $ mkLit 0) (Var d))
               , (d, mkACase (mkLams [y] $ mkLit 0) (Var n))]) $
          Var n `mkApps` [Var d `mkApps` [Var d `mkApps` [mkLit 0]]]
@@ -129,7 +129,7 @@ exprs =
      Let (Rec [ (go,  mkLams [x] (mkACase (mkLams [y] $ mkLit 0) (Var go2 `mkVarApps` [x])))
               , (go2, mkLams [x] (mkACase (mkLams [y] $ mkLit 0) (Var go `mkVarApps` [x])))]) $
          Var go `mkApps` [go2 `mkLApps` [0,1], mkLit 0]
-  , ("mutual recursion (functions), one boring (d 1 would be bad)",) $
+  , ("mutual recursion (functions), one boring (d 1*_ would be bad)",) $
      mkNrLet d (f `mkLApps` [0]) $
          Let (Rec [ (go,  mkLams [x, y] (Var d `mkApps` [go2 `mkLApps` [1,2]]))
                   , (go2, mkLams [x] (mkACase (mkLams [y] $ mkLit 0) (Var go `mkVarApps` [x])))]) $
@@ -142,24 +142,24 @@ exprs =
     mkNrLet d (f `mkLApps` [0]) $
         mkNrLet n (Var f `mkApps` [d `mkLApps` [1]]) $
             mkLams [x] $ Var n `mkVarApps` [x]
-  , ("a thunk (non-function-type), in mutual recursion, still calls once (d 0 would be bad)",) $
+  , ("a thunk (non-function-type), in mutual recursion, still calls once (d ω*_ would be bad)",) $
     mkNrLet d (f `mkLApps` [0]) $
         Let (Rec [ (x, Var d `mkApps` [go `mkLApps` [1,2]])
                  , (go, mkLams [y] $ mkACase (mkLams [z] $ Var x) (Var go `mkVarApps` [x]) ) ]) $
             Var go `mkApps` [mkLit 0, go `mkLApps` [0,1]]
-  , ("a thunk (non-function-type), in mutual recursion, causes many calls (d 1 would be bad)",) $
+  , ("a thunk (non-function-type), in mutual recursion, causes many calls (d 1*_ would be bad)",) $
     mkNrLet d (f `mkLApps` [0]) $
         Let (Rec [ (x, Var go `mkApps` [go `mkLApps` [1,2], go `mkLApps` [1,2]])
                  , (go, mkLams [x] $ mkACase (Var d) (Var go `mkVarApps` [x]) ) ]) $
             Var go `mkApps` [mkLit 0, go `mkLApps` [0,1]]
-  , ("a thunk (function type), in mutual recursion, still calls once (d 1 would be good)",) $
+  , ("a thunk (function type), in mutual recursion, still calls once (d 1*_ would be good)",) $
     mkNrLet d (f `mkLApps` [0]) $
         Let (Rec [ (n, Var go `mkApps` [d `mkLApps` [1]])
                  , (go, mkLams [x] $ mkACase (Var n) (Var go `mkApps` [Var n `mkVarApps` [x]]) ) ]) $
             Var go `mkApps` [mkLit 0, go `mkLApps` [0,1]]
-  , ("a thunk (non-function-type) co-calls with the body (d 1 would be bad)",) $
+  , ("a thunk (non-function-type) co-calls with the body (d 1*_ would be bad)",) $
     mkNrLet d (f `mkLApps` [0]) $
-        mkNrLet x (d `mkLApps` [1]) $
+        mkLet x (d `mkLApps` [1]) $
             Var d `mkVarApps` [x]
   ]
 
diff --git a/testsuite/tests/callarity/unittest/CallArity1.stderr b/testsuite/tests/callarity/unittest/CallArity1.stderr
index eace81b095..daf9a5fe44 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.stderr
+++ b/testsuite/tests/callarity/unittest/CallArity1.stderr
@@ -1,77 +1,77 @@
 go2:
-    go C(C(A))
-    d C(U)
+    go ω*C(C(U))
+    d 1*C(U)
 nested_go2:
-    go C(C(U))
-    go2 C(C(U))
-    d C(U)
-    n C(U)
-d0 (go 2 would be bad):
-    go C(U)
-    d U
+    go ω*C(C(U))
+    go2 1*C(C(U))
+    d 1*C(U)
+    n 1*C(U)
+d0 (go _*C(C(U)) would be bad):
+    go ω*C(U)
+    d ω*C(U)
 go2 (in case crut):
-    go C(C(U))
-    d C(U)
+    go ω*C(C(U))
+    d 1*C(U)
 go2 (in function call):
-    go C(C(U))
-    d C(U)
+    go ω*C(C(U))
+    d 1*C(U)
 go2 (using surrounding interesting let):
-    go C(C(U))
-    d C(U)
-    n C(U)
+    go ω*C(C(U))
+    d 1*C(U)
+    n 1*C(U)
 go2 (using surrounding boring let):
-    go C(C(U))
-    d C(U)
-    z U
-two calls, one from let and from body (d 1 would be bad):
-    go C(C(U))
-    d U
-a thunk in a recursion (d 1 would be bad):
-    d U
-    n U
-two thunks, one called multiple times (both arity 1 would be bad!):
-    d U
-    n C(U)
+    go ω*C(C(U))
+    d 1*C(U)
+    z ω*U
+two calls, one from let and from body (d 1*_ would be bad):
+    go 1*C(C(U))
+    d ω*C(U)
+a thunk in a recursion (d 1*_ would be bad):
+    d ω*U
+    n ω*U
+two thunks, one called multiple times (both 1*_ would be bad!):
+    d ω*C(U)
+    n 1*C(U)
 two functions, not thunks:
-    go C(C(U))
-    go2 C(C(U))
-a thunk, called multiple times via a forking recursion (d 1 would be bad!):
-    go2 C(C(U))
-    d U
+    go 1*C(C(U))
+    go2 1*C(C(U))
+a thunk, called multiple times via a forking recursion (d 1*_ would be bad!):
+    go2 ω*C(C(U))
+    d ω*C(U)
 a function, one called multiple times via a forking recursion:
-    go C(C(U))
-    go2 C(C(U))
+    go ω*C(C(U))
+    go2 ω*C(C(U))
 two functions (recursive):
-    go C(C(U))
-    go2 C(C(U))
-mutual recursion (thunks), called mutiple times (both arity 1 would be bad!):
-    d U
-    n U
+    go ω*C(C(U))
+    go2 ω*C(C(U))
+mutual recursion (thunks), called mutiple times (both 1*_ would be bad!):
+    d ω*U
+    n ω*U
 mutual recursion (functions), but no thunks:
-    go C(C(U))
-    go2 C(C(U))
-mutual recursion (functions), one boring (d 1 would be bad):
-    go C(C(U))
-    go2 C(C(U))
-    d U
+    go ω*C(C(U))
+    go2 ω*C(C(U))
+mutual recursion (functions), one boring (d 1*_ would be bad):
+    go ω*C(C(U))
+    go2 ω*C(C(U))
+    d ω*C(U)
 a thunk (non-function-type), called twice, still calls once:
-    x U
-    d C(U)
+    x ω*U
+    d 1*C(U)
 a thunk (function type), called multiple times, still calls once:
-    d C(U)
-    n U
-a thunk (non-function-type), in mutual recursion, still calls once (d 0 would be bad):
-    go C(C(U))
-    x U
-    d C(U)
-a thunk (non-function-type), in mutual recursion, causes many calls (d 1 would be bad):
-    go C(C(U))
-    x U
-    d U
-a thunk (function type), in mutual recursion, still calls once (d 1 would be good):
-    go C(U)
-    d C(U)
-    n U
-a thunk (non-function-type) co-calls with the body (d 1 would be bad):
-    x U
-    d U
+    d 1*C(U)
+    n ω*C(U)
+a thunk (non-function-type), in mutual recursion, still calls once (d ω*_ would be bad):
+    go ω*C(C(U))
+    x ω*U
+    d 1*C(U)
+a thunk (non-function-type), in mutual recursion, causes many calls (d 1*_ would be bad):
+    go ω*C(C(U))
+    x ω*U
+    d ω*C(U)
+a thunk (function type), in mutual recursion, still calls once (d 1*_ would be good):
+    go ω*C(U)
+    d 1*C(U)
+    n ω*U
+a thunk (non-function-type) co-calls with the body (d 1*_ would be bad):
+    x ω*U
+    d ω*C(U)
-- 
2.12.1


From 442d6ac11f01bbc40bcfebbb50789184c785a1b0 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 7 Apr 2017 00:28:43 +0200
Subject: [PATCH 029/117] New Usage lattice with annotated one-shot lambdas

---
 compiler/basicTypes/Usage.hs             | 110 ++++++++++++++++++++++++-------
 compiler/simplCore/CallArity/Analysis.hs |  53 +++++++--------
 compiler/simplCore/CallArity/Types.hs    |   9 ++-
 compiler/simplCore/SimplUtils.hs         |   2 +-
 4 files changed, 118 insertions(+), 56 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 057a59e996..28f298ed31 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -1,25 +1,45 @@
-module Usage where
+module Usage
+  ( Multiplicity (..)
+  , botMultiplicity, topMultiplicity, lubMultiplicity
+  , Use
+  , topUse, lubUse, abstractUse, applyUse
+  , Usage (..)
+  , multiplicity, use, botUsage, topUsage, lubUsage
+  , UsageSig
+  , botUsageSig, topUsageSig, lubUsageSig, consUsageSig, unconsUsageSig
+  , useArity
+  , trimUse, trimUsage, trimUsageSig
+  ) where
 
 import BasicTypes
 import Binary
-import Maybes ( expectJust )
 import Outputable
 
-import Data.Function ( on )
-
 -- * Types
 
-type Use = Arity
-
 data Multiplicity
   = Once
   | Many
   deriving (Eq, Ord, Show)
 
+-- | The @Ord@ instance is incompatible with the lattice and only used when
+-- acting as a key type in a map.
+data Use
+  = TopUse
+  -- ^ A single use where we don't know any further details of how
+  --
+  --     * a potential nested lambda body is used
+  --     * potential product components are used
+  | Call !Usage
+  -- ^ A single use where the lambda body is used according to @Usage@.
+  deriving (Eq, Ord, Show)
+
+-- | The @Ord@ instance is incompatible with the lattice and only used when
+-- acting as a key type in a map.
 data Usage
   = Absent
-  | Used Multiplicity {-# UNPACK #-} !Use
-  deriving (Eq, Show)
+  | Used !Multiplicity !Use
+  deriving (Eq, Ord, Show)
 
 multiplicity :: Usage -> Maybe Multiplicity
 multiplicity (Used m _) = Just m
@@ -29,6 +49,8 @@ use :: Usage -> Maybe Use
 use (Used _ u) = Just u
 use _ = Nothing
 
+-- | The constructors should not be exported. Use @consUsageSig@ and
+-- @unconsUsageSig@ instead, or else the derived @Eq@ instance is invalid.
 data UsageSig
   = BotUsageSig -- ^ All further args absent
   | TopUsageSig -- ^ All further args used many times
@@ -41,10 +63,12 @@ data UsageSig
 -- appropriate integer type with pos. Inf.
 
 topUse :: Use
-topUse = 0
+topUse = TopUse
 
 lubUse :: Use -> Use -> Use
-lubUse = min
+lubUse TopUse _ = TopUse
+lubUse _ TopUse = TopUse
+lubUse (Call u1) (Call u2) = Call (lubUsage u1 u2)
 
 botMultiplicity :: Multiplicity
 botMultiplicity = Once
@@ -83,9 +107,31 @@ lubUsageSig (ArgUsage u1 s1) (ArgUsage u2 s2) = ArgUsage (lubUsage u1 u2) (lubUs
 
 -- * Working with @Use@, @Usage@ and @UsageSig@
 
-mapUsageArity :: (Arity -> Arity) -> Usage -> Usage
-mapUsageArity f (Used multi use) = Used multi (f use)
-mapUsageArity f u = u
+-- | Abstracts the given @Use@ as a singular body @Usage@ behind a
+-- lambda binder. This is useful in the @App@lication rule and the only way
+-- to introduce a call use.
+abstractUse :: Use -> Use
+abstractUse use = Call (Used Once use)
+
+-- | Dual to @abstractUse@, this will return the @Usage@ of the lambda body,
+-- relative to the given single @Use@ of the outer expression. Useful in the
+-- @Lam@bda rule and the only meaningful way to eliminate a call use.
+applyUse :: Use -> Usage
+applyUse (Call usage) = usage
+applyUse _ = topUsage
+
+useArity :: Use -> Arity
+useArity (Call (Used _ u)) = 1 + useArity u
+useArity _ = 0
+
+trimUse :: Arity -> Use -> Use
+trimUse arity (Call usage)
+  | arity > 0 = Call (trimUsage (arity - 1) usage)
+trimUse _ _ = topUse
+
+trimUsage :: Arity -> Usage -> Usage
+trimUsage arity (Used multi use) = Used multi (trimUse arity use)
+trimUsage _ u = u
 
 consUsageSig :: Usage -> UsageSig -> UsageSig
 consUsageSig u s
@@ -105,27 +151,32 @@ unconsUsageSig BotUsageSig = (botUsage, BotUsageSig)
 unconsUsageSig TopUsageSig = (topUsage, TopUsageSig)
 unconsUsageSig (ArgUsage u s) = (u, s)
 
-trimUsageSig :: Arity -> UsageSig -> UsageSig
-trimUsageSig 0 _ = topUsageSig
-trimUsageSig _ TopUsageSig = topUsageSig
-trimUsageSig arity sig = consUsageSig headUsage (trimUsageSig (arity - 1) tailUsage)
+-- | Trims a @UsageSig@ by looking at how the associated value is used.
+--
+-- The resulting @UsageSig@ will only have as many arguments as the @Use@ has
+-- call nestings.
+trimUsageSig :: Use -> UsageSig -> UsageSig
+trimUsageSig _ BotUsageSig = BotUsageSig
+trimUsageSig (Call Absent) _ = BotUsageSig -- Since the result isn't forced, no further argument will
+trimUsageSig _ TopUsageSig = TopUsageSig
+trimUsageSig (Call (Used _ u)) sig = consUsageSig head_usage (trimUsageSig u tail_usage)
   where
-    (headUsage, tailUsage) = unconsUsageSig sig
+    (head_usage, tail_usage) = unconsUsageSig sig
+trimUsageSig _ _ = TopUsageSig
 
 -- * Pretty-printing
 
--- | Formats use like a Call demand.
-pprUse :: Use -> SDoc
-pprUse 0 = text "U"
-pprUse u = text "C" <> parens (pprUse (u - 1))
-
 instance Outputable Multiplicity where
   ppr Once = text "1"
   ppr Many = text "ω"
 
+instance Outputable Use where
+  ppr TopUse = text "U"
+  ppr (Call usage) = text "C" <> parens (ppr usage)
+
 instance Outputable Usage where
   ppr Absent = text "A"
-  ppr (Used multi use) = ppr multi <> char '*' <> pprUse use
+  ppr (Used multi use) = ppr multi <> char '*' <> ppr use
 
 instance Outputable UsageSig where
   ppr BotUsageSig = text "A,A.."
@@ -145,6 +196,16 @@ instance Binary Multiplicity where
       _ -> return Many
 
 -- | Mostly important for serializing @UsageSig@ in interface files.
+instance Binary Use where
+  put_ bh TopUse = putByte bh 0
+  put_ bh (Call usage) = putByte bh 1 >> put_ bh usage
+  get  bh = do
+    h <- getByte bh
+    case h of
+      0 -> return TopUse
+      _ -> Call <$> get bh
+
+-- | Mostly important for serializing @UsageSig@ in interface files.
 instance Binary Usage where
   put_ bh Absent = putByte bh 0
   put_ bh (Used multi use) = putByte bh 1 >> put_ bh multi >> put_ bh use
@@ -154,6 +215,7 @@ instance Binary Usage where
       0 -> return Absent
       _ -> Used <$> get bh <*> get bh
 
+-- | Mostly important for serializing @UsageSig@ in interface files.
 instance Binary UsageSig where
   put_ bh BotUsageSig = putByte bh 0
   put_ bh TopUsageSig = putByte bh 1
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index ef4bc3f3ef..576174378d 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -504,19 +504,20 @@ callArityExpr nodes (Lam id e)
   | isTyVar id = callArityExprMap nodes (Lam id) e -- Non-value lambdas are ignored
   | otherwise  = transfer' <$> callArityExpr nodes e
   where
-    transfer' transfer 0 = do
-      -- We have a lambda that may be called multiple times, so its free variables
-      -- can all be co-called.
-      -- Also regardless of the variable not being interesting,
-      -- we have to add the var as an argument.
-      (ut, e') <- transfer 0
-      return (makeIdArg id (multiplyFreeVarUsages Many ut), Lam id e')
-
-    transfer' transfer use = do
-      -- We have a lambda that we are applying to. decrease arity.
-      (ut, e') <- transfer (use - 1)
-      -- TODO: annotate id
-      return (makeIdArg id ut, Lam id e')
+    transfer' transfer use
+      | Absent <- applyUse use
+      = return (emptyUsageType, Lam id e)
+      | Used multi bodyUse <- applyUse use
+      = do
+        -- We have a lambda that may be called multiple times, so its free variables
+        -- can all be co-called.
+        -- Also regardless of the variable not being interesting,
+        -- we have to add the var as an argument.
+        (ut, e') <- transfer bodyUse
+        let id' | Once <- multi = id `setIdOneShotInfo` OneShotLam
+                | otherwise = id
+        let ut' = multiplyFreeVarUsages multi ut
+        return (makeIdArg id' ut', Lam id' e')
 
 callArityExpr nodes (App f (Type t)) = callArityExprMap nodes (flip App (Type t)) f
 
@@ -525,8 +526,8 @@ callArityExpr nodes (App f (Type t)) = callArityExprMap nodes (flip App (Type t)
 callArityExpr nodes (App f a) = do
   transfer_f <- callArityExpr nodes f
   transfer_a <- callArityExpr nodes a
-  return $ \use -> do
-    (ut_f, f') <- transfer_f (use + 1)
+  return $ \result_use -> do
+    (ut_f, f') <- transfer_f (abstractUse result_use)
     --pprTrace "App:f'" (ppr (ut_f, f')) $ return ()
     -- peel off one argument from the type
     let (arg_usage, ut_f') = peelUsageType ut_f
@@ -536,9 +537,9 @@ callArityExpr nodes (App f a) = do
     -- of just a single @Use@ by multipliying the analysis result with the
     -- @Usage@s inherent @Multiplicity@.
     case oneifyUsageIfThunk a arg_usage of
-      Absent -> return (ut_f', App f' a) -- TODO: Visit a, too? Seems unnecessary, wasn't called at all
-      Used multi use -> do
-          (ut_a, a') <- transfer_a use
+      Absent -> return (ut_f', App f' a) -- TODO: Visit a, too? Seems unnecessary, wasn't called at all and should be taken care of by WW.
+      Used multi arg_use -> do
+          (ut_a, a') <- transfer_a arg_use
           --pprTrace "App:a'" (text "safe_arity:" <+> ppr safe_arity <+> ppr (ut_a, a')) $ return ()
           let ut_a' = multiplyFreeVarUsages multi ut_a
           return (ut_f' `both` ut_a', App f' a')
@@ -552,7 +553,7 @@ callArityExpr nodes (Case scrut bndr ty alts) = do
   transfer_alts <- forM alts $ \(dc, bndrs, e) ->
     callArityExprMap nodes (dc, bndrs,) e
   return $ \use -> do
-    (ut_scrut, scrut') <- transfer_scrut 0
+    (ut_scrut, scrut') <- transfer_scrut topUse
     (ut_alts, alts') <- unzip <$> mapM ($ use) transfer_alts
     let ut = trimArgs use (lubTypes ut_alts) `both` ut_scrut
     -- TODO: Think harder about the diverging case (e.g. matching on `undefined`).
@@ -675,7 +676,7 @@ unleashCall is_recursive ut_scope (id, rhs) transfer_rhs
     usage_id = -- How @id@ was used in its scope.
       -- ... except for bottoms, where we can't eta-expand.
       -- See Note [Trimming arity]
-      mapUsageArity (trimArity id)
+      trimUsage (trimmedArity id)
       -- See Note [Thunks in recursive groups]
       -- @is_recursive@ implies multiplicity @Many@ (otherwise, why would it be
       -- recursive?), although the co-call graph doesn't model it that way.
@@ -718,14 +719,14 @@ isThunk = not . exprIsCheap
 oneifyUsageIfThunk :: CoreExpr -> Usage -> Usage
 oneifyUsageIfThunk e (Used Many use)
   -- A thunk was called multiple times! Do not eta-expand
-  | isThunk e = Used Once 0
+  | isThunk e = Used Once topUse
   -- In case e is cheap and we use the let-bound var of e with @Used Many 0@, this
   -- allows us to at least analyze the cheap RHS with multiplicity @Once@ before we
   -- potentially hit a lambda binder, where we proceed normally with @Used Many 0@.
   -- I'm not sure if this actually buys us anything, @e@ is cheap after all.
   -- But it may still be non-@exprIsTrivial@, so just leaving it here for the
   -- time being.
-  | use == 0 = Used Once 0
+  | use == topUse = Used Once topUse
 oneifyUsageIfThunk _ u = u
 
 -- | Multiplies with @Many@; $\omega*_$ formally. @manifyUsage Absent = Absent@
@@ -762,7 +763,7 @@ callArityLetEnv ut_rhss ut_body
         | otherwise            = unionUnVarGraphs $ map cross_call ut_rhss
     cross_call (id, ut_rhs) = completeBipartiteGraph called_by_id called_with_id
       where
-        is_thunk = use (idCallArity id) == Just 0 -- This is a new annotation, from this FP iteration!
+        is_thunk = use (idCallArity id) == Just topUse -- This is a new annotation, from this FP iteration!
         -- We only add self cross calls if we really can recurse into ourselves.
         -- This is not the case for thunks (and non-recursive bindings, but
         -- then there won't be any mention of id in the rhs).
@@ -782,12 +783,12 @@ callArityLetEnv ut_rhss ut_body
     ut_new = modifyCoCalls (cross_calls `unionUnVarGraph`) ut_combined
 
 -- See Note [Trimming arity]
-trimArity :: Id -> Arity -> Arity
-trimArity id a = minimum [a, max_arity_by_type, max_arity_by_strsig]
+trimmedArity :: Id -> Arity
+trimmedArity id = minimum [max_arity_by_type, max_arity_by_strsig]
   where
     max_arity_by_type = length (typeArity (idType id))
     max_arity_by_strsig
         | isBotRes result_info = length demands
-        | otherwise = a
+        | otherwise = maxBound
 
     (demands, result_info) = splitStrictSig (idStrictness id)
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index dd6a709f74..2d7e929b71 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -1,6 +1,5 @@
 module CallArity.Types where
 
-import BasicTypes
 import CoreArity ( typeArity )
 import CoreSyn
 import Id
@@ -48,14 +47,14 @@ emptyUsageType = UT emptyUnVarGraph emptyVarEnv topUsageSig
 unitUsageType :: Id -> Use -> UsageType
 unitUsageType id use = emptyUsageType { ut_uses = unitVarEnv id use }
 
-unusedArgsUsageType :: Arity -> UsageType
-unusedArgsUsageType arity = trimArgs arity (unusedArgs emptyUsageType)
+unusedArgsUsageType :: Use -> UsageType
+unusedArgsUsageType use = trimArgs use (unusedArgs emptyUsageType)
 
 unusedArgs :: UsageType -> UsageType
 unusedArgs ut = ut { ut_args = botUsageSig }
 
-trimArgs :: Int -> UsageType -> UsageType
-trimArgs arity = modifyArgs (trimUsageSig arity)
+trimArgs :: Use -> UsageType -> UsageType
+trimArgs use = modifyArgs (trimUsageSig use)
 
 typeDelList :: [Id] -> UsageType -> UsageType
 typeDelList ids ae = foldr typeDel ae ids
diff --git a/compiler/simplCore/SimplUtils.hs b/compiler/simplCore/SimplUtils.hs
index 9e009b9751..c1d85644e0 100644
--- a/compiler/simplCore/SimplUtils.hs
+++ b/compiler/simplCore/SimplUtils.hs
@@ -1435,7 +1435,7 @@ tryEtaExpandRhs env is_rec bndr rhs
             -- and @CallArity.Analysis.oneifyUsageIfThunk@.
             -- TODO: Also figure out if CoreArity yields better results at all.
             new_arity2
-              | Just arity <- use usage
+              | Just arity <- useArity <$> use usage
               , exprIsCheap rhs || Just Once == multiplicity usage
               = arity
               | otherwise
-- 
2.12.1


From 50e4b82a8f881e69de61882138147da9d6e3421d Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 7 Apr 2017 22:07:44 +0200
Subject: [PATCH 030/117] Fixing bugs related to the domain change. No
 transformation stuff in analysis anymore

---
 compiler/basicTypes/Usage.hs                     | 222 ++++++++++++++++-------
 compiler/simplCore/CallArity/Analysis.hs         | 115 ++++++------
 compiler/simplCore/CallArity/FrameworkBuilder.hs |  16 +-
 compiler/simplCore/CallArity/Types.hs            |  49 +++--
 compiler/simplCore/SimplUtils.hs                 |  11 +-
 5 files changed, 253 insertions(+), 160 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 28f298ed31..12ee810144 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -1,14 +1,13 @@
 module Usage
   ( Multiplicity (..)
   , botMultiplicity, topMultiplicity, lubMultiplicity
-  , Use
-  , topUse, lubUse, abstractUse, applyUse
+  , SingleUse
+  , topSingleUse, lubSingleUse, bothSingleUse, abstractSingleUse, applySingleUse
   , Usage (..)
-  , multiplicity, use, botUsage, topUsage, lubUsage
+  , multiplicity, botUsage, topUsage, lubUsage, bothUsage, manifyUsage, expandArity
   , UsageSig
-  , botUsageSig, topUsageSig, lubUsageSig, consUsageSig, unconsUsageSig
-  , useArity
-  , trimUse, trimUsage, trimUsageSig
+  , botUsageSig, topUsageSig, lubUsageSig, consUsageSig, unconsUsageSig, manifyUsageSig
+  , trimSingleUse, trimUsage, trimUsageSig
   ) where
 
 import BasicTypes
@@ -22,32 +21,55 @@ data Multiplicity
   | Many
   deriving (Eq, Ord, Show)
 
--- | The @Ord@ instance is incompatible with the lattice and only used when
+-- | A @SingleUse@ describes how an expression is used, after it hit WHNF.
+-- Some examples:
+--
+--    * A single use of @seq a b@ unleashes nothing beyond the WHNF use on @a@,
+--      but uses @b@ fully, in an unspecified manner.
+--    * A single use of @f x@ unleashes, beyond evaluation to WHNF, a call use
+--      on @f@, where the result of the call (e.g. the lambda body) is used once.
+--
+-- The @Ord@ instance is incompatible with the lattice and only used when
 -- acting as a key type in a map.
-data Use
-  = TopUse
-  -- ^ A single use where we don't know any further details of how
+data SingleUse
+  = HeadUse
+  -- ^ A @SingleUse@ which just evaluates the expression to WHNF. No resulting
+  -- lambdas are called and usage of all product components is absent.
+  | Call !Multiplicity !SingleUse
+  -- ^ @Call m u@ denotes a @SingleUse@ where, after hitting WHNF, the lambda
+  -- body is used according to @u@ with multiplicity @m@. @Call Many u@ would
+  -- mean the expression was called potentially many times, after being brought
+  -- to WHNF.
   --
-  --     * a potential nested lambda body is used
-  --     * potential product components are used
-  | Call !Usage
-  -- ^ A single use where the lambda body is used according to @Usage@.
+  -- Use @abstractSingleUse@ to introduce this constructor and
+  -- @abstractSingleUse@ to eliminate @Call@s.
+  | TopUse
+  -- ^ A @SingleUse@ where, after hitting WHNF of the expression,
+  -- we don't know any further details of how
+  --
+  --     * a resulting nested lambda body is used
+  --     * resulting product components are used
   deriving (Eq, Ord, Show)
 
--- | The @Ord@ instance is incompatible with the lattice and only used when
+-- | @Id@entifiers can be used multiple times and are the only means to
+-- introduce sharing of work, evaluating expressions into WHNF, that is.
+-- @Usage@ can track how often an identifier was used and how each of the
+-- @SingleUse@s looked like.
+--
+-- The @Ord@ instance is incompatible with the lattice and only used when
 -- acting as a key type in a map.
 data Usage
   = Absent
-  | Used !Multiplicity !Use
+  | Used !Multiplicity !SingleUse
   deriving (Eq, Ord, Show)
 
 multiplicity :: Usage -> Maybe Multiplicity
 multiplicity (Used m _) = Just m
 multiplicity _ = Nothing
 
-use :: Usage -> Maybe Use
-use (Used _ u) = Just u
-use _ = Nothing
+singleUse :: Usage -> Maybe SingleUse
+singleUse (Used _ u) = Just u
+singleUse _ = Nothing
 
 -- | The constructors should not be exported. Use @consUsageSig@ and
 -- @unconsUsageSig@ instead, or else the derived @Eq@ instance is invalid.
@@ -59,17 +81,6 @@ data UsageSig
 
 -- * Lattice operations
 
--- TODO: decide if botUse would be valuable, and if so, change @Use@ to an
--- appropriate integer type with pos. Inf.
-
-topUse :: Use
-topUse = TopUse
-
-lubUse :: Use -> Use -> Use
-lubUse TopUse _ = TopUse
-lubUse _ TopUse = TopUse
-lubUse (Call u1) (Call u2) = Call (lubUsage u1 u2)
-
 botMultiplicity :: Multiplicity
 botMultiplicity = Once
 
@@ -81,16 +92,44 @@ lubMultiplicity Once m = m
 lubMultiplicity m Once = m
 lubMultiplicity _ _    = Many
 
+botSingleUse :: SingleUse
+botSingleUse = HeadUse
+
+topSingleUse :: SingleUse
+topSingleUse = TopUse
+
+lubSingleUse :: SingleUse -> SingleUse -> SingleUse
+lubSingleUse TopUse _ = TopUse
+lubSingleUse _ TopUse = TopUse
+lubSingleUse HeadUse u = u
+lubSingleUse u HeadUse = u
+lubSingleUse (Call m1 u1) (Call m2 u2) = Call (lubMultiplicity m1 m2) (lubSingleUse u1 u2)
+
+-- | Think 'plus' on @SingleUse@s, for sequential composition.
+bothSingleUse :: SingleUse -> SingleUse -> SingleUse
+bothSingleUse TopUse _ = TopUse
+bothSingleUse _ TopUse = TopUse
+bothSingleUse HeadUse u = u
+bothSingleUse u HeadUse = u
+bothSingleUse (Call _ u1) (Call _ u2) = Call Many (lubSingleUse u1 u2)
+
 botUsage :: Usage
 botUsage = Absent
 
 topUsage :: Usage
-topUsage = Used topMultiplicity topUse
+topUsage = Used topMultiplicity topSingleUse
 
 lubUsage :: Usage -> Usage -> Usage
 lubUsage Absent u = u
 lubUsage u Absent = u
-lubUsage (Used m1 u1) (Used m2 u2) = Used (lubMultiplicity m1 m2) (lubUse u1 u2)
+lubUsage (Used m1 u1) (Used m2 u2) = Used (lubMultiplicity m1 m2) (lubSingleUse u1 u2)
+
+-- | Think 'plus' on @Usage@s, for sequential composition.
+-- E.g. if @Usage@s from scrutinee and case branches should be combined.
+bothUsage :: Usage -> Usage -> Usage
+bothUsage Absent u = u
+bothUsage u Absent = u
+bothUsage (Used _ u1) (Used _ u2) = Used Many (bothSingleUse u1 u2)
 
 botUsageSig :: UsageSig
 botUsageSig = BotUsageSig
@@ -107,31 +146,72 @@ lubUsageSig (ArgUsage u1 s1) (ArgUsage u2 s2) = ArgUsage (lubUsage u1 u2) (lubUs
 
 -- * Working with @Use@, @Usage@ and @UsageSig@
 
--- | Abstracts the given @Use@ as a singular body @Usage@ behind a
--- lambda binder. This is useful in the @App@lication rule and the only way
--- to introduce a call use.
-abstractUse :: Use -> Use
-abstractUse use = Call (Used Once use)
+-- | Abstracts the given @SingleUse@ as a singular body @Usage@ behind a
+-- lambda binder. This is useful in the @App@lication rule.
+abstractSingleUse :: SingleUse -> SingleUse
+abstractSingleUse use = Call Once use
 
--- | Dual to @abstractUse@, this will return the @Usage@ of the lambda body,
+-- | Dual to @abstractSingleUse@, this will return the @Usage@ of the lambda body,
 -- relative to the given single @Use@ of the outer expression. Useful in the
--- @Lam@bda rule and the only meaningful way to eliminate a call use.
-applyUse :: Use -> Usage
-applyUse (Call usage) = usage
-applyUse _ = topUsage
+-- @Lam@bda rule.
+applySingleUse :: SingleUse -> Usage
+applySingleUse HeadUse = Absent -- The lambda will be reduced to WHNF, but the body will stay untouched.
+applySingleUse (Call multi use) = Used multi use
+applySingleUse _ = topUsage
 
-useArity :: Use -> Arity
-useArity (Call (Used _ u)) = 1 + useArity u
-useArity _ = 0
-
-trimUse :: Arity -> Use -> Use
-trimUse arity (Call usage)
-  | arity > 0 = Call (trimUsage (arity - 1) usage)
-trimUse _ _ = topUse
+trimSingleUse :: Arity -> SingleUse -> SingleUse
+trimSingleUse arity (Call m body)
+  | arity > 0 = Call m (trimSingleUse (arity - 1) body)
+trimSingleUse _ _ = topSingleUse
 
 trimUsage :: Arity -> Usage -> Usage
-trimUsage arity (Used multi use) = Used multi (trimUse arity use)
-trimUsage _ u = u
+trimUsage arity (Used m use) = Used m (trimSingleUse arity use)
+trimUsage arity usg = usg
+
+-- | @manifyUsage u = bothUsage u u@. For when an id is used more than once
+-- with the same @Usage@. This is different than just changing the top-level
+-- @Multiplicity@ to @Many@, which would correspond to an additional @seq@
+-- @Usage@ of the top-level expression (e.g. without applying any args).
+manifyUsage :: Usage -> Usage
+manifyUsage u = bothUsage u u
+
+expandArity :: Usage -> Arity -> Arity
+expandArity Absent cheap_arity
+  -- We could potentially expand as far as we want, since the result doesn't
+  -- seem to be used. This happens when doing something like @seq (f 1 2) e@,
+  -- where @e@ doesn't contain any reference to @f@. We *could* expand @f@,
+  -- but that would be counter-intuitive, since someone who writes such code
+  -- would expect that the call to @seq@ reduces something.
+  = cheap_arity
+expandArity (Used Many _) 0
+  -- This is a special case, accounting for the fact that let-bindings
+  -- are evaluated at most once. Consider @f `seq` ... f x ... @: @seq@ makes
+  -- it possible to end up with an @Usage@ of @Used Many (Call Once TopUse)@,
+  -- where the outer @Multiplicity@ and the top-level one-shot @Multiplicity@
+  -- are out of sync. Eta-expansion would be counter-intuitive, as the lifted
+  -- abstraction would hide the work which we wanted to evaluate strictly.
+  -- Thus we don't eta-expand:
+  = 0
+expandArity (Used _ u) cheap_arity
+  = impl u cheap_arity
+  where
+    impl HeadUse cheap_arity -- the application expression we accumulated does non-trivial work, so
+      -- Same reason as for the above @Absent@ case
+      = cheap_arity
+    impl TopUse cheap_arity
+      -- No chance we can expand anything
+      = cheap_arity
+    impl (Call Many u) 0
+      -- the application expression we accumulated does non-trivial work,
+      -- which we aren't allowed to push into a non-one-shot lambda. So
+      -- we don't expand any further.
+      = 0
+    impl (Call _ u) cheap_arity
+      -- This is the case that may actually expand arity:
+      -- When we're out of @cheap_arity@ here, we may expand nonetheless.
+      -- It's OK to push work into a one-shot lambda, or to expand as long
+      -- as the accumulated application expression is cheap.
+      = 1 + impl u (max 0 (cheap_arity - 1))
 
 consUsageSig :: Usage -> UsageSig -> UsageSig
 consUsageSig u s
@@ -151,15 +231,21 @@ unconsUsageSig BotUsageSig = (botUsage, BotUsageSig)
 unconsUsageSig TopUsageSig = (topUsage, TopUsageSig)
 unconsUsageSig (ArgUsage u s) = (u, s)
 
+-- | Maps @manifyUsage@ over each argument usage.
+manifyUsageSig :: UsageSig -> UsageSig
+manifyUsageSig TopUsageSig = TopUsageSig
+manifyUsageSig BotUsageSig = BotUsageSig
+manifyUsageSig (ArgUsage u s) = consUsageSig (manifyUsage u) (manifyUsageSig s)
+
 -- | Trims a @UsageSig@ by looking at how the associated value is used.
 --
--- The resulting @UsageSig@ will only have as many arguments as the @Use@ has
+-- The resulting @UsageSig@ will only have as many arguments as the @SingleUse@ has
 -- call nestings.
-trimUsageSig :: Use -> UsageSig -> UsageSig
+trimUsageSig :: SingleUse -> UsageSig -> UsageSig
 trimUsageSig _ BotUsageSig = BotUsageSig
-trimUsageSig (Call Absent) _ = BotUsageSig -- Since the result isn't forced, no further argument will
+trimUsageSig HeadUse _ = BotUsageSig -- Since the result isn't forced beyond WHNF, no further argument will
 trimUsageSig _ TopUsageSig = TopUsageSig
-trimUsageSig (Call (Used _ u)) sig = consUsageSig head_usage (trimUsageSig u tail_usage)
+trimUsageSig (Call _ u) sig = consUsageSig head_usage (trimUsageSig u tail_usage)
   where
     (head_usage, tail_usage) = unconsUsageSig sig
 trimUsageSig _ _ = TopUsageSig
@@ -170,17 +256,21 @@ instance Outputable Multiplicity where
   ppr Once = text "1"
   ppr Many = text "ω"
 
-instance Outputable Use where
+instance Outputable SingleUse where
+  ppr HeadUse = text "HU"
   ppr TopUse = text "U"
-  ppr (Call usage) = text "C" <> parens (ppr usage)
+  ppr (Call multi body) = text "C^" <> ppr multi <> parens (ppr body)
 
 instance Outputable Usage where
   ppr Absent = text "A"
   ppr (Used multi use) = ppr multi <> char '*' <> ppr use
 
+pprEllipsis :: Usage -> SDoc
+pprEllipsis usage = ppr usage <> char ',' <> ppr usage <> text ".."
+
 instance Outputable UsageSig where
-  ppr BotUsageSig = text "A,A.."
-  ppr TopUsageSig = text "U,U.."
+  ppr BotUsageSig = pprEllipsis botUsage
+  ppr TopUsageSig = pprEllipsis topUsage
   ppr (ArgUsage u sig) = ppr u <> char ',' <> ppr sig
 
 -- * Serialization
@@ -196,14 +286,16 @@ instance Binary Multiplicity where
       _ -> return Many
 
 -- | Mostly important for serializing @UsageSig@ in interface files.
-instance Binary Use where
-  put_ bh TopUse = putByte bh 0
-  put_ bh (Call usage) = putByte bh 1 >> put_ bh usage
+instance Binary SingleUse where
+  put_ bh HeadUse = putByte bh 0
+  put_ bh TopUse = putByte bh 1
+  put_ bh (Call multi use) = putByte bh 2 >> put_ bh multi >> put_ bh use
   get  bh = do
     h <- getByte bh
     case h of
-      0 -> return TopUse
-      _ -> Call <$> get bh
+      0 -> return HeadUse
+      1 -> return TopUse
+      _ -> Call <$> get bh <*> get bh
 
 -- | Mostly important for serializing @UsageSig@ in interface files.
 instance Binary Usage where
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 576174378d..169a396d42 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -435,17 +435,17 @@ callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
 callArityAnalProgram _dflags = exprToModule . callArityRHS . moduleToExpr
 
 callArityRHS :: CoreExpr -> CoreExpr
-callArityRHS e = snd (buildAndRun (callArityExpr emptyVarEnv e) topUse)
+callArityRHS e = snd (buildAndRun (callArityExpr emptyVarEnv e) topSingleUse)
 
 -- | The main analysis function. See Note [Analysis type signature]
 callArityExpr
   :: VarEnv FrameworkNode
   -> CoreExpr
-  -> FrameworkBuilder (Use -> TransferFunction AnalResult)
+  -> FrameworkBuilder (SingleUse -> TransferFunction AnalResult)
 
 callArityExprTrivial
   :: CoreExpr
-  -> FrameworkBuilder (Use -> TransferFunction AnalResult)
+  -> FrameworkBuilder (SingleUse -> TransferFunction AnalResult)
 callArityExprTrivial e
   = return (\_ -> return (emptyUsageType, e))
 
@@ -453,7 +453,7 @@ callArityExprMap
   :: VarEnv FrameworkNode
   -> (CoreExpr -> a)
   -> CoreExpr
-  -> FrameworkBuilder (Use -> TransferFunction (UsageType, a)) -- @a@ instead of @CoreExpr@
+  -> FrameworkBuilder (SingleUse -> TransferFunction (UsageType, a)) -- @a@ instead of @CoreExpr@
 callArityExprMap nodes f e
   = transfer' <$> callArityExpr nodes e
   where
@@ -500,24 +500,21 @@ callArityExpr nodes e@(Var id) = return transfer
       -- binders.
       = return (unitUsageType id use, e)
 
-callArityExpr nodes (Lam id e)
-  | isTyVar id = callArityExprMap nodes (Lam id) e -- Non-value lambdas are ignored
-  | otherwise  = transfer' <$> callArityExpr nodes e
-  where
-    transfer' transfer use
-      | Absent <- applyUse use
-      = return (emptyUsageType, Lam id e)
-      | Used multi bodyUse <- applyUse use
-      = do
-        -- We have a lambda that may be called multiple times, so its free variables
-        -- can all be co-called.
-        -- Also regardless of the variable not being interesting,
-        -- we have to add the var as an argument.
-        (ut, e') <- transfer bodyUse
-        let id' | Once <- multi = id `setIdOneShotInfo` OneShotLam
-                | otherwise = id
-        let ut' = multiplyFreeVarUsages multi ut
-        return (makeIdArg id' ut', Lam id' e')
+callArityExpr nodes (Lam id body)
+  | isTyVar id
+  = callArityExprMap nodes (Lam id) body -- Non-value lambdas are ignored
+  | otherwise
+  = do
+    transfer_body <- callArityExpr nodes body
+    return $ \use ->
+      case applySingleUse use of -- Get at the @Usage@ of the body
+        Absent -> return (emptyUsageType, Lam id body)
+        Used multi body_use -> do
+          (ut_body, body') <- transfer_body body_use
+          let id' | Once <- multi = id `setIdOneShotInfo` OneShotLam
+                  | otherwise = id
+          let ut = multiplyFreeVarUsages multi ut_body
+          return (makeIdArg id' ut, Lam id' body')
 
 callArityExpr nodes (App f (Type t)) = callArityExprMap nodes (flip App (Type t)) f
 
@@ -527,22 +524,24 @@ callArityExpr nodes (App f a) = do
   transfer_f <- callArityExpr nodes f
   transfer_a <- callArityExpr nodes a
   return $ \result_use -> do
-    (ut_f, f') <- transfer_f (abstractUse result_use)
+    (ut_f, f') <- transfer_f (abstractSingleUse result_use)
     --pprTrace "App:f'" (ppr (ut_f, f')) $ return ()
     -- peel off one argument from the type
     let (arg_usage, ut_f') = peelUsageType ut_f
-    -- In call-by-need, arguments are evaluated at most once, so they qualify as
-    -- thunk.
-    -- This 'lifts' the transfer function of @a@ into one taking a @Usage@ instead
-    -- of just a single @Use@ by multipliying the analysis result with the
-    -- @Usage@s inherent @Multiplicity@.
-    case oneifyUsageIfThunk a arg_usage of
-      Absent -> return (ut_f', App f' a) -- TODO: Visit a, too? Seems unnecessary, wasn't called at all and should be taken care of by WW.
-      Used multi arg_use -> do
+    case arg_usage of
+      -- TODO: Visit a, too? Seems unnecessary, wasn't called at all and
+      -- should be taken care of by WW.
+      Absent -> return (ut_f', App f' a)
+      Used _ arg_use -> do
+          -- We can ignore the multiplicity, as the work done before the first
+          -- lambda is uncovered will be shared (call-by-need!). This is the same
+          -- argument as for let-bound right hand sides.
+          -- Although we could use the multiplicity in the same way we do for
+          -- let-bindings: An argument only used once does not need to be
+          -- memoized.
           (ut_a, a') <- transfer_a arg_use
-          --pprTrace "App:a'" (text "safe_arity:" <+> ppr safe_arity <+> ppr (ut_a, a')) $ return ()
-          let ut_a' = multiplyFreeVarUsages multi ut_a
-          return (ut_f' `both` ut_a', App f' a')
+          --pprTrace "App:a'" (text "arg_use:" <+> ppr arg_use <+> ppr (ut_a, a')) $ return ()
+          return (ut_f' `both` ut_a, App f' a')
 
 -- Case expression.
 callArityExpr nodes (Case scrut bndr ty alts) = do
@@ -553,7 +552,7 @@ callArityExpr nodes (Case scrut bndr ty alts) = do
   transfer_alts <- forM alts $ \(dc, bndrs, e) ->
     callArityExprMap nodes (dc, bndrs,) e
   return $ \use -> do
-    (ut_scrut, scrut') <- transfer_scrut topUse
+    (ut_scrut, scrut') <- transfer_scrut topSingleUse
     (ut_alts, alts') <- unzip <$> mapM ($ use) transfer_alts
     let ut = trimArgs use (lubTypes ut_alts) `both` ut_scrut
     -- TODO: Think harder about the diverging case (e.g. matching on `undefined`).
@@ -587,7 +586,7 @@ callArityExpr letdown_nodes (Let bind e) = do
       -- This is a little more complicated, as we'll introduce a new FrameworkNode
       -- which we'll depend on ourselves.
       node <- registerTransferFunction (LowerThan (minimum (eltsUFM letup_nodes))) $ \node -> do
-        let transfer :: Use -> TransferFunction AnalResult
+        let transfer :: SingleUse -> TransferFunction AnalResult
             transfer use = do
               (ut_body, e') <- transfer_body use
               -- This is the actual fixed-point iteration: we depend on usage
@@ -650,7 +649,7 @@ callArityBind letdown_nodes = go letdown_nodes emptyVarEnv
 unleashLet
   :: Bool
   -> [(Id, CoreExpr)]
-  -> ((Id, CoreExpr) -> Use -> TransferFunction AnalResult)
+  -> ((Id, CoreExpr) -> SingleUse -> TransferFunction AnalResult)
   -> UsageType
   -> UsageType
   -> TransferFunction (UsageType, [(Id, CoreExpr)])
@@ -665,40 +664,40 @@ unleashCall
   :: Bool
   -> UsageType
   -> (Id, CoreExpr)
-  -> (Use -> TransferFunction AnalResult)
+  -> (SingleUse -> TransferFunction AnalResult)
   -> TransferFunction (UsageType, (Id, CoreExpr))
 unleashCall is_recursive ut_scope (id, rhs) transfer_rhs
-  | Absent <- usage_rhs
+  | Absent <- usage_id
   = return (emptyUsageType, (id `setIdCallArity` Absent, rhs)) -- No call to @id@ (yet)
-  | Used multi use <- usage_rhs
-  = analyse multi use
+  | Used _ use <- usage_id
+  -- The work required to get the RHS of let-bindings to WHNF is shared among
+  -- all uses, so the multiplicity can be ignored *when analysing the RHS*.
+  -- We still annotate the binder with the multiplity, as @Once@ means
+  -- we don't have to memoize the result.
+  = analyse use
   where
     usage_id = -- How @id@ was used in its scope.
       -- ... except for bottoms, where we can't eta-expand.
       -- See Note [Trimming arity]
+      -- TODO: Try to move this into SimplUtils or whereever we perform
+      -- eta-expansion. This has nothing to do with the analysis per-se.
       trimUsage (trimmedArity id)
       -- See Note [Thunks in recursive groups]
-      -- @is_recursive@ implies multiplicity @Many@ (otherwise, why would it be
+      -- @is_recursive@ implies more than one call (otherwise, why would it be
       -- recursive?), although the co-call graph doesn't model it that way.
       -- Self-edges in the co-call graph correspond to non-linear recursion.
       -- Kind-of a leaky abstraction, maybe we could somehow merge the
-      -- @is_recursive@ flag into the analysis environment.
+      -- @is_recursive@ flag into @UsageType@.
       . apply_when is_recursive manifyUsage
       . lookupUsage ut_scope
       $ id
     apply_when b f = if b then f else Prelude.id
-    -- The usage propagated to the let-binding is another one, as we might
-    -- decide to share the work needed to get the RHS to WHNF. See
-    -- @oneifyUsageIfThunk@. We use this usage to analyse the RHS, but annotate
-    -- with @usage_id@, which represents how the binder was used in its scope.
-    usage_rhs = oneifyUsageIfThunk rhs usage_id
-    analyse multi use = do
+    analyse use = do
       (ut_rhs, rhs') <- transfer_rhs use
-      let ut_rhs' = multiplyFreeVarUsages multi ut_rhs
       let id' = id
             `setIdCallArity` usage_id -- How the *binder* was used
-            `setIdArgUsage` ut_args ut_rhs' -- How the *RHS* uses its args
-      return (ut_rhs', (id', rhs'))
+            `setIdArgUsage` ut_args ut_rhs -- How the *RHS* uses its args
+      return (ut_rhs, (id', rhs'))
 
 -- | See Note [What is a thunk].
 -- This should always be in sync with @SimplUtils.tryEtaExpandRhs@.
@@ -719,22 +718,16 @@ isThunk = not . exprIsCheap
 oneifyUsageIfThunk :: CoreExpr -> Usage -> Usage
 oneifyUsageIfThunk e (Used Many use)
   -- A thunk was called multiple times! Do not eta-expand
-  | isThunk e = Used Once topUse
+  | isThunk e = Used Once topSingleUse
   -- In case e is cheap and we use the let-bound var of e with @Used Many 0@, this
   -- allows us to at least analyze the cheap RHS with multiplicity @Once@ before we
   -- potentially hit a lambda binder, where we proceed normally with @Used Many 0@.
   -- I'm not sure if this actually buys us anything, @e@ is cheap after all.
   -- But it may still be non-@exprIsTrivial@, so just leaving it here for the
   -- time being.
-  | use == topUse = Used Once topUse
+  | use == topSingleUse = Used Once topSingleUse
 oneifyUsageIfThunk _ u = u
 
--- | Multiplies with @Many@; $\omega*_$ formally. @manifyUsage Absent = Absent@
--- still!
-manifyUsage :: Usage -> Usage
-manifyUsage (Used Once use) = Used Many use
-manifyUsage u = u
-
 -- Combining the results from body and rhs of a let binding
 -- See Note [Analysis II: The Co-Called analysis]
 callArityLetEnv
@@ -763,7 +756,7 @@ callArityLetEnv ut_rhss ut_body
         | otherwise            = unionUnVarGraphs $ map cross_call ut_rhss
     cross_call (id, ut_rhs) = completeBipartiteGraph called_by_id called_with_id
       where
-        is_thunk = use (idCallArity id) == Just topUse -- This is a new annotation, from this FP iteration!
+        is_thunk = idArity id == 0 -- See Note [Thunks in recursive groups]
         -- We only add self cross calls if we really can recurse into ourselves.
         -- This is not the case for thunks (and non-recursive bindings, but
         -- then there won't be any mention of id in the rhs).
diff --git a/compiler/simplCore/CallArity/FrameworkBuilder.hs b/compiler/simplCore/CallArity/FrameworkBuilder.hs
index 00d7254bd5..f31b2d64dc 100644
--- a/compiler/simplCore/CallArity/FrameworkBuilder.hs
+++ b/compiler/simplCore/CallArity/FrameworkBuilder.hs
@@ -31,11 +31,11 @@ newtype FrameworkNode
   = FrameworkNode Int
   deriving (Show, Eq, Ord, Outputable)
 
-type TransferFunction a = Worklist.TransferFunction (FrameworkNode, Use) AnalResult a
-type ChangeDetector = Worklist.ChangeDetector (FrameworkNode, Use) AnalResult
-type DataFlowFramework = Worklist.DataFlowFramework (FrameworkNode, Use) AnalResult
+type TransferFunction a = Worklist.TransferFunction (FrameworkNode, SingleUse) AnalResult a
+type ChangeDetector = Worklist.ChangeDetector (FrameworkNode, SingleUse) AnalResult
+type DataFlowFramework = Worklist.DataFlowFramework (FrameworkNode, SingleUse) AnalResult
 -- | Maps @FrameworkNode@ to incoming usage dependent @TransferFunction@s
-type NodeTransferEnv = IntMap (Use -> TransferFunction AnalResult, ChangeDetector)
+type NodeTransferEnv = IntMap (SingleUse -> TransferFunction AnalResult, ChangeDetector)
 
 newtype FrameworkBuilder a
   = FB { unFB :: State NodeTransferEnv a }
@@ -55,7 +55,7 @@ data RequestedPriority
 
 registerTransferFunction
   :: RequestedPriority
-  -> (FrameworkNode -> FrameworkBuilder (a, (Use -> TransferFunction AnalResult, ChangeDetector)))
+  -> (FrameworkNode -> FrameworkBuilder (a, (SingleUse -> TransferFunction AnalResult, ChangeDetector)))
   -> FrameworkBuilder a
 registerTransferFunction prio f = FB $ do
   nodes <- get
@@ -74,14 +74,14 @@ registerTransferFunction prio f = FB $ do
     unFB (f (FrameworkNode node))
   return result
 
-dependOnWithDefault :: AnalResult -> (FrameworkNode, Use) -> TransferFunction AnalResult
+dependOnWithDefault :: AnalResult -> (FrameworkNode, SingleUse) -> TransferFunction AnalResult
 dependOnWithDefault def which = do
   --pprTrace "dependOnWithDefault:before" (text "node:" <+> ppr node <+> text "use:" <+> ppr use) $ return ()
   res <- fromMaybe def <$> Worklist.dependOn which
   --pprTrace "dependOnWithDefault:after" (vcat [text "node:" <+> ppr node, text "use:" <+> ppr use, text "res:" <+> ppr res]) $ return ()
   return res
 
-buildAndRun :: FrameworkBuilder (Use -> TransferFunction AnalResult) -> Use -> AnalResult
+buildAndRun :: FrameworkBuilder (SingleUse -> TransferFunction AnalResult) -> SingleUse -> AnalResult
 buildAndRun buildTransfer use = lookup_result (Worklist.runFramework fw (Set.singleton (node, use)))
   where
     (node, fw) = buildFramework $
@@ -91,7 +91,7 @@ buildAndRun buildTransfer use = lookup_result (Worklist.runFramework fw (Set.sin
         -- introduce a cycle.
         return (node, (transfer, Worklist.alwaysChangeDetector))
 
-    lookup_result :: Map (FrameworkNode, Use) AnalResult -> AnalResult
+    lookup_result :: Map (FrameworkNode, SingleUse) AnalResult -> AnalResult
     lookup_result result_map = case Map.lookup (node, use) result_map of
       Nothing -> pprPanic "CallArity.FrameworkBuilder.buildAndRun" empty
       Just res -> res
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index 2d7e929b71..b1dea7a563 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -20,7 +20,7 @@ data UsageType
   { ut_cocalled :: !UnVarGraph
   -- ^ Models cardinality, e.g. at most {1, many} via the co-call relation for
   -- _interesting_ variables
-  , ut_uses :: !(VarEnv Use)
+  , ut_uses :: !(VarEnv SingleUse)
   -- ^ Models per var usage and absence (card 0)
   , ut_args :: !UsageSig
   -- ^ Collects the signature for captured lambda binders
@@ -44,16 +44,16 @@ isInteresting v = not $ null (typeArity (idType v))
 emptyUsageType :: UsageType
 emptyUsageType = UT emptyUnVarGraph emptyVarEnv topUsageSig
 
-unitUsageType :: Id -> Use -> UsageType
+unitUsageType :: Id -> SingleUse -> UsageType
 unitUsageType id use = emptyUsageType { ut_uses = unitVarEnv id use }
 
-unusedArgsUsageType :: Use -> UsageType
+unusedArgsUsageType :: SingleUse -> UsageType
 unusedArgsUsageType use = trimArgs use (unusedArgs emptyUsageType)
 
 unusedArgs :: UsageType -> UsageType
 unusedArgs ut = ut { ut_args = botUsageSig }
 
-trimArgs :: Use -> UsageType -> UsageType
+trimArgs :: SingleUse -> UsageType -> UsageType
 trimArgs use = modifyArgs (trimUsageSig use)
 
 typeDelList :: [Id] -> UsageType -> UsageType
@@ -88,26 +88,41 @@ calledWith ut id
   | otherwise
   = domType ut
 
-addCrossCoCalls :: UnVarSet -> UnVarSet -> UsageType -> UsageType
-addCrossCoCalls set1 set2
-  = modifyCoCalls (completeBipartiteGraph set1 set2 `unionUnVarGraph`)
-
 -- Replaces the co-call graph by a complete graph (i.e. no information)
 multiplyFreeVarUsages :: Multiplicity -> UsageType -> UsageType
-multiplyFreeVarUsages Once res = res
-multiplyFreeVarUsages Many res = modifyCoCalls (const (completeGraph (domType res))) res
+multiplyFreeVarUsages Once ut = ut
+multiplyFreeVarUsages Many ut@(UT _ u args)
+  = UT
+  { ut_cocalled = completeGraph (domType ut)
+  , ut_uses = mapVarEnv (\use -> bothSingleUse use use) u
+  , ut_args = manifyUsageSig args
+  }
 
--- Used for application and cases
+-- | Corresponds to sequential composition of expressions.
+-- Used for application and cases.
+-- Note this returns the @UsageSig@ from the first argument.
 both :: UsageType -> UsageType -> UsageType
-both r1 r2 = addCrossCoCalls (domType r1) (domType r2) ((r1 `lubType` r2) { ut_args = ut_args r1 })
+both ut1@(UT g1 u1 args) ut2@(UT g2 u2 _)
+  = UT
+  { ut_cocalled = unionUnVarGraphs [g1, g2, completeBipartiteGraph (domType ut1) (domType ut2)]
+  , ut_uses = bothUseEnv u1 u2
+  , ut_args = args
+  }
 
--- Used when combining results from alternative cases; take the minimum
+-- | Used when combining results from alternative cases; take the minimum
 lubType :: UsageType -> UsageType -> UsageType
-lubType (UT g1 ae1 args1) (UT g2 ae2 args2)
-  = UT (g1 `unionUnVarGraph` g2) (ae1 `lubUseEnv` ae2) (lubUsageSig args1 args2)
+lubType (UT g1 u1 args1) (UT g2 u2 args2)
+  = UT
+  { ut_cocalled = unionUnVarGraph g1 g2
+  , ut_uses = lubUseEnv u1 u2
+  , ut_args = lubUsageSig args1 args2
+  }
+
+lubUseEnv :: VarEnv SingleUse -> VarEnv SingleUse -> VarEnv SingleUse
+lubUseEnv = plusVarEnv_C lubSingleUse
 
-lubUseEnv :: VarEnv Use -> VarEnv Use -> VarEnv Use
-lubUseEnv = plusVarEnv_C lubUse
+bothUseEnv :: VarEnv SingleUse -> VarEnv SingleUse -> VarEnv SingleUse
+bothUseEnv = plusVarEnv_C bothSingleUse
 
 lubTypes :: [UsageType] -> UsageType
 lubTypes = foldl lubType (unusedArgs emptyUsageType)
diff --git a/compiler/simplCore/SimplUtils.hs b/compiler/simplCore/SimplUtils.hs
index c1d85644e0..08975fe9fc 100644
--- a/compiler/simplCore/SimplUtils.hs
+++ b/compiler/simplCore/SimplUtils.hs
@@ -67,7 +67,6 @@ import Literal
 
 import Control.Monad    ( when )
 import Data.List        ( sortBy )
-import Data.Maybe ( fromMaybe )
 
 {-
 ************************************************************************
@@ -1429,18 +1428,12 @@ tryEtaExpandRhs env is_rec bndr rhs
       = return (exprArity rhs, rhs)
 
       | sm_eta_expand (getMode env)      -- Provided eta-expansion is on
-      , let new_arity1 = findRhsArity dflags bndr rhs old_arity
+      , let cheap_arity = findRhsArity dflags bndr rhs old_arity
             usage = idCallArity bndr
             -- This should always be in sync with @CallArity.Analysis.isThunk@
             -- and @CallArity.Analysis.oneifyUsageIfThunk@.
             -- TODO: Also figure out if CoreArity yields better results at all.
-            new_arity2
-              | Just arity <- useArity <$> use usage
-              , exprIsCheap rhs || Just Once == multiplicity usage
-              = arity
-              | otherwise
-              = 0
-            new_arity  = max new_arity1 new_arity2
+            new_arity = expandArity usage cheap_arity
       , new_arity > old_arity      -- And the current manifest arity isn't enough
       = if is_rec == Recursive && isJoinId bndr
            then WARN(True, text "Can't eta-expand recursive join point:" <+>
-- 
2.12.1


From eae07e4cf55b041f84ed4d795c698338001bae94 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sat, 8 Apr 2017 09:42:49 +0200
Subject: [PATCH 031/117] Implementing the C^omega(U) = U equivalence and
 adjusted the CallArity1 unit test

---
 compiler/basicTypes/Usage.hs                       | 36 +++++----
 testsuite/tests/callarity/unittest/CallArity1.hs   |  2 +-
 .../tests/callarity/unittest/CallArity1.stderr     | 90 +++++++++++-----------
 3 files changed, 67 insertions(+), 61 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 12ee810144..572e529406 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -43,7 +43,7 @@ data SingleUse
   --
   -- Use @abstractSingleUse@ to introduce this constructor and
   -- @abstractSingleUse@ to eliminate @Call@s.
-  | TopUse
+  | UnknownUse
   -- ^ A @SingleUse@ where, after hitting WHNF of the expression,
   -- we don't know any further details of how
   --
@@ -51,6 +51,12 @@ data SingleUse
   --     * resulting product components are used
   deriving (Eq, Ord, Show)
 
+-- | A smart constructor for @Call@ which normalizes according to the equivalence
+-- @Many UnknownUse = UnknownUse@.
+mkCall :: Multiplicity -> SingleUse -> SingleUse
+mkCall Many UnknownUse = UnknownUse
+mkCall m u = Call m u
+
 -- | @Id@entifiers can be used multiple times and are the only means to
 -- introduce sharing of work, evaluating expressions into WHNF, that is.
 -- @Usage@ can track how often an identifier was used and how each of the
@@ -96,22 +102,22 @@ botSingleUse :: SingleUse
 botSingleUse = HeadUse
 
 topSingleUse :: SingleUse
-topSingleUse = TopUse
+topSingleUse = UnknownUse
 
 lubSingleUse :: SingleUse -> SingleUse -> SingleUse
-lubSingleUse TopUse _ = TopUse
-lubSingleUse _ TopUse = TopUse
+lubSingleUse UnknownUse _ = UnknownUse
+lubSingleUse _ UnknownUse = UnknownUse
 lubSingleUse HeadUse u = u
 lubSingleUse u HeadUse = u
-lubSingleUse (Call m1 u1) (Call m2 u2) = Call (lubMultiplicity m1 m2) (lubSingleUse u1 u2)
+lubSingleUse (Call m1 u1) (Call m2 u2) = mkCall (lubMultiplicity m1 m2) (lubSingleUse u1 u2)
 
 -- | Think 'plus' on @SingleUse@s, for sequential composition.
 bothSingleUse :: SingleUse -> SingleUse -> SingleUse
-bothSingleUse TopUse _ = TopUse
-bothSingleUse _ TopUse = TopUse
+bothSingleUse UnknownUse _ = UnknownUse
+bothSingleUse _ UnknownUse = UnknownUse
 bothSingleUse HeadUse u = u
 bothSingleUse u HeadUse = u
-bothSingleUse (Call _ u1) (Call _ u2) = Call Many (lubSingleUse u1 u2)
+bothSingleUse (Call _ u1) (Call _ u2) = mkCall Many (lubSingleUse u1 u2)
 
 botUsage :: Usage
 botUsage = Absent
@@ -149,7 +155,7 @@ lubUsageSig (ArgUsage u1 s1) (ArgUsage u2 s2) = ArgUsage (lubUsage u1 u2) (lubUs
 -- | Abstracts the given @SingleUse@ as a singular body @Usage@ behind a
 -- lambda binder. This is useful in the @App@lication rule.
 abstractSingleUse :: SingleUse -> SingleUse
-abstractSingleUse use = Call Once use
+abstractSingleUse use = mkCall Once use
 
 -- | Dual to @abstractSingleUse@, this will return the @Usage@ of the lambda body,
 -- relative to the given single @Use@ of the outer expression. Useful in the
@@ -161,7 +167,7 @@ applySingleUse _ = topUsage
 
 trimSingleUse :: Arity -> SingleUse -> SingleUse
 trimSingleUse arity (Call m body)
-  | arity > 0 = Call m (trimSingleUse (arity - 1) body)
+  | arity > 0 = mkCall m (trimSingleUse (arity - 1) body)
 trimSingleUse _ _ = topSingleUse
 
 trimUsage :: Arity -> Usage -> Usage
@@ -186,7 +192,7 @@ expandArity Absent cheap_arity
 expandArity (Used Many _) 0
   -- This is a special case, accounting for the fact that let-bindings
   -- are evaluated at most once. Consider @f `seq` ... f x ... @: @seq@ makes
-  -- it possible to end up with an @Usage@ of @Used Many (Call Once TopUse)@,
+  -- it possible to end up with an @Usage@ of @Used Many (Call Once UnknownUse)@,
   -- where the outer @Multiplicity@ and the top-level one-shot @Multiplicity@
   -- are out of sync. Eta-expansion would be counter-intuitive, as the lifted
   -- abstraction would hide the work which we wanted to evaluate strictly.
@@ -198,7 +204,7 @@ expandArity (Used _ u) cheap_arity
     impl HeadUse cheap_arity -- the application expression we accumulated does non-trivial work, so
       -- Same reason as for the above @Absent@ case
       = cheap_arity
-    impl TopUse cheap_arity
+    impl UnknownUse cheap_arity
       -- No chance we can expand anything
       = cheap_arity
     impl (Call Many u) 0
@@ -258,7 +264,7 @@ instance Outputable Multiplicity where
 
 instance Outputable SingleUse where
   ppr HeadUse = text "HU"
-  ppr TopUse = text "U"
+  ppr UnknownUse = text "U"
   ppr (Call multi body) = text "C^" <> ppr multi <> parens (ppr body)
 
 instance Outputable Usage where
@@ -288,13 +294,13 @@ instance Binary Multiplicity where
 -- | Mostly important for serializing @UsageSig@ in interface files.
 instance Binary SingleUse where
   put_ bh HeadUse = putByte bh 0
-  put_ bh TopUse = putByte bh 1
+  put_ bh UnknownUse = putByte bh 1
   put_ bh (Call multi use) = putByte bh 2 >> put_ bh multi >> put_ bh use
   get  bh = do
     h <- getByte bh
     case h of
       0 -> return HeadUse
-      1 -> return TopUse
+      1 -> return UnknownUse
       _ -> Call <$> get bh <*> get bh
 
 -- | Mostly important for serializing @UsageSig@ in interface files.
diff --git a/testsuite/tests/callarity/unittest/CallArity1.hs b/testsuite/tests/callarity/unittest/CallArity1.hs
index 81dc1db940..bdb8754308 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.hs
+++ b/testsuite/tests/callarity/unittest/CallArity1.hs
@@ -59,7 +59,7 @@ exprs =
                         mkLams [z] $ Var d `mkVarApps` [x] )$
                     Var go2 `mkApps` [mkLit 1] ) $
         go `mkLApps` [0, 0]
-  , ("d0 (go _*C(C(U)) would be bad)",) $
+  , ("d0 (go _*C^1(C^1(U)) would be bad)",) $
      mkRFun go [x]
         (mkNrLet d (mkACase (Var go `mkVarApps` [x])
                           (mkLams [y] $ Var y)
diff --git a/testsuite/tests/callarity/unittest/CallArity1.stderr b/testsuite/tests/callarity/unittest/CallArity1.stderr
index daf9a5fe44..ca01b80bf1 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.stderr
+++ b/testsuite/tests/callarity/unittest/CallArity1.stderr
@@ -1,77 +1,77 @@
 go2:
-    go ω*C(C(U))
-    d 1*C(U)
+    go ω*C^ω(C^1(U))
+    d 1*C^1(U)
 nested_go2:
-    go ω*C(C(U))
-    go2 1*C(C(U))
-    d 1*C(U)
-    n 1*C(U)
-d0 (go _*C(C(U)) would be bad):
-    go ω*C(U)
-    d ω*C(U)
+    go ω*C^ω(C^1(U))
+    go2 1*C^1(C^1(U))
+    d 1*C^1(U)
+    n 1*C^1(U)
+d0 (go _*C^1(C^1(U)) would be bad):
+    go ω*U
+    d ω*U
 go2 (in case crut):
-    go ω*C(C(U))
-    d 1*C(U)
+    go ω*C^ω(C^1(U))
+    d 1*C^1(U)
 go2 (in function call):
-    go ω*C(C(U))
-    d 1*C(U)
+    go ω*C^ω(C^1(U))
+    d 1*C^1(U)
 go2 (using surrounding interesting let):
-    go ω*C(C(U))
-    d 1*C(U)
-    n 1*C(U)
+    go ω*C^ω(C^1(U))
+    d 1*C^1(U)
+    n 1*C^1(U)
 go2 (using surrounding boring let):
-    go ω*C(C(U))
-    d 1*C(U)
+    go ω*C^ω(C^1(U))
+    d 1*C^1(U)
     z ω*U
 two calls, one from let and from body (d 1*_ would be bad):
-    go 1*C(C(U))
-    d ω*C(U)
+    go 1*C^1(C^1(U))
+    d ω*C^1(U)
 a thunk in a recursion (d 1*_ would be bad):
     d ω*U
     n ω*U
 two thunks, one called multiple times (both 1*_ would be bad!):
-    d ω*C(U)
-    n 1*C(U)
+    d ω*U
+    n 1*C^1(U)
 two functions, not thunks:
-    go 1*C(C(U))
-    go2 1*C(C(U))
+    go 1*C^1(C^1(U))
+    go2 1*C^1(C^1(U))
 a thunk, called multiple times via a forking recursion (d 1*_ would be bad!):
-    go2 ω*C(C(U))
-    d ω*C(U)
+    go2 ω*C^ω(C^1(U))
+    d ω*U
 a function, one called multiple times via a forking recursion:
-    go ω*C(C(U))
-    go2 ω*C(C(U))
+    go ω*C^ω(C^1(U))
+    go2 ω*C^ω(C^1(U))
 two functions (recursive):
-    go ω*C(C(U))
-    go2 ω*C(C(U))
+    go ω*C^ω(C^1(U))
+    go2 ω*C^ω(C^1(U))
 mutual recursion (thunks), called mutiple times (both 1*_ would be bad!):
     d ω*U
     n ω*U
 mutual recursion (functions), but no thunks:
-    go ω*C(C(U))
-    go2 ω*C(C(U))
+    go ω*C^ω(C^1(U))
+    go2 ω*C^ω(C^1(U))
 mutual recursion (functions), one boring (d 1*_ would be bad):
-    go ω*C(C(U))
-    go2 ω*C(C(U))
-    d ω*C(U)
+    go ω*C^ω(C^1(U))
+    go2 ω*C^ω(C^1(U))
+    d ω*U
 a thunk (non-function-type), called twice, still calls once:
     x ω*U
-    d 1*C(U)
+    d 1*C^1(U)
 a thunk (function type), called multiple times, still calls once:
-    d 1*C(U)
-    n ω*C(U)
+    d 1*C^1(U)
+    n ω*U
 a thunk (non-function-type), in mutual recursion, still calls once (d ω*_ would be bad):
-    go ω*C(C(U))
+    go ω*C^ω(C^1(U))
     x ω*U
-    d 1*C(U)
+    d 1*C^1(U)
 a thunk (non-function-type), in mutual recursion, causes many calls (d 1*_ would be bad):
-    go ω*C(C(U))
+    go ω*C^ω(C^1(U))
     x ω*U
-    d ω*C(U)
+    d ω*U
 a thunk (function type), in mutual recursion, still calls once (d 1*_ would be good):
-    go ω*C(U)
-    d 1*C(U)
+    go ω*U
+    d 1*C^1(U)
     n ω*U
 a thunk (non-function-type) co-calls with the body (d 1*_ would be bad):
     x ω*U
-    d ω*C(U)
+    d ω*C^1(U)
-- 
2.12.1


From d4315533ef33827fa66da829fce0d3c5120e2d06 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sat, 8 Apr 2017 15:01:10 +0200
Subject: [PATCH 032/117] More precise usage sigs

---
 compiler/basicTypes/Usage.hs             | 6 +++++-
 compiler/simplCore/CallArity/Analysis.hs | 7 +++++--
 2 files changed, 10 insertions(+), 3 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 572e529406..facbbc3474 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -2,7 +2,7 @@ module Usage
   ( Multiplicity (..)
   , botMultiplicity, topMultiplicity, lubMultiplicity
   , SingleUse
-  , topSingleUse, lubSingleUse, bothSingleUse, abstractSingleUse, applySingleUse
+  , topSingleUse, lubSingleUse, bothSingleUse, abstractSingleUse, applySingleUse, singleCallUse
   , Usage (..)
   , multiplicity, botUsage, topUsage, lubUsage, bothUsage, manifyUsage, expandArity
   , UsageSig
@@ -165,6 +165,10 @@ applySingleUse HeadUse = Absent -- The lambda will be reduced to WHNF, but the b
 applySingleUse (Call multi use) = Used multi use
 applySingleUse _ = topUsage
 
+singleCallUse :: Arity -> SingleUse
+singleCallUse 0 = topSingleUse
+singleCallUse arity = mkCall Once (singleCallUse (arity - 1))
+
 trimSingleUse :: Arity -> SingleUse -> SingleUse
 trimSingleUse arity (Call m body)
   | arity > 0 = mkCall m (trimSingleUse (arity - 1) body)
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 169a396d42..a92b456dcf 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -490,6 +490,8 @@ callArityExpr nodes e@(Var id) = return transfer
         return ((unitUsageType id use) { ut_args = ut_args ut_callee }, e)
 
       | isGlobalId id
+      , use `lubSingleUse` singleCallUse (idArity id) == singleCallUse (idArity id)
+      -- TODO: Instead manify the UsageSig
       -- A global id from another module which has a usage signature.
       = return ((unitUsageType id use) { ut_args = idArgUsage id }, e)
 
@@ -694,9 +696,10 @@ unleashCall is_recursive ut_scope (id, rhs) transfer_rhs
     apply_when b f = if b then f else Prelude.id
     analyse use = do
       (ut_rhs, rhs') <- transfer_rhs use
+      (ut_sig, _) <- transfer_rhs (singleCallUse (idArity id)) -- no need to expand that Arity... This is used for exported globals only
       let id' = id
-            `setIdCallArity` usage_id -- How the *binder* was used
-            `setIdArgUsage` ut_args ut_rhs -- How the *RHS* uses its args
+            `setIdCallArity` usage_id -- How the binder was used
+            `setIdArgUsage` ut_args ut_sig -- How a single call uses its args
       return (ut_rhs, (id', rhs'))
 
 -- | See Note [What is a thunk].
-- 
2.12.1


From 73c897f766d068b18fa16c8e5daaeb938f6e4b8b Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sat, 8 Apr 2017 17:22:20 +0200
Subject: [PATCH 033/117] Some clean up

---
 compiler/simplCore/CallArity/Analysis.hs | 55 +++++++++++---------------------
 compiler/simplCore/CallArity/Types.hs    |  6 ++--
 2 files changed, 21 insertions(+), 40 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index a92b456dcf..7c247588c2 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -472,6 +472,7 @@ callArityExpr nodes (Tick t e) = callArityExprMap nodes (Tick t) e
 callArityExpr nodes (Cast e c) = callArityExprMap nodes (flip Cast c) e
 
 -- The interesting cases: Variables, Lambdas, Lets, Applications, Cases
+
 callArityExpr nodes e@(Var id) = return transfer
   where
     transfer use
@@ -479,10 +480,12 @@ callArityExpr nodes e@(Var id) = return transfer
       -- We don't track uninteresting vars and implicitly assume they are called
       -- multiple times with every other variable.
       -- See Note [Taking boring variables into account]
+      -- TODO: Do we really need this? Those uninteresting vars aren't that
+      -- uninteresting after all...
       = return (emptyUsageType, e)
 
       | Just node <- lookupVarEnv nodes id
-      -- A local let-binding.
+      -- A local let-binding, e.g. a binding from this module.
       = do
         (ut_callee, _) <- dependOnWithDefault (unusedArgsUsageType use, e) (node, use)
         -- It is crucial that we only use ut_args here, as every other field
@@ -490,13 +493,16 @@ callArityExpr nodes e@(Var id) = return transfer
         return ((unitUsageType id use) { ut_args = ut_args ut_callee }, e)
 
       | isGlobalId id
-      , use `lubSingleUse` singleCallUse (idArity id) == singleCallUse (idArity id)
-      -- TODO: Instead manify the UsageSig
       -- A global id from another module which has a usage signature.
-      = return ((unitUsageType id use) { ut_args = idArgUsage id }, e)
+      -- We don't need to track the id itself, though.
+      = return (emptyUsageType { ut_args = sig }, e)
+          where
+            call = singleCallUse (idArity id)
+            sig | use `lubSingleUse` call == call = idArgUsage id
+                | otherwise = topUsageSig
 
       | otherwise
-      -- interesting LocalId, not present in @nodes@, e.g. a lambda-bound variable.
+      -- An interesting LocalId, not present in @nodes@, e.g. a lambda-bound variable.
       -- We are only second-order, so we don't model signatures for parameters!
       -- Their usage is interesting to note nonetheless for annotating lambda
       -- binders.
@@ -504,7 +510,8 @@ callArityExpr nodes e@(Var id) = return transfer
 
 callArityExpr nodes (Lam id body)
   | isTyVar id
-  = callArityExprMap nodes (Lam id) body -- Non-value lambdas are ignored
+  -- Non-value lambdas are ignored
+  = callArityExprMap nodes (Lam id) body
   | otherwise
   = do
     transfer_body <- callArityExpr nodes body
@@ -515,7 +522,10 @@ callArityExpr nodes (Lam id body)
           (ut_body, body') <- transfer_body body_use
           let id' | Once <- multi = id `setIdOneShotInfo` OneShotLam
                   | otherwise = id
-          let ut = multiplyFreeVarUsages multi ut_body
+          -- TODO: This *should* be OK: free vars are manified,
+          --       closed vars are not. Argument usages are manified,
+          --       which should be conservative enough.
+          let ut = multiplyUsages multi ut_body
           return (makeIdArg id' ut, Lam id' body')
 
 callArityExpr nodes (App f (Type t)) = callArityExprMap nodes (flip App (Type t)) f
@@ -554,7 +564,7 @@ callArityExpr nodes (Case scrut bndr ty alts) = do
   transfer_alts <- forM alts $ \(dc, bndrs, e) ->
     callArityExprMap nodes (dc, bndrs,) e
   return $ \use -> do
-    (ut_scrut, scrut') <- transfer_scrut topSingleUse
+    (ut_scrut, scrut') <- transfer_scrut topSingleUse -- TODO: Product component usage
     (ut_alts, alts') <- unzip <$> mapM ($ use) transfer_alts
     let ut = trimArgs use (lubTypes ut_alts) `both` ut_scrut
     -- TODO: Think harder about the diverging case (e.g. matching on `undefined`).
@@ -702,35 +712,6 @@ unleashCall is_recursive ut_scope (id, rhs) transfer_rhs
             `setIdArgUsage` ut_args ut_sig -- How a single call uses its args
       return (ut_rhs, (id', rhs'))
 
--- | See Note [What is a thunk].
--- This should always be in sync with @SimplUtils.tryEtaExpandRhs@.
--- TODO: Factor out @exprIsCheap@ into the environment, like in CoreArity.
-isThunk :: CoreExpr -> Bool
-isThunk = not . exprIsCheap
-
-{-| If a (future, in the case of arguments) let-bound expression is a thunk, we
-    need to make sure that we don't accidentally duplicate work by eta-expansion.
-    Which we do if we expand a thunk which we use multiple times.
-
-    So: If we use a thunk @Many 2@, we must be sure that we are OK with
-    losing shared work by eta-expansion (@exprIsCheap@). Otherwise we have to
-    fall back to @One 0@.
-
-    This function should be used anywhere expressions are to be let-bound.
--}
-oneifyUsageIfThunk :: CoreExpr -> Usage -> Usage
-oneifyUsageIfThunk e (Used Many use)
-  -- A thunk was called multiple times! Do not eta-expand
-  | isThunk e = Used Once topSingleUse
-  -- In case e is cheap and we use the let-bound var of e with @Used Many 0@, this
-  -- allows us to at least analyze the cheap RHS with multiplicity @Once@ before we
-  -- potentially hit a lambda binder, where we proceed normally with @Used Many 0@.
-  -- I'm not sure if this actually buys us anything, @e@ is cheap after all.
-  -- But it may still be non-@exprIsTrivial@, so just leaving it here for the
-  -- time being.
-  | use == topSingleUse = Used Once topSingleUse
-oneifyUsageIfThunk _ u = u
-
 -- Combining the results from body and rhs of a let binding
 -- See Note [Analysis II: The Co-Called analysis]
 callArityLetEnv
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index b1dea7a563..e776e3d16e 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -89,9 +89,9 @@ calledWith ut id
   = domType ut
 
 -- Replaces the co-call graph by a complete graph (i.e. no information)
-multiplyFreeVarUsages :: Multiplicity -> UsageType -> UsageType
-multiplyFreeVarUsages Once ut = ut
-multiplyFreeVarUsages Many ut@(UT _ u args)
+multiplyUsages :: Multiplicity -> UsageType -> UsageType
+multiplyUsages Once ut = ut
+multiplyUsages Many ut@(UT _ u args)
   = UT
   { ut_cocalled = completeGraph (domType ut)
   , ut_uses = mapVarEnv (\use -> bothSingleUse use use) u
-- 
2.12.1


From 66d454992f2f7a8a8f3ab7b6dd4d83727111e429 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 11 Apr 2017 18:11:16 +0200
Subject: [PATCH 034/117] Quick fix for a syntax error. Already includes new
 Product Usages

---
 compiler/basicTypes/Usage.hs             | 45 ++++++++++++++++++++++++--------
 compiler/simplCore/CallArity/Analysis.hs | 14 ++++++----
 2 files changed, 43 insertions(+), 16 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index facbbc3474..3b67a6ab8f 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -2,7 +2,7 @@ module Usage
   ( Multiplicity (..)
   , botMultiplicity, topMultiplicity, lubMultiplicity
   , SingleUse
-  , topSingleUse, lubSingleUse, bothSingleUse, abstractSingleUse, applySingleUse, singleCallUse
+  , topSingleUse, lubSingleUse, bothSingleUse, abstractSingleUse, applySingleUse, singleCallUse, mkProductSingleUse
   , Usage (..)
   , multiplicity, botUsage, topUsage, lubUsage, bothUsage, manifyUsage, expandArity
   , UsageSig
@@ -43,6 +43,9 @@ data SingleUse
   --
   -- Use @abstractSingleUse@ to introduce this constructor and
   -- @abstractSingleUse@ to eliminate @Call@s.
+  | Product ![Usage]
+  -- ^ A @SingleUse@ which, after evaluating a product constructor, will use the
+  -- product's components according to the @Usage@s given.
   | UnknownUse
   -- ^ A @SingleUse@ where, after hitting WHNF of the expression,
   -- we don't know any further details of how
@@ -52,10 +55,17 @@ data SingleUse
   deriving (Eq, Ord, Show)
 
 -- | A smart constructor for @Call@ which normalizes according to the equivalence
--- @Many UnknownUse = UnknownUse@.
-mkCall :: Multiplicity -> SingleUse -> SingleUse
-mkCall Many UnknownUse = UnknownUse
-mkCall m u = Call m u
+-- @Call Many UnknownUse = UnknownUse@.
+mkCallSingleUse :: Multiplicity -> SingleUse -> SingleUse
+mkCallSingleUse Many UnknownUse = UnknownUse
+mkCallSingleUse m u = Call m u
+
+-- | A smart constructor for @Product@ which normalizes according to the equivalence
+-- @Product [topUsage, topUsage..] = UnknownUse@.
+mkProductSingleUse :: [Usage] -> SingleUse
+mkProductSingleUse components
+  | all (== topUsage) components = UnknownUse
+  | otherwise = Product components
 
 -- | @Id@entifiers can be used multiple times and are the only means to
 -- introduce sharing of work, evaluating expressions into WHNF, that is.
@@ -109,7 +119,11 @@ lubSingleUse UnknownUse _ = UnknownUse
 lubSingleUse _ UnknownUse = UnknownUse
 lubSingleUse HeadUse u = u
 lubSingleUse u HeadUse = u
-lubSingleUse (Call m1 u1) (Call m2 u2) = mkCall (lubMultiplicity m1 m2) (lubSingleUse u1 u2)
+lubSingleUse (Product c1) (Product c2)
+  = mkProductSingleUse (zipWith lubUsage c1 c2)
+lubSingleUse (Call m1 u1) (Call m2 u2)
+  = mkCallSingleUse (lubMultiplicity m1 m2) (lubSingleUse u1 u2)
+lubSingleUse _ _ = UnknownUse
 
 -- | Think 'plus' on @SingleUse@s, for sequential composition.
 bothSingleUse :: SingleUse -> SingleUse -> SingleUse
@@ -117,7 +131,10 @@ bothSingleUse UnknownUse _ = UnknownUse
 bothSingleUse _ UnknownUse = UnknownUse
 bothSingleUse HeadUse u = u
 bothSingleUse u HeadUse = u
-bothSingleUse (Call _ u1) (Call _ u2) = mkCall Many (lubSingleUse u1 u2)
+bothSingleUse (Product c1) (Product c2)
+  = mkProductSingleUse (zipWith bothUsage c1 c2)
+bothSingleUse (Call _ u1) (Call _ u2)
+  = mkCallSingleUse Many (lubSingleUse u1 u2)
 
 botUsage :: Usage
 botUsage = Absent
@@ -155,7 +172,7 @@ lubUsageSig (ArgUsage u1 s1) (ArgUsage u2 s2) = ArgUsage (lubUsage u1 u2) (lubUs
 -- | Abstracts the given @SingleUse@ as a singular body @Usage@ behind a
 -- lambda binder. This is useful in the @App@lication rule.
 abstractSingleUse :: SingleUse -> SingleUse
-abstractSingleUse use = mkCall Once use
+abstractSingleUse use = mkCallSingleUse Once use
 
 -- | Dual to @abstractSingleUse@, this will return the @Usage@ of the lambda body,
 -- relative to the given single @Use@ of the outer expression. Useful in the
@@ -167,11 +184,11 @@ applySingleUse _ = topUsage
 
 singleCallUse :: Arity -> SingleUse
 singleCallUse 0 = topSingleUse
-singleCallUse arity = mkCall Once (singleCallUse (arity - 1))
+singleCallUse arity = mkCallSingleUse Once (singleCallUse (arity - 1))
 
 trimSingleUse :: Arity -> SingleUse -> SingleUse
 trimSingleUse arity (Call m body)
-  | arity > 0 = mkCall m (trimSingleUse (arity - 1) body)
+  | arity > 0 = mkCallSingleUse m (trimSingleUse (arity - 1) body)
 trimSingleUse _ _ = topSingleUse
 
 trimUsage :: Arity -> Usage -> Usage
@@ -211,6 +228,9 @@ expandArity (Used _ u) cheap_arity
     impl UnknownUse cheap_arity
       -- No chance we can expand anything
       = cheap_arity
+    impl (Product _) cheap_arity
+      -- This doesn't really make sense anyway.
+      = cheap_arity
     impl (Call Many u) 0
       -- the application expression we accumulated does non-trivial work,
       -- which we aren't allowed to push into a non-one-shot lambda. So
@@ -269,6 +289,7 @@ instance Outputable Multiplicity where
 instance Outputable SingleUse where
   ppr HeadUse = text "HU"
   ppr UnknownUse = text "U"
+  ppr (Product components) = text "U" <> parens (hcat (punctuate (char ',') (map ppr components)))
   ppr (Call multi body) = text "C^" <> ppr multi <> parens (ppr body)
 
 instance Outputable Usage where
@@ -299,12 +320,14 @@ instance Binary Multiplicity where
 instance Binary SingleUse where
   put_ bh HeadUse = putByte bh 0
   put_ bh UnknownUse = putByte bh 1
-  put_ bh (Call multi use) = putByte bh 2 >> put_ bh multi >> put_ bh use
+  put_ bh (Product components) = putByte bh 2 >> put_ bh components
+  put_ bh (Call multi use) = putByte bh 3 >> put_ bh multi >> put_ bh use
   get  bh = do
     h <- getByte bh
     case h of
       0 -> return HeadUse
       1 -> return UnknownUse
+      2 -> Product <$> get bh
       _ -> Call <$> get bh <*> get bh
 
 -- | Mostly important for serializing @UsageSig@ in interface files.
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 7c247588c2..e23d652f08 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -495,11 +495,7 @@ callArityExpr nodes e@(Var id) = return transfer
       | isGlobalId id
       -- A global id from another module which has a usage signature.
       -- We don't need to track the id itself, though.
-      = return (emptyUsageType { ut_args = sig }, e)
-          where
-            call = singleCallUse (idArity id)
-            sig | use `lubSingleUse` call == call = idArgUsage id
-                | otherwise = topUsageSig
+      = return (unleashUsageSig id use, e)
 
       | otherwise
       -- An interesting LocalId, not present in @nodes@, e.g. a lambda-bound variable.
@@ -623,6 +619,14 @@ callArityExpr letdown_nodes (Let bind e) = do
         --pprTrace "Let" (ppr (ut, let')) $ return ()
         return (typeDelList (bindersOf bind) ut, let')
 
+unleashUsageSig :: Id -> SingleUse -> UsageType
+unleashUsageSig id use
+  = emptyUsageType { ut_args = sig }
+  where
+    call = singleCallUse (idArity id)
+    sig | (use `lubSingleUse` call) == call = idArgUsage id
+        | otherwise = topUsageSig
+
 callArityBind
   :: VarEnv FrameworkNode
   -> [(Id, CoreExpr)]
-- 
2.12.1


From 9356eaaf3d77b169c7913b1d4b64eb3f12e0d56e Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 13 Apr 2017 17:20:49 +0200
Subject: [PATCH 035/117] Fixed 1*U for exported identifiers

---
 compiler/simplCore/CallArity/Analysis.hs | 10 +++++++---
 1 file changed, 7 insertions(+), 3 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index e23d652f08..eb58683076 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -418,12 +418,16 @@ Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
 -- Represents the fact that a CoreProgram is like a sequence of
 -- nested lets, where the exports are returned in the inner-most let
 -- as a tuple. As a result, all exported identifiers are handled as called
--- with each other, with arity 0.
+-- with each other, with @topUsage@.
 moduleToExpr :: CoreProgram -> CoreExpr
 moduleToExpr = impl []
   where
-    impl exported [] = mkBigCoreTup (map Var exported)
-    impl exported (bind:prog) = Let bind (impl (filter isExportedId (bindersOf bind) ++ exported) prog)
+    impl exported []
+      -- @duplicate@, otherwise those Vars appear to be used once
+      = mkBigCoreTup (map Var (duplicate exported))
+    impl exported (bind:prog)
+      = Let bind (impl (filter isExportedId (bindersOf bind) ++ exported) prog)
+    duplicate = concatMap (replicate 2)
 
 -- | The left inverse to @moduleToExpr@: @exprToModule . moduleToExpr = id \@CoreProgram@
 exprToModule :: CoreExpr -> CoreProgram
-- 
2.12.1


From 946d6b5aa48ec435ec219528fc305903db33122c Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Wed, 19 Apr 2017 21:14:42 +0200
Subject: [PATCH 036/117] Implemented product uses

---
 compiler/basicTypes/Usage.hs             | 198 ++++++++++------
 compiler/simplCore/CallArity/Analysis.hs | 393 ++++++++++++++++++++-----------
 compiler/simplCore/CallArity/Types.hs    |  41 ++--
 compiler/simplCore/SimplCore.hs          |   2 +-
 compiler/simplCore/SimplUtils.hs         |  39 ++-
 compiler/stranal/DmdAnal.hs              |   2 +-
 nofib                                    |   2 +-
 7 files changed, 434 insertions(+), 243 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 3b67a6ab8f..5a7c124eb6 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -1,8 +1,10 @@
+{-# LANGUAGE CPP #-}
+
 module Usage
   ( Multiplicity (..)
   , botMultiplicity, topMultiplicity, lubMultiplicity
   , SingleUse
-  , topSingleUse, lubSingleUse, bothSingleUse, abstractSingleUse, applySingleUse, singleCallUse, mkProductSingleUse
+  , botSingleUse, topSingleUse, lubSingleUse, leqSingleUse, bothSingleUse, mkCallUse, peelCallUse, mkProductUse, peelProductUse, boundDepth
   , Usage (..)
   , multiplicity, botUsage, topUsage, lubUsage, bothUsage, manifyUsage, expandArity
   , UsageSig
@@ -10,9 +12,15 @@ module Usage
   , trimSingleUse, trimUsage, trimUsageSig
   ) where
 
+#include "HsVersions.h"
+
 import BasicTypes
 import Binary
+import Demand ( TypeShape(..) )
 import Outputable
+import Util
+
+import Control.Arrow ( second )
 
 -- * Types
 
@@ -21,7 +29,7 @@ data Multiplicity
   | Many
   deriving (Eq, Ord, Show)
 
--- | A @SingleUse@ describes how an expression is used, after it hit WHNF.
+-- | A `SingleUse` describes how an expression is used, after it hit WHNF.
 -- Some examples:
 --
 --    * A single use of @seq a b@ unleashes nothing beyond the WHNF use on @a@,
@@ -29,50 +37,55 @@ data Multiplicity
 --    * A single use of @f x@ unleashes, beyond evaluation to WHNF, a call use
 --      on @f@, where the result of the call (e.g. the lambda body) is used once.
 --
--- The @Ord@ instance is incompatible with the lattice and only used when
+-- The `Ord` instance is incompatible with the lattice and only used when
 -- acting as a key type in a map.
 data SingleUse
   = HeadUse
-  -- ^ A @SingleUse@ which just evaluates the expression to WHNF. No resulting
+  -- ^ A `SingleUse` which just evaluates the expression to WHNF. No resulting
   -- lambdas are called and usage of all product components is absent.
   | Call !Multiplicity !SingleUse
-  -- ^ @Call m u@ denotes a @SingleUse@ where, after hitting WHNF, the lambda
+  -- ^ @Call m u@ denotes a `SingleUse` where, after hitting WHNF, the lambda
   -- body is used according to @u@ with multiplicity @m@. @Call Many u@ would
   -- mean the expression was called potentially many times, after being brought
   -- to WHNF.
   --
-  -- Use @abstractSingleUse@ to introduce this constructor and
-  -- @abstractSingleUse@ to eliminate @Call@s.
+  -- Use `mkCallUse` to introduce this constructor and `peelCallUse` to
+  -- eliminate `Call`s.
   | Product ![Usage]
-  -- ^ A @SingleUse@ which, after evaluating a product constructor, will use the
-  -- product's components according to the @Usage@s given.
+  -- ^ A `SingleUse` which, after evaluating a product constructor, will use the
+  -- product's components according to the `Usage`s given.
+  --
+  -- Use `mkProductUse` to introduce this constructor and `peelProductUse` to
+  -- eliminate `Product`s.
   | UnknownUse
-  -- ^ A @SingleUse@ where, after hitting WHNF of the expression,
+  -- ^ A `SingleUse` where, after hitting WHNF of the expression,
   -- we don't know any further details of how
   --
   --     * a resulting nested lambda body is used
   --     * resulting product components are used
   deriving (Eq, Ord, Show)
 
--- | A smart constructor for @Call@ which normalizes according to the equivalence
+-- | A smart constructor for `Call` which normalizes according to the equivalence
 -- @Call Many UnknownUse = UnknownUse@.
-mkCallSingleUse :: Multiplicity -> SingleUse -> SingleUse
-mkCallSingleUse Many UnknownUse = UnknownUse
-mkCallSingleUse m u = Call m u
-
--- | A smart constructor for @Product@ which normalizes according to the equivalence
--- @Product [topUsage, topUsage..] = UnknownUse@.
-mkProductSingleUse :: [Usage] -> SingleUse
-mkProductSingleUse components
-  | all (== topUsage) components = UnknownUse
+mkCallUse :: Multiplicity -> SingleUse -> SingleUse
+mkCallUse Many UnknownUse = UnknownUse
+mkCallUse m u = Call m u
+
+-- | A smart constructor for `Product` which normalizes according to the equivalences
+-- @Product [topUsage, topUsage..] === topSingleUse@ and
+-- @Product [botUsage, botUsage..] === botSingleUse@.
+mkProductUse :: [Usage] -> SingleUse
+mkProductUse components
+  | all (== topUsage) components = topSingleUse
+  | all (== botUsage) components = botSingleUse
   | otherwise = Product components
 
--- | @Id@entifiers can be used multiple times and are the only means to
+-- | `CoreSym.Id`entifiers can be used multiple times and are the only means to
 -- introduce sharing of work, evaluating expressions into WHNF, that is.
--- @Usage@ can track how often an identifier was used and how each of the
--- @SingleUse@s looked like.
+-- `Usage` can track how often an identifier was used and how each of the
+-- `SingleUse`s looked like.
 --
--- The @Ord@ instance is incompatible with the lattice and only used when
+-- The `Ord` instance is incompatible with the lattice and only used when
 -- acting as a key type in a map.
 data Usage
   = Absent
@@ -83,10 +96,6 @@ multiplicity :: Usage -> Maybe Multiplicity
 multiplicity (Used m _) = Just m
 multiplicity _ = Nothing
 
-singleUse :: Usage -> Maybe SingleUse
-singleUse (Used _ u) = Just u
-singleUse _ = Nothing
-
 -- | The constructors should not be exported. Use @consUsageSig@ and
 -- @unconsUsageSig@ instead, or else the derived @Eq@ instance is invalid.
 data UsageSig
@@ -120,21 +129,29 @@ lubSingleUse _ UnknownUse = UnknownUse
 lubSingleUse HeadUse u = u
 lubSingleUse u HeadUse = u
 lubSingleUse (Product c1) (Product c2)
-  = mkProductSingleUse (zipWith lubUsage c1 c2)
+  | equalLength c1 c2
+  -- If this is not true, we probably have uses from different case branches.
+  -- In that case, returning topSingleUse is the right thing to do.
+  = mkProductUse (zipWith lubUsage c1 c2)
 lubSingleUse (Call m1 u1) (Call m2 u2)
-  = mkCallSingleUse (lubMultiplicity m1 m2) (lubSingleUse u1 u2)
-lubSingleUse _ _ = UnknownUse
+  = mkCallUse (lubMultiplicity m1 m2) (lubSingleUse u1 u2)
+lubSingleUse _ _ = topSingleUse
+
+leqSingleUse :: SingleUse -> SingleUse -> Bool
+leqSingleUse a b = lubSingleUse a b == b
 
--- | Think 'plus' on @SingleUse@s, for sequential composition.
+-- | Think \'plus\' on `SingleUse`s, for sequential composition.
 bothSingleUse :: SingleUse -> SingleUse -> SingleUse
 bothSingleUse UnknownUse _ = UnknownUse
 bothSingleUse _ UnknownUse = UnknownUse
 bothSingleUse HeadUse u = u
 bothSingleUse u HeadUse = u
 bothSingleUse (Product c1) (Product c2)
-  = mkProductSingleUse (zipWith bothUsage c1 c2)
+  | equalLength c1 c2
+  = mkProductUse (zipWith bothUsage c1 c2)
 bothSingleUse (Call _ u1) (Call _ u2)
-  = mkCallSingleUse Many (lubSingleUse u1 u2)
+  = mkCallUse Many (lubSingleUse u1 u2)
+bothSingleUse _ _ = topSingleUse
 
 botUsage :: Usage
 botUsage = Absent
@@ -147,8 +164,8 @@ lubUsage Absent u = u
 lubUsage u Absent = u
 lubUsage (Used m1 u1) (Used m2 u2) = Used (lubMultiplicity m1 m2) (lubSingleUse u1 u2)
 
--- | Think 'plus' on @Usage@s, for sequential composition.
--- E.g. if @Usage@s from scrutinee and case branches should be combined.
+-- | Think \'plus\' on `Usage`s, for sequential composition.
+-- E.g. if `Usage`s from scrutinee and case branches should be combined.
 bothUsage :: Usage -> Usage -> Usage
 bothUsage Absent u = u
 bothUsage u Absent = u
@@ -167,38 +184,75 @@ lubUsageSig TopUsageSig _ = TopUsageSig
 lubUsageSig _ TopUsageSig = TopUsageSig
 lubUsageSig (ArgUsage u1 s1) (ArgUsage u2 s2) = ArgUsage (lubUsage u1 u2) (lubUsageSig s1 s2)
 
--- * Working with @Use@, @Usage@ and @UsageSig@
-
--- | Abstracts the given @SingleUse@ as a singular body @Usage@ behind a
--- lambda binder. This is useful in the @App@lication rule.
-abstractSingleUse :: SingleUse -> SingleUse
-abstractSingleUse use = mkCallSingleUse Once use
-
--- | Dual to @abstractSingleUse@, this will return the @Usage@ of the lambda body,
--- relative to the given single @Use@ of the outer expression. Useful in the
--- @Lam@bda rule.
-applySingleUse :: SingleUse -> Usage
-applySingleUse HeadUse = Absent -- The lambda will be reduced to WHNF, but the body will stay untouched.
-applySingleUse (Call multi use) = Used multi use
-applySingleUse _ = topUsage
-
-singleCallUse :: Arity -> SingleUse
-singleCallUse 0 = topSingleUse
-singleCallUse arity = mkCallSingleUse Once (singleCallUse (arity - 1))
-
-trimSingleUse :: Arity -> SingleUse -> SingleUse
-trimSingleUse arity (Call m body)
-  | arity > 0 = mkCallSingleUse m (trimSingleUse (arity - 1) body)
+-- * Working with `SingleUse`, `Usage` and `UsageSig`
+
+-- | Eliminates a `Call`. This will return the `Usage` of the lambda body,
+-- relative to the given `SingleUse` of the outer expression. Useful in the
+-- `CoreSyn.Lam`bda rule.
+peelCallUse :: SingleUse -> Maybe Usage
+peelCallUse HeadUse = Just Absent -- The lambda will be reduced to WHNF, but the body will stay untouched.
+peelCallUse (Call multi use) = Just (Used multi use)
+peelCallUse UnknownUse = Just topUsage
+peelCallUse _ = Nothing
+
+peelProductUse :: Arity -> SingleUse -> Maybe [Usage]
+peelProductUse n HeadUse = Just (replicate n botUsage)
+peelProductUse n UnknownUse = Just (replicate n topUsage)
+peelProductUse n (Product comps)
+  = ASSERT2( comps `lengthIs` n, text "peelProductUse" $$ ppr n $$ ppr comps)
+    Just comps
+peelProductUse _ (Call _ _) = Nothing -- might happen with unsafeCoerce (#9208)
+
+-- | Since the lattice modeled by `SingleUse` has infinite height, we run might
+-- run into trouble regarding convergence. This happens in practice for product
+-- usages on lazy infinite stream functions such as `filter`, where the recursion
+-- propagates strictly increasing product use chains for the argument.
+-- That would never converge, so at some point we have to artificially bound
+-- the height of the lattice.
+--
+-- Although there also may be infinitely many nested Calls, we don't need to
+-- worry about them, since there should be no program for which the analysis
+-- constructs an infinite chain of Calls.
+boundDepth :: Int -> SingleUse -> SingleUse
+boundDepth max_height use = snd (boundUse 0 use)
+  where
+    wrap impl height u -- simple caching wrapper around the actual impl
+      | ret@(True, _) <- impl height u
+      = ret
+      | otherwise
+      = (False, u)
+    boundUsage = wrap impl
+      where
+        impl height (Used m u) = second (Used m) (boundUse height u)
+        impl _ u = (False, u)
+    boundUse = wrap impl
+      where
+        impl height (Product comps)
+          | height < max_height
+          , (changed, comps') <- mapAndUnzip (boundUsage (height + 1)) comps
+          = (or changed, Product comps')
+          | otherwise
+          = (True, topSingleUse)
+        impl height (Call m u) = second (Call m) (boundUse height u)
+        impl _ u = (False, u)
+
+trimSingleUse :: TypeShape -> SingleUse -> SingleUse
+trimSingleUse _ HeadUse = HeadUse
+trimSingleUse (TsFun shape) (Call m body)
+  = mkCallUse m (trimSingleUse shape body)
+trimSingleUse (TsProd shapes) (Product comps)
+  | equalLength shapes comps
+  = mkProductUse (zipWith trimUsage shapes comps)
 trimSingleUse _ _ = topSingleUse
 
-trimUsage :: Arity -> Usage -> Usage
-trimUsage arity (Used m use) = Used m (trimSingleUse arity use)
-trimUsage arity usg = usg
+trimUsage :: TypeShape -> Usage -> Usage
+trimUsage shape (Used m use) = Used m (trimSingleUse shape use)
+trimUsage _ usg = usg
 
 -- | @manifyUsage u = bothUsage u u@. For when an id is used more than once
--- with the same @Usage@. This is different than just changing the top-level
--- @Multiplicity@ to @Many@, which would correspond to an additional @seq@
--- @Usage@ of the top-level expression (e.g. without applying any args).
+-- with the same `Usage`. This is different than just changing the top-level
+-- `Multiplicity` to `Many`, which would correspond to an additional `seq`
+-- `Usage` of the top-level expression (e.g. without applying any args).
 manifyUsage :: Usage -> Usage
 manifyUsage u = bothUsage u u
 
@@ -213,7 +267,7 @@ expandArity Absent cheap_arity
 expandArity (Used Many _) 0
   -- This is a special case, accounting for the fact that let-bindings
   -- are evaluated at most once. Consider @f `seq` ... f x ... @: @seq@ makes
-  -- it possible to end up with an @Usage@ of @Used Many (Call Once UnknownUse)@,
+  -- it possible to end up with an `Usage` of @Used Many (Call Once UnknownUse)@,
   -- where the outer @Multiplicity@ and the top-level one-shot @Multiplicity@
   -- are out of sync. Eta-expansion would be counter-intuitive, as the lifted
   -- abstraction would hide the work which we wanted to evaluate strictly.
@@ -231,7 +285,7 @@ expandArity (Used _ u) cheap_arity
     impl (Product _) cheap_arity
       -- This doesn't really make sense anyway.
       = cheap_arity
-    impl (Call Many u) 0
+    impl (Call Many _) 0
       -- the application expression we accumulated does non-trivial work,
       -- which we aren't allowed to push into a non-one-shot lambda. So
       -- we don't expand any further.
@@ -267,9 +321,9 @@ manifyUsageSig TopUsageSig = TopUsageSig
 manifyUsageSig BotUsageSig = BotUsageSig
 manifyUsageSig (ArgUsage u s) = consUsageSig (manifyUsage u) (manifyUsageSig s)
 
--- | Trims a @UsageSig@ by looking at how the associated value is used.
+-- | Trims a `UsageSig` by looking at how the associated value is used.
 --
--- The resulting @UsageSig@ will only have as many arguments as the @SingleUse@ has
+-- The resulting `UsageSig` will only have as many arguments as the `SingleUse` has
 -- call nestings.
 trimUsageSig :: SingleUse -> UsageSig -> UsageSig
 trimUsageSig _ BotUsageSig = BotUsageSig
@@ -306,7 +360,7 @@ instance Outputable UsageSig where
 
 -- * Serialization
 
--- | Mostly important for serializing @UsageSig@ in interface files.
+-- | Mostly important for serializing `UsageSig` in interface files.
 instance Binary Multiplicity where
   put_ bh Once = putByte bh 0
   put_ bh Many = putByte bh 1
@@ -316,7 +370,7 @@ instance Binary Multiplicity where
       0 -> return Once
       _ -> return Many
 
--- | Mostly important for serializing @UsageSig@ in interface files.
+-- | Mostly important for serializing `UsageSig` in interface files.
 instance Binary SingleUse where
   put_ bh HeadUse = putByte bh 0
   put_ bh UnknownUse = putByte bh 1
@@ -330,7 +384,7 @@ instance Binary SingleUse where
       2 -> Product <$> get bh
       _ -> Call <$> get bh <*> get bh
 
--- | Mostly important for serializing @UsageSig@ in interface files.
+-- | Mostly important for serializing `UsageSig` in interface files.
 instance Binary Usage where
   put_ bh Absent = putByte bh 0
   put_ bh (Used multi use) = putByte bh 1 >> put_ bh multi >> put_ bh use
@@ -340,7 +394,7 @@ instance Binary Usage where
       0 -> return Absent
       _ -> Used <$> get bh <*> get bh
 
--- | Mostly important for serializing @UsageSig@ in interface files.
+-- | Mostly important for serializing `UsageSig` in interface files.
 instance Binary UsageSig where
   put_ bh BotUsageSig = putByte bh 0
   put_ bh TopUsageSig = putByte bh 1
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index eb58683076..6508409602 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -8,24 +8,24 @@ module CallArity.Analysis where
 import CallArity.Types
 import CallArity.FrameworkBuilder
 
-import DynFlags      ( DynFlags )
-import Maybes
-import VarEnv
-
-import Control.Monad ( forM )
-import qualified Data.Set as Set
-
 import BasicTypes
 import CoreSyn
-import CoreArity ( typeArity )
-import CoreUtils ( exprIsCheap )
-import Demand ( isBotRes, splitStrictSig )
-import MkCore
+import DataCon ( dataConTyCon )
+import DynFlags      ( DynFlags )
+import FamInstEnv
 import Id
+import Maybes ( expectJust, fromMaybe, isJust )
+import MkCore
+import TyCon ( isDataProductTyCon_maybe )
 import UniqFM
 import UnVarGraph
 import Usage
-import Var ( isTyVar )
+import Var ( isId, isTyVar )
+import VarEnv
+import WwLib ( findTypeShape )
+
+import Control.Monad ( forM )
+import qualified Data.Set as Set
 
 
 {-
@@ -89,7 +89,7 @@ obtain bits of information:
      and if called, which what arity.
 
  II. The Co-Called analysis:
-     For every two variables, whether there is a possibility that both are being
+     For every two variables, whether there is a possibility that bothUsageType are being
      called.
      We obtain as a special case: For every variables, whether there is a
      possibility that it is being called twice.
@@ -155,7 +155,7 @@ The interesting cases of the analysis:
    Only one can be execuded, so
    Return (alt₁ ∪ alt₂ ∪...)
  * App e₁ e₂ (and analogously Case scrut alts), with non-trivial e₂:
-   We get the results from both sides, with the argument evaluated at most once.
+   We get the results from bothUsageType sides, with the argument evaluated at most once.
    Additionally, anything called by e₁ can possibly be called with anything
    from e₂.
    Return: C(e₁) ∪ C(e₂) ∪ (fv e₁) × (fv e₂)
@@ -245,7 +245,7 @@ vs.
                     in go 1
             False -> n
 
-In both cases, the body and the rhs of the inner let call n at most once.
+In bothUsageType cases, the body and the rhs of the inner let call n at most once.
 But only in the second case that holds for the whole expression! The
 crucial difference is that in the first case, the rhs of `go` can call
 *both* `go` and `n`, and hence can call `n` multiple times as it recurses,
@@ -302,7 +302,7 @@ and the following specification:
     * Every call from `expr` to a variable bound to n in `callArityEnv` has at
       least n value arguments.
     * For two interesting variables `v1` and `v2`, they are not adjacent in `coCalls`,
-      then in no execution of `expr` both are being called.
+      then in no execution of `expr` bothUsageType are being called.
   Furthermore, expr' is expr with the callArity field of the `IdInfo` updated.
 
 
@@ -320,7 +320,7 @@ Note [Taking boring variables into account]
 
 If we decide that the variable bound in `let x = e1 in e2` is not interesting,
 the analysis of `e2` will not report anything about `x`. To ensure that
-`callArityBind` does still do the right thing we have to take that into account
+`registerBindingGroup` does still do the right thing we have to take that into account
 everytime we look up up `x` in the analysis result of `e2`.
   * Instead of calling lookupUsage, we return (0, True), indicating
     that this variable might be called many times with no arguments.
@@ -378,28 +378,6 @@ to them. The plan is as follows: Treat the top-level binds as nested lets around
 a body representing “all external calls”, which returns a pessimistic
 UsageType (the co-call graph is the complete graph, all arityies 0).
 
-Note [Trimming arity]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-In the Call Arity papers, we are working on an untyped lambda calculus with no
-other id annotations, where eta-expansion is always possible. But this is not
-the case for Core!
- 1. We need to ensure the invariant
-      callArity e <= typeArity (exprType e)
-    for the same reasons that exprArity needs this invariant (see Note
-    [exprArity invariant] in CoreArity).
-
-    If we are not doing that, a too-high arity annotation will be stored with
-    the id, confusing the simplifier later on.
-
- 2. Eta-expanding a right hand side might invalidate existing annotations. In
-    particular, if an id has a strictness annotation of <...><...>b, then
-    passing two arguments to it will definitely bottom out, so the simplifier
-    will throw away additional parameters. This conflicts with Call Arity! So
-    we ensure that we never eta-expand such a value beyond the number of
-    arguments mentioned in the strictness signature.
-    See #10176 for a real-world-example.
-
 Note [What is a thunk]
 ~~~~~~~~~~~~~~~~~~~~~~
 
@@ -413,6 +391,25 @@ oughtweigh the cost of doing that repeatedly. Therefore, this implementation of
 Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
 -}
 
+data AnalEnv
+  = AE
+  { ae_sigs :: VarEnv FrameworkNode
+  -- ^ 'FrameworkNode's of visible local let-bound identifiers. It is crucial
+  -- that only the 'UsageSig' component is used, as the usage on free vars might
+  -- be unstable and thus too optimistic.
+  , ae_fam_envs :: FamInstEnvs
+  -- ^ Needed for 'findTypeShape' to resolve type/data families.
+  }
+
+initialAnalEnv :: FamInstEnvs -> AnalEnv
+initialAnalEnv fam_envs
+  = AE
+  { ae_sigs = emptyVarEnv
+  , ae_fam_envs = fam_envs
+  }
+
+extendAnalEnv :: AnalEnv -> Id -> FrameworkNode -> AnalEnv
+extendAnalEnv env id node = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
 
 -- | See Note [Analysing top-level-binds]
 -- Represents the fact that a CoreProgram is like a sequence of
@@ -435,15 +432,17 @@ exprToModule (Let bind e) = bind : exprToModule e
 exprToModule _ = []
 
 -- Main entry point
-callArityAnalProgram :: DynFlags -> CoreProgram -> CoreProgram
-callArityAnalProgram _dflags = exprToModule . callArityRHS . moduleToExpr
+callArityAnalProgram :: DynFlags -> FamInstEnvs -> CoreProgram -> IO CoreProgram
+callArityAnalProgram _dflags fam_envs
+  = return . exprToModule . callArityRHS fam_envs . moduleToExpr
 
-callArityRHS :: CoreExpr -> CoreExpr
-callArityRHS e = snd (buildAndRun (callArityExpr emptyVarEnv e) topSingleUse)
+callArityRHS :: FamInstEnvs -> CoreExpr -> CoreExpr
+callArityRHS fam_envs e
+  = snd (buildAndRun (callArityExpr (initialAnalEnv fam_envs) e) topSingleUse)
 
 -- | The main analysis function. See Note [Analysis type signature]
 callArityExpr
-  :: VarEnv FrameworkNode
+  :: AnalEnv
   -> CoreExpr
   -> FrameworkBuilder (SingleUse -> TransferFunction AnalResult)
 
@@ -454,12 +453,12 @@ callArityExprTrivial e
   = return (\_ -> return (emptyUsageType, e))
 
 callArityExprMap
-  :: VarEnv FrameworkNode
+  :: AnalEnv
   -> (CoreExpr -> a)
   -> CoreExpr
   -> FrameworkBuilder (SingleUse -> TransferFunction (UsageType, a)) -- @a@ instead of @CoreExpr@
-callArityExprMap nodes f e
-  = transfer' <$> callArityExpr nodes e
+callArityExprMap env f e
+  = transfer' <$> callArityExpr env e
   where
     transfer' transfer use = do
       (ut, e') <- transfer use
@@ -472,12 +471,12 @@ callArityExpr _ e@(Coercion _) = callArityExprTrivial e
 
 -- The transparent cases
 -- TODO: What if @tickishIsCode@? See CoreArity
-callArityExpr nodes (Tick t e) = callArityExprMap nodes (Tick t) e
-callArityExpr nodes (Cast e c) = callArityExprMap nodes (flip Cast c) e
+callArityExpr env (Tick t e) = callArityExprMap env (Tick t) e
+callArityExpr env (Cast e c) = callArityExprMap env (flip Cast c) e
 
 -- The interesting cases: Variables, Lambdas, Lets, Applications, Cases
 
-callArityExpr nodes e@(Var id) = return transfer
+callArityExpr env e@(Var id) = return transfer
   where
     transfer use
       | not (isInteresting id)
@@ -488,18 +487,23 @@ callArityExpr nodes e@(Var id) = return transfer
       -- uninteresting after all...
       = return (emptyUsageType, e)
 
-      | Just node <- lookupVarEnv nodes id
+      | Just node <- lookupVarEnv (ae_sigs env) id
       -- A local let-binding, e.g. a binding from this module.
       = do
-        (ut_callee, _) <- dependOnWithDefault (unusedArgsUsageType use, e) (node, use)
+        (ut_callee, _) <- dependOnWithDefault (botUsageType, e) (node, use)
         -- It is crucial that we only use ut_args here, as every other field
         -- might be unstable and thus too optimistic.
         return ((unitUsageType id use) { ut_args = ut_args ut_callee }, e)
 
+      | isDataConWorkId id
+      -- Some data constructor, on which we can try to unleash product use
+      -- as a `UsageSig`.
+      = return (emptyUsageType { ut_args = dataConUsageSig (idArity id) use }, e)
+
       | isGlobalId id
       -- A global id from another module which has a usage signature.
       -- We don't need to track the id itself, though.
-      = return (unleashUsageSig id use, e)
+      = return (emptyUsageType { ut_args = globalIdUsageSig id use }, e)
 
       | otherwise
       -- An interesting LocalId, not present in @nodes@, e.g. a lambda-bound variable.
@@ -508,15 +512,15 @@ callArityExpr nodes e@(Var id) = return transfer
       -- binders.
       = return (unitUsageType id use, e)
 
-callArityExpr nodes (Lam id body)
+callArityExpr env (Lam id body)
   | isTyVar id
   -- Non-value lambdas are ignored
-  = callArityExprMap nodes (Lam id) body
+  = callArityExprMap env (Lam id) body
   | otherwise
   = do
-    transfer_body <- callArityExpr nodes body
+    transfer_body <- callArityExpr env body
     return $ \use ->
-      case applySingleUse use of -- Get at the @Usage@ of the body
+      case fromMaybe topUsage (peelCallUse use) of -- Get at the relative @Usage@ of the body
         Absent -> return (emptyUsageType, Lam id body)
         Used multi body_use -> do
           (ut_body, body') <- transfer_body body_use
@@ -528,18 +532,16 @@ callArityExpr nodes (Lam id body)
           let ut = multiplyUsages multi ut_body
           return (makeIdArg id' ut, Lam id' body')
 
-callArityExpr nodes (App f (Type t)) = callArityExprMap nodes (flip App (Type t)) f
+callArityExpr env (App f (Type t)) = callArityExprMap env (flip App (Type t)) f
 
--- Application. Increase arity for the called expression, nothing to know about
--- the second
-callArityExpr nodes (App f a) = do
-  transfer_f <- callArityExpr nodes f
-  transfer_a <- callArityExpr nodes a
+callArityExpr env (App f a) = do
+  transfer_f <- callArityExpr env f
+  transfer_a <- callArityExpr env a
   return $ \result_use -> do
-    (ut_f, f') <- transfer_f (abstractSingleUse result_use)
+    (ut_f, f') <- transfer_f (mkCallUse Once result_use)
     --pprTrace "App:f'" (ppr (ut_f, f')) $ return ()
     -- peel off one argument from the type
-    let (arg_usage, ut_f') = peelUsageType ut_f
+    let (arg_usage, ut_f') = peelArgUsage ut_f
     case arg_usage of
       -- TODO: Visit a, too? Seems unnecessary, wasn't called at all and
       -- should be taken care of by WW.
@@ -553,38 +555,34 @@ callArityExpr nodes (App f a) = do
           -- memoized.
           (ut_a, a') <- transfer_a arg_use
           --pprTrace "App:a'" (text "arg_use:" <+> ppr arg_use <+> ppr (ut_a, a')) $ return ()
-          return (ut_f' `both` ut_a, App f' a')
-
--- Case expression.
-callArityExpr nodes (Case scrut bndr ty alts) = do
-  transfer_scrut <- callArityExpr nodes scrut
-    -- TODO: Do we have to do something special with bndr?
-    --       Don't think so, we can't make use of the information.
-    --       We also shouldn't track them in the co call graph (they are boring)
-  transfer_alts <- forM alts $ \(dc, bndrs, e) ->
-    callArityExprMap nodes (dc, bndrs,) e
+          return (ut_f' `bothUsageType` ut_a, App f' a')
+
+callArityExpr env (Case scrut case_bndr ty alts) = do
+  transfer_scrut <- callArityExpr env scrut
+  transfer_alts <- mapM (analyseCaseAlternative env case_bndr) alts
   return $ \use -> do
-    (ut_scrut, scrut') <- transfer_scrut topSingleUse -- TODO: Product component usage
-    (ut_alts, alts') <- unzip <$> mapM ($ use) transfer_alts
-    let ut = trimArgs use (lubTypes ut_alts) `both` ut_scrut
-    -- TODO: Think harder about the diverging case (e.g. matching on `undefined`).
-    --       In that case we will declare all arguments as unused from the alts.
+    (ut_alts, alts', scrut_uses) <- unzip3 <$> mapM ($ use) transfer_alts
+    let ut_alt = lubUsageTypes ut_alts
+    let case_bndr' = setIdCallArity case_bndr (lookupUsage ut_alt case_bndr)
+    let scrut_use = propagateProductUse alts' scrut_uses
+    (ut_scrut, scrut') <- transfer_scrut scrut_use
+    let ut = ut_alt `bothUsageType` ut_scrut
     -- pprTrace "callArityExpr:Case"
     --          (vcat [ppr scrut, ppr ut])
     --pprTrace "Case" (vcat [text "ut_scrut:" <+> ppr ut_scrut, text "ut_alts:" <+> ppr ut_alts, text "cat:" <+> ppr cat]) (return ())
-    return (ut, Case scrut' bndr ty alts')
+    return (ut, Case scrut' case_bndr' ty alts')
 
-callArityExpr letdown_nodes (Let bind e) = do
+callArityExpr env (Let bind e) = do
   let initial_binds = flattenBinds [bind]
   let ids = map fst initial_binds
   -- The order in which we call callArityExpr here is important: This makes sure
   -- the FP iteration will first stabilize bindings before analyzing the body.
   -- Nope, in fact it does exactly the opposite!
-  (letdown_nodes', letup_nodes) <- callArityBind letdown_nodes initial_binds
-  let lookup_letup_node id = expectJust ": the RHS of id wasn't registered" (lookupVarEnv letup_nodes id)
+  (env', nodes) <- registerBindingGroup env initial_binds
+  let lookup_node id = expectJust ": the RHS of id wasn't registered" (lookupVarEnv nodes id)
   let transfer_rhs (id, rhs) use =
-        dependOnWithDefault (unusedArgsUsageType use, rhs) (lookup_letup_node id, use)
-  transfer_body <- callArityExpr letdown_nodes' e
+        dependOnWithDefault (botUsageType, rhs) (lookup_node id, use)
+  transfer_body <- callArityExpr env' e
 
   case bind of
     NonRec _ _ ->
@@ -593,11 +591,11 @@ callArityExpr letdown_nodes (Let bind e) = do
       return $ \use -> do
         (ut_body, e') <- transfer_body use
         (ut, [(id', rhs')]) <- unleashLet False initial_binds transfer_rhs ut_body ut_body
-        return (typeDelList (bindersOf bind) ut, Let (NonRec id' rhs') e')
+        return (delUsageTypes (bindersOf bind) ut, Let (NonRec id' rhs') e')
     Rec _ -> do -- The binding group stored in the @Rec@ constructor is always the initial one!
       -- This is a little more complicated, as we'll introduce a new FrameworkNode
       -- which we'll depend on ourselves.
-      node <- registerTransferFunction (LowerThan (minimum (eltsUFM letup_nodes))) $ \node -> do
+      node <- registerTransferFunction (LowerThan (minimum (eltsUFM nodes))) $ \node -> do
         let transfer :: SingleUse -> TransferFunction AnalResult
             transfer use = do
               (ut_body, e') <- transfer_body use
@@ -619,52 +617,166 @@ callArityExpr letdown_nodes (Let bind e) = do
 
       -- Now for the actual TransferFunction of this expr...
       return $ \use -> do
-        (ut, let') <- dependOnWithDefault (emptyUsageType, Let bind e) (node, use)
+        (ut, let') <- dependOnWithDefault (botUsageType, Let bind e) (node, use)
         --pprTrace "Let" (ppr (ut, let')) $ return ()
-        return (typeDelList (bindersOf bind) ut, let')
+        return (delUsageTypes (bindersOf bind) ut, let')
 
-unleashUsageSig :: Id -> SingleUse -> UsageType
-unleashUsageSig id use
-  = emptyUsageType { ut_args = sig }
+-- | Consider the expression
+--
+-- @
+--     case (,) (f x) (g y) of
+--       (,) a _ -> a
+-- @
+--
+-- The pair has product use @U(w*U,A)@, but how do we propagate that information?
+--
+-- By the time we hit the actual product constructor identifier in the application,
+-- we'll have an incoming use of @C^1(C^1(w*U(U,A)))@. What we need is a
+-- compatible `UsageSig`, which is @w*U -> A -> .@ in this case.
+--
+-- `dataConUsageSig` does exactly this: First peel off one-shot calls according
+-- to the constructors `idArity`, then peel off the product use to get at the
+-- usage on its components.
+dataConUsageSig :: Arity -> SingleUse -> UsageSig
+dataConUsageSig arity use = fromMaybe botUsageSig sig_maybe
+  where
+    peelSingleShotCalls 0 use = Just use
+    peelSingleShotCalls n call
+      | Just Absent <- peelCallUse call
+      = Just botSingleUse -- (,) x `seq` ...: Nothing unleashed in this case
+      | Just (Used Once use) <- peelCallUse call
+      = peelSingleShotCalls (n - 1) use
+      | otherwise
+      = Nothing
+    sig_maybe = do
+      product_use <- peelSingleShotCalls arity use
+      component_usages <- peelProductUse arity product_use
+      return (foldr consUsageSig botUsageSig component_usages)
+
+globalIdUsageSig :: Id -> SingleUse -> UsageSig
+globalIdUsageSig id use
+  | use <= no_call -- @f x `seq` ...@ for a GlobalId `f` with arity > 1
+  = botUsageSig
+  | use <= single_call
+  = idArgUsage id
+  | otherwise
+  = topUsageSig
+  where
+    (<=) = leqSingleUse
+    arity = idArity id
+    mk_one_shot = mkCallUse Once
+    no_call = iterate mk_one_shot botSingleUse !! max 0 (arity - 1)
+    single_call = iterate mk_one_shot topSingleUse !! arity
+
+analyseCaseAlternative
+  :: AnalEnv
+  -> Id
+  -> Alt CoreBndr
+  -> FrameworkBuilder (SingleUse -> TransferFunction (UsageType, Alt CoreBndr, SingleUse))
+analyseCaseAlternative env case_bndr (dc, alt_bndrs, e)
+  = transfer <$> callArityExpr env e
   where
-    call = singleCallUse (idArity id)
-    sig | (use `lubSingleUse` call) == call = idArgUsage id
-        | otherwise = topUsageSig
+    transfer transfer_alt use = do
+      let fam_envs = ae_fam_envs env
+      (ut_alt, e') <- transfer_alt use
+      let (ut_alt', alt_bndr_usages) = findBndrsUsages fam_envs ut_alt alt_bndrs
+      let (_, case_bndr_usage) = findBndrUsage fam_envs ut_alt case_bndr
+      -- We have to combine usages of alts_bndrs with that of case_bndr.
+      -- Usage info flows from case_bndr to alt_bndrs, but not the other way
+      -- around! This means that we later on annotate case_bndr solely based
+      -- on how its @Id@ was used, not on how the components were used.
+      let alt_bndr_usages' = addCaseBndrUsage case_bndr_usage alt_bndr_usages
+      let alt_bndrs' = setBndrsUsageInfo alt_bndrs alt_bndr_usages
+      let product_use = mkProductUse alt_bndr_usages'
+      -- product_use doesn't yet take into account strictness annotations of the
+      -- constructor. That's to be done when we finally match on dc.
+      return (ut_alt', (dc, alt_bndrs', e'), product_use)
+
+findBndrUsage :: FamInstEnvs -> UsageType -> Id -> (UsageType, Usage)
+findBndrUsage fam_envs ut id
+  = (delUsageType id ut, usage')
+  where
+    usage = lookupUsage ut id
+    shape = findTypeShape fam_envs (idType id)
+    -- See Note [Trimming a demand to a type] in Demand.hs
+    usage' = trimUsage shape usage
 
-callArityBind
-  :: VarEnv FrameworkNode
+findBndrsUsages :: FamInstEnvs -> UsageType -> [Var] -> (UsageType, [Usage])
+findBndrsUsages fam_envs ut = foldr step (ut, [])
+  where
+    step b (ut, usages)
+      | isId b
+      , (ut', usage) <- findBndrUsage fam_envs ut b
+      = (ut', usage:usages)
+      | otherwise
+      = (ut, usages)
+
+addCaseBndrUsage :: Usage -> [Usage] -> [Usage]
+addCaseBndrUsage Absent alt_bndr_usages = alt_bndr_usages
+addCaseBndrUsage (Used _ use) alt_bndr_usages
+  | Just case_comp_usages <- peelProductUse (length alt_bndr_usages) use
+  = zipWith bothUsage case_comp_usages alt_bndr_usages
+  | otherwise
+  = topUsage <$ alt_bndr_usages
+
+setBndrsUsageInfo :: [Var] -> [Usage] -> [Var]
+setBndrsUsageInfo [] _ = []
+setBndrsUsageInfo (b:bndrs) (usage:usages)
+  | isId b
+  = setIdCallArity b usage : setBndrsUsageInfo bndrs usages
+setBndrsUsageInfo (b:bndrs) usages
+  = setBndrsUsageInfo bndrs usages
+
+propagateProductUse
+  :: [Alt CoreBndr]
+  -> [SingleUse]
+  -> SingleUse
+propagateProductUse alts scrut_uses
+  -- Only one alternative with a product constructor
+  | [(DataAlt dc, bndrs, rhs)] <- alts
+  , [scrut_use] <- scrut_uses
+  , let tycon = dataConTyCon dc
+  -- Don't include newtypes, as they aren't really constructors introducing
+  -- indirections.
+  , isJust (isDataProductTyCon_maybe tycon)
+  -- This is a good place to make sure we don't construct an infinitely depth
+  -- use, which can happen when analysing e.g. lazy streams.
+  = boundDepth 100 scrut_use
+
+  | otherwise
+  -- We *could* lub the uses from the different branches, but there's not much
+  -- to be won there, except for maybe head strictness.
+  = topSingleUse
+
+registerBindingGroup
+  :: AnalEnv
   -> [(Id, CoreExpr)]
-  -> FrameworkBuilder (VarEnv FrameworkNode, VarEnv FrameworkNode)
-callArityBind letdown_nodes = go letdown_nodes emptyVarEnv
+  -> FrameworkBuilder (AnalEnv, VarEnv FrameworkNode)
+registerBindingGroup env = go env emptyVarEnv
   where
-    go letdown_nodes letup_nodes [] = return (letdown_nodes, letup_nodes)
-    go letdown_nodes letup_nodes ((id, rhs):binds) =
-      registerTransferFunction HighestAvailable $ \letup_node ->
-        registerTransferFunction HighestAvailable $ \letdown_node -> do
-          (letdown_nodes', letup_nodes') <- go
-            (extendVarEnv letdown_nodes id letdown_node)
-            (extendVarEnv letup_nodes id letup_node)
+    go env nodes [] = return (env, nodes)
+    go env nodes ((id, rhs):binds) =
+      registerTransferFunction HighestAvailable $ \node ->
+        registerTransferFunction HighestAvailable $ \args_node -> do
+          (env', nodes') <- go
+            (extendAnalEnv env id args_node)
+            (extendVarEnv nodes id node)
             binds
-          transfer_up' <- callArityExpr letdown_nodes' rhs
-          let transfer_up use = do
-                --pprTrace "Bind:Before" (text "id:" <+> ppr id <+> text "use:" <+> ppr use) $ return ()
-                res <- transfer_up' use
-                --pprTrace "Bind:Finished" (ppr res) $ return ()
-                return res
-          let transfer_down use = dependOnWithDefault (unusedArgsUsageType use, rhs) (letup_node, use)
-          let change_detector_down _ (old, _) (new, _) =
+          transfer <- callArityExpr env' rhs
+          let transfer_args use = dependOnWithDefault (botUsageType, rhs) (node, use)
+          let change_detector_args _ (old, _) (new, _) =
                 -- The only reason we split the transfer fuctions up is cheap
-                -- change detection for the LetDown case. This implies that
-                -- use sites of the LetDown component may only use the ut_args
+                -- change detection for the arg usage case. This implies that
+                -- use sites of these sig nodes may only use the ut_args
                 -- component!
                 -- FIXME: Encode this in the FrameworkNode type somehow, but I
                 -- don't think it's worth the trouble.
                 --pprTrace "change_detector_down" (ppr (ut_args old) <+> ppr (ut_args new) <+> ppr (ut_args old /= ut_args new)) $
                 ut_args old /= ut_args new
-          let ret = (letdown_nodes', letup_nodes') -- What we return from callArityBind
-          let letup = (transfer_up, alwaysChangeDetector) -- What we register for letup_node
-          let letdown = (transfer_down, change_detector_down) -- What we register for letdown_node
-          return ((ret, letup), letdown) -- registerTransferFunction  will peel `snd`s away for registration
+          let ret = (env', nodes') -- What we return from 'registerBindingGroup'
+          let full = (transfer, alwaysChangeDetector) -- What we register for @node@
+          let args = (transfer_args, change_detector_args) -- What we register for @arg_node@
+          return ((ret, full), args) -- registerTransferFunction  will peel `snd`s away for registration
 
 unleashLet
   :: Bool
@@ -676,8 +788,12 @@ unleashLet
 unleashLet is_recursive binds transfer_rhs ut_usage ut_body = do
   (ut_rhss, binds') <- fmap unzip $ forM binds $ \bind ->
     unleashCall is_recursive ut_usage bind (transfer_rhs bind)
+  -- Note that information flows from @unleashCall@ to @callArityLetEnv@
+  -- via the annotated @binds'@!
   let ids = map fst binds'
   let ut_final = callArityLetEnv (zip ids ut_rhss) ut_body
+  -- @ut_final@ still tracks usages of @ids@. We still need them for identifying
+  -- the fixed-point!
   return (ut_final, binds')
 
 unleashCall
@@ -697,27 +813,31 @@ unleashCall is_recursive ut_scope (id, rhs) transfer_rhs
   = analyse use
   where
     usage_id = -- How @id@ was used in its scope.
-      -- ... except for bottoms, where we can't eta-expand.
-      -- See Note [Trimming arity]
-      -- TODO: Try to move this into SimplUtils or whereever we perform
-      -- eta-expansion. This has nothing to do with the analysis per-se.
-      trimUsage (trimmedArity id)
       -- See Note [Thunks in recursive groups]
       -- @is_recursive@ implies more than one call (otherwise, why would it be
       -- recursive?), although the co-call graph doesn't model it that way.
       -- Self-edges in the co-call graph correspond to non-linear recursion.
       -- Kind-of a leaky abstraction, maybe we could somehow merge the
       -- @is_recursive@ flag into @UsageType@.
-      . apply_when is_recursive manifyUsage
+      apply_when is_recursive manifyUsage
       . lookupUsage ut_scope
       $ id
     apply_when b f = if b then f else Prelude.id
     analyse use = do
       (ut_rhs, rhs') <- transfer_rhs use
-      (ut_sig, _) <- transfer_rhs (singleCallUse (idArity id)) -- no need to expand that Arity... This is used for exported globals only
+      -- sig is used for exported globals only. Note that in the case where
+      -- idArity id == 0, there is no interesting @UsageSig@ to be had.
+      -- In that case we *could* try to analyze with arity 1, just for the
+      -- signature.
+      -- TODO: Think harder about UsageSigs and how they should be handled with
+      -- Used Many.
+      -- Also we can't eta-expand beyond idArity anyway (exported!), so our best
+      -- bet is a single call with idArity.
+      let single_call = iterate (mkCallUse Once) botSingleUse !! idArity id
+      usage_sig <- ut_args . fst <$> transfer_rhs single_call
       let id' = id
             `setIdCallArity` usage_id -- How the binder was used
-            `setIdArgUsage` ut_args ut_sig -- How a single call uses its args
+            `setIdArgUsage` usage_sig -- How a single call uses its args
       return (ut_rhs, (id', rhs'))
 
 -- Combining the results from body and rhs of a let binding
@@ -738,7 +858,7 @@ callArityLetEnv ut_rhss ut_body
     -- which we have to handle, for the recursive case even any of ut_rhss may.
     -- This is why we have to union in appropriate cross_calls, which basically
     -- perform substitution of Id to UsageType.
-    ut_combined = lubTypes (ut_body : map (unusedArgs . snd) ut_rhss)
+    ut_combined = lubUsageTypes (ut_body : map (unusedArgs . snd) ut_rhss)
 
     cross_calls
         -- Calculating cross_calls is expensive. Simply be conservative
@@ -758,7 +878,7 @@ callArityLetEnv ut_rhss ut_body
         --    If id doesn't recurse into itself, everything from all the _other_ variables
         --    If id is self-recursive, everything can happen.
         ut_before_id
-            | is_thunk  = lubTypes (ut_body : map (unusedArgs . snd) (filter ((/= id) . fst) ut_rhss))
+            | is_thunk  = lubUsageTypes (ut_body : map (unusedArgs . snd) (filter ((/= id) . fst) ut_rhss))
             | otherwise = ut_combined
         -- What do we want to know from these?
         -- Which calls can happen next to any recursive call.
@@ -766,14 +886,3 @@ callArityLetEnv ut_rhss ut_body
         called_by_id = domType ut_rhs
 
     ut_new = modifyCoCalls (cross_calls `unionUnVarGraph`) ut_combined
-
--- See Note [Trimming arity]
-trimmedArity :: Id -> Arity
-trimmedArity id = minimum [max_arity_by_type, max_arity_by_strsig]
-  where
-    max_arity_by_type = length (typeArity (idType id))
-    max_arity_by_strsig
-        | isBotRes result_info = length demands
-        | otherwise = maxBound
-
-    (demands, result_info) = splitStrictSig (idStrictness id)
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index e776e3d16e..146f377c73 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -9,7 +9,7 @@ import Usage
 import VarEnv
 
 ---------------------------------------
--- Functions related to UsageType --
+-- Functions related to UsageType    --
 ---------------------------------------
 
 -- Result type for the two analyses.
@@ -44,29 +44,26 @@ isInteresting v = not $ null (typeArity (idType v))
 emptyUsageType :: UsageType
 emptyUsageType = UT emptyUnVarGraph emptyVarEnv topUsageSig
 
+botUsageType :: UsageType
+botUsageType = unusedArgs emptyUsageType
+
 unitUsageType :: Id -> SingleUse -> UsageType
 unitUsageType id use = emptyUsageType { ut_uses = unitVarEnv id use }
 
-unusedArgsUsageType :: SingleUse -> UsageType
-unusedArgsUsageType use = trimArgs use (unusedArgs emptyUsageType)
-
 unusedArgs :: UsageType -> UsageType
 unusedArgs ut = ut { ut_args = botUsageSig }
 
-trimArgs :: SingleUse -> UsageType -> UsageType
-trimArgs use = modifyArgs (trimUsageSig use)
-
-typeDelList :: [Id] -> UsageType -> UsageType
-typeDelList ids ae = foldr typeDel ae ids
+delUsageTypes :: [Id] -> UsageType -> UsageType
+delUsageTypes ids ae = foldr delUsageType ae ids
 
-typeDel :: Id -> UsageType -> UsageType
-typeDel id (UT g ae args) = UT (g `delNode` id) (ae `delVarEnv` id) args
+delUsageType :: Id -> UsageType -> UsageType
+delUsageType id (UT g ae args) = UT (g `delNode` id) (ae `delVarEnv` id) args
 
 domType :: UsageType -> UnVarSet
-domType ca_type = varEnvDom (ut_uses ca_type)
+domType ut = varEnvDom (ut_uses ut)
 
 makeIdArg :: Id -> UsageType -> UsageType
-makeIdArg id ut = typeDel id (modifyArgs (consUsageSig (lookupUsage ut id)) ut)
+makeIdArg id ut = delUsageType id (modifyArgs (consUsageSig (lookupUsage ut id)) ut)
 
 -- In the result, find out the minimum arity and whether the variable is called
 -- at most once.
@@ -101,17 +98,17 @@ multiplyUsages Many ut@(UT _ u args)
 -- | Corresponds to sequential composition of expressions.
 -- Used for application and cases.
 -- Note this returns the @UsageSig@ from the first argument.
-both :: UsageType -> UsageType -> UsageType
-both ut1@(UT g1 u1 args) ut2@(UT g2 u2 _)
+bothUsageType :: UsageType -> UsageType -> UsageType
+bothUsageType ut1@(UT g1 u1 args) ut2@(UT g2 u2 _)
   = UT
   { ut_cocalled = unionUnVarGraphs [g1, g2, completeBipartiteGraph (domType ut1) (domType ut2)]
   , ut_uses = bothUseEnv u1 u2
   , ut_args = args
   }
 
--- | Used when combining results from alternative cases; take the minimum
-lubType :: UsageType -> UsageType -> UsageType
-lubType (UT g1 u1 args1) (UT g2 u2 args2)
+-- | Used when combining results from alternative cases
+lubUsageType :: UsageType -> UsageType -> UsageType
+lubUsageType (UT g1 u1 args1) (UT g2 u2 args2)
   = UT
   { ut_cocalled = unionUnVarGraph g1 g2
   , ut_uses = lubUseEnv u1 u2
@@ -124,13 +121,13 @@ lubUseEnv = plusVarEnv_C lubSingleUse
 bothUseEnv :: VarEnv SingleUse -> VarEnv SingleUse -> VarEnv SingleUse
 bothUseEnv = plusVarEnv_C bothSingleUse
 
-lubTypes :: [UsageType] -> UsageType
-lubTypes = foldl lubType (unusedArgs emptyUsageType)
+lubUsageTypes :: [UsageType] -> UsageType
+lubUsageTypes = foldl lubUsageType botUsageType
 
 -- | Peels off a single argument usage from the signature, corresponding to how
 -- @App f a@ uses @a@ under the given incoming arity.
-peelUsageType :: UsageType -> (Usage, UsageType)
-peelUsageType ut = (usg, ut { ut_args = args' })
+peelArgUsage :: UsageType -> (Usage, UsageType)
+peelArgUsage ut = (usg, ut { ut_args = args' })
   where
     (usg, args') = unconsUsageSig (ut_args ut)
 
diff --git a/compiler/simplCore/SimplCore.hs b/compiler/simplCore/SimplCore.hs
index bca9a33a26..4ebed770ca 100644
--- a/compiler/simplCore/SimplCore.hs
+++ b/compiler/simplCore/SimplCore.hs
@@ -471,7 +471,7 @@ doCorePass CoreDoStaticArgs          = {-# SCC "StaticArgs" #-}
                                        doPassU doStaticArgs
 
 doCorePass CoreDoCallArity           = {-# SCC "CallArity" #-}
-                                       doPassD callArityAnalProgram
+                                       doPassDFM callArityAnalProgram
 
 doCorePass CoreDoStrictness          = {-# SCC "NewStranal" #-}
                                        doPassDFM dmdAnalProgram
diff --git a/compiler/simplCore/SimplUtils.hs b/compiler/simplCore/SimplUtils.hs
index 08975fe9fc..01bcfc45d2 100644
--- a/compiler/simplCore/SimplUtils.hs
+++ b/compiler/simplCore/SimplUtils.hs
@@ -1430,10 +1430,9 @@ tryEtaExpandRhs env is_rec bndr rhs
       | sm_eta_expand (getMode env)      -- Provided eta-expansion is on
       , let cheap_arity = findRhsArity dflags bndr rhs old_arity
             usage = idCallArity bndr
-            -- This should always be in sync with @CallArity.Analysis.isThunk@
-            -- and @CallArity.Analysis.oneifyUsageIfThunk@.
-            -- TODO: Also figure out if CoreArity yields better results at all.
-            new_arity = expandArity usage cheap_arity
+            expanded_arity = expandArity usage cheap_arity
+            -- See Note [Trimming arity]
+            new_arity = min expanded_arity (maxArity bndr)
       , new_arity > old_arity      -- And the current manifest arity isn't enough
       = if is_rec == Recursive && isJoinId bndr
            then WARN(True, text "Can't eta-expand recursive join point:" <+>
@@ -1447,6 +1446,17 @@ tryEtaExpandRhs env is_rec bndr rhs
     old_arity    = exprArity rhs -- See Note [Do not expand eta-expand PAPs]
     old_id_arity = idArity bndr
 
+-- See Note [Trimming arity]
+maxArity :: Id -> Arity
+maxArity id = minimum [max_arity_by_type, max_arity_by_strsig]
+  where
+    max_arity_by_type = length (typeArity (idType id))
+    max_arity_by_strsig
+        | isBotRes result_info = length demands
+        | otherwise = maxBound
+
+    (demands, result_info) = splitStrictSig (idStrictness id)
+
 {-
 Note [Eta-expanding at let bindings]
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
@@ -1495,6 +1505,27 @@ But note that this won't eta-expand, say
 Does it matter not eta-expanding such functions?  I'm not sure.  Perhaps
 strictness analysis will have less to bite on?
 
+Note [Trimming arity]
+~~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+Further eta-expansion based on usage information may yield an arity that is
+incompatible with type and strictness information.
+
+ 1. We need to ensure the invariant
+      expanded_arity e <= typeArity (exprType e)
+    for the same reasons that exprArity needs this invariant (see Note
+    [exprArity invariant] in CoreArity).
+
+    If we are not doing that, a too-high arity annotation will be stored with
+    the id, confusing the simplifier later on.
+
+ 2. Eta-expanding a right hand side might invalidate existing annotations. In
+    particular, if an id has a strictness annotation of <...><...>b, then
+    passing two arguments to it will definitely bottom out, so the simplifier
+    will throw away additional parameters. This conflicts with eta-expansion! So
+    we ensure that we never expand such a value beyond the number of
+    arguments mentioned in the strictness signature.
+    See #10176 for a real-world-example.
 
 ************************************************************************
 *                                                                      *
diff --git a/compiler/stranal/DmdAnal.hs b/compiler/stranal/DmdAnal.hs
index 12496104b4..e267ac64ba 100644
--- a/compiler/stranal/DmdAnal.hs
+++ b/compiler/stranal/DmdAnal.hs
@@ -1066,7 +1066,7 @@ type DFunFlag = Bool  -- indicates if the lambda being considered is in the
 notArgOfDfun :: DFunFlag
 notArgOfDfun = False
 
--- ^ Holds all (mostly read-only) state of the analysis.
+-- | Holds all (mostly read-only) state of the analysis.
 data AnalEnv
   = AE { ae_dflags :: DynFlags
        -- ^ Compiler flags
diff --git a/nofib b/nofib
index 3ac6f2db09..48e36515ae 160000
--- a/nofib
+++ b/nofib
@@ -1 +1 @@
-Subproject commit 3ac6f2db09254c52a87f3f1c79798f27d390e899
+Subproject commit 48e36515ae308b6dc356e6b059ce223212696f41
-- 
2.12.1


From 1d2482f6481a899fa7a85f1ad9ed6eaac350ac83 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 20 Apr 2017 12:11:57 +0200
Subject: [PATCH 037/117] Fixed a stupid binder annotation bug

---
 compiler/simplCore/CallArity/Analysis.hs | 8 +++++---
 1 file changed, 5 insertions(+), 3 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 6508409602..0087aa657d 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -16,6 +16,7 @@ import FamInstEnv
 import Id
 import Maybes ( expectJust, fromMaybe, isJust )
 import MkCore
+import Outputable
 import TyCon ( isDataProductTyCon_maybe )
 import UniqFM
 import UnVarGraph
@@ -697,8 +698,8 @@ findBndrUsage fam_envs ut id
   = (delUsageType id ut, usage')
   where
     usage = lookupUsage ut id
-    shape = findTypeShape fam_envs (idType id)
     -- See Note [Trimming a demand to a type] in Demand.hs
+    shape = findTypeShape fam_envs (idType id)
     usage' = trimUsage shape usage
 
 findBndrsUsages :: FamInstEnvs -> UsageType -> [Var] -> (UsageType, [Usage])
@@ -720,12 +721,13 @@ addCaseBndrUsage (Used _ use) alt_bndr_usages
   = topUsage <$ alt_bndr_usages
 
 setBndrsUsageInfo :: [Var] -> [Usage] -> [Var]
-setBndrsUsageInfo [] _ = []
+setBndrsUsageInfo [] [] = []
 setBndrsUsageInfo (b:bndrs) (usage:usages)
   | isId b
   = setIdCallArity b usage : setBndrsUsageInfo bndrs usages
 setBndrsUsageInfo (b:bndrs) usages
-  = setBndrsUsageInfo bndrs usages
+  = b : setBndrsUsageInfo bndrs usages
+setBndrsUsageInfo _ usages = pprPanic "No Ids, but a Usage left" (ppr usages)
 
 propagateProductUse
   :: [Alt CoreBndr]
-- 
2.12.1


From d5c939b7df3dbe6e932a7b609df185cff3e8c163 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 20 Apr 2017 15:35:14 +0200
Subject: [PATCH 038/117] Fixed the CallArity1 test

---
 testsuite/tests/callarity/unittest/CallArity1.hs | 3 ++-
 1 file changed, 2 insertions(+), 1 deletion(-)

diff --git a/testsuite/tests/callarity/unittest/CallArity1.hs b/testsuite/tests/callarity/unittest/CallArity1.hs
index bdb8754308..0ccffcf429 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.hs
+++ b/testsuite/tests/callarity/unittest/CallArity1.hs
@@ -22,6 +22,7 @@ import Unique
 import UniqSet
 import CoreLint
 import FastString
+import FamInstEnv
 
 -- Build IDs. use mkTemplateLocal, more predictable than proper uniques
 go, go2, x, d, n, y, z, scrutf, scruta :: Id
@@ -174,7 +175,7 @@ main = do
                 Nothing -> return ()
             putMsg dflags (text n <> char ':')
             -- liftIO $ putMsg dflags (ppr e)
-            let e' = callArityRHS e
+            let e' = callArityRHS emptyFamInstEnvs e
             let bndrs = nonDetEltsUniqSet (allBoundIds e')
               -- It should be OK to use nonDetEltsUniqSet here, if it becomes a
               -- problem we should use DVarSet
-- 
2.12.1


From 29e2bbda46d4fdd1130d83142bbc6c4738a500dc Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 25 Apr 2017 17:56:21 +0200
Subject: [PATCH 039/117] Recognizing strict fields now

---
 compiler/basicTypes/Usage.hs             |  9 +++++++--
 compiler/simplCore/CallArity/Analysis.hs | 21 +++++++++++++++++++--
 2 files changed, 26 insertions(+), 4 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 5a7c124eb6..4f8e3b9b1f 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -6,7 +6,7 @@ module Usage
   , SingleUse
   , botSingleUse, topSingleUse, lubSingleUse, leqSingleUse, bothSingleUse, mkCallUse, peelCallUse, mkProductUse, peelProductUse, boundDepth
   , Usage (..)
-  , multiplicity, botUsage, topUsage, lubUsage, bothUsage, manifyUsage, expandArity
+  , multiplicity, botUsage, topUsage, lubUsage, bothUsage, seqUsage, manifyUsage, expandArity
   , UsageSig
   , botUsageSig, topUsageSig, lubUsageSig, consUsageSig, unconsUsageSig, manifyUsageSig
   , trimSingleUse, trimUsage, trimUsageSig
@@ -195,11 +195,12 @@ peelCallUse (Call multi use) = Just (Used multi use)
 peelCallUse UnknownUse = Just topUsage
 peelCallUse _ = Nothing
 
+-- | @peelProductUse (length comps) (mkProductUse comps) = Just comps@
 peelProductUse :: Arity -> SingleUse -> Maybe [Usage]
 peelProductUse n HeadUse = Just (replicate n botUsage)
 peelProductUse n UnknownUse = Just (replicate n topUsage)
 peelProductUse n (Product comps)
-  = ASSERT2( comps `lengthIs` n, text "peelProductUse" $$ ppr n $$ ppr comps)
+  = ASSERT2(comps `lengthIs` n, text "peelProductUse" $$ ppr n $$ ppr comps)
     Just comps
 peelProductUse _ (Call _ _) = Nothing -- might happen with unsafeCoerce (#9208)
 
@@ -249,6 +250,10 @@ trimUsage :: TypeShape -> Usage -> Usage
 trimUsage shape (Used m use) = Used m (trimSingleUse shape use)
 trimUsage _ usg = usg
 
+-- | `Usage` unleashed on `x` in @x `seq` ...@.
+seqUsage :: Usage
+seqUsage = Used Once HeadUse
+
 -- | @manifyUsage u = bothUsage u u@. For when an id is used more than once
 -- with the same `Usage`. This is different than just changing the top-level
 -- `Multiplicity` to `Many`, which would correspond to an additional `seq`
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 0087aa657d..d4167890de 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -10,7 +10,7 @@ import CallArity.FrameworkBuilder
 
 import BasicTypes
 import CoreSyn
-import DataCon ( dataConTyCon )
+import DataCon ( DataCon, dataConTyCon, dataConRepStrictness, isMarkedStrict )
 import DynFlags      ( DynFlags )
 import FamInstEnv
 import Id
@@ -743,13 +743,30 @@ propagateProductUse alts scrut_uses
   , isJust (isDataProductTyCon_maybe tycon)
   -- This is a good place to make sure we don't construct an infinitely depth
   -- use, which can happen when analysing e.g. lazy streams.
-  = boundDepth 100 scrut_use
+  -- Also see Note [Demand on scrutinee of a product case] in DmdAnal.hs.
+  = addDataConStrictness dc (boundDepth 100 scrut_use)
 
   | otherwise
   -- We *could* lub the uses from the different branches, but there's not much
   -- to be won there, except for maybe head strictness.
   = topSingleUse
 
+addDataConStrictness :: DataCon -> SingleUse -> SingleUse
+-- See Note [Add demands for strict constructors] in DmdAnal.hs
+addDataConStrictness dc use
+  = maybe use (mkProductUse . add_component_strictness) (peelProductUse arity use)
+  where
+    add_component_strictness :: [Usage] -> [Usage]
+    add_component_strictness = zipWith add strs
+
+    strs = dataConRepStrictness dc
+    arity = length strs
+
+    add str Absent = Absent -- See the note; We want to eliminate these in WW.
+    add str usage@(Used _ _)
+      | isMarkedStrict str = usage `bothUsage` seqUsage
+      | otherwise = usage
+
 registerBindingGroup
   :: AnalEnv
   -> [(Id, CoreExpr)]
-- 
2.12.1


From 349728809356a947d85ec4b42e86abe0049bf61e Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 25 Apr 2017 18:23:40 +0200
Subject: [PATCH 040/117] Hopefully restoring old exprIsCheap behavior

---
 compiler/simplCore/SimplUtils.hs | 5 ++++-
 1 file changed, 4 insertions(+), 1 deletion(-)

diff --git a/compiler/simplCore/SimplUtils.hs b/compiler/simplCore/SimplUtils.hs
index 01bcfc45d2..8713b3d773 100644
--- a/compiler/simplCore/SimplUtils.hs
+++ b/compiler/simplCore/SimplUtils.hs
@@ -1428,7 +1428,10 @@ tryEtaExpandRhs env is_rec bndr rhs
       = return (exprArity rhs, rhs)
 
       | sm_eta_expand (getMode env)      -- Provided eta-expansion is on
-      , let cheap_arity = findRhsArity dflags bndr rhs old_arity
+      , let trivial_arity = findRhsArity dflags bndr rhs old_arity
+            cheap_arity
+              | exprIsCheap rhs = max 1 trivial_arity
+              | otherwise = trivial_arity
             usage = idCallArity bndr
             expanded_arity = expandArity usage cheap_arity
             -- See Note [Trimming arity]
-- 
2.12.1


From 61c6515d5957191daff50e8e8ac2b710dc4918f7 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Wed, 26 Apr 2017 19:28:29 +0200
Subject: [PATCH 041/117] Took the time to rethink fix-pointing, which was
 probably buggy

---
 compiler/simplCore/CallArity/Analysis.hs | 41 +++++++++++++-------------------
 compiler/utils/UnVarGraph.hs             |  9 +++++--
 2 files changed, 24 insertions(+), 26 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index d4167890de..2579e0426d 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -865,11 +865,11 @@ callArityLetEnv
   :: [(Id, UsageType)]
   -> UsageType
   -> UsageType
-callArityLetEnv ut_rhss ut_body
+callArityLetEnv rhss ut_body
     = -- (if length ae_rhss > 300 then pprTrace "callArityLetEnv" (vcat [ppr ae_rhss, ppr ae_body, ppr ae_new]) else id) $
       ut_new
   where
-    ids = map fst ut_rhss
+    (ids, ut_rhss) = unzip rhss
 
     -- This is already the complete type, but with references from the current
     -- binding group not resolved.
@@ -877,31 +877,24 @@ callArityLetEnv ut_rhss ut_body
     -- which we have to handle, for the recursive case even any of ut_rhss may.
     -- This is why we have to union in appropriate cross_calls, which basically
     -- perform substitution of Id to UsageType.
-    ut_combined = lubUsageTypes (ut_body : map (unusedArgs . snd) ut_rhss)
 
-    cross_calls
-        -- Calculating cross_calls is expensive. Simply be conservative
-        -- if the mutually recursive group becomes too large.
-        -- TODO: I *think* 5 is enough here, but this used to be 25.
-        | length ut_rhss > 5 = completeGraph (domType ut_combined)
-        | otherwise            = unionUnVarGraphs $ map cross_call ut_rhss
-    cross_call (id, ut_rhs) = completeBipartiteGraph called_by_id called_with_id
+    ut_all = ut_body : map unusedArgs ut_rhss
+    ut_combined = lubUsageTypes ut_all
+
+    cross_calls ut_rhs = botUsageType { ut_uses = uses, ut_cocalled = graph }
       where
-        is_thunk = idArity id == 0 -- See Note [Thunks in recursive groups]
-        -- We only add self cross calls if we really can recurse into ourselves.
-        -- This is not the case for thunks (and non-recursive bindings, but
-        -- then there won't be any mention of id in the rhs).
-        -- A thunk is not evaluated more than once, so the only
-        -- relevant calls are from other bindings or the body.
-        -- What rhs are relevant as happening before (or after) calling id?
-        --    If id doesn't recurse into itself, everything from all the _other_ variables
-        --    If id is self-recursive, everything can happen.
-        ut_before_id
-            | is_thunk  = lubUsageTypes (ut_body : map (unusedArgs . snd) (filter ((/= id) . fst) ut_rhss))
-            | otherwise = ut_combined
         -- What do we want to know from these?
         -- Which calls can happen next to any recursive call.
-        called_with_id = unionUnVarSets $ map (calledWith ut_before_id) ids
+        called_with_id = unionUnVarSets $ map (calledWith ut_combined) ids
         called_by_id = domType ut_rhs
+        graph = completeBipartiteGraph called_by_id called_with_id
+        uses = bothUseEnv (ut_uses ut_rhs) (restrict (ut_uses ut_combined) called_with_id)
+        restrict = restrictVarEnv_UnVarSet
 
-    ut_new = modifyCoCalls (cross_calls `unionUnVarGraph`) ut_combined
+    ut_new
+        -- Calculating cross_calls is expensive. Simply be conservative
+        -- if the mutually recursive group becomes too large.
+        -- Combining all rhs and the body with `bothUsageType` corresponds to
+        -- cocalls in the complete graph.
+        | length ut_rhss > 25 = foldr bothUsageType botUsageType ut_all
+        | otherwise           = lubUsageTypes $ ut_combined : map cross_calls ut_rhss
diff --git a/compiler/utils/UnVarGraph.hs b/compiler/utils/UnVarGraph.hs
index 228f3b5220..f48e3bbb07 100644
--- a/compiler/utils/UnVarGraph.hs
+++ b/compiler/utils/UnVarGraph.hs
@@ -16,8 +16,8 @@ equal to g, but twice as expensive and large.
 -}
 module UnVarGraph
     ( UnVarSet
-    , emptyUnVarSet, mkUnVarSet, varEnvDom, unionUnVarSet, unionUnVarSets
-    , delUnVarSet
+    , emptyUnVarSet, mkUnVarSet, varEnvDom, restrictVarEnv_UnVarSet
+    , unionUnVarSet, unionUnVarSets, delUnVarSet
     , elemUnVarSet, isEmptyUnVarSet
     , UnVarGraph
     , emptyUnVarGraph
@@ -68,6 +68,11 @@ mkUnVarSet vs = UnVarSet $ S.fromList $ map k vs
 varEnvDom :: VarEnv a -> UnVarSet
 varEnvDom ae = UnVarSet $ ufmToSet_Directly ae
 
+restrictVarEnv_UnVarSet :: VarEnv a -> UnVarSet -> VarEnv a
+restrictVarEnv_UnVarSet env (UnVarSet s) = filterVarEnv_Directly keep env
+  where
+    keep u _ = getKey u `S.member` s
+
 unionUnVarSet :: UnVarSet -> UnVarSet -> UnVarSet
 unionUnVarSet (UnVarSet set1) (UnVarSet set2) = UnVarSet (set1 `S.union` set2)
 
-- 
2.12.1


From ca01574cd2d2066dffedd66d421f30dffb6c0330 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 28 Apr 2017 17:56:35 +0200
Subject: [PATCH 042/117] ... and fixed even more bugs identified while fixing
 tests

---
 compiler/simplCore/CallArity/Analysis.hs           | 54 +++++++++++++---------
 compiler/simplCore/CallArity/Types.hs              | 17 +------
 testsuite/tests/callarity/unittest/CallArity1.hs   | 34 ++++++++------
 .../tests/callarity/unittest/CallArity1.stderr     | 25 ++++++----
 4 files changed, 69 insertions(+), 61 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 2579e0426d..262aa7e18e 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -416,18 +416,18 @@ extendAnalEnv env id node = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
 -- Represents the fact that a CoreProgram is like a sequence of
 -- nested lets, where the exports are returned in the inner-most let
 -- as a tuple. As a result, all exported identifiers are handled as called
--- with each other, with @topUsage@.
+-- with each other, with `topUsage`.
 moduleToExpr :: CoreProgram -> CoreExpr
 moduleToExpr = impl []
   where
     impl exported []
       -- @duplicate@, otherwise those Vars appear to be used once
-      = mkBigCoreTup (map Var (duplicate exported))
+      = mkBigCoreVarTup (duplicate exported)
     impl exported (bind:prog)
       = Let bind (impl (filter isExportedId (bindersOf bind) ++ exported) prog)
     duplicate = concatMap (replicate 2)
 
--- | The left inverse to @moduleToExpr@: @exprToModule . moduleToExpr = id \@CoreProgram@
+-- | The left inverse to `moduleToExpr`: `exprToModule . moduleToExpr = id \@CoreProgram`
 exprToModule :: CoreExpr -> CoreProgram
 exprToModule (Let bind e) = bind : exprToModule e
 exprToModule _ = []
@@ -480,14 +480,6 @@ callArityExpr env (Cast e c) = callArityExprMap env (flip Cast c) e
 callArityExpr env e@(Var id) = return transfer
   where
     transfer use
-      | not (isInteresting id)
-      -- We don't track uninteresting vars and implicitly assume they are called
-      -- multiple times with every other variable.
-      -- See Note [Taking boring variables into account]
-      -- TODO: Do we really need this? Those uninteresting vars aren't that
-      -- uninteresting after all...
-      = return (emptyUsageType, e)
-
       | Just node <- lookupVarEnv (ae_sigs env) id
       -- A local let-binding, e.g. a binding from this module.
       = do
@@ -652,7 +644,7 @@ dataConUsageSig arity use = fromMaybe botUsageSig sig_maybe
     sig_maybe = do
       product_use <- peelSingleShotCalls arity use
       component_usages <- peelProductUse arity product_use
-      return (foldr consUsageSig botUsageSig component_usages)
+      return (foldr consUsageSig topUsageSig component_usages)
 
 globalIdUsageSig :: Id -> SingleUse -> UsageSig
 globalIdUsageSig id use
@@ -852,7 +844,7 @@ unleashCall is_recursive ut_scope (id, rhs) transfer_rhs
       -- Used Many.
       -- Also we can't eta-expand beyond idArity anyway (exported!), so our best
       -- bet is a single call with idArity.
-      let single_call = iterate (mkCallUse Once) botSingleUse !! idArity id
+      let single_call = iterate (mkCallUse Once) topSingleUse !! idArity id
       usage_sig <- ut_args . fst <$> transfer_rhs single_call
       let id' = id
             `setIdCallArity` usage_id -- How the binder was used
@@ -866,29 +858,45 @@ callArityLetEnv
   -> UsageType
   -> UsageType
 callArityLetEnv rhss ut_body
-    = -- (if length ae_rhss > 300 then pprTrace "callArityLetEnv" (vcat [ppr ae_rhss, ppr ae_body, ppr ae_new]) else id) $
+    = --pprTrace "callArityLetEnv" (vcat [ppr rhss, ppr ut_body, ppr ut_new]) $
       ut_new
   where
     (ids, ut_rhss) = unzip rhss
 
+    body_and_rhss good_id
+      = (ut_body :)            -- always include the usage type of the body
+      . map (unusedArgs . snd) -- we are only interested in the usage types
+      . filter (good_id . fst) -- check if the id associated with the usage type is a good_id
+      $ rhss
+
     -- This is already the complete type, but with references from the current
     -- binding group not resolved.
     -- For the non-recursive case, at least ut_body may refer to some bound var
     -- which we have to handle, for the recursive case even any of ut_rhss may.
     -- This is why we have to union in appropriate cross_calls, which basically
     -- perform substitution of Id to UsageType.
+    ut_all = body_and_rhss (\id_rhs -> True)
 
-    ut_all = ut_body : map unusedArgs ut_rhss
-    ut_combined = lubUsageTypes ut_all
-
-    cross_calls ut_rhs = botUsageType { ut_uses = uses, ut_cocalled = graph }
+    cross_calls (id, ut_rhs) = botUsageType { ut_uses = uses, ut_cocalled = graph }
       where
-        -- What do we want to know from these?
-        -- Which calls can happen next to any recursive call.
-        called_with_id = unionUnVarSets $ map (calledWith ut_combined) ids
+        -- ut_others excludes the defining rhs itself, because that is already
+        -- accounted for based on the recorded Usage, which is always manified
+        -- for recursive binders.
+        -- This ensures we don't duplicate shared work, while also manifying anything
+        -- under a lambda for recursive groups. In the case of a non-recursive
+        -- binding, there is no mention of the id in the rhs anyway.
+        ut_others = lubUsageTypes (body_and_rhss (\id_rhs -> id /= id_rhs))
+        -- Since Co-Call graphs are not transitive, but recursion is, we have to
+        -- conservatively assume that id was called with every neighbor in
+        -- ut_others of any of the ids of the binding group.
+        called_with_id = unionUnVarSets $ map (calledWith ut_others) ids
         called_by_id = domType ut_rhs
+        -- As long as called_with_id does not contain every node in ut_others,
+        -- the whole Co-Call hassle played out: We can be more precise than
+        -- just smashing everything together with `bothUsageType` (which would
+        -- correspond exactly to the scenario called_with_id = domType ut_others).
         graph = completeBipartiteGraph called_by_id called_with_id
-        uses = bothUseEnv (ut_uses ut_rhs) (restrict (ut_uses ut_combined) called_with_id)
+        uses = bothUseEnv (ut_uses ut_rhs) (restrict (ut_uses ut_others) called_with_id)
         restrict = restrictVarEnv_UnVarSet
 
     ut_new
@@ -897,4 +905,4 @@ callArityLetEnv rhss ut_body
         -- Combining all rhs and the body with `bothUsageType` corresponds to
         -- cocalls in the complete graph.
         | length ut_rhss > 25 = foldr bothUsageType botUsageType ut_all
-        | otherwise           = lubUsageTypes $ ut_combined : map cross_calls ut_rhss
+        | otherwise           = lubUsageTypes (ut_all ++ map cross_calls rhss)
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index 146f377c73..c50055d6c1 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -36,11 +36,6 @@ modifyCoCalls modifier ut = ut { ut_cocalled = modifier (ut_cocalled ut) }
 -- and the elaborated expression with annotated Ids
 type AnalResult = (UsageType, CoreExpr)
 
--- Which bindings should we look at?
--- See Note [Which variables are interesting]
-isInteresting :: Var -> Bool
-isInteresting v = not $ null (typeArity (idType v))
-
 emptyUsageType :: UsageType
 emptyUsageType = UT emptyUnVarGraph emptyVarEnv topUsageSig
 
@@ -72,18 +67,10 @@ lookupUsage (UT g ae _) id = case lookupVarEnv ae id of
   Just use
     | id `elemUnVarSet` neighbors g id -> Used Many use
     | otherwise -> Used Once use
-  Nothing
-    | isInteresting id -> botUsage
-    -- If v is boring, we will not find it in ut_usage, but always assume topUsage.
-    -- See Note [Taking boring variables into account]
-    | otherwise -> topUsage
+  Nothing -> botUsage
 
 calledWith :: UsageType -> Id -> UnVarSet
-calledWith ut id
-  | isInteresting id
-  = neighbors (ut_cocalled ut) id
-  | otherwise
-  = domType ut
+calledWith ut id = neighbors (ut_cocalled ut) id
 
 -- Replaces the co-call graph by a complete graph (i.e. no information)
 multiplyUsages :: Multiplicity -> UsageType -> UsageType
diff --git a/testsuite/tests/callarity/unittest/CallArity1.hs b/testsuite/tests/callarity/unittest/CallArity1.hs
index 0ccffcf429..b6af62aba9 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.hs
+++ b/testsuite/tests/callarity/unittest/CallArity1.hs
@@ -87,20 +87,13 @@ exprs =
                               (mkLams [y] $ Var y)
                       ) $ mkLams [z] $ Var d `mkVarApps` [x]) $
             Var f `mkApps` [n `mkLApps` [0],  go `mkLApps` [0, 0]]
-  , ("go2 (using surrounding boring let)",) $
-     mkNrLet z (mkLit 0) $
-         mkRFun go [x]
-            (mkNrLet d (mkACase (Var go `mkVarApps` [x])
-                              (mkLams [y] $ Var y)
-                      ) $ mkLams [z] $ Var d `mkVarApps` [x]) $
-            Var f `mkApps` [Var z,  go `mkLApps` [0, 0]]
   , ("two calls, one from let and from body (d 1*_ would be bad)",) $
-     mkNrLet  d (mkACase (mkLams [y] $ mkLit 0) (mkLams [y] $ mkLit 0)) $
+     mkNrLet  d (mkACase (mkLams [y] $ Var y) (mkLams [y] $ Var y)) $
      mkFun go [x,y] (mkVarApps (Var d) [x]) $
      mkApps (Var d) [mkLApps go [1,2]]
   , ("a thunk in a recursion (d 1*_ would be bad)",) $
-     mkRLet n (mkACase (mkLams [y] $ mkLit 0) (Var n)) $
-     mkRLet d (mkACase (mkLams [y] $ mkLit 0) (Var d)) $
+     mkRLet n (mkACase (mkLams [y] $ Var y) (Var n)) $
+     mkRLet d (mkACase (mkLams [y] $ Var y) (Var d)) $
          Var n `mkApps` [d `mkLApps` [0]]
   , ("two thunks, one called multiple times (both 1*_ would be bad!)",) $
      mkNrLet n (mkACase (mkLams [y] $ mkLit 0) (f `mkLApps` [0])) $
@@ -119,8 +112,8 @@ exprs =
      mkRLet go2 (mkLams [x] (mkACase (Var go2 `mkApps` [Var go2 `mkApps` [mkLit 0, mkLit 0]]) (go `mkLApps` [0]))) $
          go2 `mkLApps` [0,1]
   , ("two functions (recursive)",) $
-     mkRLet go  (mkLams [x] (mkACase (mkLams [y] $ mkLit 0) (Var go `mkVarApps` [x]))) $
-     mkRLet go2 (mkLams [x] (mkACase (mkLams [y] $ mkLit 0) (Var go2 `mkVarApps` [x]))) $
+     mkRLet go  (mkLams [x] (mkACase (Var f `mkVarApps` [x]) (Var go `mkVarApps` [x]))) $
+     mkRLet go2 (mkLams [x] (mkACase (Var f `mkVarApps` [x]) (Var go2 `mkVarApps` [x]))) $
          Var go `mkApps` [go2 `mkLApps` [0,1], mkLit 0]
   , ("mutual recursion (thunks), called mutiple times (both 1*_ would be bad!)",) $
      Let (Rec [ (n, mkACase (mkLams [y] $ mkLit 0) (Var d))
@@ -151,17 +144,30 @@ exprs =
   , ("a thunk (non-function-type), in mutual recursion, causes many calls (d 1*_ would be bad)",) $
     mkNrLet d (f `mkLApps` [0]) $
         Let (Rec [ (x, Var go `mkApps` [go `mkLApps` [1,2], go `mkLApps` [1,2]])
-                 , (go, mkLams [x] $ mkACase (Var d) (Var go `mkVarApps` [x]) ) ]) $
+                 , (go, mkLams [y] $ mkACase (Var d) (Var go `mkVarApps` [x]) ) ]) $
             Var go `mkApps` [mkLit 0, go `mkLApps` [0,1]]
-  , ("a thunk (function type), in mutual recursion, still calls once (d 1*_ would be good)",) $
+  , ("a thunk (function type), in mutual recursion, still calls once",) $
     mkNrLet d (f `mkLApps` [0]) $
         Let (Rec [ (n, Var go `mkApps` [d `mkLApps` [1]])
+                 , (go, mkLams [x] $ mkACase (Var f `mkVarApps` [x]) (Var go `mkApps` [Var n `mkVarApps` [x]]) ) ]) $
+            Var go `mkApps` [mkLit 0, go `mkLApps` [0,1]]
+  , ("a thunk (function type), in mutual recursion, absent",) $
+    mkLet d (f `mkLApps` [0]) $
+        Let (Rec [ (n, Var go `mkApps` [d `mkLApps` [1]]) -- FIXME: Check UsageSigs
                  , (go, mkLams [x] $ mkACase (Var n) (Var go `mkApps` [Var n `mkVarApps` [x]]) ) ]) $
             Var go `mkApps` [mkLit 0, go `mkLApps` [0,1]]
   , ("a thunk (non-function-type) co-calls with the body (d 1*_ would be bad)",) $
     mkNrLet d (f `mkLApps` [0]) $
         mkLet x (d `mkLApps` [1]) $
             Var d `mkVarApps` [x]
+  , ("body cocalls d and n, n calls d (anything other than d w*C^w(U) = w*U would be bad)",) $
+    mkNrLet d (f `mkLApps` [0]) $
+        mkLet n (mkLams [y] $ d `mkLApps` [1]) $
+            Var f `mkApps` [d `mkLApps` [0], n `mkLApps` [0]]
+  , ("body calls d and n mutually exclusive, n calls d. d should be called once",) $
+    mkNrLet d (f `mkLApps` [0]) $
+        mkLet n (mkLams [y] $ d `mkLApps` [1]) $
+          mkACase (d `mkLApps` [0]) (n `mkLApps` [0])
   ]
 
 main = do
diff --git a/testsuite/tests/callarity/unittest/CallArity1.stderr b/testsuite/tests/callarity/unittest/CallArity1.stderr
index ca01b80bf1..801b659908 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.stderr
+++ b/testsuite/tests/callarity/unittest/CallArity1.stderr
@@ -19,13 +19,9 @@ go2 (using surrounding interesting let):
     go ω*C^ω(C^1(U))
     d 1*C^1(U)
     n 1*C^1(U)
-go2 (using surrounding boring let):
-    go ω*C^ω(C^1(U))
-    d 1*C^1(U)
-    z ω*U
 two calls, one from let and from body (d 1*_ would be bad):
     go 1*C^1(C^1(U))
-    d ω*C^1(U)
+    d ω*U
 a thunk in a recursion (d 1*_ would be bad):
     d ω*U
     n ω*U
@@ -66,12 +62,23 @@ a thunk (non-function-type), in mutual recursion, still calls once (d ω*_ would
     d 1*C^1(U)
 a thunk (non-function-type), in mutual recursion, causes many calls (d 1*_ would be bad):
     go ω*C^ω(C^1(U))
-    x ω*U
+    x A
     d ω*U
-a thunk (function type), in mutual recursion, still calls once (d 1*_ would be good):
+a thunk (function type), in mutual recursion, still calls once:
     go ω*U
     d 1*C^1(U)
     n ω*U
+a thunk (function type), in mutual recursion, absent:
+    go ω*U
+    d A
+    n ω*U
 a thunk (non-function-type) co-calls with the body (d 1*_ would be bad):
-    x ω*U
-    d ω*C^1(U)
+    x 1*U
+    d ω*U
+body cocalls d and n, n calls d (anything other than d w*C^w(U) = w*U would be bad):
+    d ω*U
+    n 1*C^1(U)
+body calls d and n mutually exclusive, n calls d. d should be called once:
+    d 1*C^1(U)
+    n 1*C^1(U)
+
-- 
2.12.1


From 8521652867a07116afa7ea95ba17c0a6ea5fa037 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 28 Apr 2017 18:09:57 +0200
Subject: [PATCH 043/117] No more omega. Using w instead. Also deleted some
 superfluous comments

---
 compiler/basicTypes/Usage.hs                       |  2 +-
 compiler/simplCore/CallArity/Analysis.hs           | 10 ++-
 .../tests/callarity/unittest/CallArity1.stderr     | 74 +++++++++++-----------
 3 files changed, 42 insertions(+), 44 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 4f8e3b9b1f..69f4290f70 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -343,7 +343,7 @@ trimUsageSig _ _ = TopUsageSig
 
 instance Outputable Multiplicity where
   ppr Once = text "1"
-  ppr Many = text "ω"
+  ppr Many = text "w"
 
 instance Outputable SingleUse where
   ppr HeadUse = text "HU"
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 262aa7e18e..1ac5b9b974 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -471,7 +471,7 @@ callArityExpr _ e@(Type _) = callArityExprTrivial e
 callArityExpr _ e@(Coercion _) = callArityExprTrivial e
 
 -- The transparent cases
--- TODO: What if @tickishIsCode@? See CoreArity
+-- TODO: What if @tickishIsCode@? See CoreArity. Although DmdAnal doesn't handle it
 callArityExpr env (Tick t e) = callArityExprMap env (Tick t) e
 callArityExpr env (Cast e c) = callArityExprMap env (flip Cast c) e
 
@@ -567,15 +567,13 @@ callArityExpr env (Case scrut case_bndr ty alts) = do
 
 callArityExpr env (Let bind e) = do
   let initial_binds = flattenBinds [bind]
-  let ids = map fst initial_binds
-  -- The order in which we call callArityExpr here is important: This makes sure
-  -- the FP iteration will first stabilize bindings before analyzing the body.
-  -- Nope, in fact it does exactly the opposite!
   (env', nodes) <- registerBindingGroup env initial_binds
-  let lookup_node id = expectJust ": the RHS of id wasn't registered" (lookupVarEnv nodes id)
+  let lookup_node id =
+        expectJust ": the RHS of id wasn't registered" (lookupVarEnv nodes id)
   let transfer_rhs (id, rhs) use =
         dependOnWithDefault (botUsageType, rhs) (lookup_node id, use)
   transfer_body <- callArityExpr env' e
+  let ids = map fst initial_binds
 
   case bind of
     NonRec _ _ ->
diff --git a/testsuite/tests/callarity/unittest/CallArity1.stderr b/testsuite/tests/callarity/unittest/CallArity1.stderr
index 801b659908..1beddb3ec2 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.stderr
+++ b/testsuite/tests/callarity/unittest/CallArity1.stderr
@@ -1,82 +1,82 @@
 go2:
-    go ω*C^ω(C^1(U))
+    go w*C^w(C^1(U))
     d 1*C^1(U)
 nested_go2:
-    go ω*C^ω(C^1(U))
+    go w*C^w(C^1(U))
     go2 1*C^1(C^1(U))
     d 1*C^1(U)
     n 1*C^1(U)
 d0 (go _*C^1(C^1(U)) would be bad):
-    go ω*U
-    d ω*U
+    go w*U
+    d w*U
 go2 (in case crut):
-    go ω*C^ω(C^1(U))
+    go w*C^w(C^1(U))
     d 1*C^1(U)
 go2 (in function call):
-    go ω*C^ω(C^1(U))
+    go w*C^w(C^1(U))
     d 1*C^1(U)
 go2 (using surrounding interesting let):
-    go ω*C^ω(C^1(U))
+    go w*C^w(C^1(U))
     d 1*C^1(U)
     n 1*C^1(U)
 two calls, one from let and from body (d 1*_ would be bad):
     go 1*C^1(C^1(U))
-    d ω*U
+    d w*U
 a thunk in a recursion (d 1*_ would be bad):
-    d ω*U
-    n ω*U
+    d w*U
+    n w*U
 two thunks, one called multiple times (both 1*_ would be bad!):
-    d ω*U
+    d w*U
     n 1*C^1(U)
 two functions, not thunks:
     go 1*C^1(C^1(U))
     go2 1*C^1(C^1(U))
 a thunk, called multiple times via a forking recursion (d 1*_ would be bad!):
-    go2 ω*C^ω(C^1(U))
-    d ω*U
+    go2 w*C^w(C^1(U))
+    d w*U
 a function, one called multiple times via a forking recursion:
-    go ω*C^ω(C^1(U))
-    go2 ω*C^ω(C^1(U))
+    go w*C^w(C^1(U))
+    go2 w*C^w(C^1(U))
 two functions (recursive):
-    go ω*C^ω(C^1(U))
-    go2 ω*C^ω(C^1(U))
+    go w*C^w(C^1(U))
+    go2 w*C^w(C^1(U))
 mutual recursion (thunks), called mutiple times (both 1*_ would be bad!):
-    d ω*U
-    n ω*U
+    d w*U
+    n w*U
 mutual recursion (functions), but no thunks:
-    go ω*C^ω(C^1(U))
-    go2 ω*C^ω(C^1(U))
+    go w*C^w(C^1(U))
+    go2 w*C^w(C^1(U))
 mutual recursion (functions), one boring (d 1*_ would be bad):
-    go ω*C^ω(C^1(U))
-    go2 ω*C^ω(C^1(U))
-    d ω*U
+    go w*C^w(C^1(U))
+    go2 w*C^w(C^1(U))
+    d w*U
 a thunk (non-function-type), called twice, still calls once:
-    x ω*U
+    x w*U
     d 1*C^1(U)
 a thunk (function type), called multiple times, still calls once:
     d 1*C^1(U)
-    n ω*U
-a thunk (non-function-type), in mutual recursion, still calls once (d ω*_ would be bad):
-    go ω*C^ω(C^1(U))
-    x ω*U
+    n w*U
+a thunk (non-function-type), in mutual recursion, still calls once (d w*_ would be bad):
+    go w*C^w(C^1(U))
+    x w*U
     d 1*C^1(U)
 a thunk (non-function-type), in mutual recursion, causes many calls (d 1*_ would be bad):
-    go ω*C^ω(C^1(U))
+    go w*C^w(C^1(U))
     x A
-    d ω*U
+    d w*U
 a thunk (function type), in mutual recursion, still calls once:
-    go ω*U
+    go w*U
     d 1*C^1(U)
-    n ω*U
+    n w*U
 a thunk (function type), in mutual recursion, absent:
-    go ω*U
+    go w*U
     d A
-    n ω*U
+    n w*U
 a thunk (non-function-type) co-calls with the body (d 1*_ would be bad):
     x 1*U
-    d ω*U
+    d w*U
 body cocalls d and n, n calls d (anything other than d w*C^w(U) = w*U would be bad):
-    d ω*U
+    d w*U
     n 1*C^1(U)
 body calls d and n mutually exclusive, n calls d. d should be called once:
     d 1*C^1(U)
-- 
2.12.1


From 34568cbe346b4a06bb99ab42cbad48dbf39913a5 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 28 Apr 2017 21:38:52 +0200
Subject: [PATCH 044/117] test cases for product usage

---
 compiler/simplCore/CallArity/Analysis.hs           |  3 --
 testsuite/tests/callarity/unittest/CallArity1.hs   | 50 ++++++++++++++++++----
 .../tests/callarity/unittest/CallArity1.stderr     |  7 ++-
 3 files changed, 48 insertions(+), 12 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 1ac5b9b974..cd17146ce7 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -471,7 +471,6 @@ callArityExpr _ e@(Type _) = callArityExprTrivial e
 callArityExpr _ e@(Coercion _) = callArityExprTrivial e
 
 -- The transparent cases
--- TODO: What if @tickishIsCode@? See CoreArity. Although DmdAnal doesn't handle it
 callArityExpr env (Tick t e) = callArityExprMap env (Tick t) e
 callArityExpr env (Cast e c) = callArityExprMap env (flip Cast c) e
 
@@ -536,8 +535,6 @@ callArityExpr env (App f a) = do
     -- peel off one argument from the type
     let (arg_usage, ut_f') = peelArgUsage ut_f
     case arg_usage of
-      -- TODO: Visit a, too? Seems unnecessary, wasn't called at all and
-      -- should be taken care of by WW.
       Absent -> return (ut_f', App f' a)
       Used _ arg_use -> do
           -- We can ignore the multiplicity, as the work done before the first
diff --git a/testsuite/tests/callarity/unittest/CallArity1.hs b/testsuite/tests/callarity/unittest/CallArity1.hs
index b6af62aba9..4ee56fbd3e 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.hs
+++ b/testsuite/tests/callarity/unittest/CallArity1.hs
@@ -1,10 +1,11 @@
 {-# LANGUAGE TupleSections #-}
+import BasicTypes
 import CoreSyn
 import CoreUtils
 import Id
 import Type
 import MkCore
-import CallArity.Analysis (callArityRHS)
+import CallArity.Analysis ( callArityRHS )
 import MkId
 import SysTools
 import DynFlags
@@ -15,7 +16,7 @@ import Literal
 import GHC
 import Control.Monad
 import Control.Monad.IO.Class
-import System.Environment( getArgs )
+import System.Environment ( getArgs )
 import VarSet
 import PprCore
 import Unique
@@ -25,9 +26,9 @@ import FastString
 import FamInstEnv
 
 -- Build IDs. use mkTemplateLocal, more predictable than proper uniques
-go, go2, x, d, n, y, z, scrutf, scruta :: Id
-[go, go2, x,d, n, y, z, scrutf, scruta, f] = mkTestIds
-    (words "go go2 x d n y z scrutf scruta f")
+go, go2, x, d, n, y, z, scrutf, scruta, f, p, _1, _2 :: Id
+[go, go2, x,d, n, y, z, scrutf, scruta, f, p, _1, _2] = mkTestIds
+    (words "go go2 x d n y z scrutf scruta f p _1 _2")
     [ mkFunTys [intTy, intTy] intTy
     , mkFunTys [intTy, intTy] intTy
     , intTy
@@ -37,9 +38,15 @@ go, go2, x, d, n, y, z, scrutf, scruta :: Id
     , intTy
     , mkFunTys [boolTy] boolTy
     , boolTy
-    , mkFunTys [intTy, intTy] intTy -- protoypical external function
+    , mkFunTys [intTy, intTy] intTy -- protoypical external function, for which there is no signature info
+    , pairType -- implicitly bound to a case binder when matching a pair
+    , mkFunTys [intTy] intTy
+    , mkFunTys [intTy] intTy
     ]
 
+pairType :: Type
+pairType = mkBoxedTupleTy [mkFunTys [intTy] intTy, mkFunTys [intTy] intTy]
+
 exprs :: [(String, CoreExpr)]
 exprs =
   [ ("go2",) $ --pprTraceIt "go2" $
@@ -136,7 +143,7 @@ exprs =
     mkNrLet d (f `mkLApps` [0]) $
         mkNrLet n (Var f `mkApps` [d `mkLApps` [1]]) $
             mkLams [x] $ Var n `mkVarApps` [x]
-  , ("a thunk (non-function-type), in mutual recursion, still calls once (d ω*_ would be bad)",) $
+  , ("a thunk (non-function-type), in mutual recursion, still calls once (d w*_ would be bad)",) $
     mkNrLet d (f `mkLApps` [0]) $
         Let (Rec [ (x, Var d `mkApps` [go `mkLApps` [1,2]])
                  , (go, mkLams [y] $ mkACase (mkLams [z] $ Var x) (Var go `mkVarApps` [x]) ) ]) $
@@ -167,7 +174,16 @@ exprs =
   , ("body calls d and n mutually exclusive, n calls d. d should be called once",) $
     mkNrLet d (f `mkLApps` [0]) $
         mkLet n (mkLams [y] $ d `mkLApps` [1]) $
-          mkACase (d `mkLApps` [0]) (n `mkLApps` [0])
+            mkACase (d `mkLApps` [0]) (n `mkLApps` [0])
+  -- Product related tests
+  , ("calling the first tuple component once",) $
+    mkLet d (f `mkLApps` [0]) $
+        mkLet n (mkLams [y] $ d `mkLApps` [1]) $
+            elimPair (mkVarPair d n) (_1 `mkLApps` [0])
+  , ("calling the second tuple component twice (expect n 1*U and d w*U by transitivity)",) $
+    mkLet d (f `mkLApps` [0]) $
+        mkLet n (mkLams [y] $ d `mkLApps` [1]) $
+            elimPair (mkVarPair d n) (Var _2 `mkApps` [_2 `mkLApps` [0]])
   ]
 
 main = do
@@ -215,6 +231,24 @@ mkRFun v xs rhs body = mkRLet v (mkLams xs rhs) body
 mkLit :: Integer -> CoreExpr
 mkLit i = Lit (mkLitInteger i intTy)
 
+pairDataCon :: DataCon
+pairDataCon = tupleDataCon Boxed 2
+
+mkPair :: CoreExpr -> CoreExpr -> CoreExpr
+mkPair fst snd = mkCoreConApps pairDataCon
+  [Type (CoreUtils.exprType fst)
+  , Type (CoreUtils.exprType snd)
+  , fst
+  , snd
+  ]
+
+elimPair :: CoreExpr -> CoreExpr -> CoreExpr
+elimPair pair alt
+  = Case pair p (CoreUtils.exprType alt) [(DataAlt pairDataCon, [_1, _2], alt)]
+
+mkVarPair :: Id -> Id -> CoreExpr
+mkVarPair fst snd = mkPair (Var fst) (Var snd)
+
 -- Collects all let-bound IDs
 allBoundIds :: CoreExpr -> VarSet
 allBoundIds (Let (NonRec v rhs) body) = allBoundIds rhs `unionVarSet` allBoundIds body `extendVarSet` v
diff --git a/testsuite/tests/callarity/unittest/CallArity1.stderr b/testsuite/tests/callarity/unittest/CallArity1.stderr
index 1beddb3ec2..2d02a30dbb 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.stderr
+++ b/testsuite/tests/callarity/unittest/CallArity1.stderr
@@ -81,4 +81,9 @@ body cocalls d and n, n calls d (anything other than d w*C^w(U) = w*U would be b
 body calls d and n mutually exclusive, n calls d. d should be called once:
     d 1*C^1(U)
     n 1*C^1(U)
-
+calling the first tuple component once:
+    d 1*C^1(U)
+    n A
+calling the second tuple component twice (expect n 1*U and d w*U by transitivity):
+    d w*U
+    n 1*U
-- 
2.12.1


From 315dc780a836d57a17a97d4dbf63be38b6178cb4 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 1 May 2017 17:13:04 +0200
Subject: [PATCH 045/117] Hit the boundDepth bug on infinite binary trees. Also
 made sure we never let variables escape their scope

---
 compiler/coreSyn/CoreArity.hs                    | 12 ++++--
 compiler/simplCore/CallArity/Analysis.hs         | 48 ++++++++++++++----------
 compiler/simplCore/SimplUtils.hs                 | 13 +++++--
 testsuite/tests/callarity/unittest/CallArity1.hs | 34 +++++++++--------
 4 files changed, 64 insertions(+), 43 deletions(-)

diff --git a/compiler/coreSyn/CoreArity.hs b/compiler/coreSyn/CoreArity.hs
index 88c3a7abaf..f7d0a2f6e6 100644
--- a/compiler/coreSyn/CoreArity.hs
+++ b/compiler/coreSyn/CoreArity.hs
@@ -559,7 +559,7 @@ rhsEtaExpandArity :: DynFlags -> CheapAppFun -> CoreExpr -> Arity
 rhsEtaExpandArity dflags cheap_app e
   = case (arityType env e) of
       ATop (os:oss)
-        | isOneShotInfo os || has_lam e -> 1 + length oss
+        | isOneShotInfo os || has_lam e || is_cheap_case e -> 1 + length oss
                                    -- Don't expand PAPs/thunks
                                    -- Note [Eta expanding thunks]
         | otherwise       -> 0
@@ -573,6 +573,10 @@ rhsEtaExpandArity dflags cheap_app e
     has_lam (Lam b e)  = isId b || has_lam e
     has_lam _          = False
 
+    -- If the case wasn't cheap, the arityType would return ATop 0.
+    is_cheap_case Case{} = True
+    is_cheap_case _ = False
+
 {-
 Note [Arity analysis]
 ~~~~~~~~~~~~~~~~~~~~~
@@ -634,9 +638,9 @@ We don't eta-expand
 When we see
      f = case y of p -> \x -> blah
 should we eta-expand it? Well, if 'x' is a one-shot state token
-then 'yes' because 'f' will only be applied once.  But otherwise
-we (conservatively) say no.  My main reason is to avoid expanding
-PAPSs
+then 'yes' because 'f' will only be applied once. Also if 'y' is cheap to
+compute. But otherwise we (conservatively) say no.  My main reason is to avoid
+expanding PAPs
         f = g d  ==>  f = \x. g d x
 because that might in turn make g inline (if it has an inline pragma),
 which we might not want.  After all, INLINE pragmas say "inline only
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index cd17146ce7..5139b23129 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -1,10 +1,12 @@
-{-# LANGUAGE TupleSections #-}
+{-# LANGUAGE CPP, TupleSections #-}
 --
 -- Copyright (c) 2014 Joachim Breitner
 --
 
 module CallArity.Analysis where
 
+#include "HsVersions.h"
+
 import CallArity.Types
 import CallArity.FrameworkBuilder
 
@@ -21,6 +23,7 @@ import TyCon ( isDataProductTyCon_maybe )
 import UniqFM
 import UnVarGraph
 import Usage
+import Util
 import Var ( isId, isTyVar )
 import VarEnv
 import WwLib ( findTypeShape )
@@ -439,7 +442,9 @@ callArityAnalProgram _dflags fam_envs
 
 callArityRHS :: FamInstEnvs -> CoreExpr -> CoreExpr
 callArityRHS fam_envs e
-  = snd (buildAndRun (callArityExpr (initialAnalEnv fam_envs) e) topSingleUse)
+  = ASSERT2( isEmptyUnVarSet (domType ut), text "Free vars in UsageType:" $$ ppr ut ) e'
+  where
+    (ut, e') = buildAndRun (callArityExpr (initialAnalEnv fam_envs) e) topSingleUse
 
 -- | The main analysis function. See Note [Analysis type signature]
 callArityExpr
@@ -498,10 +503,10 @@ callArityExpr env e@(Var id) = return transfer
       = return (emptyUsageType { ut_args = globalIdUsageSig id use }, e)
 
       | otherwise
-      -- An interesting LocalId, not present in @nodes@, e.g. a lambda-bound variable.
+      -- A LocalId not present in @nodes@, e.g. a lambda or case-bound variable.
       -- We are only second-order, so we don't model signatures for parameters!
       -- Their usage is interesting to note nonetheless for annotating lambda
-      -- binders.
+      -- binders and scrutinees.
       = return (unitUsageType id use, e)
 
 callArityExpr env (Lam id body)
@@ -554,12 +559,11 @@ callArityExpr env (Case scrut case_bndr ty alts) = do
     (ut_alts, alts', scrut_uses) <- unzip3 <$> mapM ($ use) transfer_alts
     let ut_alt = lubUsageTypes ut_alts
     let case_bndr' = setIdCallArity case_bndr (lookupUsage ut_alt case_bndr)
+    let ut_alt' = delUsageType case_bndr ut_alt
     let scrut_use = propagateProductUse alts' scrut_uses
     (ut_scrut, scrut') <- transfer_scrut scrut_use
-    let ut = ut_alt `bothUsageType` ut_scrut
-    -- pprTrace "callArityExpr:Case"
-    --          (vcat [ppr scrut, ppr ut])
-    --pprTrace "Case" (vcat [text "ut_scrut:" <+> ppr ut_scrut, text "ut_alts:" <+> ppr ut_alts, text "cat:" <+> ppr cat]) (return ())
+    let ut = ut_alt' `bothUsageType` ut_scrut
+    --pprTrace "Case" (vcat [text "ut_scrut:" <+> ppr ut_scrut, text "ut_alts:" <+> ppr ut_alts, text "ut:" <+> ppr ut]) (return ())
     return (ut, Case scrut' case_bndr' ty alts')
 
 callArityExpr env (Let bind e) = do
@@ -597,7 +601,7 @@ callArityExpr env (Let bind e) = do
             change_detector changed_refs (old, _) (new, _) =
               -- since we only care for arity and called once information of the
               -- previous iteration, we can efficiently test for changes.
-              --pprTrace "change_detector" (vcat[ppr node, ppr changed_refs, ppr old, ppr new])
+              --pprTrace "change_detector" (vcat[ppr node, ppr changed_refs, ppr old, ppr new]) $
               map fst (Set.toList changed_refs) /= [node]
               || any (\id -> lookupUsage old id /= lookupUsage new id) ids
 
@@ -731,7 +735,7 @@ propagateProductUse alts scrut_uses
   -- This is a good place to make sure we don't construct an infinitely depth
   -- use, which can happen when analysing e.g. lazy streams.
   -- Also see Note [Demand on scrutinee of a product case] in DmdAnal.hs.
-  = addDataConStrictness dc (boundDepth 100 scrut_use)
+  = addDataConStrictness dc (boundDepth 5 scrut_use)
 
   | otherwise
   -- We *could* lub the uses from the different branches, but there's not much
@@ -829,18 +833,22 @@ unleashCall is_recursive ut_scope (id, rhs) transfer_rhs
       . lookupUsage ut_scope
       $ id
     apply_when b f = if b then f else Prelude.id
+    -- make_usage_sig is used for exported globals only. Note that in the case
+    -- where idArity id == 0, there is no interesting @UsageSig@ to be had.
+    -- In that case we *could* try to analyze with arity 1, just for the
+    -- signature.
+    -- TODO: Think harder about UsageSigs and how they should be handled with
+    -- Used Many.
+    -- Also we can't eta-expand beyond idArity anyway (exported!), so our best
+    -- bet is a single call with idArity.
+    single_call = iterate (mkCallUse Once) topSingleUse !! idArity id
+    make_usage_sig use = ut_args . fst <$> transfer_rhs use
     analyse use = do
       (ut_rhs, rhs') <- transfer_rhs use
-      -- sig is used for exported globals only. Note that in the case where
-      -- idArity id == 0, there is no interesting @UsageSig@ to be had.
-      -- In that case we *could* try to analyze with arity 1, just for the
-      -- signature.
-      -- TODO: Think harder about UsageSigs and how they should be handled with
-      -- Used Many.
-      -- Also we can't eta-expand beyond idArity anyway (exported!), so our best
-      -- bet is a single call with idArity.
-      let single_call = iterate (mkCallUse Once) topSingleUse !! idArity id
-      usage_sig <- ut_args . fst <$> transfer_rhs single_call
+      usage_sig <-
+        if isExportedId id
+          then make_usage_sig single_call
+          else return topUsageSig
       let id' = id
             `setIdCallArity` usage_id -- How the binder was used
             `setIdArgUsage` usage_sig -- How a single call uses its args
diff --git a/compiler/simplCore/SimplUtils.hs b/compiler/simplCore/SimplUtils.hs
index 8713b3d773..4366e6b1d9 100644
--- a/compiler/simplCore/SimplUtils.hs
+++ b/compiler/simplCore/SimplUtils.hs
@@ -1428,10 +1428,7 @@ tryEtaExpandRhs env is_rec bndr rhs
       = return (exprArity rhs, rhs)
 
       | sm_eta_expand (getMode env)      -- Provided eta-expansion is on
-      , let trivial_arity = findRhsArity dflags bndr rhs old_arity
-            cheap_arity
-              | exprIsCheap rhs = max 1 trivial_arity
-              | otherwise = trivial_arity
+      , let cheap_arity = findRhsArity dflags bndr rhs old_arity
             usage = idCallArity bndr
             expanded_arity = expandArity usage cheap_arity
             -- See Note [Trimming arity]
@@ -1442,6 +1439,14 @@ tryEtaExpandRhs env is_rec bndr rhs
                              ppr bndr)
                 return (old_arity, rhs)
            else do { tick (EtaExpansion bndr)
+                   ; pprTrace "tryEtaExpandRhs" (vcat
+                       [ ppr bndr
+                       , text "old_arity: " <> ppr old_arity
+                       , text "cheap_arity: " <> ppr cheap_arity
+                       , text "usage: " <> ppr usage
+                       , text "expanded_arity: " <> ppr expanded_arity
+                       , text "new_arity: " <> ppr new_arity
+                       ]) (return ())
                    ; return (new_arity, etaExpand new_arity rhs) }
       | otherwise
       = return (old_arity, rhs)
diff --git a/testsuite/tests/callarity/unittest/CallArity1.hs b/testsuite/tests/callarity/unittest/CallArity1.hs
index 4ee56fbd3e..4917afaa7e 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.hs
+++ b/testsuite/tests/callarity/unittest/CallArity1.hs
@@ -24,11 +24,12 @@ import UniqSet
 import CoreLint
 import FastString
 import FamInstEnv
+import Name
 
 -- Build IDs. use mkTemplateLocal, more predictable than proper uniques
-go, go2, x, d, n, y, z, scrutf, scruta, f, p, _1, _2 :: Id
-[go, go2, x,d, n, y, z, scrutf, scruta, f, p, _1, _2] = mkTestIds
-    (words "go go2 x d n y z scrutf scruta f p _1 _2")
+go, go2, x, d, n, y, z, p, _1, _2 :: Id
+[go,go2, x, d, n, y, z, p, _1, _2] = mkLocalTestIds
+    (words "go go2 x d n y z p _1 _2")
     [ mkFunTys [intTy, intTy] intTy
     , mkFunTys [intTy, intTy] intTy
     , intTy
@@ -36,14 +37,14 @@ go, go2, x, d, n, y, z, scrutf, scruta, f, p, _1, _2 :: Id
     , mkFunTys [intTy] intTy
     , intTy
     , intTy
-    , mkFunTys [boolTy] boolTy
-    , boolTy
-    , mkFunTys [intTy, intTy] intTy -- protoypical external function, for which there is no signature info
     , pairType -- implicitly bound to a case binder when matching a pair
-    , mkFunTys [intTy] intTy
-    , mkFunTys [intTy] intTy
+    , mkFunTys [intTy] intTy -- fst pair selector, implicitly bound in case match
+    , mkFunTys [intTy] intTy -- snd pair selector
     ]
 
+f :: Id -- protoypical external function, for which there is no signature info
+f = mkGlobalTestId 42 "f" (mkFunTys [intTy, intTy] intTy)
+
 pairType :: Type
 pairType = mkBoxedTupleTy [mkFunTys [intTy] intTy, mkFunTys [intTy] intTy]
 
@@ -192,7 +193,7 @@ main = do
         getSessionDynFlags >>= setSessionDynFlags . flip gopt_set Opt_SuppressUniques
         dflags <- getSessionDynFlags
         liftIO $ forM_ exprs $ \(n,e) -> do
-            case lintExpr dflags [f,scrutf,scruta] e of
+            case lintExpr dflags [f] e of
                 Just msg -> putMsg dflags (msg $$ text "in" <+> text n)
                 Nothing -> return ()
             putMsg dflags (text n <> char ':')
@@ -208,13 +209,16 @@ main = do
 mkLApps :: Id -> [Integer] -> CoreExpr
 mkLApps v = mkApps (Var v) . map mkLit
 
-mkACase = mkIfThenElse (mkVarApps (Var scrutf) [scruta])
+mkACase = mkIfThenElse (Var trueDataConId)
+
+mkLocalTestId :: Int -> String -> Type -> Id
+mkLocalTestId i s ty = mkSysLocal (mkFastString s) (mkBuiltinUnique i) ty
 
-mkTestId :: Int -> String -> Type -> Id
-mkTestId i s ty = mkSysLocal (mkFastString s) (mkBuiltinUnique i) ty
+mkLocalTestIds :: [String] -> [Type] -> [Id]
+mkLocalTestIds ns tys = zipWith3 mkLocalTestId [0..] ns tys
 
-mkTestIds :: [String] -> [Type] -> [Id]
-mkTestIds ns tys = zipWith3 mkTestId [0..] ns tys
+mkGlobalTestId :: Int -> String -> Type -> Id
+mkGlobalTestId i s ty = mkVanillaGlobal (mkSystemVarName (mkBuiltinUnique i) (mkFastString s)) ty
 
 mkNrLet :: Id -> CoreExpr -> CoreExpr -> CoreExpr
 mkNrLet v rhs body = Let (NonRec v rhs) body
@@ -236,7 +240,7 @@ pairDataCon = tupleDataCon Boxed 2
 
 mkPair :: CoreExpr -> CoreExpr -> CoreExpr
 mkPair fst snd = mkCoreConApps pairDataCon
-  [Type (CoreUtils.exprType fst)
+  [ Type (CoreUtils.exprType fst)
   , Type (CoreUtils.exprType snd)
   , fst
   , snd
-- 
2.12.1


From 5e3201563b14107f02343fffcbcfc1b58ce6f663 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 1 May 2017 23:12:27 +0200
Subject: [PATCH 046/117] Borrowing UsageSigs from Strictness

---
 compiler/basicTypes/Demand.hs            |  2 +-
 compiler/basicTypes/Usage.hs             | 35 +++++++++++++++++++++++++++++---
 compiler/simplCore/CallArity/Analysis.hs |  7 ++++++-
 compiler/simplCore/SimplUtils.hs         | 11 +++-------
 4 files changed, 42 insertions(+), 13 deletions(-)

diff --git a/compiler/basicTypes/Demand.hs b/compiler/basicTypes/Demand.hs
index 98b1915622..e0a591dd4c 100644
--- a/compiler/basicTypes/Demand.hs
+++ b/compiler/basicTypes/Demand.hs
@@ -8,7 +8,7 @@
 {-# LANGUAGE CPP, FlexibleInstances, TypeSynonymInstances, RecordWildCards #-}
 
 module Demand (
-        StrDmd, UseDmd(..), Count,
+        StrDmd, UseDmd(..), Count(..), ArgUse, Use (..),
 
         Demand, CleanDemand, getStrDmd, getUseDmd,
         mkProdDmd, mkOnceUsedDmd, mkManyUsedDmd, mkHeadStrict, oneifyDmd,
diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 69f4290f70..3f724bb982 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -6,9 +6,12 @@ module Usage
   , SingleUse
   , botSingleUse, topSingleUse, lubSingleUse, leqSingleUse, bothSingleUse, mkCallUse, peelCallUse, mkProductUse, peelProductUse, boundDepth
   , Usage (..)
-  , multiplicity, botUsage, topUsage, lubUsage, bothUsage, seqUsage, manifyUsage, expandArity
+  , multiplicity, botUsage, topUsage, lubUsage, bothUsage
+  , seqUsage
+  , manifyUsage, expandArity
   , UsageSig
-  , botUsageSig, topUsageSig, lubUsageSig, consUsageSig, unconsUsageSig, manifyUsageSig
+  , botUsageSig, topUsageSig, lubUsageSig
+  , consUsageSig, unconsUsageSig, usageSigFromUsages, manifyUsageSig, usageSigFromStrictSig
   , trimSingleUse, trimUsage, trimUsageSig
   ) where
 
@@ -16,7 +19,8 @@ module Usage
 
 import BasicTypes
 import Binary
-import Demand ( TypeShape(..) )
+import Demand ( TypeShape(..), StrictSig, splitStrictSig )
+import qualified Demand
 import Outputable
 import Util
 
@@ -320,12 +324,37 @@ unconsUsageSig BotUsageSig = (botUsage, BotUsageSig)
 unconsUsageSig TopUsageSig = (topUsage, TopUsageSig)
 unconsUsageSig (ArgUsage u s) = (u, s)
 
+usageSigFromUsages :: [Usage] -> UsageSig
+usageSigFromUsages = foldr consUsageSig topUsageSig
+
 -- | Maps @manifyUsage@ over each argument usage.
 manifyUsageSig :: UsageSig -> UsageSig
 manifyUsageSig TopUsageSig = TopUsageSig
 manifyUsageSig BotUsageSig = BotUsageSig
 manifyUsageSig (ArgUsage u s) = consUsageSig (manifyUsage u) (manifyUsageSig s)
 
+-- | For conveniently working with PrimOps. I've no nerve right now to go through
+-- all entries in primops.txt.pp.
+usageSigFromStrictSig :: StrictSig -> UsageSig
+usageSigFromStrictSig sig
+  = usageSigFromUsages (map (usageFromArgUse . Demand.getUseDmd) dmds)
+  where
+    (dmds, _) = splitStrictSig sig
+
+multiplicityFromCount :: Demand.Count -> Multiplicity
+multiplicityFromCount Demand.One = Once
+multiplicityFromCount Demand.Many = Many
+
+singleUseFromUseDmd :: Demand.UseDmd -> SingleUse
+singleUseFromUseDmd Demand.UHead = topSingleUse
+singleUseFromUseDmd (Demand.UCall c u) = mkCallUse (multiplicityFromCount c) (singleUseFromUseDmd u)
+singleUseFromUseDmd (Demand.UProd comps) = mkProductUse (map usageFromArgUse comps)
+singleUseFromUseDmd Demand.Used = botSingleUse
+
+usageFromArgUse :: Demand.ArgUse -> Usage
+usageFromArgUse Demand.Abs = Absent
+usageFromArgUse (Demand.Use c u) = Used (multiplicityFromCount c) (singleUseFromUseDmd u)
+
 -- | Trims a `UsageSig` by looking at how the associated value is used.
 --
 -- The resulting `UsageSig` will only have as many arguments as the `SingleUse` has
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 5139b23129..4f39bccc7d 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -643,13 +643,18 @@ dataConUsageSig arity use = fromMaybe botUsageSig sig_maybe
     sig_maybe = do
       product_use <- peelSingleShotCalls arity use
       component_usages <- peelProductUse arity product_use
-      return (foldr consUsageSig topUsageSig component_usages)
+      return (usageSigFromUsages component_usages)
 
 globalIdUsageSig :: Id -> SingleUse -> UsageSig
 globalIdUsageSig id use
   | use <= no_call -- @f x `seq` ...@ for a GlobalId `f` with arity > 1
   = botUsageSig
   | use <= single_call
+  , isPrimOpId id
+  -- Reusing the usage declarations in primops.txt.pp for the time being...
+  -- We would annotate them with something isomorphic anyway.
+  = usageSigFromStrictSig (idStrictness id)
+  | use <= single_call
   = idArgUsage id
   | otherwise
   = topUsageSig
diff --git a/compiler/simplCore/SimplUtils.hs b/compiler/simplCore/SimplUtils.hs
index 4366e6b1d9..87438f4012 100644
--- a/compiler/simplCore/SimplUtils.hs
+++ b/compiler/simplCore/SimplUtils.hs
@@ -1429,6 +1429,8 @@ tryEtaExpandRhs env is_rec bndr rhs
 
       | sm_eta_expand (getMode env)      -- Provided eta-expansion is on
       , let cheap_arity = findRhsArity dflags bndr rhs old_arity
+            -- The following four lines can go away if CoreArity was aware
+            -- of Usage information
             usage = idCallArity bndr
             expanded_arity = expandArity usage cheap_arity
             -- See Note [Trimming arity]
@@ -1439,14 +1441,7 @@ tryEtaExpandRhs env is_rec bndr rhs
                              ppr bndr)
                 return (old_arity, rhs)
            else do { tick (EtaExpansion bndr)
-                   ; pprTrace "tryEtaExpandRhs" (vcat
-                       [ ppr bndr
-                       , text "old_arity: " <> ppr old_arity
-                       , text "cheap_arity: " <> ppr cheap_arity
-                       , text "usage: " <> ppr usage
-                       , text "expanded_arity: " <> ppr expanded_arity
-                       , text "new_arity: " <> ppr new_arity
-                       ]) (return ())
+                   --; pprTrace "tryEtaExpandRhs" (vcat [ ppr bndr, text "old_arity: " <> ppr old_arity, text "cheap_arity: " <> ppr cheap_arity, text "usage: " <> ppr usage, text "expanded_arity: " <> ppr expanded_arity, text "new_arity: " <> ppr new_arity]) (return ())
                    ; return (new_arity, etaExpand new_arity rhs) }
       | otherwise
       = return (old_arity, rhs)
-- 
2.12.1


From 4605049324582345ae5c37f08607141810823ef8 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 4 May 2017 18:42:32 +0200
Subject: [PATCH 047/117] Intermediate commit, on bug hunt

---
 compiler/basicTypes/Usage.hs             |  6 +--
 compiler/simplCore/CallArity/Analysis.hs | 65 ++++++++++++++++++--------------
 compiler/simplCore/CallArity/Types.hs    | 14 ++++---
 3 files changed, 48 insertions(+), 37 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 3f724bb982..e745e56b29 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -186,7 +186,7 @@ lubUsageSig BotUsageSig s = s
 lubUsageSig s BotUsageSig = s
 lubUsageSig TopUsageSig _ = TopUsageSig
 lubUsageSig _ TopUsageSig = TopUsageSig
-lubUsageSig (ArgUsage u1 s1) (ArgUsage u2 s2) = ArgUsage (lubUsage u1 u2) (lubUsageSig s1 s2)
+lubUsageSig (ArgUsage u1 s1) (ArgUsage u2 s2) = consUsageSig (lubUsage u1 u2) (lubUsageSig s1 s2)
 
 -- * Working with `SingleUse`, `Usage` and `UsageSig`
 
@@ -235,10 +235,10 @@ boundDepth max_height use = snd (boundUse 0 use)
         impl height (Product comps)
           | height < max_height
           , (changed, comps') <- mapAndUnzip (boundUsage (height + 1)) comps
-          = (or changed, Product comps')
+          = (or changed, mkProductUse comps')
           | otherwise
           = (True, topSingleUse)
-        impl height (Call m u) = second (Call m) (boundUse height u)
+        impl height (Call m u) = second (mkCallUse m) (boundUse height u)
         impl _ u = (False, u)
 
 trimSingleUse :: TypeShape -> SingleUse -> SingleUse
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 4f39bccc7d..054cbb8331 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -490,6 +490,7 @@ callArityExpr env e@(Var id) = return transfer
         (ut_callee, _) <- dependOnWithDefault (botUsageType, e) (node, use)
         -- It is crucial that we only use ut_args here, as every other field
         -- might be unstable and thus too optimistic.
+        pprTrace "callArityExpr.Var" (vcat [ppr id, ppr use, ppr (ut_args ut_callee)]) (return ())
         return ((unitUsageType id use) { ut_args = ut_args ut_callee }, e)
 
       | isDataConWorkId id
@@ -536,7 +537,7 @@ callArityExpr env (App f a) = do
   transfer_a <- callArityExpr env a
   return $ \result_use -> do
     (ut_f, f') <- transfer_f (mkCallUse Once result_use)
-    --pprTrace "App:f'" (ppr (ut_f, f')) $ return ()
+    --pprTrace "App:f'" (ppr f') $ return ()
     -- peel off one argument from the type
     let (arg_usage, ut_f') = peelArgUsage ut_f
     case arg_usage of
@@ -558,7 +559,7 @@ callArityExpr env (Case scrut case_bndr ty alts) = do
   return $ \use -> do
     (ut_alts, alts', scrut_uses) <- unzip3 <$> mapM ($ use) transfer_alts
     let ut_alt = lubUsageTypes ut_alts
-    let case_bndr' = setIdCallArity case_bndr (lookupUsage ut_alt case_bndr)
+    let case_bndr' = setIdCallArity case_bndr (lookupUsage NonRecursive ut_alt case_bndr)
     let ut_alt' = delUsageType case_bndr ut_alt
     let scrut_use = propagateProductUse alts' scrut_uses
     (ut_scrut, scrut') <- transfer_scrut scrut_use
@@ -582,7 +583,7 @@ callArityExpr env (Let bind e) = do
       -- call id. Thus we also can spare to allocate a new @FrameworkNode@.
       return $ \use -> do
         (ut_body, e') <- transfer_body use
-        (ut, [(id', rhs')]) <- unleashLet False initial_binds transfer_rhs ut_body ut_body
+        (ut, [(id', rhs')]) <- unleashLet NonRecursive initial_binds transfer_rhs ut_body ut_body
         return (delUsageTypes (bindersOf bind) ut, Let (NonRec id' rhs') e')
     Rec _ -> do -- The binding group stored in the @Rec@ constructor is always the initial one!
       -- This is a little more complicated, as we'll introduce a new FrameworkNode
@@ -594,16 +595,17 @@ callArityExpr env (Let bind e) = do
               -- This is the actual fixed-point iteration: we depend on usage
               -- results from the previous iteration, defaulting to just the body.
               (ut_usage, Let (Rec old_bind) _) <- dependOnWithDefault (ut_body, Let bind e') (node, use)
-              (ut, bind') <- unleashLet True old_bind transfer_rhs ut_usage ut_body
+              (ut, bind') <- unleashLet Recursive old_bind transfer_rhs ut_usage ut_body
               return (ut, Let (Rec bind') e')
 
         let change_detector :: ChangeDetector
             change_detector changed_refs (old, _) (new, _) =
               -- since we only care for arity and called once information of the
               -- previous iteration, we can efficiently test for changes.
+              pprTrace "change_detector" (ppr ids) $
               --pprTrace "change_detector" (vcat[ppr node, ppr changed_refs, ppr old, ppr new]) $
               map fst (Set.toList changed_refs) /= [node]
-              || any (\id -> lookupUsage old id /= lookupUsage new id) ids
+              || any (\id -> lookupUsage Recursive old id /= lookupUsage Recursive new id) ids
 
         return (node, (transfer, change_detector))
 
@@ -693,7 +695,7 @@ findBndrUsage :: FamInstEnvs -> UsageType -> Id -> (UsageType, Usage)
 findBndrUsage fam_envs ut id
   = (delUsageType id ut, usage')
   where
-    usage = lookupUsage ut id
+    usage = lookupUsage NonRecursive ut id
     -- See Note [Trimming a demand to a type] in Demand.hs
     shape = findTypeShape fam_envs (idType id)
     usage' = trimUsage shape usage
@@ -731,7 +733,7 @@ propagateProductUse
   -> SingleUse
 propagateProductUse alts scrut_uses
   -- Only one alternative with a product constructor
-  | [(DataAlt dc, bndrs, rhs)] <- alts
+  | [(DataAlt dc, _, _)] <- alts
   , [scrut_use] <- scrut_uses
   , let tycon = dataConTyCon dc
   -- Don't include newtypes, as they aren't really constructors introducing
@@ -740,7 +742,7 @@ propagateProductUse alts scrut_uses
   -- This is a good place to make sure we don't construct an infinitely depth
   -- use, which can happen when analysing e.g. lazy streams.
   -- Also see Note [Demand on scrutinee of a product case] in DmdAnal.hs.
-  = addDataConStrictness dc (boundDepth 5 scrut_use)
+  = addDataConStrictness dc (boundDepth 3 scrut_use)
 
   | otherwise
   -- We *could* lub the uses from the different branches, but there's not much
@@ -758,7 +760,7 @@ addDataConStrictness dc use
     strs = dataConRepStrictness dc
     arity = length strs
 
-    add str Absent = Absent -- See the note; We want to eliminate these in WW.
+    add _ Absent = Absent -- See the note; We want to eliminate these in WW.
     add str usage@(Used _ _)
       | isMarkedStrict str = usage `bothUsage` seqUsage
       | otherwise = usage
@@ -778,31 +780,39 @@ registerBindingGroup env = go env emptyVarEnv
             (extendVarEnv nodes id node)
             binds
           transfer <- callArityExpr env' rhs
+          let transfer' use = do
+                pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return ()
+                ret@(ut_rhs, e) <- transfer use
+                pprTrace "unleashCall:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut_rhs)]) $ return ()
+                return ret
           let transfer_args use = dependOnWithDefault (botUsageType, rhs) (node, use)
-          let change_detector_args _ (old, _) (new, _) =
+          let change_detector_args node (old, _) (new, _) =
                 -- The only reason we split the transfer fuctions up is cheap
                 -- change detection for the arg usage case. This implies that
                 -- use sites of these sig nodes may only use the ut_args
                 -- component!
                 -- FIXME: Encode this in the FrameworkNode type somehow, but I
                 -- don't think it's worth the trouble.
-                --pprTrace "change_detector_down" (ppr (ut_args old) <+> ppr (ut_args new) <+> ppr (ut_args old /= ut_args new)) $
+                pprTrace "change_detector_down" (vcat [ppr node, ppr id, ppr (ut_args old <= ut_args new), ppr (lubUsageSig (ut_args old) (ut_args new)), ppr (ut_args old), ppr (ut_args new), ppr (ut_args old /= ut_args new)]) $
+                ASSERT2( ut_args old <= ut_args new, text "CallArity.change_detector_down: Not monotone" $$ ppr (ut_args old) $$ ppr (ut_args new) )
                 ut_args old /= ut_args new
+                  where
+                    a <= b = lubUsageSig a b == b
           let ret = (env', nodes') -- What we return from 'registerBindingGroup'
-          let full = (transfer, alwaysChangeDetector) -- What we register for @node@
+          let full = (transfer', alwaysChangeDetector) -- What we register for @node@
           let args = (transfer_args, change_detector_args) -- What we register for @arg_node@
           return ((ret, full), args) -- registerTransferFunction  will peel `snd`s away for registration
 
 unleashLet
-  :: Bool
+  :: RecFlag
   -> [(Id, CoreExpr)]
   -> ((Id, CoreExpr) -> SingleUse -> TransferFunction AnalResult)
   -> UsageType
   -> UsageType
   -> TransferFunction (UsageType, [(Id, CoreExpr)])
-unleashLet is_recursive binds transfer_rhs ut_usage ut_body = do
+unleashLet rec binds transfer_rhs ut_usage ut_body = do
   (ut_rhss, binds') <- fmap unzip $ forM binds $ \bind ->
-    unleashCall is_recursive ut_usage bind (transfer_rhs bind)
+    unleashCall rec ut_usage bind (transfer_rhs bind)
   -- Note that information flows from @unleashCall@ to @callArityLetEnv@
   -- via the annotated @binds'@!
   let ids = map fst binds'
@@ -812,12 +822,12 @@ unleashLet is_recursive binds transfer_rhs ut_usage ut_body = do
   return (ut_final, binds')
 
 unleashCall
-  :: Bool
+  :: RecFlag
   -> UsageType
   -> (Id, CoreExpr)
   -> (SingleUse -> TransferFunction AnalResult)
   -> TransferFunction (UsageType, (Id, CoreExpr))
-unleashCall is_recursive ut_scope (id, rhs) transfer_rhs
+unleashCall rec ut_scope (id, rhs) transfer_rhs
   | Absent <- usage_id
   = return (emptyUsageType, (id `setIdCallArity` Absent, rhs)) -- No call to @id@ (yet)
   | Used _ use <- usage_id
@@ -827,17 +837,14 @@ unleashCall is_recursive ut_scope (id, rhs) transfer_rhs
   -- we don't have to memoize the result.
   = analyse use
   where
-    usage_id = -- How @id@ was used in its scope.
-      -- See Note [Thunks in recursive groups]
-      -- @is_recursive@ implies more than one call (otherwise, why would it be
-      -- recursive?), although the co-call graph doesn't model it that way.
-      -- Self-edges in the co-call graph correspond to non-linear recursion.
-      -- Kind-of a leaky abstraction, maybe we could somehow merge the
-      -- @is_recursive@ flag into @UsageType@.
-      apply_when is_recursive manifyUsage
-      . lookupUsage ut_scope
-      $ id
-    apply_when b f = if b then f else Prelude.id
+    -- How @id@ was used in its scope.
+    -- See Note [Thunks in recursive groups]
+    -- @isRec rec@ implies more than one call (otherwise, why would it be
+    -- recursive?), although the co-call graph doesn't model it that way.
+    -- Self-edges in the co-call graph correspond to non-linear recursion.
+    -- Kind-of a leaky abstraction...
+    usage_id = lookupUsage rec ut_scope id
+
     -- make_usage_sig is used for exported globals only. Note that in the case
     -- where idArity id == 0, there is no interesting @UsageSig@ to be had.
     -- In that case we *could* try to analyze with arity 1, just for the
@@ -866,7 +873,7 @@ callArityLetEnv
   -> UsageType
   -> UsageType
 callArityLetEnv rhss ut_body
-    = --pprTrace "callArityLetEnv" (vcat [ppr rhss, ppr ut_body, ppr ut_new]) $
+    = pprTrace "callArityLetEnv" (vcat [ppr (map fst rhss), ppr (map snd rhss), ppr ut_body, ppr ut_new, ppr (map (lookupUsage Recursive ut_new . fst) rhss)]) $
       ut_new
   where
     (ids, ut_rhss) = unzip rhss
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index c50055d6c1..0e050f7f0e 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -1,6 +1,6 @@
 module CallArity.Types where
 
-import CoreArity ( typeArity )
+import BasicTypes
 import CoreSyn
 import Id
 import Outputable
@@ -58,14 +58,18 @@ domType :: UsageType -> UnVarSet
 domType ut = varEnvDom (ut_uses ut)
 
 makeIdArg :: Id -> UsageType -> UsageType
-makeIdArg id ut = delUsageType id (modifyArgs (consUsageSig (lookupUsage ut id)) ut)
+makeIdArg id ut = delUsageType id (modifyArgs (consUsageSig (lookupUsage NonRecursive ut id)) ut)
 
 -- In the result, find out the minimum arity and whether the variable is called
 -- at most once.
-lookupUsage :: UsageType -> Id -> Usage
-lookupUsage (UT g ae _) id = case lookupVarEnv ae id of
+lookupUsage :: RecFlag -> UsageType -> Id -> Usage
+lookupUsage rec (UT g ae _) id = case lookupVarEnv ae id of
   Just use
     | id `elemUnVarSet` neighbors g id -> Used Many use
+    -- we assume recursive bindings to be called multiple times, what's the
+    -- point otherwise? It's a little sad we don't encode it in the co-call
+    -- graph directly, though.
+    | isRec rec -> manifyUsage (Used Once use)
     | otherwise -> Used Once use
   Nothing -> botUsage
 
@@ -124,5 +128,5 @@ instance Outputable UsageType where
   ppr (UT cocalled arities args) = vcat
     [ text "arg usages:" <+> ppr args
     , text "co-calls:" <+> ppr cocalled
-    , text "arities:" <+> ppr arities
+    , text "uses:" <+> ppr arities
     ]
-- 
2.12.1


From 7255a527b22af9479a1ae244e4138d432187c68e Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 8 May 2017 18:28:47 +0200
Subject: [PATCH 048/117] Fixed fix-pointing (hopefully)

---
 compiler/ghc.cabal.in                            |   1 +
 compiler/ghc.mk                                  |   1 +
 compiler/simplCore/CallArity/Analysis.hs         | 143 ++++++++++----------
 compiler/simplCore/CallArity/FrameworkBuilder.hs |  10 +-
 compiler/simplCore/CallArity/Types.hs            |   1 +
 compiler/utils/Dequeue.hs                        | 162 +++++++++++++++++++++++
 compiler/utils/Worklist.hs                       | 105 +++++++++++----
 7 files changed, 323 insertions(+), 100 deletions(-)
 create mode 100644 compiler/utils/Dequeue.hs

diff --git a/compiler/ghc.cabal.in b/compiler/ghc.cabal.in
index 3aba59ad17..1d9f8ac339 100644
--- a/compiler/ghc.cabal.in
+++ b/compiler/ghc.cabal.in
@@ -481,6 +481,7 @@ Library
         Binary
         BooleanFormula
         BufWrite
+        Dequeue
         Digraph
         Encoding
         FastFunctions
diff --git a/compiler/ghc.mk b/compiler/ghc.mk
index 047055f577..59065c21d1 100644
--- a/compiler/ghc.mk
+++ b/compiler/ghc.mk
@@ -463,6 +463,7 @@ compiler_stage2_dll0_MODULES = \
 	CostCentre \
 	DataCon \
 	Demand \
+	Dequeue \
 	Digraph \
 	DriverPhases \
 	DynFlags \
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 054cbb8331..41d46b6a5d 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -490,7 +490,7 @@ callArityExpr env e@(Var id) = return transfer
         (ut_callee, _) <- dependOnWithDefault (botUsageType, e) (node, use)
         -- It is crucial that we only use ut_args here, as every other field
         -- might be unstable and thus too optimistic.
-        pprTrace "callArityExpr.Var" (vcat [ppr id, ppr use, ppr (ut_args ut_callee)]) (return ())
+        --pprTrace "callArityExpr.Var" (vcat [ppr id, ppr use, ppr (ut_args ut_callee)]) (return ())
         return ((unitUsageType id use) { ut_args = ut_args ut_callee }, e)
 
       | isDataConWorkId id
@@ -568,14 +568,16 @@ callArityExpr env (Case scrut case_bndr ty alts) = do
     return (ut, Case scrut' case_bndr' ty alts')
 
 callArityExpr env (Let bind e) = do
+  let fam_envs = ae_fam_envs env
   let initial_binds = flattenBinds [bind]
+  let ids = map fst initial_binds
   (env', nodes) <- registerBindingGroup env initial_binds
   let lookup_node id =
         expectJust ": the RHS of id wasn't registered" (lookupVarEnv nodes id)
   let transfer_rhs (id, rhs) use =
         dependOnWithDefault (botUsageType, rhs) (lookup_node id, use)
+  let transferred_bind b@(id, rhs) = (id, (rhs, transfer_rhs b))
   transfer_body <- callArityExpr env' e
-  let ids = map fst initial_binds
 
   case bind of
     NonRec _ _ ->
@@ -583,7 +585,8 @@ callArityExpr env (Let bind e) = do
       -- call id. Thus we also can spare to allocate a new @FrameworkNode@.
       return $ \use -> do
         (ut_body, e') <- transfer_body use
-        (ut, [(id', rhs')]) <- unleashLet NonRecursive initial_binds transfer_rhs ut_body ut_body
+        let transferred_binds = map transferred_bind initial_binds
+        (ut, [(id', rhs')]) <- unleashLet NonRecursive fam_envs transferred_binds ut_body ut_body
         return (delUsageTypes (bindersOf bind) ut, Let (NonRec id' rhs') e')
     Rec _ -> do -- The binding group stored in the @Rec@ constructor is always the initial one!
       -- This is a little more complicated, as we'll introduce a new FrameworkNode
@@ -591,18 +594,21 @@ callArityExpr env (Let bind e) = do
       node <- registerTransferFunction (LowerThan (minimum (eltsUFM nodes))) $ \node -> do
         let transfer :: SingleUse -> TransferFunction AnalResult
             transfer use = do
+              --use <- pprTrace "Rec:begin" (ppr ids) $ return use
               (ut_body, e') <- transfer_body use
               -- This is the actual fixed-point iteration: we depend on usage
               -- results from the previous iteration, defaulting to just the body.
               (ut_usage, Let (Rec old_bind) _) <- dependOnWithDefault (ut_body, Let bind e') (node, use)
-              (ut, bind') <- unleashLet Recursive old_bind transfer_rhs ut_usage ut_body
+              let transferred_binds = map transferred_bind old_bind
+              (ut, bind') <- unleashLet Recursive fam_envs transferred_binds ut_usage ut_body
+              --ut <- pprTrace "Rec:end" (ppr ids) $ return ut
               return (ut, Let (Rec bind') e')
 
         let change_detector :: ChangeDetector
             change_detector changed_refs (old, _) (new, _) =
               -- since we only care for arity and called once information of the
               -- previous iteration, we can efficiently test for changes.
-              pprTrace "change_detector" (ppr ids) $
+              --pprTrace "change_detector" (vcat[ppr ids, ppr node, ppr changed_refs]) $
               --pprTrace "change_detector" (vcat[ppr node, ppr changed_refs, ppr old, ppr new]) $
               map fst (Set.toList changed_refs) /= [node]
               || any (\id -> lookupUsage Recursive old id /= lookupUsage Recursive new id) ids
@@ -678,8 +684,8 @@ analyseCaseAlternative env case_bndr (dc, alt_bndrs, e)
     transfer transfer_alt use = do
       let fam_envs = ae_fam_envs env
       (ut_alt, e') <- transfer_alt use
-      let (ut_alt', alt_bndr_usages) = findBndrsUsages fam_envs ut_alt alt_bndrs
-      let (_, case_bndr_usage) = findBndrUsage fam_envs ut_alt case_bndr
+      let (ut_alt', alt_bndr_usages) = findBndrsUsages NonRecursive fam_envs ut_alt alt_bndrs
+      let (_, case_bndr_usage) = findBndrUsage NonRecursive fam_envs ut_alt case_bndr
       -- We have to combine usages of alts_bndrs with that of case_bndr.
       -- Usage info flows from case_bndr to alt_bndrs, but not the other way
       -- around! This means that we later on annotate case_bndr solely based
@@ -691,21 +697,21 @@ analyseCaseAlternative env case_bndr (dc, alt_bndrs, e)
       -- constructor. That's to be done when we finally match on dc.
       return (ut_alt', (dc, alt_bndrs', e'), product_use)
 
-findBndrUsage :: FamInstEnvs -> UsageType -> Id -> (UsageType, Usage)
-findBndrUsage fam_envs ut id
+findBndrUsage :: RecFlag -> FamInstEnvs -> UsageType -> Id -> (UsageType, Usage)
+findBndrUsage rec_flag fam_envs ut id
   = (delUsageType id ut, usage')
   where
-    usage = lookupUsage NonRecursive ut id
+    usage = lookupUsage rec_flag ut id
     -- See Note [Trimming a demand to a type] in Demand.hs
     shape = findTypeShape fam_envs (idType id)
     usage' = trimUsage shape usage
 
-findBndrsUsages :: FamInstEnvs -> UsageType -> [Var] -> (UsageType, [Usage])
-findBndrsUsages fam_envs ut = foldr step (ut, [])
+findBndrsUsages :: RecFlag -> FamInstEnvs -> UsageType -> [Var] -> (UsageType, [Usage])
+findBndrsUsages rec_flag fam_envs ut = foldr step (ut, [])
   where
     step b (ut, usages)
       | isId b
-      , (ut', usage) <- findBndrUsage fam_envs ut b
+      , (ut', usage) <- findBndrUsage rec_flag fam_envs ut b
       = (ut', usage:usages)
       | otherwise
       = (ut, usages)
@@ -742,7 +748,7 @@ propagateProductUse alts scrut_uses
   -- This is a good place to make sure we don't construct an infinitely depth
   -- use, which can happen when analysing e.g. lazy streams.
   -- Also see Note [Demand on scrutinee of a product case] in DmdAnal.hs.
-  = addDataConStrictness dc (boundDepth 3 scrut_use)
+  = addDataConStrictness dc (boundDepth 5 scrut_use)
 
   | otherwise
   -- We *could* lub the uses from the different branches, but there's not much
@@ -781,19 +787,23 @@ registerBindingGroup env = go env emptyVarEnv
             binds
           transfer <- callArityExpr env' rhs
           let transfer' use = do
-                pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return ()
+                --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
                 ret@(ut_rhs, e) <- transfer use
-                pprTrace "unleashCall:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut_rhs)]) $ return ()
+                --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut_rhs)]) $ return ret
+                return ret
+          let transfer_args use = do
+                --use <- pprTrace "args:begin" (ppr id <+> text "::" <+> ppr use) $ return use
+                ret@(ut, e) <- dependOnWithDefault (botUsageType, rhs) (node, use)
+                --ret <- pprTrace "args:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut)]) $ return ret
                 return ret
-          let transfer_args use = dependOnWithDefault (botUsageType, rhs) (node, use)
-          let change_detector_args node (old, _) (new, _) =
+          let change_detector_args nodes (old, _) (new, _) =
                 -- The only reason we split the transfer fuctions up is cheap
                 -- change detection for the arg usage case. This implies that
                 -- use sites of these sig nodes may only use the ut_args
                 -- component!
                 -- FIXME: Encode this in the FrameworkNode type somehow, but I
                 -- don't think it's worth the trouble.
-                pprTrace "change_detector_down" (vcat [ppr node, ppr id, ppr (ut_args old <= ut_args new), ppr (lubUsageSig (ut_args old) (ut_args new)), ppr (ut_args old), ppr (ut_args new), ppr (ut_args old /= ut_args new)]) $
+                --pprTrace "change_detector_down" (vcat [ppr node, ppr id, ppr (ut_args old <= ut_args new), ppr (lubUsageSig (ut_args old) (ut_args new)), ppr (ut_args old), ppr (ut_args new), ppr (ut_args old /= ut_args new)]) $
                 ASSERT2( ut_args old <= ut_args new, text "CallArity.change_detector_down: Not monotone" $$ ppr (ut_args old) $$ ppr (ut_args new) )
                 ut_args old /= ut_args new
                   where
@@ -805,66 +815,59 @@ registerBindingGroup env = go env emptyVarEnv
 
 unleashLet
   :: RecFlag
-  -> [(Id, CoreExpr)]
-  -> ((Id, CoreExpr) -> SingleUse -> TransferFunction AnalResult)
+  -> FamInstEnvs
+  -> [(Id, (CoreExpr, SingleUse -> TransferFunction AnalResult))]
   -> UsageType
   -> UsageType
   -> TransferFunction (UsageType, [(Id, CoreExpr)])
-unleashLet rec binds transfer_rhs ut_usage ut_body = do
-  (ut_rhss, binds') <- fmap unzip $ forM binds $ \bind ->
-    unleashCall rec ut_usage bind (transfer_rhs bind)
-  -- Note that information flows from @unleashCall@ to @callArityLetEnv@
-  -- via the annotated @binds'@!
-  let ids = map fst binds'
+unleashLet rec_flag fam_envs transferred_binds ut_usage ut_body = do
+  let (ids, transferred_rhss) = unzip transferred_binds
+  (ut_rhss, rhss') <- fmap unzip $ forM transferred_binds $ \(id, (rhs, transfer)) ->
+    unleashUsage rhs transfer (lookupUsage rec_flag ut_usage id)
   let ut_final = callArityLetEnv (zip ids ut_rhss) ut_body
-  -- @ut_final@ still tracks usages of @ids@. We still need them for identifying
-  -- the fixed-point!
-  return (ut_final, binds')
 
-unleashCall
-  :: RecFlag
-  -> UsageType
-  -> (Id, CoreExpr)
+  -- Now use that information to annotate binders.
+  let (_, usages) = findBndrsUsages rec_flag fam_envs ut_final ids
+  let ids' = setBndrsUsageInfo ids usages
+  ids'' <- forM (zip ids' transferred_rhss) $ \(id, (_, transfer)) ->
+    annotateExportedIdArgUsage id transfer
+
+  -- This intentionally still contains the @Id@s of the binding group, because
+  -- the recursive rule looks at their usages to determine stability.
+  return (ut_final, zip ids'' rhss')
+
+annotateExportedIdArgUsage
+  :: Id
   -> (SingleUse -> TransferFunction AnalResult)
-  -> TransferFunction (UsageType, (Id, CoreExpr))
-unleashCall rec ut_scope (id, rhs) transfer_rhs
-  | Absent <- usage_id
-  = return (emptyUsageType, (id `setIdCallArity` Absent, rhs)) -- No call to @id@ (yet)
-  | Used _ use <- usage_id
-  -- The work required to get the RHS of let-bindings to WHNF is shared among
-  -- all uses, so the multiplicity can be ignored *when analysing the RHS*.
-  -- We still annotate the binder with the multiplity, as @Once@ means
-  -- we don't have to memoize the result.
-  = analyse use
-  where
-    -- How @id@ was used in its scope.
-    -- See Note [Thunks in recursive groups]
-    -- @isRec rec@ implies more than one call (otherwise, why would it be
-    -- recursive?), although the co-call graph doesn't model it that way.
-    -- Self-edges in the co-call graph correspond to non-linear recursion.
-    -- Kind-of a leaky abstraction...
-    usage_id = lookupUsage rec ut_scope id
-
-    -- make_usage_sig is used for exported globals only. Note that in the case
-    -- where idArity id == 0, there is no interesting @UsageSig@ to be had.
+  -> TransferFunction Id
+annotateExportedIdArgUsage id transfer_rhs
+  | not (isExportedId id) = return id
+  | otherwise = do
+    -- We can't eta-expand beyond idArity anyway (exported!), so our best
+    -- bet is a single call with idArity.
+    -- Note that in the case where idArity id == 0, there is no interesting
+    -- @UsageSig@ to be had.
     -- In that case we *could* try to analyze with arity 1, just for the
     -- signature.
     -- TODO: Think harder about UsageSigs and how they should be handled with
     -- Used Many.
-    -- Also we can't eta-expand beyond idArity anyway (exported!), so our best
-    -- bet is a single call with idArity.
-    single_call = iterate (mkCallUse Once) topSingleUse !! idArity id
-    make_usage_sig use = ut_args . fst <$> transfer_rhs use
-    analyse use = do
-      (ut_rhs, rhs') <- transfer_rhs use
-      usage_sig <-
-        if isExportedId id
-          then make_usage_sig single_call
-          else return topUsageSig
-      let id' = id
-            `setIdCallArity` usage_id -- How the binder was used
-            `setIdArgUsage` usage_sig -- How a single call uses its args
-      return (ut_rhs, (id', rhs'))
+    let single_call = iterate (mkCallUse Once) topSingleUse !! idArity id
+    usage_sig <- ut_args . fst <$> transfer_rhs single_call
+    return (id `setIdArgUsage` usage_sig)
+
+unleashUsage
+  :: CoreExpr
+  -> (SingleUse -> TransferFunction AnalResult)
+  -> (Usage -> TransferFunction AnalResult)
+unleashUsage rhs transfer_rhs usage
+  | Absent <- usage
+  = return (emptyUsageType, rhs)
+  | Used _ use <- usage
+  -- The work required to get the RHS of let-bindings to WHNF is shared among
+  -- all use sites, so the multiplicity can be ignored *when analysing the RHS*.
+  -- We still annotate the binder with the multiplity later on, as @Once@ means
+  -- we don't have to memoize the result.
+  = transfer_rhs use
 
 -- Combining the results from body and rhs of a let binding
 -- See Note [Analysis II: The Co-Called analysis]
@@ -873,7 +876,7 @@ callArityLetEnv
   -> UsageType
   -> UsageType
 callArityLetEnv rhss ut_body
-    = pprTrace "callArityLetEnv" (vcat [ppr (map fst rhss), ppr (map snd rhss), ppr ut_body, ppr ut_new, ppr (map (lookupUsage Recursive ut_new . fst) rhss)]) $
+    = --pprTrace "callArityLetEnv" (vcat [ppr (map fst rhss), ppr (map snd rhss), ppr ut_body, ppr ut_new, ppr (map (lookupUsage Recursive ut_new . fst) rhss)]) $
       ut_new
   where
     (ids, ut_rhss) = unzip rhss
diff --git a/compiler/simplCore/CallArity/FrameworkBuilder.hs b/compiler/simplCore/CallArity/FrameworkBuilder.hs
index f31b2d64dc..4a60007a14 100644
--- a/compiler/simplCore/CallArity/FrameworkBuilder.hs
+++ b/compiler/simplCore/CallArity/FrameworkBuilder.hs
@@ -75,10 +75,10 @@ registerTransferFunction prio f = FB $ do
   return result
 
 dependOnWithDefault :: AnalResult -> (FrameworkNode, SingleUse) -> TransferFunction AnalResult
-dependOnWithDefault def which = do
-  --pprTrace "dependOnWithDefault:before" (text "node:" <+> ppr node <+> text "use:" <+> ppr use) $ return ()
-  res <- fromMaybe def <$> Worklist.dependOn which
-  --pprTrace "dependOnWithDefault:after" (vcat [text "node:" <+> ppr node, text "use:" <+> ppr use, text "res:" <+> ppr res]) $ return ()
+dependOnWithDefault def (node, use) = do
+  --use <- pprTrace "dependOnWithDefault:before" (text "node:" <+> ppr node <+> text "use:" <+> ppr use) $ return use
+  res <- fromMaybe def <$> Worklist.dependOn (node, use)
+  --res <- pprTrace "dependOnWithDefault:after" (vcat [text "node:" <+> ppr node, text "use:" <+> ppr use]) $ return res
   return res
 
 buildAndRun :: FrameworkBuilder (SingleUse -> TransferFunction AnalResult) -> SingleUse -> AnalResult
@@ -87,8 +87,6 @@ buildAndRun buildTransfer use = lookup_result (Worklist.runFramework fw (Set.sin
     (node, fw) = buildFramework $
       registerTransferFunction (LowerThan (FrameworkNode 0)) $ \node -> do
         transfer <- buildTransfer
-        -- We only get away with using alwaysChangeDetector because this won't
-        -- introduce a cycle.
         return (node, (transfer, Worklist.alwaysChangeDetector))
 
     lookup_result :: Map (FrameworkNode, SingleUse) AnalResult -> AnalResult
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index 0e050f7f0e..79453c05e5 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -69,6 +69,7 @@ lookupUsage rec (UT g ae _) id = case lookupVarEnv ae id of
     -- we assume recursive bindings to be called multiple times, what's the
     -- point otherwise? It's a little sad we don't encode it in the co-call
     -- graph directly, though.
+    -- See Note [Thunks in recursive groups]
     | isRec rec -> manifyUsage (Used Once use)
     | otherwise -> Used Once use
   Nothing -> botUsage
diff --git a/compiler/utils/Dequeue.hs b/compiler/utils/Dequeue.hs
new file mode 100644
index 0000000000..bbe5cc89cf
--- /dev/null
+++ b/compiler/utils/Dequeue.hs
@@ -0,0 +1,162 @@
+{-# LANGUAGE CPP #-}
+{- |
+Module      :  Data.Dequeue
+Description :  A typeclass and an implementation for double-ended queues.
+Copyright   :  (c) Henry Bucklow 2009-2010
+License     :  BSD3
+
+Maintainer  :  henry@elsie.org.uk
+Stability   :  provisional
+Portability :  portable
+
+A typeclass for double-ended queues, and an implementation of Banker's
+Dequeues, as described in Chris Okasaki's Purely Functional Data Structures.
+-}
+module Dequeue (
+    -- * The 'Dequeue' type class.
+    Dequeue(..),
+    -- * Banker's Dequeues
+    BankersDequeue,
+) where
+
+import Prelude hiding (foldl, foldr, foldl1, foldr1, length, last)
+
+import Control.Monad
+import Data.Foldable
+import Data.Maybe (listToMaybe)
+import qualified Data.List as List
+import Outputable (Outputable, ppr, text, (<+>))
+
+-- | A typeclass for double-ended queues.
+class Foldable q => Dequeue q where
+    -- | Generates an empty queue.
+    empty :: q a
+    -- | Returns 'True' if this queue is empty.
+    null :: q a -> Bool
+#if !MIN_VERSION_base(4,8,0)
+    -- | Returns the number of elements in this queue.
+    length :: q a -> Int
+#endif
+    -- | Returns the item on the front of the queue.
+    first :: q a -> Maybe a
+    -- | Returns the item on the end of the queue.
+    last :: q a -> Maybe a
+    -- | Returns the first n items from the front of the queue, in the order
+    --   they would be popped.
+    takeFront :: Int -> q a -> [a]
+    -- | Returns the last n items from the end of the queue, in the order they
+    --  would be popped.
+    takeBack :: Int -> q a -> [a]
+    -- | Pushes an item onto the front of the queue.
+    pushFront :: q a -> a -> q a
+    -- | Pops an item from the front of the queue.
+    popFront :: q a -> Maybe (a, q a)
+    -- | Pushes an item onto the back of the queue.
+    pushBack :: q a -> a -> q a
+    -- | Pops an item from the back of the queue.
+    popBack :: q a -> Maybe (a, q a)
+    -- | Converts a list into a queue.
+    fromList :: [a] -> q a
+
+-- | An implementation of Banker's Dequeues, as described in Chris Okasaki's
+--   Purely Functional Data Structures. The functions for the 'Dequeue'
+--   instance have the following complexities (where n is the 'length' of the
+--   queue):
+--
+--    * 'length': O(1)
+--
+--    * 'first': O(1)
+--
+--    * 'last': O(1)
+--
+--    * 'takeFront': O(n)
+--
+--    * 'takeBack': O(n)
+--
+--    * 'pushFront': O(1) amortised
+--
+--    * 'popFront': O(1) amortised
+--
+--    * 'pushBack': O(1) amortised
+--
+--    * 'popBack': O(1) amortised
+--
+--    * 'fromList': O(n)
+data BankersDequeue a = BankersDequeue Int [a] Int [a]
+
+instance Functor BankersDequeue where
+    fmap f (BankersDequeue sizeF front sizeR rear) =
+        BankersDequeue sizeF (fmap f front) sizeR (fmap f rear)
+
+instance Foldable BankersDequeue where
+    fold (BankersDequeue _ front _ rear) = fold (front ++ reverse rear)
+    foldMap f (BankersDequeue _ front _ rear) = foldMap f (front ++ reverse rear)
+    foldr f a (BankersDequeue _ front _ rear) = foldr f a (front ++ reverse rear)
+    foldl f a (BankersDequeue _ front _ rear) = foldl f a (front ++ reverse rear)
+    foldr1 f (BankersDequeue _ front _ rear) = foldr1 f (front ++ reverse rear)
+    foldl1 f (BankersDequeue _ front _ rear) = foldl1 f (front ++ reverse rear)
+#if MIN_VERSION_base(4,8,0)
+    length (BankersDequeue sizeF _ sizeR _) = sizeF + sizeR
+#endif
+
+instance Dequeue BankersDequeue where
+    empty = BankersDequeue 0 [] 0 []
+    null (BankersDequeue 0 [] 0 []) = True
+    null _ = False
+#if !MIN_VERSION_base(4,8,0)
+    length (BankersDequeue sizeF _ sizeR _) = sizeF + sizeR
+#endif
+    first (BankersDequeue _ [] _ [x]) = Just x
+    first (BankersDequeue _ front _ _) =  listToMaybe front
+    last (BankersDequeue _ [x] _ []) = Just x
+    last (BankersDequeue _ _ _ rear) = listToMaybe rear
+    takeFront i (BankersDequeue sizeF front _ rear) =
+        take i front ++ take (i - sizeF) (reverse rear)
+    takeBack i (BankersDequeue _ front sizeR rear) =
+        take i rear ++ take (i - sizeR) (reverse front)
+    pushFront (BankersDequeue sizeF front sizeR rear) x =
+        check $ BankersDequeue (sizeF + 1) (x : front) sizeR rear
+    popFront (BankersDequeue _ [] _ []) = Nothing
+    popFront (BankersDequeue _ [] _ [x]) = Just (x, empty)
+    popFront (BankersDequeue _ [] _ _) = error "Queue is too far unbalanced."
+    popFront (BankersDequeue sizeF (f : fs) sizeR rear) =
+        Just (f, check $ BankersDequeue (sizeF - 1) fs sizeR rear)
+    pushBack (BankersDequeue sizeF front sizeR rear) x =
+        check $ BankersDequeue sizeF front (sizeR + 1) (x : rear)
+    popBack (BankersDequeue _ [] _ []) = Nothing
+    popBack (BankersDequeue _ [x] _ []) = Just (x, empty)
+    popBack (BankersDequeue _ _ _ []) = error "Queue is too far unbalanced."
+    popBack (BankersDequeue sizeF front sizeR (r : rs)) =
+        Just (r, check $ BankersDequeue sizeF front (sizeR - 1) rs)
+    fromList list = check $ BankersDequeue (List.length list) list 0 []
+
+-- | The maximum number of times longer one half of a 'BankersDequeue' is
+--   permitted to be relative to the other.
+bqBalance :: Int
+bqBalance = 4
+
+-- | Checks to see if the queue is too far out of balance. If it is, it
+--   rebalances it.
+check :: BankersDequeue a -> BankersDequeue a
+check q@(BankersDequeue sizeF front sizeR rear)
+    | sizeF > c * sizeR + 1 =
+        let front' = take size1 front
+            rear' = rear ++ reverse (drop size1 front)
+        in
+        BankersDequeue size1 front' size2 rear'
+    | sizeR > c * sizeF + 1 =
+        let front' = front ++ reverse (drop size1 rear)
+            rear' = take size1 rear
+        in
+        BankersDequeue size2 front' size1 rear'
+    | otherwise = q
+    where
+        size1 = (sizeF + sizeR) `div` 2
+        size2 = (sizeF + sizeR) - size1
+        c = bqBalance
+
+instance Eq a => Eq (BankersDequeue a) where
+    queue1 == queue2 = toList queue1 == toList queue2
+
+instance Outputable a => Outputable (BankersDequeue a) where
+    ppr dq = text "Dequeue" <+> ppr (toList dq)
diff --git a/compiler/utils/Worklist.hs b/compiler/utils/Worklist.hs
index 7282fe0946..c9bb858eee 100644
--- a/compiler/utils/Worklist.hs
+++ b/compiler/utils/Worklist.hs
@@ -3,13 +3,16 @@
 {-# OPTIONS_GHC -funbox-strict-fields #-}
 module Worklist where
 
+import Control.Monad (forM_)
 import Control.Monad.Trans.State.Strict
 import Data.Map (Map)
 import qualified Data.Map as Map
 import Data.Set (Set)
 import qualified Data.Set as Set
-import Data.Maybe (fromMaybe)
-import Control.Monad (forM_)
+import Data.Maybe (isJust, fromMaybe)
+import Dequeue (BankersDequeue)
+import qualified Dequeue as Dequeue
+import Outputable
 
 newtype TransferFunction node lattice a
   = TFM (State (WorklistState node lattice) a)
@@ -47,13 +50,45 @@ emptyNodeInfo = NodeInfo Nothing Set.empty Set.empty
 
 type Graph node lattice = Map node (NodeInfo node lattice)
 
+data QueuedMap k v
+  = QueuedMap
+  { queue :: !(BankersDequeue k)
+  , mapping :: !(Map k v)
+  }
+
+emptyQueuedMap :: QueuedMap k v
+emptyQueuedMap = QueuedMap Dequeue.empty Map.empty
+
+enqueueUpdating :: Ord k => k -> v -> (v -> v) -> QueuedMap k v -> QueuedMap k v
+enqueueUpdating k v updater qm = qm { queue = queue', mapping = mapping' }
+  where
+    queue'
+      -- | Map.member k (mapping qm) = queue qm
+      | True = queue qm
+      | otherwise = Dequeue.pushBack (queue qm) k
+    mapping' = Map.alter (Just . maybe v updater) k (mapping qm)
+
+dequeue :: Ord k => QueuedMap k v -> (Maybe (k, v), QueuedMap k v)
+dequeue qm
+  -- | Just (k, queue') <- Dequeue.popFront (queue qm)
+  --, (mv, mapping') <- Map.updateLookupWithKey (\_ _ -> Nothing) k (mapping qm)
+  | Just ((k, v), mapping') <- Map.maxViewWithKey (mapping qm)
+  -- = case mv of
+      -- Nothing -> pprPanic "queue and mapping should have the same keys" $
+        --ppr (length (queue qm)) <+> text " vs. " <+> ppr (Map.size (mapping qm))
+      --Just v -> (Just (k, v), qm { queue = queue', mapping = mapping' })
+  = (Just (k, v), qm { mapping = mapping' })
+  | otherwise
+  = (Nothing, qm)
+
 data WorklistState node lattice
   = WorklistState
-  { graph :: !(Graph node lattice)
+  { framework :: !(DataFlowFramework node lattice)
+  , graph :: !(Graph node lattice)
+  , unstable :: !(QueuedMap node (Set node)) -- unstable nodes and its changed references
   , callStack :: !(Set node)
   , referencedNodes :: !(Set node)
   , loopBreakers :: !(Set node)
-  , framework :: !(DataFlowFramework node lattice)
   }
 
 zoomGraph :: State (Graph node lattice) a -> State (WorklistState node lattice) a
@@ -61,6 +96,11 @@ zoomGraph modifyGraph = state $ \st ->
   let (res, g) = runState modifyGraph (graph st)
   in  (res, st { graph = g })
 
+zoomUnstable :: State (QueuedMap node (Set node)) a -> State (WorklistState node lattice) a
+zoomUnstable modifyUnstable = state $ \st ->
+  let (res, u) = runState modifyUnstable (unstable st)
+  in  (res, st { unstable = u })
+
 zoomReferencedNodes :: State (Set node) a -> State (WorklistState node lattice) a
 zoomReferencedNodes modifier = state $ \st ->
   let (res, rn) = runState modifier (referencedNodes st)
@@ -71,21 +111,34 @@ zoomLoopBreakers modifier = state $ \st ->
   let (res, lb) = runState modifier (loopBreakers st)
   in  (res, st { loopBreakers = lb })
 
-initialWorklistState :: DataFlowFramework node lattice -> WorklistState node lattice
-initialWorklistState = WorklistState Map.empty Set.empty Set.empty Set.empty
+initialWorklistState
+  :: QueuedMap node (Set node)
+  -> DataFlowFramework node lattice
+  -> WorklistState node lattice
+initialWorklistState unstable fw =
+  WorklistState fw Map.empty unstable Set.empty Set.empty Set.empty
 
 dependOn :: Ord node => node -> TransferFunction node lattice (Maybe lattice)
 dependOn node = TFM $ do
   loopDetected <- Set.member node <$> gets callStack
+  isNotYetStable <- Map.member node <$> gets (mapping . unstable)
   maybeNodeInfo <- Map.lookup node <$> gets graph
   zoomReferencedNodes (modify' (Set.insert node)) -- save that we depend on this value
   case maybeNodeInfo of
     Nothing | loopDetected -> do
       -- We have to revisit these later
       zoomLoopBreakers (modify' (Set.insert node))
+      --return (trace "Nothing, loop detected" Nothing)
       return Nothing
-    Nothing -> fmap (\(val, _, _) -> Just val) (recompute node)
-    Just info -> return (value info)
+    Nothing -> do
+      --fmap (\(val, _, _) -> Just val) (recompute (trace "Nothing, no loop" node))
+      fmap (\(val, _, _) -> Just val) (recompute node)
+--    Just _ | isNotYetStable && not loopDetected -> do
+--      fmap (\(val, _, _) -> Just val) (recompute (trace "Just, not stable" node))
+--    Just info | isNotYetStable -> do
+--      return (value (trace "Just, looping" info))
+    Just info -> do
+      return (value info)
 
 data Diff a
   = Diff
@@ -134,6 +187,7 @@ recompute node = do
   let (TFM transfer, changeDetector) = getTransfer (framework oldState) node
   val <- transfer
   refs <- gets referencedNodes
+  --pprTrace "recompute:refs" (ppr (length refs)) $ return ()
   oldInfo <- updateGraphNode node val refs
   modify' $ \st -> st
     { referencedNodes = referencedNodes oldState
@@ -141,23 +195,24 @@ recompute node = do
     }
   return (val, oldInfo, changeDetector)
 
-enqueue :: Ord node => node -> Set node -> Map node (Set node) -> Map node (Set node)
-enqueue reference referrers_ = Map.unionWith Set.union referrersMap
-  where
-    referrersMap = Map.fromSet (\_ -> Set.singleton reference) referrers_
+enqueueUnstable :: Ord node => node -> Set node -> State (WorklistState node lattice) ()
+enqueueUnstable reference referrers_ = zoomUnstable $ modify' $
+  enqueueUpdating reference referrers_ (Set.union referrers_)
 
-dequeue :: Map node (Set node) -> Maybe ((node, Set node), Map node (Set node))
-dequeue = Map.maxViewWithKey
+dequeueUnstable :: Ord node => State (WorklistState node lattice) (Maybe (node, Set node))
+dequeueUnstable = zoomUnstable (state dequeue)
 
 lookupReferrers :: Ord node => node -> Graph node lattice -> Set node
 lookupReferrers node = maybe Set.empty referrers . Map.lookup node
 
-work :: Ord node => Map node (Set node) -> State (WorklistState node lattice) ()
-work nodes =
-  case dequeue nodes of
+work :: Ord node => State (WorklistState node lattice) ()
+work = do
+  m <- dequeueUnstable
+  case m of
     Nothing -> return ()
-    Just ((node, changedRefs), nodes') -> do
-      modify' $ \st -> st { loopBreakers = Set.empty }
+    Just (node, changedRefs) -> do
+      modify' $ \st -> st { loopBreakers = Set.empty, callStack = Set.empty, referencedNodes = Set.empty }
+      --pprTrace "work:recompute" (text "len:" <+> ppr len) (pure ())
       (newVal, oldInfo, detectChange) <- recompute node
       -- We have to enqueue all referrers to loop breakers, e.g. nodes which we
       -- returned `Nothing` from `dependOn` to break cyclic dependencies.
@@ -166,10 +221,11 @@ work nodes =
       -- rare later on.
       g <- gets graph
       lbs <- gets loopBreakers
-      let nodes'' = Set.foldr (\lb -> enqueue lb (lookupReferrers lb g)) nodes' lbs
+      forM_ lbs (\lb -> enqueueUnstable lb (lookupReferrers lb g))
       case value oldInfo of
-        Just oldVal | not (detectChange changedRefs oldVal newVal) -> work nodes''
-        _ -> work (enqueue node (referrers oldInfo) nodes'')
+        Just oldVal | not (detectChange changedRefs oldVal newVal) -> return ()
+        _ -> forM_ (referrers oldInfo) (\ref -> enqueueUnstable ref (Set.singleton node))
+      work
 
 runFramework
   :: Ord node
@@ -178,5 +234,6 @@ runFramework
   -> Map node lattice
 runFramework framework_ interestingNodes = run framework_
   where
-    st = work (Map.fromSet (const Set.empty) interestingNodes)
-    run = Map.mapMaybe value . graph . execState st . initialWorklistState
+    queuedMapOf = foldr (\n -> enqueueUpdating n Set.empty (const Set.empty)) emptyQueuedMap
+    unstable = queuedMapOf interestingNodes
+    run = Map.mapMaybe value . graph . execState work . initialWorklistState unstable
-- 
2.12.1


From 817d37d67492822e8c5348860d0fdbf946af8409 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 8 May 2017 21:21:11 +0200
Subject: [PATCH 049/117] Removed the Dequeue related stuff again

---
 compiler/ghc.cabal.in      |   1 -
 compiler/ghc.mk            |   1 -
 compiler/utils/Dequeue.hs  | 162 ---------------------------------------------
 compiler/utils/Worklist.hs |  55 +++------------
 4 files changed, 10 insertions(+), 209 deletions(-)
 delete mode 100644 compiler/utils/Dequeue.hs

diff --git a/compiler/ghc.cabal.in b/compiler/ghc.cabal.in
index 1d9f8ac339..3aba59ad17 100644
--- a/compiler/ghc.cabal.in
+++ b/compiler/ghc.cabal.in
@@ -481,7 +481,6 @@ Library
         Binary
         BooleanFormula
         BufWrite
-        Dequeue
         Digraph
         Encoding
         FastFunctions
diff --git a/compiler/ghc.mk b/compiler/ghc.mk
index 59065c21d1..047055f577 100644
--- a/compiler/ghc.mk
+++ b/compiler/ghc.mk
@@ -463,7 +463,6 @@ compiler_stage2_dll0_MODULES = \
 	CostCentre \
 	DataCon \
 	Demand \
-	Dequeue \
 	Digraph \
 	DriverPhases \
 	DynFlags \
diff --git a/compiler/utils/Dequeue.hs b/compiler/utils/Dequeue.hs
deleted file mode 100644
index bbe5cc89cf..0000000000
--- a/compiler/utils/Dequeue.hs
+++ /dev/null
@@ -1,162 +0,0 @@
-{-# LANGUAGE CPP #-}
-{- |
-Module      :  Data.Dequeue
-Description :  A typeclass and an implementation for double-ended queues.
-Copyright   :  (c) Henry Bucklow 2009-2010
-License     :  BSD3
-
-Maintainer  :  henry@elsie.org.uk
-Stability   :  provisional
-Portability :  portable
-
-A typeclass for double-ended queues, and an implementation of Banker's
-Dequeues, as described in Chris Okasaki's Purely Functional Data Structures.
--}
-module Dequeue (
-    -- * The 'Dequeue' type class.
-    Dequeue(..),
-    -- * Banker's Dequeues
-    BankersDequeue,
-) where
-
-import Prelude hiding (foldl, foldr, foldl1, foldr1, length, last)
-
-import Control.Monad
-import Data.Foldable
-import Data.Maybe (listToMaybe)
-import qualified Data.List as List
-import Outputable (Outputable, ppr, text, (<+>))
-
--- | A typeclass for double-ended queues.
-class Foldable q => Dequeue q where
-    -- | Generates an empty queue.
-    empty :: q a
-    -- | Returns 'True' if this queue is empty.
-    null :: q a -> Bool
-#if !MIN_VERSION_base(4,8,0)
-    -- | Returns the number of elements in this queue.
-    length :: q a -> Int
-#endif
-    -- | Returns the item on the front of the queue.
-    first :: q a -> Maybe a
-    -- | Returns the item on the end of the queue.
-    last :: q a -> Maybe a
-    -- | Returns the first n items from the front of the queue, in the order
-    --   they would be popped.
-    takeFront :: Int -> q a -> [a]
-    -- | Returns the last n items from the end of the queue, in the order they
-    --  would be popped.
-    takeBack :: Int -> q a -> [a]
-    -- | Pushes an item onto the front of the queue.
-    pushFront :: q a -> a -> q a
-    -- | Pops an item from the front of the queue.
-    popFront :: q a -> Maybe (a, q a)
-    -- | Pushes an item onto the back of the queue.
-    pushBack :: q a -> a -> q a
-    -- | Pops an item from the back of the queue.
-    popBack :: q a -> Maybe (a, q a)
-    -- | Converts a list into a queue.
-    fromList :: [a] -> q a
-
--- | An implementation of Banker's Dequeues, as described in Chris Okasaki's
---   Purely Functional Data Structures. The functions for the 'Dequeue'
---   instance have the following complexities (where n is the 'length' of the
---   queue):
---
---    * 'length': O(1)
---
---    * 'first': O(1)
---
---    * 'last': O(1)
---
---    * 'takeFront': O(n)
---
---    * 'takeBack': O(n)
---
---    * 'pushFront': O(1) amortised
---
---    * 'popFront': O(1) amortised
---
---    * 'pushBack': O(1) amortised
---
---    * 'popBack': O(1) amortised
---
---    * 'fromList': O(n)
-data BankersDequeue a = BankersDequeue Int [a] Int [a]
-
-instance Functor BankersDequeue where
-    fmap f (BankersDequeue sizeF front sizeR rear) =
-        BankersDequeue sizeF (fmap f front) sizeR (fmap f rear)
-
-instance Foldable BankersDequeue where
-    fold (BankersDequeue _ front _ rear) = fold (front ++ reverse rear)
-    foldMap f (BankersDequeue _ front _ rear) = foldMap f (front ++ reverse rear)
-    foldr f a (BankersDequeue _ front _ rear) = foldr f a (front ++ reverse rear)
-    foldl f a (BankersDequeue _ front _ rear) = foldl f a (front ++ reverse rear)
-    foldr1 f (BankersDequeue _ front _ rear) = foldr1 f (front ++ reverse rear)
-    foldl1 f (BankersDequeue _ front _ rear) = foldl1 f (front ++ reverse rear)
-#if MIN_VERSION_base(4,8,0)
-    length (BankersDequeue sizeF _ sizeR _) = sizeF + sizeR
-#endif
-
-instance Dequeue BankersDequeue where
-    empty = BankersDequeue 0 [] 0 []
-    null (BankersDequeue 0 [] 0 []) = True
-    null _ = False
-#if !MIN_VERSION_base(4,8,0)
-    length (BankersDequeue sizeF _ sizeR _) = sizeF + sizeR
-#endif
-    first (BankersDequeue _ [] _ [x]) = Just x
-    first (BankersDequeue _ front _ _) =  listToMaybe front
-    last (BankersDequeue _ [x] _ []) = Just x
-    last (BankersDequeue _ _ _ rear) = listToMaybe rear
-    takeFront i (BankersDequeue sizeF front _ rear) =
-        take i front ++ take (i - sizeF) (reverse rear)
-    takeBack i (BankersDequeue _ front sizeR rear) =
-        take i rear ++ take (i - sizeR) (reverse front)
-    pushFront (BankersDequeue sizeF front sizeR rear) x =
-        check $ BankersDequeue (sizeF + 1) (x : front) sizeR rear
-    popFront (BankersDequeue _ [] _ []) = Nothing
-    popFront (BankersDequeue _ [] _ [x]) = Just (x, empty)
-    popFront (BankersDequeue _ [] _ _) = error "Queue is too far unbalanced."
-    popFront (BankersDequeue sizeF (f : fs) sizeR rear) =
-        Just (f, check $ BankersDequeue (sizeF - 1) fs sizeR rear)
-    pushBack (BankersDequeue sizeF front sizeR rear) x =
-        check $ BankersDequeue sizeF front (sizeR + 1) (x : rear)
-    popBack (BankersDequeue _ [] _ []) = Nothing
-    popBack (BankersDequeue _ [x] _ []) = Just (x, empty)
-    popBack (BankersDequeue _ _ _ []) = error "Queue is too far unbalanced."
-    popBack (BankersDequeue sizeF front sizeR (r : rs)) =
-        Just (r, check $ BankersDequeue sizeF front (sizeR - 1) rs)
-    fromList list = check $ BankersDequeue (List.length list) list 0 []
-
--- | The maximum number of times longer one half of a 'BankersDequeue' is
---   permitted to be relative to the other.
-bqBalance :: Int
-bqBalance = 4
-
--- | Checks to see if the queue is too far out of balance. If it is, it
---   rebalances it.
-check :: BankersDequeue a -> BankersDequeue a
-check q@(BankersDequeue sizeF front sizeR rear)
-    | sizeF > c * sizeR + 1 =
-        let front' = take size1 front
-            rear' = rear ++ reverse (drop size1 front)
-        in
-        BankersDequeue size1 front' size2 rear'
-    | sizeR > c * sizeF + 1 =
-        let front' = front ++ reverse (drop size1 rear)
-            rear' = take size1 rear
-        in
-        BankersDequeue size2 front' size1 rear'
-    | otherwise = q
-    where
-        size1 = (sizeF + sizeR) `div` 2
-        size2 = (sizeF + sizeR) - size1
-        c = bqBalance
-
-instance Eq a => Eq (BankersDequeue a) where
-    queue1 == queue2 = toList queue1 == toList queue2
-
-instance Outputable a => Outputable (BankersDequeue a) where
-    ppr dq = text "Dequeue" <+> ppr (toList dq)
diff --git a/compiler/utils/Worklist.hs b/compiler/utils/Worklist.hs
index c9bb858eee..2b46a152d6 100644
--- a/compiler/utils/Worklist.hs
+++ b/compiler/utils/Worklist.hs
@@ -3,15 +3,14 @@
 {-# OPTIONS_GHC -funbox-strict-fields #-}
 module Worklist where
 
+import Control.Arrow (first)
 import Control.Monad (forM_)
 import Control.Monad.Trans.State.Strict
 import Data.Map (Map)
 import qualified Data.Map as Map
 import Data.Set (Set)
 import qualified Data.Set as Set
-import Data.Maybe (isJust, fromMaybe)
-import Dequeue (BankersDequeue)
-import qualified Dequeue as Dequeue
+import Data.Maybe (fromMaybe)
 import Outputable
 
 newtype TransferFunction node lattice a
@@ -50,42 +49,11 @@ emptyNodeInfo = NodeInfo Nothing Set.empty Set.empty
 
 type Graph node lattice = Map node (NodeInfo node lattice)
 
-data QueuedMap k v
-  = QueuedMap
-  { queue :: !(BankersDequeue k)
-  , mapping :: !(Map k v)
-  }
-
-emptyQueuedMap :: QueuedMap k v
-emptyQueuedMap = QueuedMap Dequeue.empty Map.empty
-
-enqueueUpdating :: Ord k => k -> v -> (v -> v) -> QueuedMap k v -> QueuedMap k v
-enqueueUpdating k v updater qm = qm { queue = queue', mapping = mapping' }
-  where
-    queue'
-      -- | Map.member k (mapping qm) = queue qm
-      | True = queue qm
-      | otherwise = Dequeue.pushBack (queue qm) k
-    mapping' = Map.alter (Just . maybe v updater) k (mapping qm)
-
-dequeue :: Ord k => QueuedMap k v -> (Maybe (k, v), QueuedMap k v)
-dequeue qm
-  -- | Just (k, queue') <- Dequeue.popFront (queue qm)
-  --, (mv, mapping') <- Map.updateLookupWithKey (\_ _ -> Nothing) k (mapping qm)
-  | Just ((k, v), mapping') <- Map.maxViewWithKey (mapping qm)
-  -- = case mv of
-      -- Nothing -> pprPanic "queue and mapping should have the same keys" $
-        --ppr (length (queue qm)) <+> text " vs. " <+> ppr (Map.size (mapping qm))
-      --Just v -> (Just (k, v), qm { queue = queue', mapping = mapping' })
-  = (Just (k, v), qm { mapping = mapping' })
-  | otherwise
-  = (Nothing, qm)
-
 data WorklistState node lattice
   = WorklistState
   { framework :: !(DataFlowFramework node lattice)
   , graph :: !(Graph node lattice)
-  , unstable :: !(QueuedMap node (Set node)) -- unstable nodes and its changed references
+  , unstable :: !(Map node (Set node)) -- unstable nodes and their changed references
   , callStack :: !(Set node)
   , referencedNodes :: !(Set node)
   , loopBreakers :: !(Set node)
@@ -96,7 +64,7 @@ zoomGraph modifyGraph = state $ \st ->
   let (res, g) = runState modifyGraph (graph st)
   in  (res, st { graph = g })
 
-zoomUnstable :: State (QueuedMap node (Set node)) a -> State (WorklistState node lattice) a
+zoomUnstable :: State (Map node (Set node)) a -> State (WorklistState node lattice) a
 zoomUnstable modifyUnstable = state $ \st ->
   let (res, u) = runState modifyUnstable (unstable st)
   in  (res, st { unstable = u })
@@ -112,7 +80,7 @@ zoomLoopBreakers modifier = state $ \st ->
   in  (res, st { loopBreakers = lb })
 
 initialWorklistState
-  :: QueuedMap node (Set node)
+  :: Map node (Set node)
   -> DataFlowFramework node lattice
   -> WorklistState node lattice
 initialWorklistState unstable fw =
@@ -121,7 +89,7 @@ initialWorklistState unstable fw =
 dependOn :: Ord node => node -> TransferFunction node lattice (Maybe lattice)
 dependOn node = TFM $ do
   loopDetected <- Set.member node <$> gets callStack
-  isNotYetStable <- Map.member node <$> gets (mapping . unstable)
+  isNotYetStable <- Map.member node <$> gets unstable
   maybeNodeInfo <- Map.lookup node <$> gets graph
   zoomReferencedNodes (modify' (Set.insert node)) -- save that we depend on this value
   case maybeNodeInfo of
@@ -135,8 +103,6 @@ dependOn node = TFM $ do
       fmap (\(val, _, _) -> Just val) (recompute node)
 --    Just _ | isNotYetStable && not loopDetected -> do
 --      fmap (\(val, _, _) -> Just val) (recompute (trace "Just, not stable" node))
---    Just info | isNotYetStable -> do
---      return (value (trace "Just, looping" info))
     Just info -> do
       return (value info)
 
@@ -197,10 +163,11 @@ recompute node = do
 
 enqueueUnstable :: Ord node => node -> Set node -> State (WorklistState node lattice) ()
 enqueueUnstable reference referrers_ = zoomUnstable $ modify' $
-  enqueueUpdating reference referrers_ (Set.union referrers_)
+  Map.alter (Just . maybe referrers_ (Set.union referrers_)) reference
 
 dequeueUnstable :: Ord node => State (WorklistState node lattice) (Maybe (node, Set node))
-dequeueUnstable = zoomUnstable (state dequeue)
+dequeueUnstable = zoomUnstable $ state $ \m ->
+  maybe (Nothing, m) (first Just) (Map.maxViewWithKey m)
 
 lookupReferrers :: Ord node => node -> Graph node lattice -> Set node
 lookupReferrers node = maybe Set.empty referrers . Map.lookup node
@@ -212,7 +179,6 @@ work = do
     Nothing -> return ()
     Just (node, changedRefs) -> do
       modify' $ \st -> st { loopBreakers = Set.empty, callStack = Set.empty, referencedNodes = Set.empty }
-      --pprTrace "work:recompute" (text "len:" <+> ppr len) (pure ())
       (newVal, oldInfo, detectChange) <- recompute node
       -- We have to enqueue all referrers to loop breakers, e.g. nodes which we
       -- returned `Nothing` from `dependOn` to break cyclic dependencies.
@@ -234,6 +200,5 @@ runFramework
   -> Map node lattice
 runFramework framework_ interestingNodes = run framework_
   where
-    queuedMapOf = foldr (\n -> enqueueUpdating n Set.empty (const Set.empty)) emptyQueuedMap
-    unstable = queuedMapOf interestingNodes
+    unstable = Map.fromSet (const Set.empty) interestingNodes
     run = Map.mapMaybe value . graph . execState work . initialWorklistState unstable
-- 
2.12.1


From 7015053a29f2ad4ca71e7494b1eb83ee2ebd821a Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 9 May 2017 19:13:59 +0200
Subject: [PATCH 050/117] Merging analysis information now. Brought up a few
 imprecisions

---
 compiler/basicTypes/Demand.hs            |  5 +-
 compiler/basicTypes/Usage.hs             | 84 +++++++++++++++++++++++---------
 compiler/ghc.cabal.in                    |  1 +
 compiler/simplCore/CallArity/Analysis.hs |  2 +-
 compiler/simplCore/DmdAnalWrapper.hs     | 76 +++++++++++++++++++++++++++++
 compiler/simplCore/SimplCore.hs          |  4 +-
 6 files changed, 145 insertions(+), 27 deletions(-)
 create mode 100644 compiler/simplCore/DmdAnalWrapper.hs

diff --git a/compiler/basicTypes/Demand.hs b/compiler/basicTypes/Demand.hs
index e0a591dd4c..a91798d727 100644
--- a/compiler/basicTypes/Demand.hs
+++ b/compiler/basicTypes/Demand.hs
@@ -10,7 +10,7 @@
 module Demand (
         StrDmd, UseDmd(..), Count(..), ArgUse, Use (..),
 
-        Demand, CleanDemand, getStrDmd, getUseDmd,
+        Demand, CleanDemand, getStrDmd, getUseDmd, setUseDmd,
         mkProdDmd, mkOnceUsedDmd, mkManyUsedDmd, mkHeadStrict, oneifyDmd,
         toCleanDmd,
         absDmd, topDmd, botDmd, seqDmd,
@@ -93,6 +93,9 @@ getStrDmd = sd
 getUseDmd :: JointDmd s u -> u
 getUseDmd = ud
 
+setUseDmd :: u -> JointDmd s u -> JointDmd s u
+setUseDmd u jd = jd { ud = u }
+
 -- Pretty-printing
 instance (Outputable s, Outputable u) => Outputable (JointDmd s u) where
   ppr (JD {sd = s, ud = u}) = angleBrackets (ppr s <> char ',' <> ppr u)
diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index e745e56b29..5cd2ee5bd2 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -11,8 +11,9 @@ module Usage
   , manifyUsage, expandArity
   , UsageSig
   , botUsageSig, topUsageSig, lubUsageSig
-  , consUsageSig, unconsUsageSig, usageSigFromUsages, manifyUsageSig, usageSigFromStrictSig
+  , consUsageSig, unconsUsageSig, usageSigFromUsages, manifyUsageSig
   , trimSingleUse, trimUsage, trimUsageSig
+  , usageFromDemand, overwriteDemandWithUsage, usageSigFromStrictSig, overwriteStrictSigWithUsageSig
   ) where
 
 #include "HsVersions.h"
@@ -333,28 +334,6 @@ manifyUsageSig TopUsageSig = TopUsageSig
 manifyUsageSig BotUsageSig = BotUsageSig
 manifyUsageSig (ArgUsage u s) = consUsageSig (manifyUsage u) (manifyUsageSig s)
 
--- | For conveniently working with PrimOps. I've no nerve right now to go through
--- all entries in primops.txt.pp.
-usageSigFromStrictSig :: StrictSig -> UsageSig
-usageSigFromStrictSig sig
-  = usageSigFromUsages (map (usageFromArgUse . Demand.getUseDmd) dmds)
-  where
-    (dmds, _) = splitStrictSig sig
-
-multiplicityFromCount :: Demand.Count -> Multiplicity
-multiplicityFromCount Demand.One = Once
-multiplicityFromCount Demand.Many = Many
-
-singleUseFromUseDmd :: Demand.UseDmd -> SingleUse
-singleUseFromUseDmd Demand.UHead = topSingleUse
-singleUseFromUseDmd (Demand.UCall c u) = mkCallUse (multiplicityFromCount c) (singleUseFromUseDmd u)
-singleUseFromUseDmd (Demand.UProd comps) = mkProductUse (map usageFromArgUse comps)
-singleUseFromUseDmd Demand.Used = botSingleUse
-
-usageFromArgUse :: Demand.ArgUse -> Usage
-usageFromArgUse Demand.Abs = Absent
-usageFromArgUse (Demand.Use c u) = Used (multiplicityFromCount c) (singleUseFromUseDmd u)
-
 -- | Trims a `UsageSig` by looking at how the associated value is used.
 --
 -- The resulting `UsageSig` will only have as many arguments as the `SingleUse` has
@@ -439,3 +418,62 @@ instance Binary UsageSig where
       0 -> return BotUsageSig
       1 -> return TopUsageSig
       _ -> ArgUsage <$> get bh <*> get bh
+
+-- * Conversion to and from @Demand.hs@
+
+-- | For conveniently working with PrimOps. I've no nerve right now to go through
+-- all entries in primops.txt.pp.
+usageSigFromStrictSig :: StrictSig -> UsageSig
+usageSigFromStrictSig sig
+  = usageSigFromUsages (map (usageFromArgUse . Demand.getUseDmd) dmds)
+  where
+    (dmds, _) = splitStrictSig sig
+
+multiplicityFromCount :: Demand.Count -> Multiplicity
+multiplicityFromCount Demand.One = Once
+multiplicityFromCount Demand.Many = Many
+
+singleUseFromUseDmd :: Demand.UseDmd -> SingleUse
+singleUseFromUseDmd Demand.UHead = topSingleUse
+singleUseFromUseDmd (Demand.UCall c u) = mkCallUse (multiplicityFromCount c) (singleUseFromUseDmd u)
+singleUseFromUseDmd (Demand.UProd comps) = mkProductUse (map usageFromArgUse comps)
+singleUseFromUseDmd Demand.Used = botSingleUse
+
+usageFromArgUse :: Demand.ArgUse -> Usage
+usageFromArgUse Demand.Abs = Absent
+usageFromArgUse (Demand.Use c u) = Used (multiplicityFromCount c) (singleUseFromUseDmd u)
+
+usageFromDemand :: Demand.Demand -> Usage
+usageFromDemand = usageFromArgUse . Demand.getUseDmd
+
+-- | Overwrites the usage component of a `Demand.Demand` with the given `Usage`.
+overwriteDemandWithUsage :: Usage -> Demand.Demand -> Demand.Demand
+overwriteDemandWithUsage = Demand.setUseDmd . usageToArgUse
+
+usageToArgUse :: Usage -> Demand.ArgUse
+usageToArgUse Absent = Demand.Abs
+usageToArgUse (Used multi use)
+  = Demand.Use (multiplicityToCount multi) (singleUseToUseDmd use)
+
+multiplicityToCount :: Multiplicity -> Demand.Count
+multiplicityToCount Once = Demand.One
+multiplicityToCount Many = Demand.Many
+
+singleUseToUseDmd :: SingleUse -> Demand.UseDmd
+singleUseToUseDmd HeadUse = Demand.UHead
+singleUseToUseDmd UnknownUse = Demand.Used
+singleUseToUseDmd (Product comps) = Demand.UProd (map usageToArgUse comps)
+singleUseToUseDmd (Call multi use)
+  = Demand.UCall (multiplicityToCount multi) (singleUseToUseDmd use)
+
+-- | Overwrites the usage component of a `Demand.StrictSig` with the given
+-- `UsageSig`.
+overwriteStrictSigWithUsageSig :: UsageSig -> StrictSig -> StrictSig
+overwriteStrictSigWithUsageSig usage_sig strict_sig = strict_sig'
+  where
+    strict_sig' = Demand.mkClosedStrictSig (overwrite usage_sig dmds) dmd_result
+    (dmds, dmd_result) = Demand.splitStrictSig strict_sig
+    overwrite _ [] = []
+    overwrite sig (dmd:dmds)
+      | (usage, sig') <- unconsUsageSig sig
+      = overwriteDemandWithUsage usage dmd : overwrite sig' dmds
diff --git a/compiler/ghc.cabal.in b/compiler/ghc.cabal.in
index 3aba59ad17..dc04c0a47e 100644
--- a/compiler/ghc.cabal.in
+++ b/compiler/ghc.cabal.in
@@ -417,6 +417,7 @@ Library
         CallArity.FrameworkBuilder
         CallArity.Analysis
         DmdAnal
+        DmdAnalWrapper
         WorkWrap
         WwLib
         FamInst
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 41d46b6a5d..fb300a3d9d 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -1,4 +1,4 @@
-{-# LANGUAGE CPP, TupleSections #-}
+{-# LANGUAGE CPP #-}
 --
 -- Copyright (c) 2014 Joachim Breitner
 --
diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
new file mode 100644
index 0000000000..c0bab5cd05
--- /dev/null
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -0,0 +1,76 @@
+{-# LANGUAGE CPP #-}
+
+module DmdAnalWrapper (combinedDmdAnalProgram) where
+
+#include "HsVersions.h"
+
+import Control.Arrow ((***))
+
+import CallArity
+import CoreSyn
+import Demand
+import DmdAnal
+import DynFlags
+import FamInstEnv
+import Id
+import Outputable
+import Util
+import Usage
+import Var
+
+combinedDmdAnalProgram :: DynFlags -> FamInstEnvs -> CoreProgram -> IO CoreProgram
+combinedDmdAnalProgram dflags fams prog = do
+  -- Call Arity first, suggesting the fact that there's no information flow
+  -- from DA to CA. There isn't from CA to DA either, of course.
+  prog' <- callArityAnalProgram dflags fams prog
+  prog'' <- dmdAnalProgram dflags fams prog'
+  return (mapBndrsProgram mergeInfo prog'')
+
+mergeInfo :: Var -> Var
+mergeInfo id
+  | isTyVar id
+  = id
+  | otherwise
+  = ASSERT2( ca_usage `leqUsage` old_usage, text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
+    ASSERT2( not (isExportedId id) || ca_usg_sig `leqUsageSig` old_usg_sig, text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
+    id'
+  where
+    -- We merge idDemandInfo with idCallArity and idStrictness with idArgUsage.
+    -- Since Demand.hs doesn't seem to enforce the equivalences from the paper,
+    -- we first convert everything to the representation of Usage.hs.
+    old_demand = idDemandInfo id
+    old_str_sig = idStrictness id
+    ca_usage = idCallArity id
+    ca_usg_sig = idArgUsage id
+
+    old_usage = usageFromDemand old_demand
+    old_usg_sig = usageSigFromStrictSig old_str_sig
+
+    new_demand = overwriteDemandWithUsage ca_usage old_demand
+    new_str_sig = overwriteStrictSigWithUsageSig ca_usg_sig old_str_sig
+
+    leqUsage l r = l `lubUsage` r == r
+    leqUsageSig l r = l `lubUsageSig` r == r
+    id' = id `setIdDemandInfo` new_demand `setIdStrictness` (if isExportedId id then new_str_sig else old_str_sig)
+
+
+mapBndrsProgram :: (Var -> Var) -> CoreProgram -> CoreProgram
+mapBndrsProgram f = map (mapBndrsBind f)
+
+mapBndrsBind :: (Var -> Var) -> CoreBind -> CoreBind
+mapBndrsBind f (NonRec id e) = NonRec (f id) (mapBndrsExpr f e)
+mapBndrsBind f (Rec bndrs) = Rec (map (f *** mapBndrsExpr f) bndrs)
+
+mapBndrsExpr :: (Var -> Var) -> CoreExpr -> CoreExpr
+mapBndrsExpr f e = case e of
+  App func arg -> App (mapBndrsExpr f func) (mapBndrsExpr f arg)
+  Lam id e -> Lam (f id) (mapBndrsExpr f e)
+  Let bind body -> Let (mapBndrsBind f bind) (mapBndrsExpr f body)
+  Case scrut id ty alts -> Case (mapBndrsExpr f scrut) (f id) ty (map (mapBndrsAlt f) alts)
+  Cast e co -> Cast (mapBndrsExpr f e) co
+  Tick t e -> Tick t (mapBndrsExpr f e)
+  Var _ -> e -- use sites carry no important annotations
+  _ -> e
+
+mapBndrsAlt :: (Var -> Var) -> Alt CoreBndr -> Alt CoreBndr
+mapBndrsAlt f (con, bndrs, e) = (con, map f bndrs, mapBndrsExpr f e)
diff --git a/compiler/simplCore/SimplCore.hs b/compiler/simplCore/SimplCore.hs
index 4ebed770ca..daf726c107 100644
--- a/compiler/simplCore/SimplCore.hs
+++ b/compiler/simplCore/SimplCore.hs
@@ -41,7 +41,7 @@ import LiberateCase     ( liberateCase )
 import SAT              ( doStaticArgs )
 import Specialise       ( specProgram)
 import SpecConstr       ( specConstrProgram)
-import DmdAnal          ( dmdAnalProgram )
+import DmdAnalWrapper   ( combinedDmdAnalProgram )
 import CallArity        ( callArityAnalProgram )
 import WorkWrap         ( wwTopBinds )
 import Vectorise        ( vectorise )
@@ -474,7 +474,7 @@ doCorePass CoreDoCallArity           = {-# SCC "CallArity" #-}
                                        doPassDFM callArityAnalProgram
 
 doCorePass CoreDoStrictness          = {-# SCC "NewStranal" #-}
-                                       doPassDFM dmdAnalProgram
+                                       doPassDFM combinedDmdAnalProgram
 
 doCorePass CoreDoWorkerWrapper       = {-# SCC "WorkWrap" #-}
                                        doPassDFU wwTopBinds
-- 
2.12.1


From 8083d5363e5e08c3582484db6e70b9865626d9c9 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 11 May 2017 11:36:17 +0200
Subject: [PATCH 051/117] Dictionary selectors

---
 compiler/basicTypes/Usage.hs             | 30 +++++++++---
 compiler/simplCore/CallArity/Analysis.hs | 78 ++++++++++++++++++++++----------
 compiler/simplCore/DmdAnalWrapper.hs     | 18 +++++---
 compiler/utils/Util.hs                   | 16 +++++++
 4 files changed, 105 insertions(+), 37 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 5cd2ee5bd2..7481eaafb6 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -200,11 +200,27 @@ peelCallUse (Call multi use) = Just (Used multi use)
 peelCallUse UnknownUse = Just topUsage
 peelCallUse _ = Nothing
 
--- | @peelProductUse (length comps) (mkProductUse comps) = Just comps@
-peelProductUse :: Arity -> SingleUse -> Maybe [Usage]
-peelProductUse n HeadUse = Just (replicate n botUsage)
-peelProductUse n UnknownUse = Just (replicate n topUsage)
-peelProductUse n (Product comps)
+-- | @peelProductUse len_hint use@ tries to treat @use@ as a product use and
+-- returns the list of usages on its components. It will adhere to the @len_hint@
+-- if supplied, meaning that the product_use is constrained to have that length.
+-- This is mostly so that `botSingleUse` and `topSingleUse`, oblivious to length
+-- information, can be translated (back) into a product use.
+--
+-- If @len_hint@ is not supplied, this function will only return `Just` in the
+-- case that @use@ actually models a proper product. Examples:
+--
+--    - @peelProductUse (Just (length comps)) (mkProductUse comps) == Just comps@
+--    - @peelProductUse Nothing (mkProductUse comps) == Just comps@
+--    - @peelProductUse (Just n) topSingleUse == Just (replicate n topUsage)@
+--    - @peelProductUse Nothing topSingleUse == Nothing@
+--    - @peelProductUse (Just n) (mkCallUse Once topSingleUse) == Nothing@
+--    - @forall n. peelProductUse (Just n) use == Nothing ==> peelProductUse Nothing use == Nothing@
+peelProductUse :: Maybe Arity -> SingleUse -> Maybe [Usage]
+peelProductUse Nothing (Product comps) = Just comps
+peelProductUse Nothing _ = Nothing
+peelProductUse (Just n) HeadUse = Just (replicate n botUsage)
+peelProductUse (Just n) UnknownUse = Just (replicate n topUsage)
+peelProductUse (Just n) (Product comps)
   = ASSERT2(comps `lengthIs` n, text "peelProductUse" $$ ppr n $$ ppr comps)
     Just comps
 peelProductUse _ (Call _ _) = Nothing -- might happen with unsafeCoerce (#9208)
@@ -434,10 +450,10 @@ multiplicityFromCount Demand.One = Once
 multiplicityFromCount Demand.Many = Many
 
 singleUseFromUseDmd :: Demand.UseDmd -> SingleUse
-singleUseFromUseDmd Demand.UHead = topSingleUse
+singleUseFromUseDmd Demand.UHead = botSingleUse
 singleUseFromUseDmd (Demand.UCall c u) = mkCallUse (multiplicityFromCount c) (singleUseFromUseDmd u)
 singleUseFromUseDmd (Demand.UProd comps) = mkProductUse (map usageFromArgUse comps)
-singleUseFromUseDmd Demand.Used = botSingleUse
+singleUseFromUseDmd Demand.Used = topSingleUse
 
 usageFromArgUse :: Demand.ArgUse -> Usage
 usageFromArgUse Demand.Abs = Absent
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index fb300a3d9d..4d7effec47 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -13,7 +13,7 @@ import CallArity.FrameworkBuilder
 import BasicTypes
 import CoreSyn
 import DataCon ( DataCon, dataConTyCon, dataConRepStrictness, isMarkedStrict )
-import DynFlags      ( DynFlags )
+import DynFlags      ( DynFlags, gopt, GeneralFlag(Opt_DmdTxDictSel) )
 import FamInstEnv
 import Id
 import Maybes ( expectJust, fromMaybe, isJust )
@@ -397,7 +397,12 @@ Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
 
 data AnalEnv
   = AE
-  { ae_sigs :: VarEnv FrameworkNode
+  { ae_dflags :: DynFlags
+  -- ^ Configuration flags. Of particular interest to this analysis:
+  --
+  --     - `Opt_DmdTxDictSel`: Control analysis of dictionary selectors.
+  --
+  , ae_sigs :: VarEnv FrameworkNode
   -- ^ 'FrameworkNode's of visible local let-bound identifiers. It is crucial
   -- that only the 'UsageSig' component is used, as the usage on free vars might
   -- be unstable and thus too optimistic.
@@ -405,10 +410,11 @@ data AnalEnv
   -- ^ Needed for 'findTypeShape' to resolve type/data families.
   }
 
-initialAnalEnv :: FamInstEnvs -> AnalEnv
-initialAnalEnv fam_envs
+initialAnalEnv :: DynFlags -> FamInstEnvs -> AnalEnv
+initialAnalEnv dflags fam_envs
   = AE
-  { ae_sigs = emptyVarEnv
+  { ae_dflags = dflags
+  , ae_sigs = emptyVarEnv
   , ae_fam_envs = fam_envs
   }
 
@@ -437,14 +443,14 @@ exprToModule _ = []
 
 -- Main entry point
 callArityAnalProgram :: DynFlags -> FamInstEnvs -> CoreProgram -> IO CoreProgram
-callArityAnalProgram _dflags fam_envs
-  = return . exprToModule . callArityRHS fam_envs . moduleToExpr
+callArityAnalProgram dflags fam_envs
+  = return . exprToModule . callArityRHS dflags fam_envs . moduleToExpr
 
-callArityRHS :: FamInstEnvs -> CoreExpr -> CoreExpr
-callArityRHS fam_envs e
+callArityRHS :: DynFlags -> FamInstEnvs -> CoreExpr -> CoreExpr
+callArityRHS dflags fam_envs e
   = ASSERT2( isEmptyUnVarSet (domType ut), text "Free vars in UsageType:" $$ ppr ut ) e'
   where
-    (ut, e') = buildAndRun (callArityExpr (initialAnalEnv fam_envs) e) topSingleUse
+    (ut, e') = buildAndRun (callArityExpr (initialAnalEnv dflags fam_envs) e) topSingleUse
 
 -- | The main analysis function. See Note [Analysis type signature]
 callArityExpr
@@ -498,6 +504,11 @@ callArityExpr env e@(Var id) = return transfer
       -- as a `UsageSig`.
       = return (emptyUsageType { ut_args = dataConUsageSig (idArity id) use }, e)
 
+      | gopt Opt_DmdTxDictSel (ae_dflags env)
+      , Just _ <- isClassOpId_maybe id
+      -- A dictionary component selector
+      = return (emptyUsageType { ut_args = dictSelUsageSig id use }, e)
+
       | isGlobalId id
       -- A global id from another module which has a usage signature.
       -- We don't need to track the id itself, though.
@@ -522,13 +533,17 @@ callArityExpr env (Lam id body)
         Absent -> return (emptyUsageType, Lam id body)
         Used multi body_use -> do
           (ut_body, body') <- transfer_body body_use
-          let id' | Once <- multi = id `setIdOneShotInfo` OneShotLam
-                  | otherwise = id
-          -- TODO: This *should* be OK: free vars are manified,
-          --       closed vars are not. Argument usages are manified,
-          --       which should be conservative enough.
-          let ut = multiplyUsages multi ut_body
-          return (makeIdArg id' ut, Lam id' body')
+          let (ut_body', usage_id) = findBndrUsage NonRecursive (ae_fam_envs env) ut_body id
+          let id' = applyWhen (multi == Once) (flip setIdOneShotInfo OneShotLam)
+                  . flip setIdCallArity usage_id
+                  $ id
+          -- Free vars are manified, closed vars are not. The usage of the current
+          -- argument `id` is *not* manified.
+          let ut = modifyArgs (consUsageSig usage_id)
+                 . multiplyUsages multi
+                 $ ut_body'
+          pprTrace "callArityExpr:Lam" (vcat [text "id:" <+> ppr id, text "usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
+          return (ut, Lam id' body')
 
 callArityExpr env (App f (Type t)) = callArityExprMap env (flip App (Type t)) f
 
@@ -650,9 +665,28 @@ dataConUsageSig arity use = fromMaybe botUsageSig sig_maybe
       = Nothing
     sig_maybe = do
       product_use <- peelSingleShotCalls arity use
-      component_usages <- peelProductUse arity product_use
+      component_usages <- peelProductUse (Just arity) product_use
       return (usageSigFromUsages component_usages)
 
+dictSelUsageSig :: Id -> SingleUse -> UsageSig
+dictSelUsageSig id use
+  | Used m dict_single_call_use <- fst . unconsUsageSig . usageSigFromStrictSig . idStrictness $ id
+  , Just comps <- peelProductUse Nothing dict_single_call_use
+  = case peelCallUse use of -- The outer call is the selector. The inner use is on the actual method!
+      Just Absent -> botUsageSig
+      Just (Used Once method_use) -> specializeDictSig comps method_use
+      Just (Used Many method_use) -> manifyUsageSig (specializeDictSig comps method_use)
+  | otherwise
+  = topUsageSig
+
+specializeDictSig :: [Usage] -> SingleUse -> UsageSig
+specializeDictSig comps method_use = consUsageSig dict_usage topUsageSig
+  where
+    dict_usage = Used Once (mkProductUse (map replace_usage comps))
+    replace_usage old
+      | old == Absent = old
+      | otherwise = Used Once method_use -- This is the selector for the method we used!
+
 globalIdUsageSig :: Id -> SingleUse -> UsageSig
 globalIdUsageSig id use
   | use <= no_call -- @f x `seq` ...@ for a GlobalId `f` with arity > 1
@@ -719,7 +753,7 @@ findBndrsUsages rec_flag fam_envs ut = foldr step (ut, [])
 addCaseBndrUsage :: Usage -> [Usage] -> [Usage]
 addCaseBndrUsage Absent alt_bndr_usages = alt_bndr_usages
 addCaseBndrUsage (Used _ use) alt_bndr_usages
-  | Just case_comp_usages <- peelProductUse (length alt_bndr_usages) use
+  | Just case_comp_usages <- peelProductUse (Just (length alt_bndr_usages)) use
   = zipWith bothUsage case_comp_usages alt_bndr_usages
   | otherwise
   = topUsage <$ alt_bndr_usages
@@ -758,7 +792,7 @@ propagateProductUse alts scrut_uses
 addDataConStrictness :: DataCon -> SingleUse -> SingleUse
 -- See Note [Add demands for strict constructors] in DmdAnal.hs
 addDataConStrictness dc use
-  = maybe use (mkProductUse . add_component_strictness) (peelProductUse arity use)
+  = maybe use (mkProductUse . add_component_strictness) (peelProductUse (Just arity) use)
   where
     add_component_strictness :: [Usage] -> [Usage]
     add_component_strictness = zipWith add strs
@@ -801,8 +835,6 @@ registerBindingGroup env = go env emptyVarEnv
                 -- change detection for the arg usage case. This implies that
                 -- use sites of these sig nodes may only use the ut_args
                 -- component!
-                -- FIXME: Encode this in the FrameworkNode type somehow, but I
-                -- don't think it's worth the trouble.
                 --pprTrace "change_detector_down" (vcat [ppr node, ppr id, ppr (ut_args old <= ut_args new), ppr (lubUsageSig (ut_args old) (ut_args new)), ppr (ut_args old), ppr (ut_args new), ppr (ut_args old /= ut_args new)]) $
                 ASSERT2( ut_args old <= ut_args new, text "CallArity.change_detector_down: Not monotone" $$ ppr (ut_args old) $$ ppr (ut_args new) )
                 ut_args old /= ut_args new
@@ -849,8 +881,6 @@ annotateExportedIdArgUsage id transfer_rhs
     -- @UsageSig@ to be had.
     -- In that case we *could* try to analyze with arity 1, just for the
     -- signature.
-    -- TODO: Think harder about UsageSigs and how they should be handled with
-    -- Used Many.
     let single_call = iterate (mkCallUse Once) topSingleUse !! idArity id
     usage_sig <- ut_args . fst <$> transfer_rhs single_call
     return (id `setIdArgUsage` usage_sig)
diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index c0bab5cd05..c8e8cce1d2 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -4,8 +4,6 @@ module DmdAnalWrapper (combinedDmdAnalProgram) where
 
 #include "HsVersions.h"
 
-import Control.Arrow ((***))
-
 import CallArity
 import CoreSyn
 import Demand
@@ -24,6 +22,7 @@ combinedDmdAnalProgram dflags fams prog = do
   -- from DA to CA. There isn't from CA to DA either, of course.
   prog' <- callArityAnalProgram dflags fams prog
   prog'' <- dmdAnalProgram dflags fams prog'
+  pprTrace "Program" (ppr prog'') $ pure ()
   return (mapBndrsProgram mergeInfo prog'')
 
 mergeInfo :: Var -> Var
@@ -31,7 +30,7 @@ mergeInfo id
   | isTyVar id
   = id
   | otherwise
-  = ASSERT2( ca_usage `leqUsage` old_usage, text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
+  = ASSERT2( isExportedId id || ca_usage `leqUsage` old_usage, text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
     ASSERT2( not (isExportedId id) || ca_usg_sig `leqUsageSig` old_usg_sig, text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
     id'
   where
@@ -51,15 +50,22 @@ mergeInfo id
 
     leqUsage l r = l `lubUsage` r == r
     leqUsageSig l r = l `lubUsageSig` r == r
-    id' = id `setIdDemandInfo` new_demand `setIdStrictness` (if isExportedId id then new_str_sig else old_str_sig)
+    id'
+      | isExportedId id = id `setIdStrictness` new_str_sig -- Only the sig matters
+      | otherwise = id `setIdDemandInfo` new_demand -- Only use sites matter
 
 
 mapBndrsProgram :: (Var -> Var) -> CoreProgram -> CoreProgram
 mapBndrsProgram f = map (mapBndrsBind f)
 
 mapBndrsBind :: (Var -> Var) -> CoreBind -> CoreBind
-mapBndrsBind f (NonRec id e) = NonRec (f id) (mapBndrsExpr f e)
-mapBndrsBind f (Rec bndrs) = Rec (map (f *** mapBndrsExpr f) bndrs)
+mapBndrsBind f (NonRec id e) = NonRec (f id) (mapBndrsExprIfNotAbsent id f e)
+mapBndrsBind f (Rec bndrs) = Rec (map (\(id, e) -> (f id, mapBndrsExprIfNotAbsent id f e)) bndrs)
+
+mapBndrsExprIfNotAbsent :: Var -> (Var -> Var) -> CoreExpr -> CoreExpr
+mapBndrsExprIfNotAbsent id f e
+  | Absent <- idCallArity id = e -- we won't have analysed e in this case.
+  | otherwise = mapBndrsExpr f e
 
 mapBndrsExpr :: (Var -> Var) -> CoreExpr -> CoreExpr
 mapBndrsExpr f e = case e of
diff --git a/compiler/utils/Util.hs b/compiler/utils/Util.hs
index 67373d9f81..51e46ca46e 100644
--- a/compiler/utils/Util.hs
+++ b/compiler/utils/Util.hs
@@ -72,6 +72,9 @@ module Util (
         removeSpaces,
         (<&&>), (<||>),
 
+        -- * Functions
+        applyWhen,
+
         -- * Edit distance
         fuzzyMatch, fuzzyLookup,
 
@@ -792,6 +795,19 @@ infixr 3 <&&> -- same as (&&)
 (<||>) = liftA2 (||)
 infixr 2 <||> -- same as (||)
 
+
+{-
+************************************************************************
+*                                                                      *
+\subsection[Utils-function]{Functions}
+*                                                                      *
+************************************************************************
+-}
+
+{-| `applyWhen b f x` applies `f` to `x` iff `b`. -}
+applyWhen :: Bool -> (a -> a) -> a -> a
+applyWhen b f = if b then f else id
+
 {-
 ************************************************************************
 *                                                                      *
-- 
2.12.1


From db95c971d34835b9c0ad002a0bb710765d2ed17e Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 11 May 2017 18:24:55 +0200
Subject: [PATCH 052/117] Added proper handling of Coercions

---
 compiler/simplCore/CallArity/Analysis.hs         | 55 ++++++++++++++++--------
 compiler/simplCore/DmdAnalWrapper.hs             | 13 +++---
 testsuite/tests/callarity/unittest/CallArity1.hs |  2 +-
 3 files changed, 46 insertions(+), 24 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 4d7effec47..bc55531e00 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -11,6 +11,7 @@ import CallArity.Types
 import CallArity.FrameworkBuilder
 
 import BasicTypes
+import Coercion ( Coercion, coVarsOfCo )
 import CoreSyn
 import DataCon ( DataCon, dataConTyCon, dataConRepStrictness, isMarkedStrict )
 import DynFlags      ( DynFlags, gopt, GeneralFlag(Opt_DmdTxDictSel) )
@@ -476,16 +477,25 @@ callArityExprMap env f e
       (ut, e') <- transfer use
       return (ut, f e')
 
--- The trivial base cases
-callArityExpr _ e@(Lit _) = callArityExprTrivial e
-callArityExpr _ e@(Type _) = callArityExprTrivial e
-callArityExpr _ e@(Coercion _) = callArityExprTrivial e
+callArityExpr _ e@(Lit _)
+  = callArityExprTrivial e
+callArityExpr _ e@(Type _)
+  = callArityExprTrivial e
 
--- The transparent cases
-callArityExpr env (Tick t e) = callArityExprMap env (Tick t) e
-callArityExpr env (Cast e c) = callArityExprMap env (flip Cast c) e
+callArityExpr _ e@(Coercion co)
+  = return (\_ -> return (coercionUsageType co, e))
 
--- The interesting cases: Variables, Lambdas, Lets, Applications, Cases
+callArityExpr env (Tick t e)
+  = callArityExprMap env (Tick t) e
+
+callArityExpr env (Cast e co)
+  = transfer' <$> callArityExpr env e
+  where
+    transfer' transfer use = do
+      (ut, e') <- transfer use
+      -- like callArityExprMap, but we also have to combine with the UsageType
+      -- of the coercion.
+      return (ut `bothUsageType` coercionUsageType co, Cast e' co)
 
 callArityExpr env e@(Var id) = return transfer
   where
@@ -496,30 +506,34 @@ callArityExpr env e@(Var id) = return transfer
         (ut_callee, _) <- dependOnWithDefault (botUsageType, e) (node, use)
         -- It is crucial that we only use ut_args here, as every other field
         -- might be unstable and thus too optimistic.
-        --pprTrace "callArityExpr.Var" (vcat [ppr id, ppr use, ppr (ut_args ut_callee)]) (return ())
+        --pprTrace "callArityExpr:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
         return ((unitUsageType id use) { ut_args = ut_args ut_callee }, e)
 
       | isDataConWorkId id
       -- Some data constructor, on which we can try to unleash product use
       -- as a `UsageSig`.
-      = return (emptyUsageType { ut_args = dataConUsageSig (idArity id) use }, e)
+      = --pprTrace "callArityExpr:DataCon" (ppr id <+> ppr use <+> ppr (dataConUsageSig (idArity id) use)) $
+        return (emptyUsageType { ut_args = dataConUsageSig (idArity id) use }, e)
 
       | gopt Opt_DmdTxDictSel (ae_dflags env)
       , Just _ <- isClassOpId_maybe id
       -- A dictionary component selector
-      = return (emptyUsageType { ut_args = dictSelUsageSig id use }, e)
+      = --pprTrace "callArityExpr:DictSel" (ppr id <+> ppr use <+> ppr (dictSelUsageSig id use)) $
+        return (emptyUsageType { ut_args = dictSelUsageSig id use }, e)
 
       | isGlobalId id
       -- A global id from another module which has a usage signature.
       -- We don't need to track the id itself, though.
-      = return (emptyUsageType { ut_args = globalIdUsageSig id use }, e)
+      = --pprTrace "callArityExpr:GlobalId" (ppr id <+> ppr use <+> ppr (globalIdUsageSig id use)) $
+        return (emptyUsageType { ut_args = globalIdUsageSig id use }, e)
 
       | otherwise
       -- A LocalId not present in @nodes@, e.g. a lambda or case-bound variable.
       -- We are only second-order, so we don't model signatures for parameters!
       -- Their usage is interesting to note nonetheless for annotating lambda
       -- binders and scrutinees.
-      = return (unitUsageType id use, e)
+      = --pprTrace "callArityExpr:OtherId" (ppr id <+> ppr use) $
+        return (unitUsageType id use, e)
 
 callArityExpr env (Lam id body)
   | isTyVar id
@@ -542,7 +556,7 @@ callArityExpr env (Lam id body)
           let ut = modifyArgs (consUsageSig usage_id)
                  . multiplyUsages multi
                  $ ut_body'
-          pprTrace "callArityExpr:Lam" (vcat [text "id:" <+> ppr id, text "usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
+          --pprTrace "callArityExpr:Lam" (vcat [text "id:" <+> ppr id, text "usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
           return (ut, Lam id' body')
 
 callArityExpr env (App f (Type t)) = callArityExprMap env (flip App (Type t)) f
@@ -636,6 +650,11 @@ callArityExpr env (Let bind e) = do
         --pprTrace "Let" (ppr (ut, let')) $ return ()
         return (delUsageTypes (bindersOf bind) ut, let')
 
+coercionUsageType :: Coercion -> UsageType
+coercionUsageType co = multiplyUsages Many ut
+  where
+    ut = emptyUsageType { ut_uses = mapVarEnv (const topSingleUse) (coVarsOfCo co) }
+
 -- | Consider the expression
 --
 -- @
@@ -670,9 +689,10 @@ dataConUsageSig arity use = fromMaybe botUsageSig sig_maybe
 
 dictSelUsageSig :: Id -> SingleUse -> UsageSig
 dictSelUsageSig id use
-  | Used m dict_single_call_use <- fst . unconsUsageSig . usageSigFromStrictSig . idStrictness $ id
+  | Used _ dict_single_call_use <- fst . unconsUsageSig . usageSigFromStrictSig . idStrictness $ id
   , Just comps <- peelProductUse Nothing dict_single_call_use
   = case peelCallUse use of -- The outer call is the selector. The inner use is on the actual method!
+      Nothing -> topUsageSig -- weird
       Just Absent -> botUsageSig
       Just (Used Once method_use) -> specializeDictSig comps method_use
       Just (Used Many method_use) -> manifyUsageSig (specializeDictSig comps method_use)
@@ -765,7 +785,8 @@ setBndrsUsageInfo (b:bndrs) (usage:usages)
   = setIdCallArity b usage : setBndrsUsageInfo bndrs usages
 setBndrsUsageInfo (b:bndrs) usages
   = b : setBndrsUsageInfo bndrs usages
-setBndrsUsageInfo _ usages = pprPanic "No Ids, but a Usage left" (ppr usages)
+setBndrsUsageInfo _ usages
+  = pprPanic "No Ids, but a Usage left" (ppr usages)
 
 propagateProductUse
   :: [Alt CoreBndr]
@@ -782,7 +803,7 @@ propagateProductUse alts scrut_uses
   -- This is a good place to make sure we don't construct an infinitely depth
   -- use, which can happen when analysing e.g. lazy streams.
   -- Also see Note [Demand on scrutinee of a product case] in DmdAnal.hs.
-  = addDataConStrictness dc (boundDepth 5 scrut_use)
+  = addDataConStrictness dc (boundDepth 10 scrut_use)
 
   | otherwise
   -- We *could* lub the uses from the different branches, but there's not much
diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index c8e8cce1d2..54e6e1d022 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -22,7 +22,7 @@ combinedDmdAnalProgram dflags fams prog = do
   -- from DA to CA. There isn't from CA to DA either, of course.
   prog' <- callArityAnalProgram dflags fams prog
   prog'' <- dmdAnalProgram dflags fams prog'
-  pprTrace "Program" (ppr prog'') $ pure ()
+  --pprTrace "Program" (ppr prog'') $ pure ()
   return (mapBndrsProgram mergeInfo prog'')
 
 mergeInfo :: Var -> Var
@@ -32,6 +32,7 @@ mergeInfo id
   | otherwise
   = ASSERT2( isExportedId id || ca_usage `leqUsage` old_usage, text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
     ASSERT2( not (isExportedId id) || ca_usg_sig `leqUsageSig` old_usg_sig, text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
+    --(if idCallArity id == Absent then pprTrace "Absent" (ppr id) else \x -> x) $
     id'
   where
     -- We merge idDemandInfo with idCallArity and idStrictness with idArgUsage.
@@ -55,19 +56,19 @@ mergeInfo id
       | otherwise = id `setIdDemandInfo` new_demand -- Only use sites matter
 
 
-mapBndrsProgram :: (Var -> Var) -> CoreProgram -> CoreProgram
+mapBndrsProgram :: HasCallStack => (Var -> Var) -> CoreProgram -> CoreProgram
 mapBndrsProgram f = map (mapBndrsBind f)
 
-mapBndrsBind :: (Var -> Var) -> CoreBind -> CoreBind
+mapBndrsBind :: HasCallStack => (Var -> Var) -> CoreBind -> CoreBind
 mapBndrsBind f (NonRec id e) = NonRec (f id) (mapBndrsExprIfNotAbsent id f e)
 mapBndrsBind f (Rec bndrs) = Rec (map (\(id, e) -> (f id, mapBndrsExprIfNotAbsent id f e)) bndrs)
 
-mapBndrsExprIfNotAbsent :: Var -> (Var -> Var) -> CoreExpr -> CoreExpr
+mapBndrsExprIfNotAbsent :: HasCallStack => Var -> (Var -> Var) -> CoreExpr -> CoreExpr
 mapBndrsExprIfNotAbsent id f e
   | Absent <- idCallArity id = e -- we won't have analysed e in this case.
   | otherwise = mapBndrsExpr f e
 
-mapBndrsExpr :: (Var -> Var) -> CoreExpr -> CoreExpr
+mapBndrsExpr :: HasCallStack => (Var -> Var) -> CoreExpr -> CoreExpr
 mapBndrsExpr f e = case e of
   App func arg -> App (mapBndrsExpr f func) (mapBndrsExpr f arg)
   Lam id e -> Lam (f id) (mapBndrsExpr f e)
@@ -78,5 +79,5 @@ mapBndrsExpr f e = case e of
   Var _ -> e -- use sites carry no important annotations
   _ -> e
 
-mapBndrsAlt :: (Var -> Var) -> Alt CoreBndr -> Alt CoreBndr
+mapBndrsAlt :: HasCallStack => (Var -> Var) -> Alt CoreBndr -> Alt CoreBndr
 mapBndrsAlt f (con, bndrs, e) = (con, map f bndrs, mapBndrsExpr f e)
diff --git a/testsuite/tests/callarity/unittest/CallArity1.hs b/testsuite/tests/callarity/unittest/CallArity1.hs
index 4917afaa7e..02c9097af4 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.hs
+++ b/testsuite/tests/callarity/unittest/CallArity1.hs
@@ -198,7 +198,7 @@ main = do
                 Nothing -> return ()
             putMsg dflags (text n <> char ':')
             -- liftIO $ putMsg dflags (ppr e)
-            let e' = callArityRHS emptyFamInstEnvs e
+            let e' = callArityRHS dflags emptyFamInstEnvs e
             let bndrs = nonDetEltsUniqSet (allBoundIds e')
               -- It should be OK to use nonDetEltsUniqSet here, if it becomes a
               -- problem we should use DVarSet
-- 
2.12.1


From 7db13c089ea2651d565acdf4d2909bcb26a5ba77 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sat, 13 May 2017 13:42:23 +0200
Subject: [PATCH 053/117] Fixed a bug in Worklist.hs

---
 .gitignore                 |  3 ++
 compiler/utils/Worklist.hs | 75 +++++++++++++++++++++-------------------------
 2 files changed, 37 insertions(+), 41 deletions(-)

diff --git a/.gitignore b/.gitignore
index 16071f62a6..a9afc3025f 100644
--- a/.gitignore
+++ b/.gitignore
@@ -192,3 +192,6 @@ GIT_COMMIT_ID
 
 # Should be equal to testdir_suffix from testsuite/driver/testlib.py.
 *.run
+
+# VSCode
+.vscode
\ No newline at end of file
diff --git a/compiler/utils/Worklist.hs b/compiler/utils/Worklist.hs
index 2b46a152d6..2f275d4739 100644
--- a/compiler/utils/Worklist.hs
+++ b/compiler/utils/Worklist.hs
@@ -56,7 +56,6 @@ data WorklistState node lattice
   , unstable :: !(Map node (Set node)) -- unstable nodes and their changed references
   , callStack :: !(Set node)
   , referencedNodes :: !(Set node)
-  , loopBreakers :: !(Set node)
   }
 
 zoomGraph :: State (Graph node lattice) a -> State (WorklistState node lattice) a
@@ -74,17 +73,12 @@ zoomReferencedNodes modifier = state $ \st ->
   let (res, rn) = runState modifier (referencedNodes st)
   in  (res, st { referencedNodes = rn })
 
-zoomLoopBreakers :: State (Set node) a -> State (WorklistState node lattice) a
-zoomLoopBreakers modifier = state $ \st ->
-  let (res, lb) = runState modifier (loopBreakers st)
-  in  (res, st { loopBreakers = lb })
-
 initialWorklistState
   :: Map node (Set node)
   -> DataFlowFramework node lattice
   -> WorklistState node lattice
 initialWorklistState unstable fw =
-  WorklistState fw Map.empty unstable Set.empty Set.empty Set.empty
+  WorklistState fw Map.empty unstable Set.empty Set.empty
 
 dependOn :: Ord node => node -> TransferFunction node lattice (Maybe lattice)
 dependOn node = TFM $ do
@@ -94,17 +88,21 @@ dependOn node = TFM $ do
   zoomReferencedNodes (modify' (Set.insert node)) -- save that we depend on this value
   case maybeNodeInfo of
     Nothing | loopDetected -> do
-      -- We have to revisit these later
-      zoomLoopBreakers (modify' (Set.insert node))
-      --return (trace "Nothing, loop detected" Nothing)
+      -- Somewhere in an outer call stack we already compute this one.
+      -- We don't recurse again and just return Nothing.
+      -- The outer call will then recognize the instability and enqueue
+      -- itself as unstable after its first approximation is computed.
       return Nothing
+      --return (trace "Nothing, loop detected" Nothing)
     Nothing -> do
-      --fmap (\(val, _, _) -> Just val) (recompute (trace "Nothing, no loop" node))
-      fmap (\(val, _, _) -> Just val) (recompute node)
---    Just _ | isNotYetStable && not loopDetected -> do
---      fmap (\(val, _, _) -> Just val) (recompute (trace "Just, not stable" node))
+      Just <$> recompute node
+      --Just <$> recompute (trace "Nothing, no loop" node)
+    Just _ | isNotYetStable && not loopDetected -> do
+      Just <$> recompute node
+      --Just <$> recompute (trace "Just, not stable" node)
     Just info -> do
       return (value info)
+      --return (trace "Just, stable" (value info))
 
 data Diff a
   = Diff
@@ -143,55 +141,50 @@ updateGraphNode node val refs = zoomGraph $ do
 recompute
   :: Ord node
   => node
-  -> State (WorklistState node lattice) (lattice, NodeInfo node lattice, ChangeDetector node lattice)
+  -> State (WorklistState node lattice) lattice
 recompute node = do
   oldState <- get
   put $ oldState
     { referencedNodes = Set.empty
     , callStack = Set.insert node (callStack oldState)
     }
-  let (TFM transfer, changeDetector) = getTransfer (framework oldState) node
-  val <- transfer
+  let (TFM transfer, detectChange) = getTransfer (framework oldState) node
+  newVal <- transfer
   refs <- gets referencedNodes
   --pprTrace "recompute:refs" (ppr (length refs)) $ return ()
-  oldInfo <- updateGraphNode node val refs
+  oldInfo <- updateGraphNode node newVal refs
+  changedRefs <- fromMaybe Set.empty <$> deleteLookupUnstable node
+  case value oldInfo of
+    Just oldVal | not (detectChange changedRefs oldVal newVal) -> return ()
+    _ -> forM_ (referrers oldInfo) (\ref -> enqueueUnstable ref (Set.singleton node))
   modify' $ \st -> st
     { referencedNodes = referencedNodes oldState
     , callStack = callStack oldState
     }
-  return (val, oldInfo, changeDetector)
+  return newVal
 
 enqueueUnstable :: Ord node => node -> Set node -> State (WorklistState node lattice) ()
 enqueueUnstable reference referrers_ = zoomUnstable $ modify' $
   Map.alter (Just . maybe referrers_ (Set.union referrers_)) reference
 
-dequeueUnstable :: Ord node => State (WorklistState node lattice) (Maybe (node, Set node))
-dequeueUnstable = zoomUnstable $ state $ \m ->
-  maybe (Nothing, m) (first Just) (Map.maxViewWithKey m)
+deleteLookupUnstable :: Ord node => node -> State (WorklistState node lattice) (Maybe (Set node))
+deleteLookupUnstable node = zoomUnstable $ state $ Map.updateLookupWithKey (\_ _ -> Nothing) node
+
+highestPriorityUnstableNode :: Ord node => State (WorklistState node lattice) (Maybe node)
+highestPriorityUnstableNode = fmap (fst . fst) . Map.maxViewWithKey <$> gets unstable
 
 lookupReferrers :: Ord node => node -> Graph node lattice -> Set node
 lookupReferrers node = maybe Set.empty referrers . Map.lookup node
 
+whileJust_ :: Monad m => m (Maybe a) -> (a -> m b) -> m ()
+whileJust_ pred action = go
+  where
+    go = pred >>= \m -> case m of
+      Nothing -> return ()
+      Just a -> action a >> go
+
 work :: Ord node => State (WorklistState node lattice) ()
-work = do
-  m <- dequeueUnstable
-  case m of
-    Nothing -> return ()
-    Just (node, changedRefs) -> do
-      modify' $ \st -> st { loopBreakers = Set.empty, callStack = Set.empty, referencedNodes = Set.empty }
-      (newVal, oldInfo, detectChange) <- recompute node
-      -- We have to enqueue all referrers to loop breakers, e.g. nodes which we
-      -- returned `Nothing` from `dependOn` to break cyclic dependencies.
-      -- Their referrers probably aren't carrying safe values, so we have to
-      -- revisit them. This looks expensive, but loopBreakers should be pretty
-      -- rare later on.
-      g <- gets graph
-      lbs <- gets loopBreakers
-      forM_ lbs (\lb -> enqueueUnstable lb (lookupReferrers lb g))
-      case value oldInfo of
-        Just oldVal | not (detectChange changedRefs oldVal newVal) -> return ()
-        _ -> forM_ (referrers oldInfo) (\ref -> enqueueUnstable ref (Set.singleton node))
-      work
+work = whileJust_ highestPriorityUnstableNode recompute
 
 runFramework
   :: Ord node
-- 
2.12.1


From 7732d2987f140c361d40a4e5ff837fe41b73dbb9 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 14 May 2017 22:01:46 +0200
Subject: [PATCH 054/117] Fixed a the letrec stabilization behavior

---
 compiler/simplCore/CallArity/Analysis.hs         | 11 +++++++---
 compiler/simplCore/CallArity/FrameworkBuilder.hs |  8 +++----
 compiler/simplCore/CallArity/Types.hs            | 28 +++++++++++++++---------
 compiler/utils/Worklist.hs                       | 16 +++++++++-----
 4 files changed, 40 insertions(+), 23 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index bc55531e00..b19919d734 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -630,8 +630,12 @@ callArityExpr env (Let bind e) = do
               (ut_usage, Let (Rec old_bind) _) <- dependOnWithDefault (ut_body, Let bind e') (node, use)
               let transferred_binds = map transferred_bind old_bind
               (ut, bind') <- unleashLet Recursive fam_envs transferred_binds ut_usage ut_body
-              --ut <- pprTrace "Rec:end" (ppr ids) $ return ut
-              return (ut, Let (Rec bind') e')
+              let lookup_old = lookupUsage Recursive ut_usage
+              let lookup_new = lookupUsage Recursive ut
+              let ut' | all (\id -> lookup_old id == lookup_new id) ids = markStable ut
+                      | otherwise = ut
+              --ut' <- pprTrace "Rec:end" (ppr ids) $ return ut'
+              return (ut', Let (Rec bind') e')
 
         let change_detector :: ChangeDetector
             change_detector changed_refs (old, _) (new, _) =
@@ -640,7 +644,8 @@ callArityExpr env (Let bind e) = do
               --pprTrace "change_detector" (vcat[ppr ids, ppr node, ppr changed_refs]) $
               --pprTrace "change_detector" (vcat[ppr node, ppr changed_refs, ppr old, ppr new]) $
               map fst (Set.toList changed_refs) /= [node]
-              || any (\id -> lookupUsage Recursive old id /= lookupUsage Recursive new id) ids
+              || not (ut_stable old) 
+              || not (ut_stable new) -- set in the transfer function through markStable
 
         return (node, (transfer, change_detector))
 
diff --git a/compiler/simplCore/CallArity/FrameworkBuilder.hs b/compiler/simplCore/CallArity/FrameworkBuilder.hs
index 4a60007a14..99636dc96c 100644
--- a/compiler/simplCore/CallArity/FrameworkBuilder.hs
+++ b/compiler/simplCore/CallArity/FrameworkBuilder.hs
@@ -75,10 +75,10 @@ registerTransferFunction prio f = FB $ do
   return result
 
 dependOnWithDefault :: AnalResult -> (FrameworkNode, SingleUse) -> TransferFunction AnalResult
-dependOnWithDefault def (node, use) = do
-  --use <- pprTrace "dependOnWithDefault:before" (text "node:" <+> ppr node <+> text "use:" <+> ppr use) $ return use
-  res <- fromMaybe def <$> Worklist.dependOn (node, use)
-  --res <- pprTrace "dependOnWithDefault:after" (vcat [text "node:" <+> ppr node, text "use:" <+> ppr use]) $ return res
+dependOnWithDefault def which = do
+  --which <- pprTrace "dependOnWithDefault:before" (ppr which) (return which)
+  res <- fromMaybe def <$> Worklist.dependOn which
+  --res <- pprTrace "dependOnWithDefault:after " (ppr which) (return res)
   return res
 
 buildAndRun :: FrameworkBuilder (SingleUse -> TransferFunction AnalResult) -> SingleUse -> AnalResult
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index 79453c05e5..69a1d1e01e 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -18,12 +18,14 @@ import VarEnv
 data UsageType
   = UT
   { ut_cocalled :: !UnVarGraph
-  -- ^ Models cardinality, e.g. at most {1, many} via the co-call relation for
-  -- _interesting_ variables
+  -- ^ Models cardinality, e.g. at most {1, many} via the co-call relation
   , ut_uses :: !(VarEnv SingleUse)
-  -- ^ Models per var usage and absence (card 0)
+  -- ^ Models how an Id was used, if at all
   , ut_args :: !UsageSig
   -- ^ Collects the signature for captured lambda binders
+  , ut_stable :: Bool
+  -- ^ Entirely irrelevant for Usage information, but needed for detecting
+  -- stabilization of fixed-point iteration.
   }
 
 modifyArgs :: (UsageSig -> UsageSig) -> UsageType -> UsageType
@@ -37,7 +39,7 @@ modifyCoCalls modifier ut = ut { ut_cocalled = modifier (ut_cocalled ut) }
 type AnalResult = (UsageType, CoreExpr)
 
 emptyUsageType :: UsageType
-emptyUsageType = UT emptyUnVarGraph emptyVarEnv topUsageSig
+emptyUsageType = UT emptyUnVarGraph emptyVarEnv topUsageSig False
 
 botUsageType :: UsageType
 botUsageType = unusedArgs emptyUsageType
@@ -52,7 +54,7 @@ delUsageTypes :: [Id] -> UsageType -> UsageType
 delUsageTypes ids ae = foldr delUsageType ae ids
 
 delUsageType :: Id -> UsageType -> UsageType
-delUsageType id (UT g ae args) = UT (g `delNode` id) (ae `delVarEnv` id) args
+delUsageType id (UT g ae args s) = UT (g `delNode` id) (ae `delVarEnv` id) args s
 
 domType :: UsageType -> UnVarSet
 domType ut = varEnvDom (ut_uses ut)
@@ -63,7 +65,7 @@ makeIdArg id ut = delUsageType id (modifyArgs (consUsageSig (lookupUsage NonRecu
 -- In the result, find out the minimum arity and whether the variable is called
 -- at most once.
 lookupUsage :: RecFlag -> UsageType -> Id -> Usage
-lookupUsage rec (UT g ae _) id = case lookupVarEnv ae id of
+lookupUsage rec (UT g ae _ _) id = case lookupVarEnv ae id of
   Just use
     | id `elemUnVarSet` neighbors g id -> Used Many use
     -- we assume recursive bindings to be called multiple times, what's the
@@ -80,31 +82,34 @@ calledWith ut id = neighbors (ut_cocalled ut) id
 -- Replaces the co-call graph by a complete graph (i.e. no information)
 multiplyUsages :: Multiplicity -> UsageType -> UsageType
 multiplyUsages Once ut = ut
-multiplyUsages Many ut@(UT _ u args)
+multiplyUsages Many ut@(UT _ u args _)
   = UT
   { ut_cocalled = completeGraph (domType ut)
   , ut_uses = mapVarEnv (\use -> bothSingleUse use use) u
   , ut_args = manifyUsageSig args
+  , ut_stable = False
   }
 
 -- | Corresponds to sequential composition of expressions.
 -- Used for application and cases.
 -- Note this returns the @UsageSig@ from the first argument.
 bothUsageType :: UsageType -> UsageType -> UsageType
-bothUsageType ut1@(UT g1 u1 args) ut2@(UT g2 u2 _)
+bothUsageType ut1@(UT g1 u1 args _) ut2@(UT g2 u2 _ _)
   = UT
   { ut_cocalled = unionUnVarGraphs [g1, g2, completeBipartiteGraph (domType ut1) (domType ut2)]
   , ut_uses = bothUseEnv u1 u2
   , ut_args = args
+  , ut_stable = False
   }
 
 -- | Used when combining results from alternative cases
 lubUsageType :: UsageType -> UsageType -> UsageType
-lubUsageType (UT g1 u1 args1) (UT g2 u2 args2)
+lubUsageType (UT g1 u1 args1 _) (UT g2 u2 args2 _)
   = UT
   { ut_cocalled = unionUnVarGraph g1 g2
   , ut_uses = lubUseEnv u1 u2
   , ut_args = lubUsageSig args1 args2
+  , ut_stable = False
   }
 
 lubUseEnv :: VarEnv SingleUse -> VarEnv SingleUse -> VarEnv SingleUse
@@ -123,10 +128,13 @@ peelArgUsage ut = (usg, ut { ut_args = args' })
   where
     (usg, args') = unconsUsageSig (ut_args ut)
 
+markStable :: UsageType -> UsageType
+markStable ut = ut { ut_stable = True }
+
 -- * Pretty-printing
 
 instance Outputable UsageType where
-  ppr (UT cocalled arities args) = vcat
+  ppr (UT cocalled arities args _) = vcat
     [ text "arg usages:" <+> ppr args
     , text "co-calls:" <+> ppr cocalled
     , text "uses:" <+> ppr arities
diff --git a/compiler/utils/Worklist.hs b/compiler/utils/Worklist.hs
index 2f275d4739..120f240a4b 100644
--- a/compiler/utils/Worklist.hs
+++ b/compiler/utils/Worklist.hs
@@ -4,7 +4,7 @@
 module Worklist where
 
 import Control.Arrow (first)
-import Control.Monad (forM_)
+import Control.Monad (forM_, when)
 import Control.Monad.Trans.State.Strict
 import Data.Map (Map)
 import qualified Data.Map as Map
@@ -153,10 +153,16 @@ recompute node = do
   refs <- gets referencedNodes
   --pprTrace "recompute:refs" (ppr (length refs)) $ return ()
   oldInfo <- updateGraphNode node newVal refs
+  --pprTrace "recompute:referrers" (ppr (length (referrers oldInfo))) $ return ()
   changedRefs <- fromMaybe Set.empty <$> deleteLookupUnstable node
   case value oldInfo of
     Just oldVal | not (detectChange changedRefs oldVal newVal) -> return ()
-    _ -> forM_ (referrers oldInfo) (\ref -> enqueueUnstable ref (Set.singleton node))
+    _ -> do
+      forM_ (referrers oldInfo) (\ref -> enqueueUnstable ref (Set.singleton node))
+      -- If the node depends itself the first time (e.g. when it gets its first value),
+      -- that will not be reflected in `oldInfo`. So we enqueue it manually
+      -- if that is the case.
+      when (Set.member node refs) (enqueueUnstable node (Set.singleton node))
   modify' $ \st -> st
     { referencedNodes = referencedNodes oldState
     , callStack = callStack oldState
@@ -168,14 +174,12 @@ enqueueUnstable reference referrers_ = zoomUnstable $ modify' $
   Map.alter (Just . maybe referrers_ (Set.union referrers_)) reference
 
 deleteLookupUnstable :: Ord node => node -> State (WorklistState node lattice) (Maybe (Set node))
-deleteLookupUnstable node = zoomUnstable $ state $ Map.updateLookupWithKey (\_ _ -> Nothing) node
+deleteLookupUnstable node = zoomUnstable $ state $ 
+  Map.updateLookupWithKey (\_ _ -> Nothing) node
 
 highestPriorityUnstableNode :: Ord node => State (WorklistState node lattice) (Maybe node)
 highestPriorityUnstableNode = fmap (fst . fst) . Map.maxViewWithKey <$> gets unstable
 
-lookupReferrers :: Ord node => node -> Graph node lattice -> Set node
-lookupReferrers node = maybe Set.empty referrers . Map.lookup node
-
 whileJust_ :: Monad m => m (Maybe a) -> (a -> m b) -> m ()
 whileJust_ pred action = go
   where
-- 
2.12.1


From c719b1b034295257874310e2876b0db70976a08d Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 15 May 2017 19:23:02 +0200
Subject: [PATCH 055/117] Re-introduced handling of trivial RHS

---
 compiler/basicTypes/Usage.hs                       |  6 +++-
 compiler/simplCore/CallArity/Analysis.hs           | 40 +++++++++++++++-------
 testsuite/tests/callarity/unittest/CallArity1.hs   |  2 +-
 .../tests/callarity/unittest/CallArity1.stderr     |  6 ++--
 .../tests/simplCore/should_compile/T4201.stdout    |  2 +-
 .../tests/stranal/should_compile/T10694.stderr     |  4 +--
 6 files changed, 39 insertions(+), 21 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 7481eaafb6..935e4f90fb 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -8,7 +8,7 @@ module Usage
   , Usage (..)
   , multiplicity, botUsage, topUsage, lubUsage, bothUsage
   , seqUsage
-  , manifyUsage, expandArity
+  , manifyUsage, oneifyUsage, expandArity
   , UsageSig
   , botUsageSig, topUsageSig, lubUsageSig
   , consUsageSig, unconsUsageSig, usageSigFromUsages, manifyUsageSig
@@ -282,6 +282,10 @@ seqUsage = Used Once HeadUse
 manifyUsage :: Usage -> Usage
 manifyUsage u = bothUsage u u
 
+oneifyUsage :: Usage -> Usage
+oneifyUsage Absent = Absent
+oneifyUsage (Used _ use) = Used Once use
+
 expandArity :: Usage -> Arity -> Arity
 expandArity Absent cheap_arity
   -- We could potentially expand as far as we want, since the result doesn't
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index b19919d734..96c4496481 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -13,6 +13,7 @@ import CallArity.FrameworkBuilder
 import BasicTypes
 import Coercion ( Coercion, coVarsOfCo )
 import CoreSyn
+import CoreUtils ( exprIsTrivial )
 import DataCon ( DataCon, dataConTyCon, dataConRepStrictness, isMarkedStrict )
 import DynFlags      ( DynFlags, gopt, GeneralFlag(Opt_DmdTxDictSel) )
 import FamInstEnv
@@ -29,6 +30,7 @@ import Var ( isId, isTyVar )
 import VarEnv
 import WwLib ( findTypeShape )
 
+import Control.Arrow ( first )
 import Control.Monad ( forM )
 import qualified Data.Set as Set
 
@@ -569,16 +571,17 @@ callArityExpr env (App f a) = do
     --pprTrace "App:f'" (ppr f') $ return ()
     -- peel off one argument from the type
     let (arg_usage, ut_f') = peelArgUsage ut_f
-    case arg_usage of
+    case considerThunkSharing a arg_usage of
       Absent -> return (ut_f', App f' a)
-      Used _ arg_use -> do
-          -- We can ignore the multiplicity, as the work done before the first
-          -- lambda is uncovered will be shared (call-by-need!). This is the same
-          -- argument as for let-bound right hand sides.
-          -- Although we could use the multiplicity in the same way we do for
+      Used m arg_use -> do
+          -- `m` will be `Once` most of the time (see `considerThunkSharing`),
+          -- so that all work before the lambda is uncovered will be shared 
+          -- (call-by-need!). This is the same argument as for let-bound 
+          -- right hand sides.
+          -- We could also use the multiplicity in the same way we do for
           -- let-bindings: An argument only used once does not need to be
           -- memoized.
-          (ut_a, a') <- transfer_a arg_use
+          (ut_a, a') <- first (multiplyUsages m) <$> transfer_a arg_use
           --pprTrace "App:a'" (text "arg_use:" <+> ppr arg_use <+> ppr (ut_a, a')) $ return ()
           return (ut_f' `bothUsageType` ut_a, App f' a')
 
@@ -732,6 +735,15 @@ globalIdUsageSig id use
     no_call = iterate mk_one_shot botSingleUse !! max 0 (arity - 1)
     single_call = iterate mk_one_shot topSingleUse !! arity
 
+-- | Evaluation of a non-trivial RHS of a let-binding or argument 
+-- is shared (call-by-need!). GHC however doesn't allocate a new thunk
+-- if it finds the expression to bind to be trivial (`exprIsTrivial`).
+-- This makes sure we share usage only if this is not the case.
+considerThunkSharing :: CoreExpr -> Usage -> Usage
+considerThunkSharing e
+  | exprIsTrivial e = id
+  | otherwise = oneifyUsage
+
 analyseCaseAlternative
   :: AnalEnv
   -> Id
@@ -918,12 +930,14 @@ unleashUsage
 unleashUsage rhs transfer_rhs usage
   | Absent <- usage
   = return (emptyUsageType, rhs)
-  | Used _ use <- usage
-  -- The work required to get the RHS of let-bindings to WHNF is shared among
-  -- all use sites, so the multiplicity can be ignored *when analysing the RHS*.
-  -- We still annotate the binder with the multiplity later on, as @Once@ means
-  -- we don't have to memoize the result.
-  = transfer_rhs use
+  | Used m use <- considerThunkSharing rhs usage
+  -- As with arguments, `m` should be `Once` most of the time 
+  -- (e.g. if `rhs` is non-trivial, see `considerThunkSharing`).
+  -- Thus, the work required to get the RHS of let-bindings 
+  -- to WHNF is shared among all use sites.
+  -- We still annotate the binder with the multiplicity later on, 
+  -- as @Once@ means we don't have to memoize the result anyway.
+  = first (multiplyUsages m) <$> transfer_rhs use
 
 -- Combining the results from body and rhs of a let binding
 -- See Note [Analysis II: The Co-Called analysis]
diff --git a/testsuite/tests/callarity/unittest/CallArity1.hs b/testsuite/tests/callarity/unittest/CallArity1.hs
index 02c9097af4..b12f076e5d 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.hs
+++ b/testsuite/tests/callarity/unittest/CallArity1.hs
@@ -181,7 +181,7 @@ exprs =
     mkLet d (f `mkLApps` [0]) $
         mkLet n (mkLams [y] $ d `mkLApps` [1]) $
             elimPair (mkVarPair d n) (_1 `mkLApps` [0])
-  , ("calling the second tuple component twice (expect n 1*U and d w*U by transitivity)",) $
+  , ("calling the second tuple component twice (expect n w*U and d w*U by transitivity)",) $
     mkLet d (f `mkLApps` [0]) $
         mkLet n (mkLams [y] $ d `mkLApps` [1]) $
             elimPair (mkVarPair d n) (Var _2 `mkApps` [_2 `mkLApps` [0]])
diff --git a/testsuite/tests/callarity/unittest/CallArity1.stderr b/testsuite/tests/callarity/unittest/CallArity1.stderr
index 2d02a30dbb..cdcefe1380 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.stderr
+++ b/testsuite/tests/callarity/unittest/CallArity1.stderr
@@ -73,7 +73,7 @@ a thunk (function type), in mutual recursion, absent:
     d A
     n w*U
 a thunk (non-function-type) co-calls with the body (d 1*_ would be bad):
-    x 1*U
+    x w*U
     d w*U
 body cocalls d and n, n calls d (anything other than d w*C^w(U) = w*U would be bad):
     d w*U
@@ -84,6 +84,6 @@ body calls d and n mutually exclusive, n calls d. d should be called once:
 calling the first tuple component once:
     d 1*C^1(U)
     n A
-calling the second tuple component twice (expect n 1*U and d w*U by transitivity):
+calling the second tuple component twice (expect n w*U and d w*U by transitivity):
     d w*U
-    n 1*U
+    n w*U
diff --git a/testsuite/tests/simplCore/should_compile/T4201.stdout b/testsuite/tests/simplCore/should_compile/T4201.stdout
index 384c62aa4c..9a4b157e53 100644
--- a/testsuite/tests/simplCore/should_compile/T4201.stdout
+++ b/testsuite/tests/simplCore/should_compile/T4201.stdout
@@ -1,3 +1,3 @@
-  {- Arity: 1, HasNoCafRefs, Strictness: <S,1*U()>m,
+  {- Arity: 1, HasNoCafRefs, Strictness: <S,1*U>m,
      Unfolding: InlineRule (0, True, True)
                 bof `cast` (Sym (N:Foo[0]) ->_R <T>_R) -}
diff --git a/testsuite/tests/stranal/should_compile/T10694.stderr b/testsuite/tests/stranal/should_compile/T10694.stderr
index e021eb37df..5ed7587af1 100644
--- a/testsuite/tests/stranal/should_compile/T10694.stderr
+++ b/testsuite/tests/stranal/should_compile/T10694.stderr
@@ -4,7 +4,7 @@ Result size of Tidy Core = {terms: 70, types: 63, coercions: 0}
 
 -- RHS size: {terms: 39, types: 25, coercions: 0}
 T10694.$wpm [InlPrag=NOINLINE] :: Int -> Int -> (# Int, Int #)
-[GblId, Arity=2, Str=<L,U(U)><L,U(U)>]
+[GblId, Arity=2, Str=<L,U><L,U>m]
 T10694.$wpm =
   \ (w_sVU :: Int) (w1_sVV :: Int) ->
     let {
@@ -40,7 +40,7 @@ pm = \ (w_sVU :: Int) (w1_sVV :: Int) -> case T10694.$wpm w_sVU w1_sVV of { (# w
 m :: Int -> Int -> Int
 [GblId,
  Arity=2,
- Str=<L,U(U)><L,U(U)>,
+ Str=<L,U><L,U>,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True, WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=2,unsat_ok=True,boring_ok=False)
          Tmpl= \ (x_aCT [Occ=Once] :: Int) (y_aCU [Occ=Once] :: Int) ->
-- 
2.12.1


From 28a1428b5915c4b030c1eb2c8b11a306b60c3744 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 16 May 2017 13:00:04 +0200
Subject: [PATCH 056/117] 2. 2 characters

---
 compiler/simplCore/CallArity/Analysis.hs | 5 +++--
 1 file changed, 3 insertions(+), 2 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 96c4496481..e669de9f51 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -680,7 +680,7 @@ coercionUsageType co = multiplyUsages Many ut
 -- to the constructors `idArity`, then peel off the product use to get at the
 -- usage on its components.
 dataConUsageSig :: Arity -> SingleUse -> UsageSig
-dataConUsageSig arity use = fromMaybe botUsageSig sig_maybe
+dataConUsageSig arity use = fromMaybe topUsageSig sig_maybe
   where
     peelSingleShotCalls 0 use = Just use
     peelSingleShotCalls n call
@@ -799,7 +799,8 @@ setBndrsUsageInfo :: [Var] -> [Usage] -> [Var]
 setBndrsUsageInfo [] [] = []
 setBndrsUsageInfo (b:bndrs) (usage:usages)
   | isId b
-  = setIdCallArity b usage : setBndrsUsageInfo bndrs usages
+  = --pprTrace "setBndrInfo" (ppr b <+> ppr usage) 
+    (setIdCallArity b usage) : setBndrsUsageInfo bndrs usages
 setBndrsUsageInfo (b:bndrs) usages
   = b : setBndrsUsageInfo bndrs usages
 setBndrsUsageInfo _ usages
-- 
2.12.1


From 8df06428edaedefef5a1ac8905c22d928316319f Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Wed, 17 May 2017 17:46:19 +0200
Subject: [PATCH 057/117] Fixed WW failures

---
 compiler/basicTypes/Demand.hs            | 9 ++++++++-
 compiler/basicTypes/Usage.hs             | 4 +++-
 compiler/simplCore/CallArity/Analysis.hs | 5 +++--
 compiler/simplCore/DmdAnalWrapper.hs     | 2 +-
 compiler/stranal/WwLib.hs                | 7 +++++--
 5 files changed, 20 insertions(+), 7 deletions(-)

diff --git a/compiler/basicTypes/Demand.hs b/compiler/basicTypes/Demand.hs
index a91798d727..a9997b3758 100644
--- a/compiler/basicTypes/Demand.hs
+++ b/compiler/basicTypes/Demand.hs
@@ -48,7 +48,7 @@ module Demand (
         deferAfterIO,
         postProcessUnsat, postProcessDmdType,
 
-        splitProdDmd_maybe, peelCallDmd, mkCallDmd, mkWorkerDemand,
+        splitProdDmd_maybe, splitProdDmd, peelCallDmd, mkCallDmd, mkWorkerDemand,
         dmdTransformSig, dmdTransformDataConSig, dmdTransformDictSelSig,
         argOneShots, argsOneShots, saturatedByOneShots,
         trimToType, TypeShape(..),
@@ -931,6 +931,13 @@ splitProdDmd_maybe (JD { sd = s, ud = u })
       (Lazy,    Use _ (UProd ux)) -> Just (mkJointDmds (replicate (length ux) Lazy) ux)
       _ -> Nothing
 
+splitProdDmd :: Int -> Demand -> Maybe [Demand]
+splitProdDmd n JD { sd = as, ud = au }
+  = do
+    let Str _ s = as
+    let Use _ u = au
+    mkJointDmds <$> splitStrProdDmd n s <*> splitUseProdDmd n u
+
 {-
 ************************************************************************
 *                                                                      *
diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 935e4f90fb..d6e1cb887e 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -81,7 +81,9 @@ mkCallUse m u = Call m u
 -- @Product [botUsage, botUsage..] === botSingleUse@.
 mkProductUse :: [Usage] -> SingleUse
 mkProductUse components
-  | all (== topUsage) components = topSingleUse
+  -- This contradicts Note [Don't optimise UProd(Used) to Used], but
+  -- I fixed the issue with WW that probably was the reason for the hack.
+  | all (== topUsage) components = topSingleUse 
   | all (== botUsage) components = botSingleUse
   | otherwise = Product components
 
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index e669de9f51..b7aeb06fed 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -830,8 +830,9 @@ propagateProductUse alts scrut_uses
 
 addDataConStrictness :: DataCon -> SingleUse -> SingleUse
 -- See Note [Add demands for strict constructors] in DmdAnal.hs
-addDataConStrictness dc use
-  = maybe use (mkProductUse . add_component_strictness) (peelProductUse (Just arity) use)
+addDataConStrictness dc
+  = maybe topSingleUse (mkProductUse . add_component_strictness) 
+  . peelProductUse (Just arity) 
   where
     add_component_strictness :: [Usage] -> [Usage]
     add_component_strictness = zipWith add strs
diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index 54e6e1d022..b7deab3320 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -32,7 +32,7 @@ mergeInfo id
   | otherwise
   = ASSERT2( isExportedId id || ca_usage `leqUsage` old_usage, text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
     ASSERT2( not (isExportedId id) || ca_usg_sig `leqUsageSig` old_usg_sig, text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
-    --(if idCallArity id == Absent then pprTrace "Absent" (ppr id) else \x -> x) $
+    --pprTrace "mergeInfo" (ppr id <+> text "Demand:" <+> ppr old_demand <+> ppr ca_usage <+> ppr new_demand <+> text "Strictness" <+> ppr old_str_sig <+> ppr ca_usg_sig <+> ppr new_str_sig) $
     id'
   where
     -- We merge idDemandInfo with idCallArity and idStrictness with idArgUsage.
diff --git a/compiler/stranal/WwLib.hs b/compiler/stranal/WwLib.hs
index 8d41426935..9d90c5aed6 100644
--- a/compiler/stranal/WwLib.hs
+++ b/compiler/stranal/WwLib.hs
@@ -577,12 +577,15 @@ mkWWstr_one dflags fam_envs arg
                 -- during simplification, so for now I've just nuked this whole case
 
   | isStrictDmd dmd
-  , Just cs <- splitProdDmd_maybe dmd
-      -- See Note [Unpacking arguments with product and polymorphic demands]
   , Just (data_con, inst_tys, inst_con_arg_tys, co)
              <- deepSplitProductType_maybe fam_envs (idType arg)
+  , Just cs <- splitProdDmd (length inst_con_arg_tys) dmd
+      -- See Note [Unpacking arguments with product and polymorphic demands]
   , cs `equalLength` inst_con_arg_tys
       -- See Note [mkWWstr and unsafeCoerce]
+  , length (filter (not . isAbsDmd) cs) < 16 
+      -- The 16 is quite arbitrary, so that we don't run into the problem outlined in 
+      -- Note [Unpacking arguments with product and polymorphic demands]
   = do { (uniq1:uniqs) <- getUniquesM
         ; let   unpk_args = zipWith3 mk_ww_arg uniqs inst_con_arg_tys cs
                 unbox_fn  = mkUnpackCase (Var arg) co uniq1
-- 
2.12.1


From c2961b8a7dae8f09c1dbd351a174d65579badec8 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 19 May 2017 01:11:17 +0200
Subject: [PATCH 058/117] 'fixed' T7116, T3772, T4930

---
 testsuite/tests/numeric/should_compile/T7116.stdout   | 8 ++++----
 testsuite/tests/simplCore/should_compile/T3772.stdout | 2 +-
 testsuite/tests/simplCore/should_compile/T4930.stderr | 2 +-
 3 files changed, 6 insertions(+), 6 deletions(-)

diff --git a/testsuite/tests/numeric/should_compile/T7116.stdout b/testsuite/tests/numeric/should_compile/T7116.stdout
index 681d171350..a4c67360b8 100644
--- a/testsuite/tests/numeric/should_compile/T7116.stdout
+++ b/testsuite/tests/numeric/should_compile/T7116.stdout
@@ -52,7 +52,7 @@ dr :: Double -> Double
 [GblId,
  Arity=1,
  Caf=NoCafRefs,
- Str=<S(S),1*U(U)>m,
+ Str=<S(S),1*U>m,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
@@ -69,7 +69,7 @@ dl :: Double -> Double
 [GblId,
  Arity=1,
  Caf=NoCafRefs,
- Str=<S(S),1*U(U)>m,
+ Str=<S(S),1*U>m,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
@@ -82,7 +82,7 @@ fr :: Float -> Float
 [GblId,
  Arity=1,
  Caf=NoCafRefs,
- Str=<S(S),1*U(U)>m,
+ Str=<S(S),1*U>m,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
@@ -101,7 +101,7 @@ fl :: Float -> Float
 [GblId,
  Arity=1,
  Caf=NoCafRefs,
- Str=<S(S),1*U(U)>m,
+ Str=<S(S),1*U>m,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
diff --git a/testsuite/tests/simplCore/should_compile/T3772.stdout b/testsuite/tests/simplCore/should_compile/T3772.stdout
index 44aee7b69e..4845f398cb 100644
--- a/testsuite/tests/simplCore/should_compile/T3772.stdout
+++ b/testsuite/tests/simplCore/should_compile/T3772.stdout
@@ -74,7 +74,7 @@ foo [InlPrag=INLINE[0]] :: Int -> ()
 [GblId,
  Arity=1,
  Caf=NoCafRefs,
- Str=<S(S),1*U(U)>,
+ Str=<S(S),1*U>,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
diff --git a/testsuite/tests/simplCore/should_compile/T4930.stderr b/testsuite/tests/simplCore/should_compile/T4930.stderr
index 9db97a5e1f..7e6ccf9a69 100644
--- a/testsuite/tests/simplCore/should_compile/T4930.stderr
+++ b/testsuite/tests/simplCore/should_compile/T4930.stderr
@@ -65,7 +65,7 @@ foo [InlPrag=INLINE[0]] :: Int -> Int
 [GblId,
  Arity=1,
  Caf=NoCafRefs,
- Str=<S(S),1*U(U)>m,
+ Str=<S(S),1*U>m,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
-- 
2.12.1


From 9feade7b95f20b50fc845657cd493f28b7b51114 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 21 May 2017 19:58:02 +0200
Subject: [PATCH 059/117] 'fixed' spec-inline

---
 testsuite/tests/simplCore/should_compile/spec-inline.stderr | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/testsuite/tests/simplCore/should_compile/spec-inline.stderr b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
index dda28c8926..b36257b9bb 100644
--- a/testsuite/tests/simplCore/should_compile/spec-inline.stderr
+++ b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
@@ -66,7 +66,7 @@ Roman.foo_$s$wgo [Occ=LoopBreaker]
 Roman.foo_$s$wgo =
   \ (sc :: GHC.Prim.Int#) (sc1 :: GHC.Prim.Int#) ->
     let {
-      m :: GHC.Prim.Int#
+      m [Dmd=<L,A>] :: GHC.Prim.Int#
       [LclId]
       m =
         GHC.Prim.+#
@@ -103,7 +103,7 @@ Roman.$wgo =
       Just x ->
         case x of { GHC.Types.I# ipv ->
         let {
-          m :: GHC.Prim.Int#
+          m [Dmd=<L,A>] :: GHC.Prim.Int#
           [LclId]
           m =
             GHC.Prim.+#
@@ -170,7 +170,7 @@ foo :: Int -> Int
 [GblId,
  Arity=1,
  Caf=NoCafRefs,
- Str=<S(S),1*U(U)>m,
+ Str=<S(S),1*U>m,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
-- 
2.12.1


From fec7eaa9c3ddbd7776495e87d3c757915c6c88d3 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 21 May 2017 19:59:46 +0200
Subject: [PATCH 060/117] Various bug fixes, testsuite more or less unchanged

---
 compiler/basicTypes/Usage.hs             |  3 +-
 compiler/coreSyn/PprCore.hs              |  6 ++-
 compiler/simplCore/CallArity/Analysis.hs | 91 +++++++++++++++++++-------------
 compiler/simplCore/DmdAnalWrapper.hs     | 32 ++++++-----
 compiler/stranal/DmdAnal.hs              |  2 +-
 5 files changed, 80 insertions(+), 54 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index d6e1cb887e..67b72dfdbd 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -81,10 +81,11 @@ mkCallUse m u = Call m u
 -- @Product [botUsage, botUsage..] === botSingleUse@.
 mkProductUse :: [Usage] -> SingleUse
 mkProductUse components
+  -- Order is important here: We want to regard U() as HU
+  | all (== botUsage) components = botSingleUse
   -- This contradicts Note [Don't optimise UProd(Used) to Used], but
   -- I fixed the issue with WW that probably was the reason for the hack.
   | all (== topUsage) components = topSingleUse 
-  | all (== botUsage) components = botSingleUse
   | otherwise = Product components
 
 -- | `CoreSym.Id`entifiers can be used multiple times and are the only means to
diff --git a/compiler/coreSyn/PprCore.hs b/compiler/coreSyn/PprCore.hs
index 5889fff949..c3a16912f2 100644
--- a/compiler/coreSyn/PprCore.hs
+++ b/compiler/coreSyn/PprCore.hs
@@ -432,17 +432,20 @@ pprIdBndrInfo info
     prag_info = inlinePragInfo info
     occ_info  = occInfo info
     dmd_info  = demandInfo info
+    usg_info  = callArityInfo info
     lbv_info  = oneShotInfo info
 
     has_prag  = not (isDefaultInlinePragma prag_info)
     has_occ   = not (isManyOccs occ_info)
     has_dmd   = not $ isTopDmd dmd_info
+    has_usg   = usg_info /= topUsage
     has_lbv   = not (hasNoOneShotInfo lbv_info)
 
     doc = showAttributes
           [ (has_prag, text "InlPrag=" <> pprInlineDebug prag_info)
           , (has_occ,  text "Occ=" <> ppr occ_info)
           , (has_dmd,  text "Dmd=" <> ppr dmd_info)
+          , (has_usg,  text "Usg=" <> ppr usg_info)
           , (has_lbv , text "OS=" <> ppr lbv_info)
           ]
 
@@ -459,10 +462,9 @@ ppIdInfo id info
     showAttributes
     [ (True, pp_scope <> ppr (idDetails id))
     , (has_arity,        text "Arity=" <> int arity)
-    , (has_arg_usage,    text "Usg=" <> ppr called_arity)
-    , (has_called_arity, text "CallArity=" <> ppr called_arity)
     , (has_caf_info,     text "Caf=" <> ppr caf_info)
     , (has_str_info,     text "Str=" <> pprStrictness str_info)
+    , (has_arg_usage,    text "ArgUsg=" <> ppr arg_usage)
     , (has_unf,          text "Unf=" <> ppr unf_info)
     , (not (null rules), text "RULES:" <+> vcat (map pprRule rules))
     ]   -- Inline pragma, occ, demand, one-shot info
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index b7aeb06fed..24094f2dbf 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -11,23 +11,25 @@ import CallArity.Types
 import CallArity.FrameworkBuilder
 
 import BasicTypes
+import Class
 import Coercion ( Coercion, coVarsOfCo )
 import CoreSyn
 import CoreUtils ( exprIsTrivial )
-import DataCon ( DataCon, dataConTyCon, dataConRepStrictness, isMarkedStrict )
+import DataCon
 import DynFlags      ( DynFlags, gopt, GeneralFlag(Opt_DmdTxDictSel) )
 import FamInstEnv
 import Id
 import Maybes ( expectJust, fromMaybe, isJust )
 import MkCore
 import Outputable
-import TyCon ( isDataProductTyCon_maybe )
+import TyCon ( isDataProductTyCon_maybe, tyConSingleDataCon_maybe )
 import UniqFM
 import UnVarGraph
 import Usage
 import Util
 import Var ( isId, isTyVar )
 import VarEnv
+import VarSet
 import WwLib ( findTypeShape )
 
 import Control.Arrow ( first )
@@ -429,14 +431,22 @@ extendAnalEnv env id node = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
 -- nested lets, where the exports are returned in the inner-most let
 -- as a tuple. As a result, all exported identifiers are handled as called
 -- with each other, with `topUsage`.
+--
+-- FIXME: Currently, this doesn't play well with Unfoldings exposed by e.g.
+-- Worker wrapper, which effectively export non-exported bindings. So
+-- we simply regard every top-level binding as exported for now.
+-- Something more optimistic like looking at the unfolding and adding all
+-- `exprFreeIds` as used multiple times might work, too. This is not something
+-- I'd like to work on right now, though.
 moduleToExpr :: CoreProgram -> CoreExpr
-moduleToExpr = impl []
+moduleToExpr = impl emptyDVarSet
   where
-    impl exported []
+    impl exposed []
       -- @duplicate@, otherwise those Vars appear to be used once
-      = mkBigCoreVarTup (duplicate exported)
-    impl exported (bind:prog)
-      = Let bind (impl (filter isExportedId (bindersOf bind) ++ exported) prog)
+      = mkBigCoreVarTup (duplicate (dVarSetElems exposed))
+    impl exposed (bind:prog)
+      = Let bind (impl (exposed_ids bind `unionDVarSet` exposed) prog)
+    exposed_ids bind = mkDVarSet (bindersOf bind)
     duplicate = concatMap (replicate 2)
 
 -- | The left inverse to `moduleToExpr`: `exprToModule . moduleToExpr = id \@CoreProgram`
@@ -511,32 +521,33 @@ callArityExpr env e@(Var id) = return transfer
         --pprTrace "callArityExpr:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
         return ((unitUsageType id use) { ut_args = ut_args ut_callee }, e)
 
-      | isDataConWorkId id
+      | isLocalId id
+      -- A LocalId not present in @nodes@, e.g. a lambda or case-bound variable.
+      -- We are only second-order, so we don't model signatures for parameters!
+      -- Their usage is interesting to note nonetheless for annotating lambda
+      -- binders and scrutinees.
+      = --pprTrace "callArityExpr:OtherId" (ppr id <+> ppr use) $
+        return (unitUsageType id use, e)
+
+      -- The other cases handle global ids
+      | Just dc <- ASSERT( isGlobalId id ) (isDataConWorkId_maybe id)
       -- Some data constructor, on which we can try to unleash product use
       -- as a `UsageSig`.
-      = --pprTrace "callArityExpr:DataCon" (ppr id <+> ppr use <+> ppr (dataConUsageSig (idArity id) use)) $
-        return (emptyUsageType { ut_args = dataConUsageSig (idArity id) use }, e)
+      = --pprTrace "callArityExpr:DataCon" (ppr id <+> ppr use <+> ppr (dataConUsageSig dc use)) $
+        return (emptyUsageType { ut_args = dataConUsageSig dc use }, e)
 
       | gopt Opt_DmdTxDictSel (ae_dflags env)
-      , Just _ <- isClassOpId_maybe id
+      , Just clazz <- isClassOpId_maybe id
       -- A dictionary component selector
-      = --pprTrace "callArityExpr:DictSel" (ppr id <+> ppr use <+> ppr (dictSelUsageSig id use)) $
-        return (emptyUsageType { ut_args = dictSelUsageSig id use }, e)
+      = --pprTrace "callArityExpr:DictSel" (ppr id <+> ppr use <+> ppr (dictSelUsageSig id clazz use)) $
+        return (emptyUsageType { ut_args = dictSelUsageSig id clazz use }, e)
 
-      | isGlobalId id
+      | otherwise
       -- A global id from another module which has a usage signature.
       -- We don't need to track the id itself, though.
-      = --pprTrace "callArityExpr:GlobalId" (ppr id <+> ppr use <+> ppr (globalIdUsageSig id use)) $
+      = --pprTrace "callArityExpr:GlobalId" (ppr id <+> ppr (idArity id) <+> ppr use <+> ppr (globalIdUsageSig id use) <+> ppr (idDetails id)) $
         return (emptyUsageType { ut_args = globalIdUsageSig id use }, e)
 
-      | otherwise
-      -- A LocalId not present in @nodes@, e.g. a lambda or case-bound variable.
-      -- We are only second-order, so we don't model signatures for parameters!
-      -- Their usage is interesting to note nonetheless for annotating lambda
-      -- binders and scrutinees.
-      = --pprTrace "callArityExpr:OtherId" (ppr id <+> ppr use) $
-        return (unitUsageType id use, e)
-
 callArityExpr env (Lam id body)
   | isTyVar id
   -- Non-value lambdas are ignored
@@ -547,7 +558,7 @@ callArityExpr env (Lam id body)
     return $ \use ->
       case fromMaybe topUsage (peelCallUse use) of -- Get at the relative @Usage@ of the body
         Absent -> return (emptyUsageType, Lam id body)
-        Used multi body_use -> do
+        u@(Used multi body_use) -> do
           (ut_body, body') <- transfer_body body_use
           let (ut_body', usage_id) = findBndrUsage NonRecursive (ae_fam_envs env) ut_body id
           let id' = applyWhen (multi == Once) (flip setIdOneShotInfo OneShotLam)
@@ -558,7 +569,7 @@ callArityExpr env (Lam id body)
           let ut = modifyArgs (consUsageSig usage_id)
                  . multiplyUsages multi
                  $ ut_body'
-          --pprTrace "callArityExpr:Lam" (vcat [text "id:" <+> ppr id, text "usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
+          --pprTrace "callArityExpr:Lam" (vcat [text "id:" <+> ppr id, text "relative body usage:" <+> ppr u, text "id usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
           return (ut, Lam id' body')
 
 callArityExpr env (App f (Type t)) = callArityExprMap env (flip App (Type t)) f
@@ -679,9 +690,10 @@ coercionUsageType co = multiplyUsages Many ut
 -- `dataConUsageSig` does exactly this: First peel off one-shot calls according
 -- to the constructors `idArity`, then peel off the product use to get at the
 -- usage on its components.
-dataConUsageSig :: Arity -> SingleUse -> UsageSig
-dataConUsageSig arity use = fromMaybe topUsageSig sig_maybe
+dataConUsageSig :: DataCon -> SingleUse -> UsageSig
+dataConUsageSig dc use = fromMaybe topUsageSig sig_maybe
   where
+    arity = dataConRepArity dc
     peelSingleShotCalls 0 use = Just use
     peelSingleShotCalls n call
       | Just Absent <- peelCallUse call
@@ -692,13 +704,18 @@ dataConUsageSig arity use = fromMaybe topUsageSig sig_maybe
       = Nothing
     sig_maybe = do
       product_use <- peelSingleShotCalls arity use
-      component_usages <- peelProductUse (Just arity) product_use
+      -- We need to consider strict constructors, where a head use will also
+      -- use its components (e.g. I#)
+      component_usages <- peelProductUse (Just arity) (addDataConStrictness dc product_use)
       return (usageSigFromUsages component_usages)
 
-dictSelUsageSig :: Id -> SingleUse -> UsageSig
-dictSelUsageSig id use
+dictSelUsageSig :: Id -> Class -> SingleUse -> UsageSig
+dictSelUsageSig id clazz use
+  -- using idArgUsage seems to loop endlessly on Data.Bits
   | Used _ dict_single_call_use <- fst . unconsUsageSig . usageSigFromStrictSig . idStrictness $ id
-  , Just comps <- peelProductUse Nothing dict_single_call_use
+  , Just dc <- tyConSingleDataCon_maybe (classTyCon clazz)
+  , let dict_length = idArity (dataConWorkId dc)
+  , Just comps <- peelProductUse (Just dict_length) dict_single_call_use
   = case peelCallUse use of -- The outer call is the selector. The inner use is on the actual method!
       Nothing -> topUsageSig -- weird
       Just Absent -> botUsageSig
@@ -725,15 +742,17 @@ globalIdUsageSig id use
   -- We would annotate them with something isomorphic anyway.
   = usageSigFromStrictSig (idStrictness id)
   | use <= single_call
-  = idArgUsage id
+  = arg_usage
   | otherwise
-  = topUsageSig
+  = --pprTrace "many" (ppr arg_usage <+> ppr (idStrictness id) <+> ppr (manifyUsageSig arg_usage)) $ 
+    manifyUsageSig arg_usage
   where
     (<=) = leqSingleUse
     arity = idArity id
     mk_one_shot = mkCallUse Once
     no_call = iterate mk_one_shot botSingleUse !! max 0 (arity - 1)
     single_call = iterate mk_one_shot topSingleUse !! arity
+    arg_usage = idArgUsage id
 
 -- | Evaluation of a non-trivial RHS of a let-binding or argument 
 -- is shared (call-by-need!). GHC however doesn't allocate a new thunk
@@ -818,7 +837,7 @@ propagateProductUse alts scrut_uses
   -- Don't include newtypes, as they aren't really constructors introducing
   -- indirections.
   , isJust (isDataProductTyCon_maybe tycon)
-  -- This is a good place to make sure we don't construct an infinitely depth
+  -- This is a good place to make sure we don't construct an infinitely deep
   -- use, which can happen when analysing e.g. lazy streams.
   -- Also see Note [Demand on scrutinee of a product case] in DmdAnal.hs.
   = addDataConStrictness dc (boundDepth 10 scrut_use)
@@ -862,12 +881,12 @@ registerBindingGroup env = go env emptyVarEnv
           transfer <- callArityExpr env' rhs
           let transfer' use = do
                 --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
-                ret@(ut_rhs, e) <- transfer use
+                ret@(ut_rhs, _) <- transfer use
                 --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut_rhs)]) $ return ret
                 return ret
           let transfer_args use = do
                 --use <- pprTrace "args:begin" (ppr id <+> text "::" <+> ppr use) $ return use
-                ret@(ut, e) <- dependOnWithDefault (botUsageType, rhs) (node, use)
+                ret@(ut, _) <- dependOnWithDefault (botUsageType, rhs) (node, use)
                 --ret <- pprTrace "args:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut)]) $ return ret
                 return ret
           let change_detector_args nodes (old, _) (new, _) =
diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index b7deab3320..8b925a313b 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -25,12 +25,16 @@ combinedDmdAnalProgram dflags fams prog = do
   --pprTrace "Program" (ppr prog'') $ pure ()
   return (mapBndrsProgram mergeInfo prog'')
 
-mergeInfo :: Var -> Var
-mergeInfo id
+mergeInfo :: Bool -> Var -> Var
+mergeInfo isLamBndr id
   | isTyVar id
   = id
-  | otherwise
-  = ASSERT2( isExportedId id || ca_usage `leqUsage` old_usage, text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
+  | otherwise 
+  -- Since LetDown analyzes the RHS stripped-off of lambdas only once with U 
+  -- instead of the whole expression, we get more conservative results in our
+  -- new analysis, where there might be multiplied uses on lambda binders if
+  -- it has more than one lambda. In that case we have to relax the assert.
+  = ASSERT2( isLamBndr || isExportedId id || ca_usage `leqUsage` old_usage, text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
     ASSERT2( not (isExportedId id) || ca_usg_sig `leqUsageSig` old_usg_sig, text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
     --pprTrace "mergeInfo" (ppr id <+> text "Demand:" <+> ppr old_demand <+> ppr ca_usage <+> ppr new_demand <+> text "Strictness" <+> ppr old_str_sig <+> ppr ca_usg_sig <+> ppr new_str_sig) $
     id'
@@ -56,28 +60,28 @@ mergeInfo id
       | otherwise = id `setIdDemandInfo` new_demand -- Only use sites matter
 
 
-mapBndrsProgram :: HasCallStack => (Var -> Var) -> CoreProgram -> CoreProgram
+mapBndrsProgram :: (Bool -> Var -> Var) -> CoreProgram -> CoreProgram
 mapBndrsProgram f = map (mapBndrsBind f)
 
-mapBndrsBind :: HasCallStack => (Var -> Var) -> CoreBind -> CoreBind
-mapBndrsBind f (NonRec id e) = NonRec (f id) (mapBndrsExprIfNotAbsent id f e)
-mapBndrsBind f (Rec bndrs) = Rec (map (\(id, e) -> (f id, mapBndrsExprIfNotAbsent id f e)) bndrs)
+mapBndrsBind :: (Bool -> Var -> Var) -> CoreBind -> CoreBind
+mapBndrsBind f (NonRec id e) = NonRec (f False id) (mapBndrsExprIfNotAbsent id f e)
+mapBndrsBind f (Rec bndrs) = Rec (map (\(id, e) -> (f False id, mapBndrsExprIfNotAbsent id f e)) bndrs)
 
-mapBndrsExprIfNotAbsent :: HasCallStack => Var -> (Var -> Var) -> CoreExpr -> CoreExpr
+mapBndrsExprIfNotAbsent :: Var -> (Bool -> Var -> Var) -> CoreExpr -> CoreExpr
 mapBndrsExprIfNotAbsent id f e
   | Absent <- idCallArity id = e -- we won't have analysed e in this case.
   | otherwise = mapBndrsExpr f e
 
-mapBndrsExpr :: HasCallStack => (Var -> Var) -> CoreExpr -> CoreExpr
+mapBndrsExpr :: (Bool -> Var -> Var) -> CoreExpr -> CoreExpr
 mapBndrsExpr f e = case e of
   App func arg -> App (mapBndrsExpr f func) (mapBndrsExpr f arg)
-  Lam id e -> Lam (f id) (mapBndrsExpr f e)
+  Lam id e -> Lam (f True id) (mapBndrsExpr f e)
   Let bind body -> Let (mapBndrsBind f bind) (mapBndrsExpr f body)
-  Case scrut id ty alts -> Case (mapBndrsExpr f scrut) (f id) ty (map (mapBndrsAlt f) alts)
+  Case scrut id ty alts -> Case (mapBndrsExpr f scrut) (f False id) ty (map (mapBndrsAlt f) alts)
   Cast e co -> Cast (mapBndrsExpr f e) co
   Tick t e -> Tick t (mapBndrsExpr f e)
   Var _ -> e -- use sites carry no important annotations
   _ -> e
 
-mapBndrsAlt :: HasCallStack => (Var -> Var) -> Alt CoreBndr -> Alt CoreBndr
-mapBndrsAlt f (con, bndrs, e) = (con, map f bndrs, mapBndrsExpr f e)
+mapBndrsAlt :: (Bool -> Var -> Var) -> Alt CoreBndr -> Alt CoreBndr
+mapBndrsAlt f (con, bndrs, e) = (con, map (f False) bndrs, mapBndrsExpr f e)
diff --git a/compiler/stranal/DmdAnal.hs b/compiler/stranal/DmdAnal.hs
index e267ac64ba..cfbb8b3a4e 100644
--- a/compiler/stranal/DmdAnal.hs
+++ b/compiler/stranal/DmdAnal.hs
@@ -1089,7 +1089,7 @@ data AnalEnv
        --   worker/wrapper related.
  }
 
-{-| Stores a @StrictSig@ per @Var@ (which represent functions).
+{-| Stores a @StrictSig@ per @LocalId@ (which represent functions).
 
 If the the @StrictSig@ of a function is satisfied (e.g. if the function is given
 enough args), it gives
-- 
2.12.1


From 0ce1f34321671096d60d9a9a16dc49cf682f1c7f Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 23 May 2017 10:19:15 +0200
Subject: [PATCH 061/117] Tried batched args, but broke  some tests.. not worth
 it at this point

---
 compiler/simplCore/CallArity/Analysis.hs | 73 +++++++++++++++++---------------
 compiler/simplCore/CallArity/Types.hs    | 17 ++++++++
 2 files changed, 56 insertions(+), 34 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 24094f2dbf..1210b572f4 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -431,22 +431,15 @@ extendAnalEnv env id node = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
 -- nested lets, where the exports are returned in the inner-most let
 -- as a tuple. As a result, all exported identifiers are handled as called
 -- with each other, with `topUsage`.
---
--- FIXME: Currently, this doesn't play well with Unfoldings exposed by e.g.
--- Worker wrapper, which effectively export non-exported bindings. So
--- we simply regard every top-level binding as exported for now.
--- Something more optimistic like looking at the unfolding and adding all
--- `exprFreeIds` as used multiple times might work, too. This is not something
--- I'd like to work on right now, though.
 moduleToExpr :: CoreProgram -> CoreExpr
-moduleToExpr = impl emptyDVarSet
+moduleToExpr = impl []
   where
     impl exposed []
       -- @duplicate@, otherwise those Vars appear to be used once
-      = mkBigCoreVarTup (duplicate (dVarSetElems exposed))
+      = mkBigCoreVarTup (duplicate exposed)
     impl exposed (bind:prog)
-      = Let bind (impl (exposed_ids bind `unionDVarSet` exposed) prog)
-    exposed_ids bind = mkDVarSet (bindersOf bind)
+      = Let bind (impl (exposed_ids bind ++ exposed) prog)
+    exposed_ids bind = filter isExportedId (bindersOf bind)
     duplicate = concatMap (replicate 2)
 
 -- | The left inverse to `moduleToExpr`: `exprToModule . moduleToExpr = id \@CoreProgram`
@@ -572,29 +565,41 @@ callArityExpr env (Lam id body)
           --pprTrace "callArityExpr:Lam" (vcat [text "id:" <+> ppr id, text "relative body usage:" <+> ppr u, text "id usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
           return (ut, Lam id' body')
 
-callArityExpr env (App f (Type t)) = callArityExprMap env (flip App (Type t)) f
-
-callArityExpr env (App f a) = do
-  transfer_f <- callArityExpr env f
-  transfer_a <- callArityExpr env a
-  return $ \result_use -> do
-    (ut_f, f') <- transfer_f (mkCallUse Once result_use)
-    --pprTrace "App:f'" (ppr f') $ return ()
-    -- peel off one argument from the type
-    let (arg_usage, ut_f') = peelArgUsage ut_f
-    case considerThunkSharing a arg_usage of
-      Absent -> return (ut_f', App f' a)
-      Used m arg_use -> do
-          -- `m` will be `Once` most of the time (see `considerThunkSharing`),
-          -- so that all work before the lambda is uncovered will be shared 
-          -- (call-by-need!). This is the same argument as for let-bound 
-          -- right hand sides.
-          -- We could also use the multiplicity in the same way we do for
-          -- let-bindings: An argument only used once does not need to be
-          -- memoized.
-          (ut_a, a') <- first (multiplyUsages m) <$> transfer_a arg_use
-          --pprTrace "App:a'" (text "arg_use:" <+> ppr arg_use <+> ppr (ut_a, a')) $ return ()
-          return (ut_f' `bothUsageType` ut_a, App f' a')
+callArityExpr env e@App{} 
+  | (f, args) <- collectArgs e
+  = do
+    let val_args = filter isValArg args 
+    let n = length val_args
+    transfer_f <- callArityExpr env f
+    transfer_val_args <- mapM (callArityExpr env) val_args
+    return $ \result_use -> do
+      (ut_f, f') <- transfer_f (iterate (mkCallUse Once) result_use !! n)
+      --pprTrace "App:f'" (ppr f') $ return ()
+      let blub ut_f [] [] = return (ut_f, [], [])
+          blub ut_f (transfer_arg:transfer_args) (arg:args) = do
+            -- peel off one argument from the type
+            let (arg_usage, ut_f') = peelArgUsage ut_f
+            -- handle the other args
+            (ut_f'', ut_args, args') <- blub ut_f' transfer_args args
+            case considerThunkSharing arg arg_usage of
+              Absent -> return (ut_f'', botUsageType:ut_args, arg:args')
+              Used m arg_use -> do
+                -- `m` will be `Once` most of the time (see `considerThunkSharing`),
+                -- so that all work before the lambda is uncovered will be shared 
+                -- (call-by-need!). This is the same argument as for let-bound 
+                -- right hand sides.
+                -- We could also use the multiplicity in the same way we do for
+                -- let-bindings: An argument only used once does not need to be
+                -- memoized.
+                (ut_arg, arg') <- first (multiplyUsages m) <$> transfer_arg arg_use
+                --pprTrace "App:arg'" (text "arg_use:" <+> ppr arg_use <+> ppr (ut_a, a')) $ return ()
+                return (ut_f'', ut_arg:ut_args, arg':args')
+      (ut_f', ut_args, val_args') <- blub ut_f transfer_val_args val_args
+      let merge_with_type_args (a:args) (va:val_args) 
+            | isValArg a = va:merge_with_type_args args val_args
+            | otherwise = a:merge_with_type_args args (va:val_args)
+          merge_with_type_args args [] = args
+      return (bothUsageTypes (ut_f':ut_args), mkApps f' (merge_with_type_args args val_args'))
 
 callArityExpr env (Case scrut case_bndr ty alts) = do
   transfer_scrut <- callArityExpr env scrut
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index 69a1d1e01e..e6f96391e9 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -8,6 +8,8 @@ import UnVarGraph
 import Usage
 import VarEnv
 
+import Data.List ( tails )
+
 ---------------------------------------
 -- Functions related to UsageType    --
 ---------------------------------------
@@ -59,6 +61,9 @@ delUsageType id (UT g ae args s) = UT (g `delNode` id) (ae `delVarEnv` id) args
 domType :: UsageType -> UnVarSet
 domType ut = varEnvDom (ut_uses ut)
 
+domTypes :: [UsageType] -> UnVarSet
+domTypes = foldr unionUnVarSet emptyUnVarSet . map domType
+
 makeIdArg :: Id -> UsageType -> UsageType
 makeIdArg id ut = delUsageType id (modifyArgs (consUsageSig (lookupUsage NonRecursive ut id)) ut)
 
@@ -90,6 +95,18 @@ multiplyUsages Many ut@(UT _ u args _)
   , ut_stable = False
   }
 
+bothUsageTypes :: [UsageType] -> UsageType
+bothUsageTypes uts 
+  = UT cocalled uses args False
+  where
+    cocalls = map ut_cocalled uts
+    uses = foldr bothUseEnv emptyVarEnv (map ut_uses uts)
+    args = foldr lubUsageSig botUsageSig (map ut_args uts)
+    pairings = drop 2 (reverse (tails uts)) -- beginning with a two element list
+    crossCalls = flip map pairings $ \(ut:others) -> 
+      completeBipartiteGraph (domType ut) (domTypes others)
+    cocalled = unionUnVarGraphs (cocalls ++ crossCalls)
+
 -- | Corresponds to sequential composition of expressions.
 -- Used for application and cases.
 -- Note this returns the @UsageSig@ from the first argument.
-- 
2.12.1


From 2a6f9565fa28f4d5ef44461e6a353894d20447a9 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 26 May 2017 16:04:11 +0200
Subject: [PATCH 062/117] Various bug fixes, stil can't compile TH/Syntax.hs
 though

---
 compiler/basicTypes/Id.hs                |   3 +
 compiler/basicTypes/MkId.hs              |  40 +++++++----
 compiler/basicTypes/Usage.hs             |  16 +++--
 compiler/coreSyn/CoreTidy.hs             |   2 +
 compiler/main/TidyPgm.hs                 |   3 +
 compiler/simplCore/CallArity/Analysis.hs | 111 ++++++++++++++++++-------------
 compiler/simplCore/CallArity/Types.hs    |  50 +++++++++-----
 compiler/simplCore/DmdAnalWrapper.hs     |  43 ++++++------
 compiler/simplCore/SimplCore.hs          |   1 +
 compiler/simplCore/Simplify.hs           |   1 +
 compiler/utils/UnVarGraph.hs             |  15 ++++-
 11 files changed, 184 insertions(+), 101 deletions(-)

diff --git a/compiler/basicTypes/Id.hs b/compiler/basicTypes/Id.hs
index 3f118835ee..61381a0068 100644
--- a/compiler/basicTypes/Id.hs
+++ b/compiler/basicTypes/Id.hs
@@ -948,10 +948,13 @@ transferPolyIdInfo old_id abstract_wrt new_id
     old_strictness  = strictnessInfo old_info
     new_strictness  = increaseStrictSigArity arity_increase old_strictness
 
+    old_arg_usage   = argUsageInfo old_info
+
     transfer new_info = new_info `setArityInfo` new_arity
                                  `setInlinePragInfo` old_inline_prag
                                  `setOccInfo` new_occ_info
                                  `setStrictnessInfo` new_strictness
+                                 `setArgUsageInfo` old_arg_usage
 
 isNeverLevPolyId :: Id -> Bool
 isNeverLevPolyId = isNeverLevPolyIdInfo . idInfo
diff --git a/compiler/basicTypes/MkId.hs b/compiler/basicTypes/MkId.hs
index a3c82f1bd6..02b5797732 100644
--- a/compiler/basicTypes/MkId.hs
+++ b/compiler/basicTypes/MkId.hs
@@ -62,6 +62,7 @@ import DataCon
 import Id
 import IdInfo
 import Demand
+import Usage
 import CoreSyn
 import Unique
 import UniqSupply
@@ -286,8 +287,9 @@ mkDictSelId name clas
              getNth arg_tys val_index
 
     base_info = noCafIdInfo
-                `setArityInfo`          1
-                `setStrictnessInfo`     strict_sig
+                `setArityInfo`         1
+                `setStrictnessInfo`    strict_sig
+                `setArgUsageInfo`      usage_sig
                 `setLevityInfoWithType` sel_ty
 
     info | new_tycon
@@ -321,6 +323,11 @@ mkDictSelId name clas
             | otherwise = mkManyUsedDmd $
                           mkProdDmd [ if name == sel_name then evalDmd else absDmd
                                     | sel_name <- sel_names ]
+    usage_sig = consUsageSig arg_usg topUsageSig
+    arg_usg | new_tycon = topUsage
+            | otherwise = Usage.Used Usage.Many $ 
+                            mkProductUse [ if name == sel_name then topUsage else botUsage
+                                         | sel_name <- sel_names ]
 
 mkDictSelRhs :: Class
              -> Int         -- 0-indexed selector among (superclasses ++ methods)
@@ -380,10 +387,11 @@ mkDataConWorkId wkr_name data_con
     alg_wkr_ty = dataConRepType data_con
     wkr_arity = dataConRepArity data_con
     wkr_info  = noCafIdInfo
-                `setArityInfo`          wkr_arity
-                `setStrictnessInfo`     wkr_sig
-                `setUnfoldingInfo`      evaldUnfolding  -- Record that it's evaluated,
-                                                        -- even if arity = 0
+                `setArityInfo`       wkr_arity
+                `setStrictnessInfo`  wkr_sig
+                `setArgUsageInfo`    topUsageSig
+                `setUnfoldingInfo`   evaldUnfolding  -- Record that it's evaluated,
+                                                     -- even if arity = 0
                 `setLevityInfoWithType` alg_wkr_ty
                   -- NB: unboxed tuples have workers, so we can't use
                   -- setNeverLevPoly
@@ -521,6 +529,7 @@ mkDataConRep dflags fam_envs wrap_name mb_bangs data_con
                          `setInlinePragInfo`    wrap_prag
                          `setUnfoldingInfo`     wrap_unf
                          `setStrictnessInfo`    wrap_sig
+                         `setArgUsageInfo`      topUsageSig
                              -- We need to get the CAF info right here because TidyPgm
                              -- does not tidy the IdInfo of implicit bindings (like the wrapper)
                              -- so it not make sure that the CAF info is sane
@@ -988,10 +997,12 @@ mkPrimOpId prim_op
     id   = mkGlobalId (PrimOpId prim_op) name ty info
 
     info = noCafIdInfo
-           `setRuleInfo`           mkRuleInfo (maybeToList $ primOpRules name prim_op)
-           `setArityInfo`          arity
-           `setStrictnessInfo`     strict_sig
-           `setInlinePragInfo`     neverInlinePragma
+           `setRuleInfo`          mkRuleInfo (maybeToList $ primOpRules name prim_op)
+           `setArityInfo`         arity
+           `setStrictnessInfo`    strict_sig
+           -- Reusing the usage declarations in primops.txt.pp for the time being...
+           `setArgUsageInfo`      usageSigFromStrictSig strict_sig
+           `setInlinePragInfo`    neverInlinePragma
            `setLevityInfoWithType` res_ty
                -- We give PrimOps a NOINLINE pragma so that we don't
                -- get silly warnings from Desugar.dsRule (the inline_shadows_rule
@@ -1021,10 +1032,11 @@ mkFCallId dflags uniq fcall ty
     name = mkFCallName uniq occ_str
 
     info = noCafIdInfo
-           `setArityInfo`          arity
-           `setStrictnessInfo`     strict_sig
+           `setArityInfo`         arity
+           `setStrictnessInfo`    strict_sig
+           `setArgUsageInfo`      topUsageSig
            `setLevityInfoWithType` ty
-
+           
     (bndrs, _) = tcSplitPiTys ty
     arity      = count isAnonTyBinder bndrs
     strict_sig = mkClosedStrictSig (replicate arity topDmd) topRes
@@ -1223,11 +1235,13 @@ runRWId = pcMiscPrelId runRWName ty info
   where
     info = noCafIdInfo `setInlinePragInfo` neverInlinePragma
                        `setStrictnessInfo` strict_sig
+                       `setArgUsageInfo`   usage_sig
                        `setArityInfo`      1
     strict_sig = mkClosedStrictSig [strictApply1Dmd] topRes
       -- Important to express its strictness,
       -- since it is not inlined until CorePrep
       -- Also see Note [runRW arg] in CorePrep
+    usage_sig = consUsageSig u'1C1U topUsageSig
 
     -- State# RealWorld
     stateRW = mkTyConApp statePrimTyCon [realWorldTy]
diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 67b72dfdbd..2d58fb4753 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -7,12 +7,12 @@ module Usage
   , botSingleUse, topSingleUse, lubSingleUse, leqSingleUse, bothSingleUse, mkCallUse, peelCallUse, mkProductUse, peelProductUse, boundDepth
   , Usage (..)
   , multiplicity, botUsage, topUsage, lubUsage, bothUsage
-  , seqUsage
   , manifyUsage, oneifyUsage, expandArity
   , UsageSig
   , botUsageSig, topUsageSig, lubUsageSig
   , consUsageSig, unconsUsageSig, usageSigFromUsages, manifyUsageSig
   , trimSingleUse, trimUsage, trimUsageSig
+  , u'1HU, u'1C1U
   , usageFromDemand, overwriteDemandWithUsage, usageSigFromStrictSig, overwriteStrictSigWithUsageSig
   ) where
 
@@ -274,10 +274,6 @@ trimUsage :: TypeShape -> Usage -> Usage
 trimUsage shape (Used m use) = Used m (trimSingleUse shape use)
 trimUsage _ usg = usg
 
--- | `Usage` unleashed on `x` in @x `seq` ...@.
-seqUsage :: Usage
-seqUsage = Used Once HeadUse
-
 -- | @manifyUsage u = bothUsage u u@. For when an id is used more than once
 -- with the same `Usage`. This is different than just changing the top-level
 -- `Multiplicity` to `Many`, which would correspond to an additional `seq`
@@ -370,6 +366,16 @@ trimUsageSig (Call _ u) sig = consUsageSig head_usage (trimUsageSig u tail_usage
     (head_usage, tail_usage) = unconsUsageSig sig
 trimUsageSig _ _ = TopUsageSig
 
+-- * Specific `Usage`s/`SingleUse`s
+
+-- | `Usage` unleashed on `x` in @x `seq` ...@.
+u'1HU:: Usage
+u'1HU = Used Once HeadUse
+
+-- | 'Called once with one argument' `Usage`: @1*C^1(U)@
+u'1C1U :: Usage
+u'1C1U = Used Once (mkCallUse Once topSingleUse)
+
 -- * Pretty-printing
 
 instance Outputable Multiplicity where
diff --git a/compiler/coreSyn/CoreTidy.hs b/compiler/coreSyn/CoreTidy.hs
index 3578b0b437..46db938e6d 100644
--- a/compiler/coreSyn/CoreTidy.hs
+++ b/compiler/coreSyn/CoreTidy.hs
@@ -202,6 +202,8 @@ tidyLetBndr rec_tidy_env env@(tidy_env, var_env) (id,rhs)
                     `setArityInfo`      exprArity rhs
                     `setStrictnessInfo` zapUsageEnvSig (strictnessInfo old_info)
                     `setDemandInfo`     demandInfo old_info
+                    `setArgUsageInfo`   argUsageInfo old_info
+                    `setCallArityInfo`  callArityInfo old_info
                     `setInlinePragInfo` inlinePragInfo old_info
                     `setUnfoldingInfo`  new_unf
 
diff --git a/compiler/main/TidyPgm.hs b/compiler/main/TidyPgm.hs
index 4b9fbae599..fa0577d486 100644
--- a/compiler/main/TidyPgm.hs
+++ b/compiler/main/TidyPgm.hs
@@ -1242,12 +1242,14 @@ tidyTopIdInfo dflags rhs_tidy_env name orig_rhs tidy_rhs idinfo show_unfold caf_
         `setCafInfo`        caf_info
         `setArityInfo`      arity
         `setStrictnessInfo` final_sig
+        `setArgUsageInfo`   arg_usage
 
   | otherwise           -- Externally-visible Ids get the whole lot
   = vanillaIdInfo
         `setCafInfo`           caf_info
         `setArityInfo`         arity
         `setStrictnessInfo`    final_sig
+        `setArgUsageInfo`      arg_usage
         `setOccInfo`           robust_occ_info
         `setInlinePragInfo`    (inlinePragInfo idinfo)
         `setUnfoldingInfo`     unfold_info
@@ -1303,6 +1305,7 @@ tidyTopIdInfo dflags rhs_tidy_env name orig_rhs tidy_rhs idinfo show_unfold caf_
     -- it to the top level. So it seems more robust just to
     -- fix it here.
     arity = exprArity orig_rhs
+    arg_usage = argUsageInfo idinfo
 
 {-
 ************************************************************************
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 1210b572f4..eaa069ad99 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -32,7 +32,7 @@ import VarEnv
 import VarSet
 import WwLib ( findTypeShape )
 
-import Control.Arrow ( first )
+import Control.Arrow ( first, second )
 import Control.Monad ( forM )
 import qualified Data.Set as Set
 
@@ -413,36 +413,51 @@ data AnalEnv
   -- be unstable and thus too optimistic.
   , ae_fam_envs :: FamInstEnvs
   -- ^ Needed for 'findTypeShape' to resolve type/data families.
+  , ae_need_sig_annotation :: VarSet
+  -- ^ `Id`s which need to be annotated with a signature, e.g. because
+  -- they are visible beyond this module. These are probably top-level
+  -- ids only, including exports and mentions in RULEs.
   }
 
-initialAnalEnv :: DynFlags -> FamInstEnvs -> AnalEnv
-initialAnalEnv dflags fam_envs
+initialAnalEnv :: DynFlags -> FamInstEnvs -> VarSet -> AnalEnv
+initialAnalEnv dflags fam_envs need_sigs
   = AE
   { ae_dflags = dflags
   , ae_sigs = emptyVarEnv
   , ae_fam_envs = fam_envs
+  , ae_need_sig_annotation = need_sigs
   }
 
 extendAnalEnv :: AnalEnv -> Id -> FrameworkNode -> AnalEnv
 extendAnalEnv env id node = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
 
 -- | See Note [Analysing top-level-binds]
--- Represents the fact that a CoreProgram is like a sequence of
--- nested lets, where the exports are returned in the inner-most let
+-- `moduleToExpr` returns a pair of externally visible top-level `Id`s
+-- (including at least exports and mentions in RULEs) and a nested
+-- `let` expression to be analysed by `callArityRHS`.
+--
+-- Represents the fact that a `CoreProgram` is like a sequence of
+-- nested lets, where the external visible ids are returned in the inner-most let
 -- as a tuple. As a result, all exported identifiers are handled as called
 -- with each other, with `topUsage`.
-moduleToExpr :: CoreProgram -> CoreExpr
+moduleToExpr :: CoreProgram -> (VarSet, CoreExpr)
 moduleToExpr = impl []
   where
     impl exposed []
-      -- @duplicate@, otherwise those Vars appear to be used once
-      = mkBigCoreVarTup (duplicate exposed)
+      = (mkVarSet exposed, mkBigCoreVarTup exposed)
     impl exposed (bind:prog)
-      = Let bind (impl (exposed_ids bind ++ exposed) prog)
-    exposed_ids bind = filter isExportedId (bindersOf bind)
-    duplicate = concatMap (replicate 2)
-
--- | The left inverse to `moduleToExpr`: `exprToModule . moduleToExpr = id \@CoreProgram`
+      = second (Let bind) (impl (exposed_ids bind ++ exposed) prog)
+    -- We are too conservative here, but we need *at least*  
+    -- 
+    --   * exported `Id`s (`isExportedId`)
+    --   * `Id`s mentioned in RULEs of this module
+    --
+    -- I'm not sure it's enough to just look into RULEs associated
+    -- with any of the binders, so we just blindly assume all top-level
+    -- `Id`s as exported (as does the demand analyzer).
+    exposed_ids bind = bindersOf bind
+
+-- | The left inverse to `moduleToExpr`: `exprToModule . snd . moduleToExpr = id \@CoreProgram`
 exprToModule :: CoreExpr -> CoreProgram
 exprToModule (Let bind e) = bind : exprToModule e
 exprToModule _ = []
@@ -450,13 +465,14 @@ exprToModule _ = []
 -- Main entry point
 callArityAnalProgram :: DynFlags -> FamInstEnvs -> CoreProgram -> IO CoreProgram
 callArityAnalProgram dflags fam_envs
-  = return . exprToModule . callArityRHS dflags fam_envs . moduleToExpr
+  = return . exprToModule . uncurry (callArityRHS dflags fam_envs) . moduleToExpr
+  -- . (\prog -> pprTrace "CallArity:Program" (ppr prog) prog)
 
-callArityRHS :: DynFlags -> FamInstEnvs -> CoreExpr -> CoreExpr
-callArityRHS dflags fam_envs e
+callArityRHS :: DynFlags -> FamInstEnvs -> VarSet -> CoreExpr -> CoreExpr
+callArityRHS dflags fam_envs need_sigs e
   = ASSERT2( isEmptyUnVarSet (domType ut), text "Free vars in UsageType:" $$ ppr ut ) e'
   where
-    (ut, e') = buildAndRun (callArityExpr (initialAnalEnv dflags fam_envs) e) topSingleUse
+    (ut, e') = buildAndRun (callArityExpr (initialAnalEnv dflags fam_envs need_sigs) e) topSingleUse
 
 -- | The main analysis function. See Note [Analysis type signature]
 callArityExpr
@@ -538,12 +554,11 @@ callArityExpr env e@(Var id) = return transfer
       | otherwise
       -- A global id from another module which has a usage signature.
       -- We don't need to track the id itself, though.
-      = --pprTrace "callArityExpr:GlobalId" (ppr id <+> ppr (idArity id) <+> ppr use <+> ppr (globalIdUsageSig id use) <+> ppr (idDetails id)) $
+      = --pprTrace "callArityExpr:GlobalId" (ppr id <+> ppr (idArity id) <+> ppr use <+> ppr (globalIdUsageSig id use) <+> ppr (idStrictness id) <+> ppr (idDetails id)) $
         return (emptyUsageType { ut_args = globalIdUsageSig id use }, e)
 
 callArityExpr env (Lam id body)
   | isTyVar id
-  -- Non-value lambdas are ignored
   = callArityExprMap env (Lam id) body
   | otherwise
   = do
@@ -574,15 +589,15 @@ callArityExpr env e@App{}
     transfer_val_args <- mapM (callArityExpr env) val_args
     return $ \result_use -> do
       (ut_f, f') <- transfer_f (iterate (mkCallUse Once) result_use !! n)
-      --pprTrace "App:f'" (ppr f') $ return ()
-      let blub ut_f [] [] = return (ut_f, [], [])
-          blub ut_f (transfer_arg:transfer_args) (arg:args) = do
+      --pprTrace "App:f'" (ppr f' <+> ppr (ut_args ut_f)) $ return ()
+      let blub ut [] [] = return (ut, [], [])
+          blub ut (transfer_arg:transfer_args) (arg:args) = do
             -- peel off one argument from the type
-            let (arg_usage, ut_f') = peelArgUsage ut_f
+            let (arg_usage, ut') = peelArgUsage ut
             -- handle the other args
-            (ut_f'', ut_args, args') <- blub ut_f' transfer_args args
+            (ut'', ut_args, args') <- blub ut' transfer_args args
             case considerThunkSharing arg arg_usage of
-              Absent -> return (ut_f'', botUsageType:ut_args, arg:args')
+              Absent -> return (ut'', botUsageType:ut_args, arg:args')
               Used m arg_use -> do
                 -- `m` will be `Once` most of the time (see `considerThunkSharing`),
                 -- so that all work before the lambda is uncovered will be shared 
@@ -592,14 +607,17 @@ callArityExpr env e@App{}
                 -- let-bindings: An argument only used once does not need to be
                 -- memoized.
                 (ut_arg, arg') <- first (multiplyUsages m) <$> transfer_arg arg_use
-                --pprTrace "App:arg'" (text "arg_use:" <+> ppr arg_use <+> ppr (ut_a, a')) $ return ()
-                return (ut_f'', ut_arg:ut_args, arg':args')
+                --pprTrace "App:arg'" (text "arg_use:" <+> ppr arg_use <+> ppr (ut_arg, arg')) $ return ()
+                return (ut'', ut_arg:ut_args, arg':args')
       (ut_f', ut_args, val_args') <- blub ut_f transfer_val_args val_args
       let merge_with_type_args (a:args) (va:val_args) 
             | isValArg a = va:merge_with_type_args args val_args
             | otherwise = a:merge_with_type_args args (va:val_args)
           merge_with_type_args args [] = args
-      return (bothUsageTypes (ut_f':ut_args), mkApps f' (merge_with_type_args args val_args'))
+      let ut = bothUsageTypes (ut_f':ut_args)
+      let e = mkApps f' (merge_with_type_args args val_args')
+      --pprTrace "App:combined" (ppr f <+> ppr val_args' <+> ppr ut) $ return ()
+      return (ut, e)
 
 callArityExpr env (Case scrut case_bndr ty alts) = do
   transfer_scrut <- callArityExpr env scrut
@@ -616,7 +634,6 @@ callArityExpr env (Case scrut case_bndr ty alts) = do
     return (ut, Case scrut' case_bndr' ty alts')
 
 callArityExpr env (Let bind e) = do
-  let fam_envs = ae_fam_envs env
   let initial_binds = flattenBinds [bind]
   let ids = map fst initial_binds
   (env', nodes) <- registerBindingGroup env initial_binds
@@ -634,7 +651,7 @@ callArityExpr env (Let bind e) = do
       return $ \use -> do
         (ut_body, e') <- transfer_body use
         let transferred_binds = map transferred_bind initial_binds
-        (ut, [(id', rhs')]) <- unleashLet NonRecursive fam_envs transferred_binds ut_body ut_body
+        (ut, [(id', rhs')]) <- unleashLet env NonRecursive transferred_binds ut_body ut_body
         return (delUsageTypes (bindersOf bind) ut, Let (NonRec id' rhs') e')
     Rec _ -> do -- The binding group stored in the @Rec@ constructor is always the initial one!
       -- This is a little more complicated, as we'll introduce a new FrameworkNode
@@ -648,7 +665,7 @@ callArityExpr env (Let bind e) = do
               -- results from the previous iteration, defaulting to just the body.
               (ut_usage, Let (Rec old_bind) _) <- dependOnWithDefault (ut_body, Let bind e') (node, use)
               let transferred_binds = map transferred_bind old_bind
-              (ut, bind') <- unleashLet Recursive fam_envs transferred_binds ut_usage ut_body
+              (ut, bind') <- unleashLet env Recursive transferred_binds ut_usage ut_body
               let lookup_old = lookupUsage Recursive ut_usage
               let lookup_new = lookupUsage Recursive ut
               let ut' | all (\id -> lookup_old id == lookup_new id) ids = markStable ut
@@ -716,8 +733,7 @@ dataConUsageSig dc use = fromMaybe topUsageSig sig_maybe
 
 dictSelUsageSig :: Id -> Class -> SingleUse -> UsageSig
 dictSelUsageSig id clazz use
-  -- using idArgUsage seems to loop endlessly on Data.Bits
-  | Used _ dict_single_call_use <- fst . unconsUsageSig . usageSigFromStrictSig . idStrictness $ id
+  | Used _ dict_single_call_use <- fst . unconsUsageSig . idArgUsage $ id
   , Just dc <- tyConSingleDataCon_maybe (classTyCon clazz)
   , let dict_length = idArity (dataConWorkId dc)
   , Just comps <- peelProductUse (Just dict_length) dict_single_call_use
@@ -742,11 +758,6 @@ globalIdUsageSig id use
   | use <= no_call -- @f x `seq` ...@ for a GlobalId `f` with arity > 1
   = botUsageSig
   | use <= single_call
-  , isPrimOpId id
-  -- Reusing the usage declarations in primops.txt.pp for the time being...
-  -- We would annotate them with something isomorphic anyway.
-  = usageSigFromStrictSig (idStrictness id)
-  | use <= single_call
   = arg_usage
   | otherwise
   = --pprTrace "many" (ppr arg_usage <+> ppr (idStrictness id) <+> ppr (manifyUsageSig arg_usage)) $ 
@@ -866,7 +877,7 @@ addDataConStrictness dc
 
     add _ Absent = Absent -- See the note; We want to eliminate these in WW.
     add str usage@(Used _ _)
-      | isMarkedStrict str = usage `bothUsage` seqUsage
+      | isMarkedStrict str = usage `bothUsage` u'1HU -- head usage imposed by `seq`
       | otherwise = usage
 
 registerBindingGroup
@@ -900,7 +911,7 @@ registerBindingGroup env = go env emptyVarEnv
                 -- use sites of these sig nodes may only use the ut_args
                 -- component!
                 --pprTrace "change_detector_down" (vcat [ppr node, ppr id, ppr (ut_args old <= ut_args new), ppr (lubUsageSig (ut_args old) (ut_args new)), ppr (ut_args old), ppr (ut_args new), ppr (ut_args old /= ut_args new)]) $
-                ASSERT2( ut_args old <= ut_args new, text "CallArity.change_detector_down: Not monotone" $$ ppr (ut_args old) $$ ppr (ut_args new) )
+                ASSERT2( ut_args old <= ut_args new, text "CallArity.change_detector_down: Not monotone" $$ ppr id $$ ppr (ut_args old) $$ ppr (ut_args new) )
                 ut_args old /= ut_args new
                   where
                     a <= b = lubUsageSig a b == b
@@ -910,34 +921,38 @@ registerBindingGroup env = go env emptyVarEnv
           return ((ret, full), args) -- registerTransferFunction  will peel `snd`s away for registration
 
 unleashLet
-  :: RecFlag
-  -> FamInstEnvs
+  :: AnalEnv 
+  -> RecFlag
   -> [(Id, (CoreExpr, SingleUse -> TransferFunction AnalResult))]
   -> UsageType
   -> UsageType
   -> TransferFunction (UsageType, [(Id, CoreExpr)])
-unleashLet rec_flag fam_envs transferred_binds ut_usage ut_body = do
+unleashLet env rec_flag transferred_binds ut_usage ut_body = do
+  let fam_envs = ae_fam_envs env
+  let need_sigs = ae_need_sig_annotation env
   let (ids, transferred_rhss) = unzip transferred_binds
   (ut_rhss, rhss') <- fmap unzip $ forM transferred_binds $ \(id, (rhs, transfer)) ->
     unleashUsage rhs transfer (lookupUsage rec_flag ut_usage id)
   let ut_final = callArityLetEnv (zip ids ut_rhss) ut_body
 
+  --pprTrace "unleashLet" (ppr ids $$ text "ut_body" <+> ppr ut_body $$ text "ut_final" <+> ppr ut_final) $ return ()
   -- Now use that information to annotate binders.
   let (_, usages) = findBndrsUsages rec_flag fam_envs ut_final ids
   let ids' = setBndrsUsageInfo ids usages
   ids'' <- forM (zip ids' transferred_rhss) $ \(id, (_, transfer)) ->
-    annotateExportedIdArgUsage id transfer
+    annotateIdArgUsage need_sigs id transfer
 
   -- This intentionally still contains the @Id@s of the binding group, because
   -- the recursive rule looks at their usages to determine stability.
   return (ut_final, zip ids'' rhss')
 
-annotateExportedIdArgUsage
-  :: Id
+annotateIdArgUsage
+  :: VarSet
+  -> Id
   -> (SingleUse -> TransferFunction AnalResult)
   -> TransferFunction Id
-annotateExportedIdArgUsage id transfer_rhs
-  | not (isExportedId id) = return id
+annotateIdArgUsage need_sigs id transfer_rhs
+  | not (id `elemVarSet` need_sigs) = return id
   | otherwise = do
     -- We can't eta-expand beyond idArity anyway (exported!), so our best
     -- bet is a single call with idArity.
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index e6f96391e9..886b5ab28c 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -3,12 +3,14 @@ module CallArity.Types where
 import BasicTypes
 import CoreSyn
 import Id
+import Maybes
 import Outputable
 import UnVarGraph
 import Usage
 import VarEnv
 
-import Data.List ( tails )
+import Control.Monad ( guard )
+import Data.List ( tails, partition )
 
 ---------------------------------------
 -- Functions related to UsageType    --
@@ -72,12 +74,12 @@ makeIdArg id ut = delUsageType id (modifyArgs (consUsageSig (lookupUsage NonRecu
 lookupUsage :: RecFlag -> UsageType -> Id -> Usage
 lookupUsage rec (UT g ae _ _) id = case lookupVarEnv ae id of
   Just use
-    | id `elemUnVarSet` neighbors g id -> Used Many use
     -- we assume recursive bindings to be called multiple times, what's the
     -- point otherwise? It's a little sad we don't encode it in the co-call
     -- graph directly, though.
     -- See Note [Thunks in recursive groups]
     | isRec rec -> manifyUsage (Used Once use)
+    | id `elemUnVarSet` neighbors g id -> Used Many use
     | otherwise -> Used Once use
   Nothing -> botUsage
 
@@ -95,29 +97,47 @@ multiplyUsages Many ut@(UT _ u args _)
   , ut_stable = False
   }
 
+asCompleteGraph :: UsageType -> Maybe UnVarSet
+asCompleteGraph ut = do
+  s <- UnVarGraph.isCompleteGraph_maybe (ut_cocalled ut)
+  guard (sizeUnVarSet s == sizeUnVarSet (domType ut))
+  return s
+
 bothUsageTypes :: [UsageType] -> UsageType
 bothUsageTypes uts 
   = UT cocalled uses args False
   where
-    cocalls = map ut_cocalled uts
     uses = foldr bothUseEnv emptyVarEnv (map ut_uses uts)
-    args = foldr lubUsageSig botUsageSig (map ut_args uts)
-    pairings = drop 2 (reverse (tails uts)) -- beginning with a two element list
-    crossCalls = flip map pairings $ \(ut:others) -> 
-      completeBipartiteGraph (domType ut) (domTypes others)
-    cocalled = unionUnVarGraphs (cocalls ++ crossCalls)
+    args 
+      = ut_args 
+      . expectJust "bothUsageTypes: argument list empty" 
+      . listToMaybe
+      $ uts
+    -- Cross calls between complete graphs yield another complete graph.
+    -- This is an important optimization for large tuples, like occuring
+    -- when analysing top-level binds as let bindings
+    (completes, incompletes) 
+      -- = ([], uts)
+      = partition (isJust . asCompleteGraph) uts
+    completeDom
+      = unionUnVarSets 
+      . map (fromJust . asCompleteGraph) 
+      $ completes
+    completePart = completeGraph completeDom
+    graphs = completePart : map ut_cocalled incompletes
+    doms = completeDom : map domType incompletes
+    -- all tails, beginning with a two element list
+    pairings = drop 2 . reverse . tails $ doms
+    crossCalls = flip map pairings $ \(dom:others) -> 
+      -- There room for improvement by reusing the result of `unionUnVarSets`
+      completeBipartiteGraph dom (unionUnVarSets others) 
+    cocalled = unionUnVarGraphs (graphs ++ crossCalls)
 
 -- | Corresponds to sequential composition of expressions.
 -- Used for application and cases.
 -- Note this returns the @UsageSig@ from the first argument.
 bothUsageType :: UsageType -> UsageType -> UsageType
-bothUsageType ut1@(UT g1 u1 args _) ut2@(UT g2 u2 _ _)
-  = UT
-  { ut_cocalled = unionUnVarGraphs [g1, g2, completeBipartiteGraph (domType ut1) (domType ut2)]
-  , ut_uses = bothUseEnv u1 u2
-  , ut_args = args
-  , ut_stable = False
-  }
+bothUsageType ut1 ut2 = bothUsageTypes [ut1, ut2]
 
 -- | Used when combining results from alternative cases
 lubUsageType :: UsageType -> UsageType -> UsageType
diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index 8b925a313b..53bba4165c 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -4,6 +4,7 @@ module DmdAnalWrapper (combinedDmdAnalProgram) where
 
 #include "HsVersions.h"
 
+import BasicTypes
 import CallArity
 import CoreSyn
 import Demand
@@ -25,8 +26,8 @@ combinedDmdAnalProgram dflags fams prog = do
   --pprTrace "Program" (ppr prog'') $ pure ()
   return (mapBndrsProgram mergeInfo prog'')
 
-mergeInfo :: Bool -> Var -> Var
-mergeInfo isLamBndr id
+mergeInfo :: TopLevelFlag -> Bool -> Var -> Var
+mergeInfo top_lvl is_lam_bndr id
   | isTyVar id
   = id
   | otherwise 
@@ -34,8 +35,8 @@ mergeInfo isLamBndr id
   -- instead of the whole expression, we get more conservative results in our
   -- new analysis, where there might be multiplied uses on lambda binders if
   -- it has more than one lambda. In that case we have to relax the assert.
-  = ASSERT2( isLamBndr || isExportedId id || ca_usage `leqUsage` old_usage, text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
-    ASSERT2( not (isExportedId id) || ca_usg_sig `leqUsageSig` old_usg_sig, text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
+  = WARN( not (is_lam_bndr || isExportedId id || ca_usage `leqUsage` old_usage), text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
+    WARN( not (not (isExportedId id) || ca_usg_sig `leqUsageSig` old_usg_sig), text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
     --pprTrace "mergeInfo" (ppr id <+> text "Demand:" <+> ppr old_demand <+> ppr ca_usage <+> ppr new_demand <+> text "Strictness" <+> ppr old_str_sig <+> ppr ca_usg_sig <+> ppr new_str_sig) $
     id'
   where
@@ -50,38 +51,42 @@ mergeInfo isLamBndr id
     old_usage = usageFromDemand old_demand
     old_usg_sig = usageSigFromStrictSig old_str_sig
 
-    new_demand = overwriteDemandWithUsage ca_usage old_demand
-    new_str_sig = overwriteStrictSigWithUsageSig ca_usg_sig old_str_sig
+    new_demand 
+      | ca_usage `leqUsage` old_usage = overwriteDemandWithUsage ca_usage old_demand
+      | otherwise = old_demand
+    new_str_sig 
+      | ca_usg_sig `leqUsageSig` old_usg_sig = overwriteStrictSigWithUsageSig ca_usg_sig old_str_sig
+      | otherwise = old_str_sig
 
     leqUsage l r = l `lubUsage` r == r
     leqUsageSig l r = l `lubUsageSig` r == r
     id'
-      | isExportedId id = id `setIdStrictness` new_str_sig -- Only the sig matters
+      | isTopLevel top_lvl = id `setIdStrictness` new_str_sig -- Only the sig matters
       | otherwise = id `setIdDemandInfo` new_demand -- Only use sites matter
 
 
-mapBndrsProgram :: (Bool -> Var -> Var) -> CoreProgram -> CoreProgram
-mapBndrsProgram f = map (mapBndrsBind f)
+mapBndrsProgram :: (TopLevelFlag -> Bool -> Var -> Var) -> CoreProgram -> CoreProgram
+mapBndrsProgram f = map (mapBndrsBind TopLevel f)
 
-mapBndrsBind :: (Bool -> Var -> Var) -> CoreBind -> CoreBind
-mapBndrsBind f (NonRec id e) = NonRec (f False id) (mapBndrsExprIfNotAbsent id f e)
-mapBndrsBind f (Rec bndrs) = Rec (map (\(id, e) -> (f False id, mapBndrsExprIfNotAbsent id f e)) bndrs)
+mapBndrsBind :: TopLevelFlag -> (TopLevelFlag -> Bool -> Var -> Var) -> CoreBind -> CoreBind
+mapBndrsBind top_lvl f (NonRec id e) = NonRec (f top_lvl False id) (mapBndrsExprIfNotAbsent id f e)
+mapBndrsBind top_lvl f (Rec bndrs) = Rec (map (\(id, e) -> (f top_lvl False id, mapBndrsExprIfNotAbsent id f e)) bndrs)
 
-mapBndrsExprIfNotAbsent :: Var -> (Bool -> Var -> Var) -> CoreExpr -> CoreExpr
+mapBndrsExprIfNotAbsent :: Var -> (TopLevelFlag -> Bool -> Var -> Var) -> CoreExpr -> CoreExpr
 mapBndrsExprIfNotAbsent id f e
   | Absent <- idCallArity id = e -- we won't have analysed e in this case.
   | otherwise = mapBndrsExpr f e
 
-mapBndrsExpr :: (Bool -> Var -> Var) -> CoreExpr -> CoreExpr
+mapBndrsExpr :: (TopLevelFlag -> Bool -> Var -> Var) -> CoreExpr -> CoreExpr
 mapBndrsExpr f e = case e of
   App func arg -> App (mapBndrsExpr f func) (mapBndrsExpr f arg)
-  Lam id e -> Lam (f True id) (mapBndrsExpr f e)
-  Let bind body -> Let (mapBndrsBind f bind) (mapBndrsExpr f body)
-  Case scrut id ty alts -> Case (mapBndrsExpr f scrut) (f False id) ty (map (mapBndrsAlt f) alts)
+  Lam id e -> Lam (f NotTopLevel True id) (mapBndrsExpr f e)
+  Let bind body -> Let (mapBndrsBind NotTopLevel f bind) (mapBndrsExpr f body)
+  Case scrut id ty alts -> Case (mapBndrsExpr f scrut) (f NotTopLevel False id) ty (map (mapBndrsAlt f) alts)
   Cast e co -> Cast (mapBndrsExpr f e) co
   Tick t e -> Tick t (mapBndrsExpr f e)
   Var _ -> e -- use sites carry no important annotations
   _ -> e
 
-mapBndrsAlt :: (Bool -> Var -> Var) -> Alt CoreBndr -> Alt CoreBndr
-mapBndrsAlt f (con, bndrs, e) = (con, map (f False) bndrs, mapBndrsExpr f e)
+mapBndrsAlt :: (TopLevelFlag -> Bool -> Var -> Var) -> Alt CoreBndr -> Alt CoreBndr
+mapBndrsAlt f (con, bndrs, e) = (con, map (f NotTopLevel False) bndrs, mapBndrsExpr f e)
diff --git a/compiler/simplCore/SimplCore.hs b/compiler/simplCore/SimplCore.hs
index daf726c107..a6a6bf799c 100644
--- a/compiler/simplCore/SimplCore.hs
+++ b/compiler/simplCore/SimplCore.hs
@@ -1052,6 +1052,7 @@ transferIdInfo exported_id local_id
   where
     local_info = idInfo local_id
     transfer exp_info = exp_info `setStrictnessInfo`    strictnessInfo local_info
+                                 `setArgUsageInfo`      argUsageInfo local_info
                                  `setUnfoldingInfo`     unfoldingInfo local_info
                                  `setInlinePragInfo`    inlinePragInfo local_info
                                  `setRuleInfo`          addRuleInfo (ruleInfo exp_info) new_info
diff --git a/compiler/simplCore/Simplify.hs b/compiler/simplCore/Simplify.hs
index 66208b3c3c..15b74351cd 100644
--- a/compiler/simplCore/Simplify.hs
+++ b/compiler/simplCore/Simplify.hs
@@ -569,6 +569,7 @@ prepareRhs top_lvl env id (Cast rhs co)    -- Note [Float coercions]
         ; return (env', Cast rhs' co) }
   where
     sanitised_info = vanillaIdInfo `setStrictnessInfo` strictnessInfo info
+                                   `setArgUsageInfo` argUsageInfo info
                                    `setDemandInfo` demandInfo info
     info = idInfo id
 
diff --git a/compiler/utils/UnVarGraph.hs b/compiler/utils/UnVarGraph.hs
index f48e3bbb07..b1d9c3df68 100644
--- a/compiler/utils/UnVarGraph.hs
+++ b/compiler/utils/UnVarGraph.hs
@@ -16,13 +16,14 @@ equal to g, but twice as expensive and large.
 -}
 module UnVarGraph
     ( UnVarSet
-    , emptyUnVarSet, mkUnVarSet, varEnvDom, restrictVarEnv_UnVarSet
+    , emptyUnVarSet, sizeUnVarSet, mkUnVarSet, varEnvDom, restrictVarEnv_UnVarSet
     , unionUnVarSet, unionUnVarSets, delUnVarSet
     , elemUnVarSet, isEmptyUnVarSet
     , UnVarGraph
     , emptyUnVarGraph
     , unionUnVarGraph, unionUnVarGraphs
     , completeGraph, completeBipartiteGraph
+    , isCompleteGraph_maybe
     , neighbors
     , delNode
     ) where
@@ -52,6 +53,9 @@ k v = getKey (getUnique v)
 emptyUnVarSet :: UnVarSet
 emptyUnVarSet = UnVarSet S.empty
 
+sizeUnVarSet :: UnVarSet -> Int
+sizeUnVarSet (UnVarSet s) = S.size s
+
 elemUnVarSet :: Var -> UnVarSet -> Bool
 elemUnVarSet v (UnVarSet s) = k v `S.member` s
 
@@ -118,6 +122,15 @@ completeBipartiteGraph s1 s2 = prune $ UnVarGraph $ unitBag $ CBPG s1 s2
 completeGraph :: UnVarSet -> UnVarGraph
 completeGraph s = prune $ UnVarGraph $ unitBag $ CG s
 
+isCompleteGraph_maybe :: UnVarGraph -> Maybe UnVarSet
+isCompleteGraph_maybe (UnVarGraph g)
+  | [CG s] <- bagToList g
+  = Just s
+  | [] <- bagToList g
+  = Just emptyUnVarSet
+  | otherwise
+  = Nothing
+
 neighbors :: UnVarGraph -> Var -> UnVarSet
 neighbors (UnVarGraph g) v = unionUnVarSets $ concatMap go $ bagToList g
   where go (CG s)       = (if v `elemUnVarSet` s then [s] else [])
-- 
2.12.1


From 2f847304a8c1621476dc0887cc5ed629e4aa4e4d Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 26 May 2017 22:50:15 +0200
Subject: [PATCH 063/117] Very clever graph data structure brought memory usage
 down, but time complexity is still unbearable

---
 compiler/utils/UnVarGraph.hs | 190 +++++++++++++++++++++++++++++--------------
 1 file changed, 127 insertions(+), 63 deletions(-)

diff --git a/compiler/utils/UnVarGraph.hs b/compiler/utils/UnVarGraph.hs
index b1d9c3df68..c7f4a30602 100644
--- a/compiler/utils/UnVarGraph.hs
+++ b/compiler/utils/UnVarGraph.hs
@@ -1,3 +1,4 @@
+{-# LANGUAGE BangPatterns #-}
 {-
 
 Copyright (c) 2014 Joachim Breitner
@@ -32,11 +33,13 @@ import Id
 import VarEnv
 import UniqFM
 import Outputable
-import Data.List
-import Bag
 import Unique
+import Maybes
 
-import qualified Data.IntSet as S
+import Data.IntSet ( IntSet )
+import qualified Data.IntSet as IntSet
+import Data.IntMap.Strict ( IntMap )
+import qualified Data.IntMap.Strict as IntMap
 
 -- We need a type for sets of variables (UnVarSet).
 -- We do not use VarSet, because for that we need to have the actual variable
@@ -44,30 +47,35 @@ import qualified Data.IntSet as S
 -- Therefore, use a IntSet directly (which is likely also a bit more efficient).
 
 -- Set of uniques, i.e. for adjancet nodes
-newtype UnVarSet = UnVarSet (S.IntSet)
+newtype UnVarSet = UnVarSet IntSet
     deriving Eq
 
 k :: Var -> Int
 k v = getKey (getUnique v)
 
 emptyUnVarSet :: UnVarSet
-emptyUnVarSet = UnVarSet S.empty
+emptyUnVarSet = UnVarSet IntSet.empty
 
 sizeUnVarSet :: UnVarSet -> Int
-sizeUnVarSet (UnVarSet s) = S.size s
+sizeUnVarSet (UnVarSet s) = IntSet.size s
 
 elemUnVarSet :: Var -> UnVarSet -> Bool
-elemUnVarSet v (UnVarSet s) = k v `S.member` s
-
+elemUnVarSet v (UnVarSet s) = k v `IntSet.member` s
 
 isEmptyUnVarSet :: UnVarSet -> Bool
-isEmptyUnVarSet (UnVarSet s) = S.null s
+isEmptyUnVarSet (UnVarSet s) = IntSet.null s
+
+differenceUnVarSet :: UnVarSet -> UnVarSet -> UnVarSet
+differenceUnVarSet (UnVarSet s1) (UnVarSet s2) = UnVarSet $ IntSet.difference s1 s2
+
+intersectionUnVarSet :: UnVarSet -> UnVarSet -> UnVarSet
+intersectionUnVarSet (UnVarSet s1) (UnVarSet s2) = UnVarSet $ IntSet.intersection s1 s2
 
 delUnVarSet :: UnVarSet -> Var -> UnVarSet
-delUnVarSet (UnVarSet s) v = UnVarSet $ k v `S.delete` s
+delUnVarSet (UnVarSet s) v = UnVarSet $ k v `IntSet.delete` s
 
 mkUnVarSet :: [Var] -> UnVarSet
-mkUnVarSet vs = UnVarSet $ S.fromList $ map k vs
+mkUnVarSet vs = UnVarSet $ IntSet.fromList $ map k vs
 
 varEnvDom :: VarEnv a -> UnVarSet
 varEnvDom ae = UnVarSet $ ufmToSet_Directly ae
@@ -75,80 +83,136 @@ varEnvDom ae = UnVarSet $ ufmToSet_Directly ae
 restrictVarEnv_UnVarSet :: VarEnv a -> UnVarSet -> VarEnv a
 restrictVarEnv_UnVarSet env (UnVarSet s) = filterVarEnv_Directly keep env
   where
-    keep u _ = getKey u `S.member` s
+    keep u _ = getKey u `IntSet.member` s
 
 unionUnVarSet :: UnVarSet -> UnVarSet -> UnVarSet
-unionUnVarSet (UnVarSet set1) (UnVarSet set2) = UnVarSet (set1 `S.union` set2)
+unionUnVarSet (UnVarSet set1) (UnVarSet set2) = UnVarSet (set1 `IntSet.union` set2)
 
 unionUnVarSets :: [UnVarSet] -> UnVarSet
 unionUnVarSets = foldr unionUnVarSet emptyUnVarSet
 
 instance Outputable UnVarSet where
     ppr (UnVarSet s) = braces $
-        hcat $ punctuate comma [ ppr (getUnique i) | i <- S.toList s]
-
+        hcat $ punctuate comma [ ppr (getUnique i) | i <- IntSet.toList s]
+
+data OverlayResolution
+    = Additive
+    | Subtractive
+    deriving (Eq, Ord, Show)
+
+complementOverlayResolution :: OverlayResolution -> OverlayResolution
+complementOverlayResolution Additive = Subtractive
+complementOverlayResolution Subtractive = Additive
+
+data UnVarGraph 
+    = UnVarGraph
+    { edge_interpretation :: !OverlayResolution
+    , edge_count_estimate :: !(Int, Int)
+    , edges :: !(IntMap UnVarSet)
+    }
+
+balance :: UnVarGraph -> UnVarGraph
+balance g@(UnVarGraph ei (_, ub) edges)
+  | ub_ratio < 0.6 = g
+  | precise_ratio < 0.6 = precise_g
+  | otherwise = complementUnVarGraph precise_g
+  where
+    nodes = IntMap.size edges
+    max_edges = nodes * nodes
+    ub_ratio :: Double
+    ub_ratio = fromIntegral ub / fromIntegral max_edges
+    edge_count = foldr ((+) . sizeUnVarSet) 0 edges
+    precise_ratio :: Double
+    precise_ratio = fromIntegral edge_count / fromIntegral max_edges
+    precise_g = UnVarGraph ei (edge_count, edge_count) edges
+
+complementUnVarGraph :: UnVarGraph -> UnVarGraph
+complementUnVarGraph (UnVarGraph res (lb, ub) edges) 
+  = UnVarGraph (complementOverlayResolution res) ec (complementEdges edges)
+  where
+    nodes = IntMap.size edges
+    max_edges = nodes*nodes
+    ec = (max_edges - ub, max_edges - lb)
 
--- The graph type. A list of complete bipartite graphs
-data Gen = CBPG UnVarSet UnVarSet -- complete bipartite
-         | CG   UnVarSet          -- complete
-newtype UnVarGraph = UnVarGraph (Bag Gen)
+complementEdges :: IntMap UnVarSet -> IntMap UnVarSet
+complementEdges edges = edges'
+  where
+    dom = UnVarSet (IntMap.keysSet edges)
+    edges' = fmap complement_neighbors edges
+    complement_neighbors neighbors
+      -- Very common cases are an empty neighbor set and the full neighbor set,
+      -- in which case we want to be pretty cheap.
+      | isEmptyUnVarSet neighbors = dom
+      | sizeUnVarSet neighbors == sizeUnVarSet dom = emptyUnVarSet
+      | otherwise = differenceUnVarSet dom neighbors
 
 emptyUnVarGraph :: UnVarGraph
-emptyUnVarGraph = UnVarGraph emptyBag
+emptyUnVarGraph = UnVarGraph Subtractive (0, 0) IntMap.empty
 
 unionUnVarGraph :: UnVarGraph -> UnVarGraph -> UnVarGraph
-{-
-Premature optimisation, it seems.
-unionUnVarGraph (UnVarGraph [CBPG s1 s2]) (UnVarGraph [CG s3, CG s4])
-    | s1 == s3 && s2 == s4
-    = pprTrace "unionUnVarGraph fired" empty $
-      completeGraph (s1 `unionUnVarSet` s2)
-unionUnVarGraph (UnVarGraph [CBPG s1 s2]) (UnVarGraph [CG s3, CG s4])
-    | s2 == s3 && s1 == s4
-    = pprTrace "unionUnVarGraph fired2" empty $
-      completeGraph (s1 `unionUnVarSet` s2)
--}
-unionUnVarGraph (UnVarGraph g1) (UnVarGraph g2)
-    = -- pprTrace "unionUnVarGraph" (ppr (length g1, length g2)) $
-      UnVarGraph (g1 `unionBags` g2)
-
+unionUnVarGraph u1@(UnVarGraph Subtractive _ _) u2
+  = unionUnVarGraph (complementUnVarGraph u1) u2
+unionUnVarGraph u1 u2@(UnVarGraph Subtractive _ _)
+  = unionUnVarGraph u1 (complementUnVarGraph u2)
+unionUnVarGraph (UnVarGraph Additive (l1, u1) e1) (UnVarGraph Additive (l2, u2) e2)
+  = balance $ UnVarGraph Additive (max l1 l2, u1 + u2) e
+  where
+    e = IntMap.unionWith unionUnVarSet e1 e2
+    
 unionUnVarGraphs :: [UnVarGraph] -> UnVarGraph
-unionUnVarGraphs = foldl' unionUnVarGraph emptyUnVarGraph
+unionUnVarGraphs = foldr unionUnVarGraph emptyUnVarGraph
 
 -- completeBipartiteGraph A B = { {a,b} | a ∈ A, b ∈ B }
 completeBipartiteGraph :: UnVarSet -> UnVarSet -> UnVarGraph
-completeBipartiteGraph s1 s2 = prune $ UnVarGraph $ unitBag $ CBPG s1 s2
-
+completeBipartiteGraph u1@(UnVarSet s1) u2@(UnVarSet s2) 
+    = balance (UnVarGraph Additive (2*a*b, 2*a*b) edges)
+    where
+      dom@(UnVarSet s) = unionUnVarSet u1 u2
+      (UnVarSet s3) = intersectionUnVarSet u1 u2 -- common elements
+      a = sizeUnVarSet u1
+      b = sizeUnVarSet u2
+      edges = IntMap.fromSet neighbors_of s
+      neighbors_of k
+        | k `IntSet.member` s3 = dom
+        | k `IntSet.member` s1 = u2
+        | k `IntSet.member` s2 = u1
+        
 completeGraph :: UnVarSet -> UnVarGraph
-completeGraph s = prune $ UnVarGraph $ unitBag $ CG s
+completeGraph (UnVarSet s) = UnVarGraph Subtractive (0, 0) (IntMap.fromSet (const emptyUnVarSet) s)
 
 isCompleteGraph_maybe :: UnVarGraph -> Maybe UnVarSet
-isCompleteGraph_maybe (UnVarGraph g)
-  | [CG s] <- bagToList g
-  = Just s
-  | [] <- bagToList g
-  = Just emptyUnVarSet
-  | otherwise
-  = Nothing
+isCompleteGraph_maybe (UnVarGraph Subtractive (0, 0) e) 
+  = Just (UnVarSet (IntMap.keysSet e))
+isCompleteGraph_maybe _ = Nothing
 
 neighbors :: UnVarGraph -> Var -> UnVarSet
-neighbors (UnVarGraph g) v = unionUnVarSets $ concatMap go $ bagToList g
-  where go (CG s)       = (if v `elemUnVarSet` s then [s] else [])
-        go (CBPG s1 s2) = (if v `elemUnVarSet` s1 then [s2] else []) ++
-                          (if v `elemUnVarSet` s2 then [s1] else [])
+neighbors (UnVarGraph res _ edges) v 
+  = fromMaybe emptyUnVarSet (interpret_edge <$> IntMap.lookup (k v) edges)
+  where dom = UnVarSet $ IntMap.keysSet edges
+        interpret_edge 
+          | res == Additive = id
+          | otherwise = differenceUnVarSet dom
 
 delNode :: UnVarGraph -> Var -> UnVarGraph
-delNode (UnVarGraph g) v = prune $ UnVarGraph $ mapBag go g
-  where go (CG s)       = CG (s `delUnVarSet` v)
-        go (CBPG s1 s2) = CBPG (s1 `delUnVarSet` v) (s2 `delUnVarSet` v)
-
-prune :: UnVarGraph -> UnVarGraph
-prune (UnVarGraph g) = UnVarGraph $ filterBag go g
-  where go (CG s)       = not (isEmptyUnVarSet s)
-        go (CBPG s1 s2) = not (isEmptyUnVarSet s1) && not (isEmptyUnVarSet s2)
-
-instance Outputable Gen where
-    ppr (CG s)       = ppr s  <> char '²'
-    ppr (CBPG s1 s2) = ppr s1 <+> char 'x' <+> ppr s2
+delNode (UnVarGraph ei (lb, ub) g) v 
+  = UnVarGraph ei (lb', ub') g2 -- No rebalance here, since the graph gets smaller anyway
+  where 
+    -- Note that we need to delete all mentioned edges, regardless of `ei`.
+    (neighbors_maybe, g1) = IntMap.updateLookupWithKey (\_ _ -> Nothing) (k v) g
+    UnVarSet neighbors = fromMaybe emptyUnVarSet neighbors_maybe
+    g2 = foldr (IntMap.adjust deleter) g1 (IntSet.toList neighbors)
+    dom = UnVarSet $ IntMap.keysSet g
+    new_dom = delUnVarSet dom v
+    deleter s
+      -- Again, optimize for the common cases
+      | sizeUnVarSet s <= 1 = emptyUnVarSet -- This assumes that v is in s
+      | sizeUnVarSet s == sizeUnVarSet dom = new_dom
+      | otherwise = delUnVarSet s v
+    del_edge_count = IntSet.size neighbors
+    lb' = lb - del_edge_count
+    ub' = ub - del_edge_count
+
 instance Outputable UnVarGraph where
-    ppr (UnVarGraph g) = ppr g
+    ppr u@(UnVarGraph ei _ g) 
+      | ei == Additive = ppr g
+      | otherwise = ppr (complementUnVarGraph u)
-- 
2.12.1


From 95fb98abc18ab4bdd2ae7e4cc7dfe191644fd1a6 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sat, 27 May 2017 10:18:04 +0200
Subject: [PATCH 064/117] A version with the dumbest co-call graph still
 exhibits quadratic behavior

---
 compiler/utils/UnVarGraph.hs | 117 ++++---------------------------------------
 1 file changed, 9 insertions(+), 108 deletions(-)

diff --git a/compiler/utils/UnVarGraph.hs b/compiler/utils/UnVarGraph.hs
index c7f4a30602..eca78a9ad9 100644
--- a/compiler/utils/UnVarGraph.hs
+++ b/compiler/utils/UnVarGraph.hs
@@ -65,12 +65,6 @@ elemUnVarSet v (UnVarSet s) = k v `IntSet.member` s
 isEmptyUnVarSet :: UnVarSet -> Bool
 isEmptyUnVarSet (UnVarSet s) = IntSet.null s
 
-differenceUnVarSet :: UnVarSet -> UnVarSet -> UnVarSet
-differenceUnVarSet (UnVarSet s1) (UnVarSet s2) = UnVarSet $ IntSet.difference s1 s2
-
-intersectionUnVarSet :: UnVarSet -> UnVarSet -> UnVarSet
-intersectionUnVarSet (UnVarSet s1) (UnVarSet s2) = UnVarSet $ IntSet.intersection s1 s2
-
 delUnVarSet :: UnVarSet -> Var -> UnVarSet
 delUnVarSet (UnVarSet s) v = UnVarSet $ k v `IntSet.delete` s
 
@@ -95,124 +89,31 @@ instance Outputable UnVarSet where
     ppr (UnVarSet s) = braces $
         hcat $ punctuate comma [ ppr (getUnique i) | i <- IntSet.toList s]
 
-data OverlayResolution
-    = Additive
-    | Subtractive
-    deriving (Eq, Ord, Show)
-
-complementOverlayResolution :: OverlayResolution -> OverlayResolution
-complementOverlayResolution Additive = Subtractive
-complementOverlayResolution Subtractive = Additive
-
-data UnVarGraph 
-    = UnVarGraph
-    { edge_interpretation :: !OverlayResolution
-    , edge_count_estimate :: !(Int, Int)
-    , edges :: !(IntMap UnVarSet)
-    }
-
-balance :: UnVarGraph -> UnVarGraph
-balance g@(UnVarGraph ei (_, ub) edges)
-  | ub_ratio < 0.6 = g
-  | precise_ratio < 0.6 = precise_g
-  | otherwise = complementUnVarGraph precise_g
-  where
-    nodes = IntMap.size edges
-    max_edges = nodes * nodes
-    ub_ratio :: Double
-    ub_ratio = fromIntegral ub / fromIntegral max_edges
-    edge_count = foldr ((+) . sizeUnVarSet) 0 edges
-    precise_ratio :: Double
-    precise_ratio = fromIntegral edge_count / fromIntegral max_edges
-    precise_g = UnVarGraph ei (edge_count, edge_count) edges
-
-complementUnVarGraph :: UnVarGraph -> UnVarGraph
-complementUnVarGraph (UnVarGraph res (lb, ub) edges) 
-  = UnVarGraph (complementOverlayResolution res) ec (complementEdges edges)
-  where
-    nodes = IntMap.size edges
-    max_edges = nodes*nodes
-    ec = (max_edges - ub, max_edges - lb)
-
-complementEdges :: IntMap UnVarSet -> IntMap UnVarSet
-complementEdges edges = edges'
-  where
-    dom = UnVarSet (IntMap.keysSet edges)
-    edges' = fmap complement_neighbors edges
-    complement_neighbors neighbors
-      -- Very common cases are an empty neighbor set and the full neighbor set,
-      -- in which case we want to be pretty cheap.
-      | isEmptyUnVarSet neighbors = dom
-      | sizeUnVarSet neighbors == sizeUnVarSet dom = emptyUnVarSet
-      | otherwise = differenceUnVarSet dom neighbors
+newtype UnVarGraph = UnVarGraph UnVarSet
 
 emptyUnVarGraph :: UnVarGraph
-emptyUnVarGraph = UnVarGraph Subtractive (0, 0) IntMap.empty
+emptyUnVarGraph = UnVarGraph emptyUnVarSet
 
 unionUnVarGraph :: UnVarGraph -> UnVarGraph -> UnVarGraph
-unionUnVarGraph u1@(UnVarGraph Subtractive _ _) u2
-  = unionUnVarGraph (complementUnVarGraph u1) u2
-unionUnVarGraph u1 u2@(UnVarGraph Subtractive _ _)
-  = unionUnVarGraph u1 (complementUnVarGraph u2)
-unionUnVarGraph (UnVarGraph Additive (l1, u1) e1) (UnVarGraph Additive (l2, u2) e2)
-  = balance $ UnVarGraph Additive (max l1 l2, u1 + u2) e
-  where
-    e = IntMap.unionWith unionUnVarSet e1 e2
+unionUnVarGraph (UnVarGraph u1) (UnVarGraph u2) = UnVarGraph (unionUnVarSet u1 u2)
     
 unionUnVarGraphs :: [UnVarGraph] -> UnVarGraph
 unionUnVarGraphs = foldr unionUnVarGraph emptyUnVarGraph
 
--- completeBipartiteGraph A B = { {a,b} | a ∈ A, b ∈ B }
 completeBipartiteGraph :: UnVarSet -> UnVarSet -> UnVarGraph
-completeBipartiteGraph u1@(UnVarSet s1) u2@(UnVarSet s2) 
-    = balance (UnVarGraph Additive (2*a*b, 2*a*b) edges)
-    where
-      dom@(UnVarSet s) = unionUnVarSet u1 u2
-      (UnVarSet s3) = intersectionUnVarSet u1 u2 -- common elements
-      a = sizeUnVarSet u1
-      b = sizeUnVarSet u2
-      edges = IntMap.fromSet neighbors_of s
-      neighbors_of k
-        | k `IntSet.member` s3 = dom
-        | k `IntSet.member` s1 = u2
-        | k `IntSet.member` s2 = u1
+completeBipartiteGraph u1 u2 = UnVarGraph (unionUnVarSet u1 u2)
         
 completeGraph :: UnVarSet -> UnVarGraph
-completeGraph (UnVarSet s) = UnVarGraph Subtractive (0, 0) (IntMap.fromSet (const emptyUnVarSet) s)
+completeGraph = UnVarGraph
 
 isCompleteGraph_maybe :: UnVarGraph -> Maybe UnVarSet
-isCompleteGraph_maybe (UnVarGraph Subtractive (0, 0) e) 
-  = Just (UnVarSet (IntMap.keysSet e))
-isCompleteGraph_maybe _ = Nothing
+isCompleteGraph_maybe (UnVarGraph u) = Just u
 
 neighbors :: UnVarGraph -> Var -> UnVarSet
-neighbors (UnVarGraph res _ edges) v 
-  = fromMaybe emptyUnVarSet (interpret_edge <$> IntMap.lookup (k v) edges)
-  where dom = UnVarSet $ IntMap.keysSet edges
-        interpret_edge 
-          | res == Additive = id
-          | otherwise = differenceUnVarSet dom
+neighbors (UnVarGraph u) v = u
 
 delNode :: UnVarGraph -> Var -> UnVarGraph
-delNode (UnVarGraph ei (lb, ub) g) v 
-  = UnVarGraph ei (lb', ub') g2 -- No rebalance here, since the graph gets smaller anyway
-  where 
-    -- Note that we need to delete all mentioned edges, regardless of `ei`.
-    (neighbors_maybe, g1) = IntMap.updateLookupWithKey (\_ _ -> Nothing) (k v) g
-    UnVarSet neighbors = fromMaybe emptyUnVarSet neighbors_maybe
-    g2 = foldr (IntMap.adjust deleter) g1 (IntSet.toList neighbors)
-    dom = UnVarSet $ IntMap.keysSet g
-    new_dom = delUnVarSet dom v
-    deleter s
-      -- Again, optimize for the common cases
-      | sizeUnVarSet s <= 1 = emptyUnVarSet -- This assumes that v is in s
-      | sizeUnVarSet s == sizeUnVarSet dom = new_dom
-      | otherwise = delUnVarSet s v
-    del_edge_count = IntSet.size neighbors
-    lb' = lb - del_edge_count
-    ub' = ub - del_edge_count
+delNode (UnVarGraph u) v = UnVarGraph $ delUnVarSet u v
 
 instance Outputable UnVarGraph where
-    ppr u@(UnVarGraph ei _ g) 
-      | ei == Additive = ppr g
-      | otherwise = ppr (complementUnVarGraph u)
+    ppr (UnVarGraph u) = ppr u
-- 
2.12.1


From c6047a259cb20bf21845edb1070b64e1fd0c282e Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 28 May 2017 16:48:54 +0200
Subject: [PATCH 065/117] 'Fixed' monotonicity issues

---
 compiler/basicTypes/Usage.hs                     | 30 +++-----
 compiler/simplCore/CallArity/Analysis.hs         | 98 +++++++++++-------------
 compiler/simplCore/CallArity/FrameworkBuilder.hs |  1 +
 compiler/simplCore/CallArity/Types.hs            |  4 +-
 compiler/utils/Worklist.hs                       | 11 ++-
 5 files changed, 66 insertions(+), 78 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 2d58fb4753..e17b43176a 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -204,29 +204,21 @@ peelCallUse UnknownUse = Just topUsage
 peelCallUse _ = Nothing
 
 -- | @peelProductUse len_hint use@ tries to treat @use@ as a product use and
--- returns the list of usages on its components. It will adhere to the @len_hint@
--- if supplied, meaning that the product_use is constrained to have that length.
+-- returns the list of usages on its components. It will adhere to the @len_hint@,
+-- meaning that the @product_use@ is constrained to have that length.
 -- This is mostly so that `botSingleUse` and `topSingleUse`, oblivious to length
 -- information, can be translated (back) into a product use.
 --
--- If @len_hint@ is not supplied, this function will only return `Just` in the
--- case that @use@ actually models a proper product. Examples:
+-- Examples:
 --
---    - @peelProductUse (Just (length comps)) (mkProductUse comps) == Just comps@
---    - @peelProductUse Nothing (mkProductUse comps) == Just comps@
---    - @peelProductUse (Just n) topSingleUse == Just (replicate n topUsage)@
---    - @peelProductUse Nothing topSingleUse == Nothing@
---    - @peelProductUse (Just n) (mkCallUse Once topSingleUse) == Nothing@
---    - @forall n. peelProductUse (Just n) use == Nothing ==> peelProductUse Nothing use == Nothing@
-peelProductUse :: Maybe Arity -> SingleUse -> Maybe [Usage]
-peelProductUse Nothing (Product comps) = Just comps
-peelProductUse Nothing _ = Nothing
-peelProductUse (Just n) HeadUse = Just (replicate n botUsage)
-peelProductUse (Just n) UnknownUse = Just (replicate n topUsage)
-peelProductUse (Just n) (Product comps)
-  = ASSERT2(comps `lengthIs` n, text "peelProductUse" $$ ppr n $$ ppr comps)
-    Just comps
-peelProductUse _ (Call _ _) = Nothing -- might happen with unsafeCoerce (#9208)
+--    - @peelProductUse (length comps) (mkProductUse comps) == Just comps@
+--    - @peelProductUse n topSingleUse == Just (replicate n topUsage)@
+--    - @peelProductUse n (mkCallUse Once topSingleUse) == Nothing@
+peelProductUse :: Arity -> SingleUse -> Maybe [Usage]
+peelProductUse n HeadUse = Just (replicate n botUsage)
+peelProductUse n UnknownUse = Just (replicate n topUsage)
+peelProductUse n (Product comps) | comps `lengthIs` n = Just comps
+peelProductUse _ _ = Nothing -- type error, might happen with GADTs and unsafeCoerce (#9208)
 
 -- | Since the lattice modeled by `SingleUse` has infinite height, we run might
 -- run into trouble regarding convergence. This happens in practice for product
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index eaa069ad99..2c9d865d23 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -1,4 +1,5 @@
 {-# LANGUAGE CPP #-}
+{-# OPTIONS_GHC -fprof-auto #-}
 --
 -- Copyright (c) 2014 Joachim Breitner
 --
@@ -441,12 +442,12 @@ extendAnalEnv env id node = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
 -- as a tuple. As a result, all exported identifiers are handled as called
 -- with each other, with `topUsage`.
 moduleToExpr :: CoreProgram -> (VarSet, CoreExpr)
-moduleToExpr = impl []
+moduleToExpr = first (\it -> pprTrace "moduleToExpr" (ppr (sizeVarSet it)) it) . impl []
   where
     impl exposed []
       = (mkVarSet exposed, mkBigCoreVarTup exposed)
     impl exposed (bind:prog)
-      = second (Let bind) (impl (exposed_ids bind ++ exposed) prog)
+      = second (Let bind) (impl (exposed_ids' bind ++ exposed) prog)
     -- We are too conservative here, but we need *at least*  
     -- 
     --   * exported `Id`s (`isExportedId`)
@@ -456,6 +457,7 @@ moduleToExpr = impl []
     -- with any of the binders, so we just blindly assume all top-level
     -- `Id`s as exported (as does the demand analyzer).
     exposed_ids bind = bindersOf bind
+    exposed_ids' bind = filter isExportedId (bindersOf bind)
 
 -- | The left inverse to `moduleToExpr`: `exprToModule . snd . moduleToExpr = id \@CoreProgram`
 exprToModule :: CoreExpr -> CoreProgram
@@ -465,7 +467,7 @@ exprToModule _ = []
 -- Main entry point
 callArityAnalProgram :: DynFlags -> FamInstEnvs -> CoreProgram -> IO CoreProgram
 callArityAnalProgram dflags fam_envs
-  = return . exprToModule . uncurry (callArityRHS dflags fam_envs) . moduleToExpr
+  = return . (\it -> pprTrace "callArity:end" (ppr (length it)) it) . exprToModule . uncurry (callArityRHS dflags fam_envs) . moduleToExpr . (\it -> pprTrace "callArity:begin" (ppr (length it)) it)
   -- . (\prog -> pprTrace "CallArity:Program" (ppr prog) prog)
 
 callArityRHS :: DynFlags -> FamInstEnvs -> VarSet -> CoreExpr -> CoreExpr
@@ -580,44 +582,29 @@ callArityExpr env (Lam id body)
           --pprTrace "callArityExpr:Lam" (vcat [text "id:" <+> ppr id, text "relative body usage:" <+> ppr u, text "id usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
           return (ut, Lam id' body')
 
-callArityExpr env e@App{} 
-  | (f, args) <- collectArgs e
-  = do
-    let val_args = filter isValArg args 
-    let n = length val_args
-    transfer_f <- callArityExpr env f
-    transfer_val_args <- mapM (callArityExpr env) val_args
-    return $ \result_use -> do
-      (ut_f, f') <- transfer_f (iterate (mkCallUse Once) result_use !! n)
-      --pprTrace "App:f'" (ppr f' <+> ppr (ut_args ut_f)) $ return ()
-      let blub ut [] [] = return (ut, [], [])
-          blub ut (transfer_arg:transfer_args) (arg:args) = do
-            -- peel off one argument from the type
-            let (arg_usage, ut') = peelArgUsage ut
-            -- handle the other args
-            (ut'', ut_args, args') <- blub ut' transfer_args args
-            case considerThunkSharing arg arg_usage of
-              Absent -> return (ut'', botUsageType:ut_args, arg:args')
-              Used m arg_use -> do
-                -- `m` will be `Once` most of the time (see `considerThunkSharing`),
-                -- so that all work before the lambda is uncovered will be shared 
-                -- (call-by-need!). This is the same argument as for let-bound 
-                -- right hand sides.
-                -- We could also use the multiplicity in the same way we do for
-                -- let-bindings: An argument only used once does not need to be
-                -- memoized.
-                (ut_arg, arg') <- first (multiplyUsages m) <$> transfer_arg arg_use
-                --pprTrace "App:arg'" (text "arg_use:" <+> ppr arg_use <+> ppr (ut_arg, arg')) $ return ()
-                return (ut'', ut_arg:ut_args, arg':args')
-      (ut_f', ut_args, val_args') <- blub ut_f transfer_val_args val_args
-      let merge_with_type_args (a:args) (va:val_args) 
-            | isValArg a = va:merge_with_type_args args val_args
-            | otherwise = a:merge_with_type_args args (va:val_args)
-          merge_with_type_args args [] = args
-      let ut = bothUsageTypes (ut_f':ut_args)
-      let e = mkApps f' (merge_with_type_args args val_args')
-      --pprTrace "App:combined" (ppr f <+> ppr val_args' <+> ppr ut) $ return ()
-      return (ut, e)
+callArityExpr env (App f (Type t)) = callArityExprMap env (flip App (Type t)) f
+
+callArityExpr env (App f a) = do
+  transfer_f <- callArityExpr env f
+  transfer_a <- callArityExpr env a
+  return $ \result_use -> do
+    (ut_f, f') <- transfer_f (mkCallUse Once result_use)
+    --pprTrace "App:f'" (ppr f') $ return ()
+    -- peel off one argument from the type
+    let (arg_usage, ut_f') = peelArgUsage ut_f
+    case considerThunkSharing a arg_usage of
+      Absent -> return (ut_f', App f' a)
+      Used m arg_use -> do
+          -- `m` will be `Once` most of the time (see `considerThunkSharing`),
+          -- so that all work before the lambda is uncovered will be shared 
+          -- (call-by-need!). This is the same argument as for let-bound 
+          -- right hand sides.
+          -- We could also use the multiplicity in the same way we do for
+          -- let-bindings: An argument only used once does not need to be
+          -- memoized.
+          (ut_a, a') <- first (multiplyUsages m) <$> transfer_a arg_use
+          --pprTrace "App:a'" (text "arg_use:" <+> ppr arg_use <+> ppr (ut_a, a')) $ return ()
+          return (ut_f' `bothUsageType` ut_a, App f' a')
 
 callArityExpr env (Case scrut case_bndr ty alts) = do
   transfer_scrut <- callArityExpr env scrut
@@ -666,12 +653,13 @@ callArityExpr env (Let bind e) = do
               (ut_usage, Let (Rec old_bind) _) <- dependOnWithDefault (ut_body, Let bind e') (node, use)
               let transferred_binds = map transferred_bind old_bind
               (ut, bind') <- unleashLet env Recursive transferred_binds ut_usage ut_body
+              let ut' = lubUsageType ut ut_usage
               let lookup_old = lookupUsage Recursive ut_usage
-              let lookup_new = lookupUsage Recursive ut
-              let ut' | all (\id -> lookup_old id == lookup_new id) ids = markStable ut
-                      | otherwise = ut
-              --ut' <- pprTrace "Rec:end" (ppr ids) $ return ut'
-              return (ut', Let (Rec bind') e')
+              let lookup_new = lookupUsage Recursive ut'
+              let ut'' | all (\id -> lookup_old id == lookup_new id) ids = markStable ut'
+                       | otherwise = ut'
+              --ut'' <- pprTrace "Rec:end" (ppr ids) $ return ut''
+              return (ut'', Let (Rec bind') e')
 
         let change_detector :: ChangeDetector
             change_detector changed_refs (old, _) (new, _) =
@@ -728,7 +716,7 @@ dataConUsageSig dc use = fromMaybe topUsageSig sig_maybe
       product_use <- peelSingleShotCalls arity use
       -- We need to consider strict constructors, where a head use will also
       -- use its components (e.g. I#)
-      component_usages <- peelProductUse (Just arity) (addDataConStrictness dc product_use)
+      component_usages <- peelProductUse arity (addDataConStrictness dc product_use)
       return (usageSigFromUsages component_usages)
 
 dictSelUsageSig :: Id -> Class -> SingleUse -> UsageSig
@@ -736,7 +724,7 @@ dictSelUsageSig id clazz use
   | Used _ dict_single_call_use <- fst . unconsUsageSig . idArgUsage $ id
   , Just dc <- tyConSingleDataCon_maybe (classTyCon clazz)
   , let dict_length = idArity (dataConWorkId dc)
-  , Just comps <- peelProductUse (Just dict_length) dict_single_call_use
+  , Just comps <- peelProductUse dict_length dict_single_call_use
   = case peelCallUse use of -- The outer call is the selector. The inner use is on the actual method!
       Nothing -> topUsageSig -- weird
       Just Absent -> botUsageSig
@@ -825,7 +813,7 @@ findBndrsUsages rec_flag fam_envs ut = foldr step (ut, [])
 addCaseBndrUsage :: Usage -> [Usage] -> [Usage]
 addCaseBndrUsage Absent alt_bndr_usages = alt_bndr_usages
 addCaseBndrUsage (Used _ use) alt_bndr_usages
-  | Just case_comp_usages <- peelProductUse (Just (length alt_bndr_usages)) use
+  | Just case_comp_usages <- peelProductUse (length alt_bndr_usages) use
   = zipWith bothUsage case_comp_usages alt_bndr_usages
   | otherwise
   = topUsage <$ alt_bndr_usages
@@ -856,7 +844,7 @@ propagateProductUse alts scrut_uses
   -- This is a good place to make sure we don't construct an infinitely deep
   -- use, which can happen when analysing e.g. lazy streams.
   -- Also see Note [Demand on scrutinee of a product case] in DmdAnal.hs.
-  = addDataConStrictness dc (boundDepth 10 scrut_use)
+  = addDataConStrictness dc (boundDepth 6 scrut_use)
 
   | otherwise
   -- We *could* lub the uses from the different branches, but there's not much
@@ -867,7 +855,7 @@ addDataConStrictness :: DataCon -> SingleUse -> SingleUse
 -- See Note [Add demands for strict constructors] in DmdAnal.hs
 addDataConStrictness dc
   = maybe topSingleUse (mkProductUse . add_component_strictness) 
-  . peelProductUse (Just arity) 
+  . peelProductUse arity
   where
     add_component_strictness :: [Usage] -> [Usage]
     add_component_strictness = zipWith add strs
@@ -897,7 +885,9 @@ registerBindingGroup env = go env emptyVarEnv
           transfer <- callArityExpr env' rhs
           let transfer' use = do
                 --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
-                ret@(ut_rhs, _) <- transfer use
+                (prev_ut_rhs, _) <- fromMaybe (botUsageType, rhs) <$> unsafePeekValue (node, use)
+                (ut_rhs, rhs') <- transfer use 
+                let ret = (lubUsageType ut_rhs prev_ut_rhs, rhs')
                 --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut_rhs)]) $ return ret
                 return ret
           let transfer_args use = do
@@ -910,7 +900,7 @@ registerBindingGroup env = go env emptyVarEnv
                 -- change detection for the arg usage case. This implies that
                 -- use sites of these sig nodes may only use the ut_args
                 -- component!
-                --pprTrace "change_detector_down" (vcat [ppr node, ppr id, ppr (ut_args old <= ut_args new), ppr (lubUsageSig (ut_args old) (ut_args new)), ppr (ut_args old), ppr (ut_args new), ppr (ut_args old /= ut_args new)]) $
+                --pprTrace "change_detector_down" (vcat [ppr node, ppr id, ppr (ut_args old <= ut_args new), ppr (ut_args old), ppr (ut_args new), ppr (ut_args old /= ut_args new)]) $
                 ASSERT2( ut_args old <= ut_args new, text "CallArity.change_detector_down: Not monotone" $$ ppr id $$ ppr (ut_args old) $$ ppr (ut_args new) )
                 ut_args old /= ut_args new
                   where
@@ -1033,5 +1023,5 @@ callArityLetEnv rhss ut_body
         -- if the mutually recursive group becomes too large.
         -- Combining all rhs and the body with `bothUsageType` corresponds to
         -- cocalls in the complete graph.
-        | length ut_rhss > 25 = foldr bothUsageType botUsageType ut_all
+        | length ut_rhss > 25 = bothUsageTypes ut_all
         | otherwise           = lubUsageTypes (ut_all ++ map cross_calls rhss)
diff --git a/compiler/simplCore/CallArity/FrameworkBuilder.hs b/compiler/simplCore/CallArity/FrameworkBuilder.hs
index 99636dc96c..17f55b61da 100644
--- a/compiler/simplCore/CallArity/FrameworkBuilder.hs
+++ b/compiler/simplCore/CallArity/FrameworkBuilder.hs
@@ -10,6 +10,7 @@ module CallArity.FrameworkBuilder
   , RequestedPriority (..)
   , registerTransferFunction
   , dependOnWithDefault
+  , Worklist.unsafePeekValue
   , buildAndRun
   ) where
 
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index 886b5ab28c..a83f8da751 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -117,8 +117,8 @@ bothUsageTypes uts
     -- This is an important optimization for large tuples, like occuring
     -- when analysing top-level binds as let bindings
     (completes, incompletes) 
-      -- = ([], uts)
-      = partition (isJust . asCompleteGraph) uts
+      = ([], uts)
+      -- = partition (isJust . asCompleteGraph) uts
     completeDom
       = unionUnVarSets 
       . map (fromJust . asCompleteGraph) 
diff --git a/compiler/utils/Worklist.hs b/compiler/utils/Worklist.hs
index 120f240a4b..86f853d71a 100644
--- a/compiler/utils/Worklist.hs
+++ b/compiler/utils/Worklist.hs
@@ -1,10 +1,11 @@
 {-# LANGUAGE ScopedTypeVariables #-}
 {-# LANGUAGE GeneralizedNewtypeDeriving #-}
 {-# OPTIONS_GHC -funbox-strict-fields #-}
+{-# OPTIONS_GHC -fprof-auto #-}
 module Worklist where
 
 import Control.Arrow (first)
-import Control.Monad (forM_, when)
+import Control.Monad (forM_, when, (<=<))
 import Control.Monad.Trans.State.Strict
 import Data.Map (Map)
 import qualified Data.Map as Map
@@ -97,13 +98,17 @@ dependOn node = TFM $ do
     Nothing -> do
       Just <$> recompute node
       --Just <$> recompute (trace "Nothing, no loop" node)
-    Just _ | isNotYetStable && not loopDetected -> do
-      Just <$> recompute node
+    -- We aren't doing this because of monotonicity issues
+    --Just _ | isNotYetStable && not loopDetected -> do
+      --Just <$> recompute node
       --Just <$> recompute (trace "Just, not stable" node)
     Just info -> do
       return (value info)
       --return (trace "Just, stable" (value info))
 
+unsafePeekValue :: Ord node => node -> TransferFunction node lattice (Maybe lattice)
+unsafePeekValue node = TFM $ (value <=< Map.lookup node) <$> gets graph
+
 data Diff a
   = Diff
   { added :: !(Set a)
-- 
2.12.1


From c01d443f70ad773f09d7a031e15df6c0f1301a77 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 28 May 2017 18:10:24 +0200
Subject: [PATCH 066/117] Revert "A version with the dumbest co-call graph
 still exhibits quadratic behavior"

This reverts commit 4dda32e34a71bdcc15d4f1d804dd7391b5138a50.
---
 compiler/utils/UnVarGraph.hs | 117 +++++++++++++++++++++++++++++++++++++++----
 1 file changed, 108 insertions(+), 9 deletions(-)

diff --git a/compiler/utils/UnVarGraph.hs b/compiler/utils/UnVarGraph.hs
index eca78a9ad9..c7f4a30602 100644
--- a/compiler/utils/UnVarGraph.hs
+++ b/compiler/utils/UnVarGraph.hs
@@ -65,6 +65,12 @@ elemUnVarSet v (UnVarSet s) = k v `IntSet.member` s
 isEmptyUnVarSet :: UnVarSet -> Bool
 isEmptyUnVarSet (UnVarSet s) = IntSet.null s
 
+differenceUnVarSet :: UnVarSet -> UnVarSet -> UnVarSet
+differenceUnVarSet (UnVarSet s1) (UnVarSet s2) = UnVarSet $ IntSet.difference s1 s2
+
+intersectionUnVarSet :: UnVarSet -> UnVarSet -> UnVarSet
+intersectionUnVarSet (UnVarSet s1) (UnVarSet s2) = UnVarSet $ IntSet.intersection s1 s2
+
 delUnVarSet :: UnVarSet -> Var -> UnVarSet
 delUnVarSet (UnVarSet s) v = UnVarSet $ k v `IntSet.delete` s
 
@@ -89,31 +95,124 @@ instance Outputable UnVarSet where
     ppr (UnVarSet s) = braces $
         hcat $ punctuate comma [ ppr (getUnique i) | i <- IntSet.toList s]
 
-newtype UnVarGraph = UnVarGraph UnVarSet
+data OverlayResolution
+    = Additive
+    | Subtractive
+    deriving (Eq, Ord, Show)
+
+complementOverlayResolution :: OverlayResolution -> OverlayResolution
+complementOverlayResolution Additive = Subtractive
+complementOverlayResolution Subtractive = Additive
+
+data UnVarGraph 
+    = UnVarGraph
+    { edge_interpretation :: !OverlayResolution
+    , edge_count_estimate :: !(Int, Int)
+    , edges :: !(IntMap UnVarSet)
+    }
+
+balance :: UnVarGraph -> UnVarGraph
+balance g@(UnVarGraph ei (_, ub) edges)
+  | ub_ratio < 0.6 = g
+  | precise_ratio < 0.6 = precise_g
+  | otherwise = complementUnVarGraph precise_g
+  where
+    nodes = IntMap.size edges
+    max_edges = nodes * nodes
+    ub_ratio :: Double
+    ub_ratio = fromIntegral ub / fromIntegral max_edges
+    edge_count = foldr ((+) . sizeUnVarSet) 0 edges
+    precise_ratio :: Double
+    precise_ratio = fromIntegral edge_count / fromIntegral max_edges
+    precise_g = UnVarGraph ei (edge_count, edge_count) edges
+
+complementUnVarGraph :: UnVarGraph -> UnVarGraph
+complementUnVarGraph (UnVarGraph res (lb, ub) edges) 
+  = UnVarGraph (complementOverlayResolution res) ec (complementEdges edges)
+  where
+    nodes = IntMap.size edges
+    max_edges = nodes*nodes
+    ec = (max_edges - ub, max_edges - lb)
+
+complementEdges :: IntMap UnVarSet -> IntMap UnVarSet
+complementEdges edges = edges'
+  where
+    dom = UnVarSet (IntMap.keysSet edges)
+    edges' = fmap complement_neighbors edges
+    complement_neighbors neighbors
+      -- Very common cases are an empty neighbor set and the full neighbor set,
+      -- in which case we want to be pretty cheap.
+      | isEmptyUnVarSet neighbors = dom
+      | sizeUnVarSet neighbors == sizeUnVarSet dom = emptyUnVarSet
+      | otherwise = differenceUnVarSet dom neighbors
 
 emptyUnVarGraph :: UnVarGraph
-emptyUnVarGraph = UnVarGraph emptyUnVarSet
+emptyUnVarGraph = UnVarGraph Subtractive (0, 0) IntMap.empty
 
 unionUnVarGraph :: UnVarGraph -> UnVarGraph -> UnVarGraph
-unionUnVarGraph (UnVarGraph u1) (UnVarGraph u2) = UnVarGraph (unionUnVarSet u1 u2)
+unionUnVarGraph u1@(UnVarGraph Subtractive _ _) u2
+  = unionUnVarGraph (complementUnVarGraph u1) u2
+unionUnVarGraph u1 u2@(UnVarGraph Subtractive _ _)
+  = unionUnVarGraph u1 (complementUnVarGraph u2)
+unionUnVarGraph (UnVarGraph Additive (l1, u1) e1) (UnVarGraph Additive (l2, u2) e2)
+  = balance $ UnVarGraph Additive (max l1 l2, u1 + u2) e
+  where
+    e = IntMap.unionWith unionUnVarSet e1 e2
     
 unionUnVarGraphs :: [UnVarGraph] -> UnVarGraph
 unionUnVarGraphs = foldr unionUnVarGraph emptyUnVarGraph
 
+-- completeBipartiteGraph A B = { {a,b} | a ∈ A, b ∈ B }
 completeBipartiteGraph :: UnVarSet -> UnVarSet -> UnVarGraph
-completeBipartiteGraph u1 u2 = UnVarGraph (unionUnVarSet u1 u2)
+completeBipartiteGraph u1@(UnVarSet s1) u2@(UnVarSet s2) 
+    = balance (UnVarGraph Additive (2*a*b, 2*a*b) edges)
+    where
+      dom@(UnVarSet s) = unionUnVarSet u1 u2
+      (UnVarSet s3) = intersectionUnVarSet u1 u2 -- common elements
+      a = sizeUnVarSet u1
+      b = sizeUnVarSet u2
+      edges = IntMap.fromSet neighbors_of s
+      neighbors_of k
+        | k `IntSet.member` s3 = dom
+        | k `IntSet.member` s1 = u2
+        | k `IntSet.member` s2 = u1
         
 completeGraph :: UnVarSet -> UnVarGraph
-completeGraph = UnVarGraph
+completeGraph (UnVarSet s) = UnVarGraph Subtractive (0, 0) (IntMap.fromSet (const emptyUnVarSet) s)
 
 isCompleteGraph_maybe :: UnVarGraph -> Maybe UnVarSet
-isCompleteGraph_maybe (UnVarGraph u) = Just u
+isCompleteGraph_maybe (UnVarGraph Subtractive (0, 0) e) 
+  = Just (UnVarSet (IntMap.keysSet e))
+isCompleteGraph_maybe _ = Nothing
 
 neighbors :: UnVarGraph -> Var -> UnVarSet
-neighbors (UnVarGraph u) v = u
+neighbors (UnVarGraph res _ edges) v 
+  = fromMaybe emptyUnVarSet (interpret_edge <$> IntMap.lookup (k v) edges)
+  where dom = UnVarSet $ IntMap.keysSet edges
+        interpret_edge 
+          | res == Additive = id
+          | otherwise = differenceUnVarSet dom
 
 delNode :: UnVarGraph -> Var -> UnVarGraph
-delNode (UnVarGraph u) v = UnVarGraph $ delUnVarSet u v
+delNode (UnVarGraph ei (lb, ub) g) v 
+  = UnVarGraph ei (lb', ub') g2 -- No rebalance here, since the graph gets smaller anyway
+  where 
+    -- Note that we need to delete all mentioned edges, regardless of `ei`.
+    (neighbors_maybe, g1) = IntMap.updateLookupWithKey (\_ _ -> Nothing) (k v) g
+    UnVarSet neighbors = fromMaybe emptyUnVarSet neighbors_maybe
+    g2 = foldr (IntMap.adjust deleter) g1 (IntSet.toList neighbors)
+    dom = UnVarSet $ IntMap.keysSet g
+    new_dom = delUnVarSet dom v
+    deleter s
+      -- Again, optimize for the common cases
+      | sizeUnVarSet s <= 1 = emptyUnVarSet -- This assumes that v is in s
+      | sizeUnVarSet s == sizeUnVarSet dom = new_dom
+      | otherwise = delUnVarSet s v
+    del_edge_count = IntSet.size neighbors
+    lb' = lb - del_edge_count
+    ub' = ub - del_edge_count
 
 instance Outputable UnVarGraph where
-    ppr (UnVarGraph u) = ppr u
+    ppr u@(UnVarGraph ei _ g) 
+      | ei == Additive = ppr g
+      | otherwise = ppr (complementUnVarGraph u)
-- 
2.12.1


From cda7f6da7d7971454972360a7893863091567fad Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 29 May 2017 11:11:32 +0200
Subject: [PATCH 067/117] 'Fixed' spec-inline... again

---
 compiler/simplCore/CallArity/Analysis.hs           |  4 ++-
 compiler/simplCore/DmdAnalWrapper.hs               | 30 +++++++++++-----------
 .../simplCore/should_compile/spec-inline.stderr    |  7 ++---
 3 files changed, 22 insertions(+), 19 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 2c9d865d23..d3df14860f 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -567,7 +567,9 @@ callArityExpr env (Lam id body)
     transfer_body <- callArityExpr env body
     return $ \use ->
       case fromMaybe topUsage (peelCallUse use) of -- Get at the relative @Usage@ of the body
-        Absent -> return (emptyUsageType, Lam id body)
+        Absent -> do
+          let id' = id `setIdCallArity` Absent
+          return (emptyUsageType, Lam id' body)
         u@(Used multi body_use) -> do
           (ut_body, body') <- transfer_body body_use
           let (ut_body', usage_id) = findBndrUsage NonRecursive (ae_fam_envs env) ut_body id
diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index 53bba4165c..ed3ab349df 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -26,8 +26,8 @@ combinedDmdAnalProgram dflags fams prog = do
   --pprTrace "Program" (ppr prog'') $ pure ()
   return (mapBndrsProgram mergeInfo prog'')
 
-mergeInfo :: TopLevelFlag -> Bool -> Var -> Var
-mergeInfo top_lvl is_lam_bndr id
+mergeInfo :: Bool -> Var -> Var
+mergeInfo is_lam_bndr id
   | isTyVar id
   = id
   | otherwise 
@@ -61,32 +61,32 @@ mergeInfo top_lvl is_lam_bndr id
     leqUsage l r = l `lubUsage` r == r
     leqUsageSig l r = l `lubUsageSig` r == r
     id'
-      | isTopLevel top_lvl = id `setIdStrictness` new_str_sig -- Only the sig matters
+      | isExportedId id = id `setIdStrictness` new_str_sig -- Only the sig matters
       | otherwise = id `setIdDemandInfo` new_demand -- Only use sites matter
 
 
-mapBndrsProgram :: (TopLevelFlag -> Bool -> Var -> Var) -> CoreProgram -> CoreProgram
-mapBndrsProgram f = map (mapBndrsBind TopLevel f)
+mapBndrsProgram :: (Bool -> Var -> Var) -> CoreProgram -> CoreProgram
+mapBndrsProgram f = map (mapBndrsBind f)
 
-mapBndrsBind :: TopLevelFlag -> (TopLevelFlag -> Bool -> Var -> Var) -> CoreBind -> CoreBind
-mapBndrsBind top_lvl f (NonRec id e) = NonRec (f top_lvl False id) (mapBndrsExprIfNotAbsent id f e)
-mapBndrsBind top_lvl f (Rec bndrs) = Rec (map (\(id, e) -> (f top_lvl False id, mapBndrsExprIfNotAbsent id f e)) bndrs)
+mapBndrsBind :: (Bool -> Var -> Var) -> CoreBind -> CoreBind
+mapBndrsBind f (NonRec id e) = NonRec (f False id) (mapBndrsExprIfNotAbsent id f e)
+mapBndrsBind f (Rec bndrs) = Rec (map (\(id, e) -> (f False id, mapBndrsExprIfNotAbsent id f e)) bndrs)
 
-mapBndrsExprIfNotAbsent :: Var -> (TopLevelFlag -> Bool -> Var -> Var) -> CoreExpr -> CoreExpr
+mapBndrsExprIfNotAbsent :: Var -> (Bool -> Var -> Var) -> CoreExpr -> CoreExpr
 mapBndrsExprIfNotAbsent id f e
   | Absent <- idCallArity id = e -- we won't have analysed e in this case.
   | otherwise = mapBndrsExpr f e
 
-mapBndrsExpr :: (TopLevelFlag -> Bool -> Var -> Var) -> CoreExpr -> CoreExpr
+mapBndrsExpr :: (Bool -> Var -> Var) -> CoreExpr -> CoreExpr
 mapBndrsExpr f e = case e of
   App func arg -> App (mapBndrsExpr f func) (mapBndrsExpr f arg)
-  Lam id e -> Lam (f NotTopLevel True id) (mapBndrsExpr f e)
-  Let bind body -> Let (mapBndrsBind NotTopLevel f bind) (mapBndrsExpr f body)
-  Case scrut id ty alts -> Case (mapBndrsExpr f scrut) (f NotTopLevel False id) ty (map (mapBndrsAlt f) alts)
+  Lam id e -> Lam (f True id) (mapBndrsExpr f e)
+  Let bind body -> Let (mapBndrsBind f bind) (mapBndrsExpr f body)
+  Case scrut id ty alts -> Case (mapBndrsExpr f scrut) (f False id) ty (map (mapBndrsAlt f) alts)
   Cast e co -> Cast (mapBndrsExpr f e) co
   Tick t e -> Tick t (mapBndrsExpr f e)
   Var _ -> e -- use sites carry no important annotations
   _ -> e
 
-mapBndrsAlt :: (TopLevelFlag -> Bool -> Var -> Var) -> Alt CoreBndr -> Alt CoreBndr
-mapBndrsAlt f (con, bndrs, e) = (con, map (f NotTopLevel False) bndrs, mapBndrsExpr f e)
+mapBndrsAlt :: (Bool -> Var -> Var) -> Alt CoreBndr -> Alt CoreBndr
+mapBndrsAlt f (con, bndrs, e) = (con, map (f False) bndrs, mapBndrsExpr f e)
diff --git a/testsuite/tests/simplCore/should_compile/spec-inline.stderr b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
index b36257b9bb..17426f55ff 100644
--- a/testsuite/tests/simplCore/should_compile/spec-inline.stderr
+++ b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
@@ -64,9 +64,9 @@ Roman.foo_$s$wgo [Occ=LoopBreaker]
   :: GHC.Prim.Int# -> GHC.Prim.Int# -> GHC.Prim.Int#
 [GblId, Arity=2, Caf=NoCafRefs, Str=<S,U><S,U>]
 Roman.foo_$s$wgo =
-  \ (sc :: GHC.Prim.Int#) (sc1 :: GHC.Prim.Int#) ->
+  \ (sc :: GHC.Prim.Int#) (sc1 [OS=OneShot] :: GHC.Prim.Int#) ->
     let {
-      m [Dmd=<L,A>] :: GHC.Prim.Int#
+      m [Dmd=<L,A>, Usg=A] :: GHC.Prim.Int#
       [LclId]
       m =
         GHC.Prim.+#
@@ -103,7 +103,7 @@ Roman.$wgo =
       Just x ->
         case x of { GHC.Types.I# ipv ->
         let {
-          m [Dmd=<L,A>] :: GHC.Prim.Int#
+          m :: GHC.Prim.Int#
           [LclId]
           m =
             GHC.Prim.+#
@@ -171,6 +171,7 @@ foo :: Int -> Int
  Arity=1,
  Caf=NoCafRefs,
  Str=<S(S),1*U>m,
+ ArgUsg=1*U,w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
-- 
2.12.1


From 0b25b6fd9f762d55651591e5312cc46ea84a4c5d Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 29 May 2017 16:18:47 +0200
Subject: [PATCH 068/117] Fixed T7116, T4908, T4930, T3772

---
 testsuite/tests/numeric/should_compile/T7116.stdout   | 4 ++++
 testsuite/tests/simplCore/should_compile/T4908.stderr | 7 +++++--
 testsuite/tests/simplCore/should_compile/T4930.stderr | 1 +
 3 files changed, 10 insertions(+), 2 deletions(-)

diff --git a/testsuite/tests/numeric/should_compile/T7116.stdout b/testsuite/tests/numeric/should_compile/T7116.stdout
index a4c67360b8..2fe344de46 100644
--- a/testsuite/tests/numeric/should_compile/T7116.stdout
+++ b/testsuite/tests/numeric/should_compile/T7116.stdout
@@ -53,6 +53,7 @@ dr :: Double -> Double
  Arity=1,
  Caf=NoCafRefs,
  Str=<S(S),1*U>m,
+ ArgUsg=1*U,w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
@@ -70,6 +71,7 @@ dl :: Double -> Double
  Arity=1,
  Caf=NoCafRefs,
  Str=<S(S),1*U>m,
+ ArgUsg=1*U,w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
@@ -83,6 +85,7 @@ fr :: Float -> Float
  Arity=1,
  Caf=NoCafRefs,
  Str=<S(S),1*U>m,
+ ArgUsg=1*U,w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
@@ -102,6 +105,7 @@ fl :: Float -> Float
  Arity=1,
  Caf=NoCafRefs,
  Str=<S(S),1*U>m,
+ ArgUsg=1*U,w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
diff --git a/testsuite/tests/simplCore/should_compile/T4908.stderr b/testsuite/tests/simplCore/should_compile/T4908.stderr
index 185b9b3529..a0a6008389 100644
--- a/testsuite/tests/simplCore/should_compile/T4908.stderr
+++ b/testsuite/tests/simplCore/should_compile/T4908.stderr
@@ -52,7 +52,9 @@ Rec {
 T4908.f_$s$wf [Occ=LoopBreaker] :: Int -> Int# -> Int# -> Bool
 [GblId, Arity=3, Caf=NoCafRefs, Str=<L,A><L,1*U><S,1*U>]
 T4908.f_$s$wf =
-  \ (sc :: Int) (sc1 :: Int#) (sc2 :: Int#) ->
+  \ (sc :: Int) 
+    (sc1 [OS=OneShot] :: Int#) 
+    (sc2 [OS=OneShot] :: Int#) ->
     case sc2 of ds {
       __DEFAULT ->
         case sc1 of ds1 {
@@ -72,7 +74,7 @@ T4908.$wf [InlPrag=[0]] :: Int# -> (Int, Int) -> Bool
  Unf=Unf{Src=<vanilla>, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True, Guidance=IF_ARGS [30 20] 101 20}]
 T4908.$wf =
-  \ (ww :: Int#) (w :: (Int, Int)) ->
+  \ (ww :: Int#) (w [OS=OneShot] :: (Int, Int)) ->
     case ww of ds {
       __DEFAULT ->
         case w of { (a, b) ->
@@ -92,6 +94,7 @@ f [InlPrag=INLINE[0]] :: Int -> (Int, Int) -> Bool
  Arity=2,
  Caf=NoCafRefs,
  Str=<S(S),1*U(1*U)><L,1*U(A,1*U(1*U))>,
+ ArgUsg=1*U(1*U),1*U(A,1*U(1*U)),w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=2,unsat_ok=True,boring_ok=False)
diff --git a/testsuite/tests/simplCore/should_compile/T4930.stderr b/testsuite/tests/simplCore/should_compile/T4930.stderr
index 7e6ccf9a69..f714107216 100644
--- a/testsuite/tests/simplCore/should_compile/T4930.stderr
+++ b/testsuite/tests/simplCore/should_compile/T4930.stderr
@@ -66,6 +66,7 @@ foo [InlPrag=INLINE[0]] :: Int -> Int
  Arity=1,
  Caf=NoCafRefs,
  Str=<S(S),1*U>m,
+ ArgUsg=1*U,w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
-- 
2.12.1


From 5a33ad3cb3a6f90516f3c8e4c373a5fac8e5bdd8 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 29 May 2017 17:47:55 +0200
Subject: [PATCH 069/117] Had a shot at a run-off the mill monotonicity check

---
 compiler/coreSyn/PprCore.hs              |   5 +-
 compiler/simplCore/CallArity/Analysis.hs |  18 +++++-
 compiler/utils/UnVarGraph.hs             | 108 ++++++++++++++++++-------------
 3 files changed, 80 insertions(+), 51 deletions(-)

diff --git a/compiler/coreSyn/PprCore.hs b/compiler/coreSyn/PprCore.hs
index c3a16912f2..042a1fef89 100644
--- a/compiler/coreSyn/PprCore.hs
+++ b/compiler/coreSyn/PprCore.hs
@@ -464,6 +464,7 @@ ppIdInfo id info
     , (has_arity,        text "Arity=" <> int arity)
     , (has_caf_info,     text "Caf=" <> ppr caf_info)
     , (has_str_info,     text "Str=" <> pprStrictness str_info)
+    , (has_usg,          text "Usg=" <> ppr usg_info)
     , (has_arg_usage,    text "ArgUsg=" <> ppr arg_usage)
     , (has_unf,          text "Unf=" <> ppr unf_info)
     , (not (null rules), text "RULES:" <+> vcat (map pprRule rules))
@@ -478,8 +479,8 @@ ppIdInfo id info
     arity = arityInfo info
     has_arity = arity /= 0
 
-    called_arity = callArityInfo info
-    has_called_arity = called_arity /= topUsage
+    usg_info = callArityInfo info
+    has_usg = usg_info /= topUsage
 
     arg_usage = argUsageInfo info
     has_arg_usage = arg_usage /= topUsageSig
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index d3df14860f..23263f3946 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -669,9 +669,21 @@ callArityExpr env (Let bind e) = do
               -- previous iteration, we can efficiently test for changes.
               --pprTrace "change_detector" (vcat[ppr ids, ppr node, ppr changed_refs]) $
               --pprTrace "change_detector" (vcat[ppr node, ppr changed_refs, ppr old, ppr new]) $
-              map fst (Set.toList changed_refs) /= [node]
-              || not (ut_stable old) 
-              || not (ut_stable new) -- set in the transfer function through markStable
+              ASSERT2( old_sig `leqUsageSig` new_sig, text "CallArity.change_detector: usage sig not monotone")
+              old_sig == new_sig &&
+              ASSERT2( sizeUFM old_uses <= sizeUFM new_uses, text "CallArity.change_detector: uses not monotone")
+              sizeUFM old_uses == sizeUFM new_uses &&
+              old_uses == new_uses &&
+              ASSERT2( edgeCount old_cocalled <= edgeCount new_cocalled, text "CallArity.change_detector: edgeCount not monotone")
+              edgeCount old_cocalled == edgeCount new_cocalled
+              where
+                old_sig = ut_args old
+                new_sig = ut_args new
+                old_uses = ut_uses old
+                new_uses = ut_uses new
+                old_cocalled = ut_cocalled old
+                new_cocalled = ut_cocalled new
+                leqUsageSig a b = lubUsageSig a b == b
 
         return (node, (transfer, change_detector))
 
diff --git a/compiler/utils/UnVarGraph.hs b/compiler/utils/UnVarGraph.hs
index c7f4a30602..4449d7bb75 100644
--- a/compiler/utils/UnVarGraph.hs
+++ b/compiler/utils/UnVarGraph.hs
@@ -20,7 +20,7 @@ module UnVarGraph
     , emptyUnVarSet, sizeUnVarSet, mkUnVarSet, varEnvDom, restrictVarEnv_UnVarSet
     , unionUnVarSet, unionUnVarSets, delUnVarSet
     , elemUnVarSet, isEmptyUnVarSet
-    , UnVarGraph
+    , UnVarGraph, edgeCount
     , emptyUnVarGraph
     , unionUnVarGraph, unionUnVarGraphs
     , completeGraph, completeBipartiteGraph
@@ -47,8 +47,9 @@ import qualified Data.IntMap.Strict as IntMap
 -- Therefore, use a IntSet directly (which is likely also a bit more efficient).
 
 -- Set of uniques, i.e. for adjancet nodes
-newtype UnVarSet = UnVarSet IntSet
-    deriving Eq
+newtype UnVarSet 
+  = UnVarSet IntSet
+  deriving Eq
 
 k :: Var -> Int
 k v = getKey (getUnique v)
@@ -92,27 +93,40 @@ unionUnVarSets :: [UnVarSet] -> UnVarSet
 unionUnVarSets = foldr unionUnVarSet emptyUnVarSet
 
 instance Outputable UnVarSet where
-    ppr (UnVarSet s) = braces $
-        hcat $ punctuate comma [ ppr (getUnique i) | i <- IntSet.toList s]
+  ppr (UnVarSet s) = braces $
+    hcat $ punctuate comma [ ppr (getUnique i) | i <- IntSet.toList s]
 
 data OverlayResolution
-    = Additive
-    | Subtractive
-    deriving (Eq, Ord, Show)
+  = Additive
+  | Subtractive
+  deriving (Eq, Ord, Show)
 
 complementOverlayResolution :: OverlayResolution -> OverlayResolution
 complementOverlayResolution Additive = Subtractive
 complementOverlayResolution Subtractive = Additive
 
 data UnVarGraph 
-    = UnVarGraph
-    { edge_interpretation :: !OverlayResolution
-    , edge_count_estimate :: !(Int, Int)
-    , edges :: !(IntMap UnVarSet)
-    }
+  = UnVarGraph
+  { edge_interpretation :: !OverlayResolution
+  , edges :: !(IntMap UnVarSet)
+  , edge_count_estimate :: !(Int, Int)
+  , edge_count :: Int -- Intentionally lazy!
+  }
+
+edgeCount :: UnVarGraph -> Int
+edgeCount = edge_count
+
+mkUnVarGraph :: OverlayResolution -> IntMap UnVarSet -> (Int, Int) -> UnVarGraph
+mkUnVarGraph ei edges ec_estimate 
+  = UnVarGraph
+  { edge_interpretation = ei
+  , edges = edges
+  , edge_count_estimate = ec_estimate
+  , edge_count = foldr ((+) . sizeUnVarSet) 0 edges
+  }
 
 balance :: UnVarGraph -> UnVarGraph
-balance g@(UnVarGraph ei (_, ub) edges)
+balance g@(UnVarGraph ei edges (_, ub) ec)
   | ub_ratio < 0.6 = g
   | precise_ratio < 0.6 = precise_g
   | otherwise = complementUnVarGraph precise_g
@@ -121,18 +135,17 @@ balance g@(UnVarGraph ei (_, ub) edges)
     max_edges = nodes * nodes
     ub_ratio :: Double
     ub_ratio = fromIntegral ub / fromIntegral max_edges
-    edge_count = foldr ((+) . sizeUnVarSet) 0 edges
     precise_ratio :: Double
-    precise_ratio = fromIntegral edge_count / fromIntegral max_edges
-    precise_g = UnVarGraph ei (edge_count, edge_count) edges
+    precise_ratio = fromIntegral ec / fromIntegral max_edges
+    precise_g = UnVarGraph ei edges (ec, ec) ec
 
 complementUnVarGraph :: UnVarGraph -> UnVarGraph
-complementUnVarGraph (UnVarGraph res (lb, ub) edges) 
-  = UnVarGraph (complementOverlayResolution res) ec (complementEdges edges)
+complementUnVarGraph (UnVarGraph res edges (lb, ub) _) 
+  = mkUnVarGraph (complementOverlayResolution res) (complementEdges edges) ec_est
   where
     nodes = IntMap.size edges
     max_edges = nodes*nodes
-    ec = (max_edges - ub, max_edges - lb)
+    ec_est = (max_edges - ub, max_edges - lb)
 
 complementEdges :: IntMap UnVarSet -> IntMap UnVarSet
 complementEdges edges = edges'
@@ -147,15 +160,15 @@ complementEdges edges = edges'
       | otherwise = differenceUnVarSet dom neighbors
 
 emptyUnVarGraph :: UnVarGraph
-emptyUnVarGraph = UnVarGraph Subtractive (0, 0) IntMap.empty
+emptyUnVarGraph = mkUnVarGraph Subtractive IntMap.empty (0, 0)
 
 unionUnVarGraph :: UnVarGraph -> UnVarGraph -> UnVarGraph
-unionUnVarGraph u1@(UnVarGraph Subtractive _ _) u2
+unionUnVarGraph u1@(UnVarGraph Subtractive _ _ _) u2
   = unionUnVarGraph (complementUnVarGraph u1) u2
-unionUnVarGraph u1 u2@(UnVarGraph Subtractive _ _)
+unionUnVarGraph u1 u2@(UnVarGraph Subtractive _ _ _)
   = unionUnVarGraph u1 (complementUnVarGraph u2)
-unionUnVarGraph (UnVarGraph Additive (l1, u1) e1) (UnVarGraph Additive (l2, u2) e2)
-  = balance $ UnVarGraph Additive (max l1 l2, u1 + u2) e
+unionUnVarGraph (UnVarGraph Additive e1 (l1, u1) _) (UnVarGraph Additive e2 (l2, u2) _)
+  = balance $ mkUnVarGraph Additive e (max l1 l2, u1 + u2) 
   where
     e = IntMap.unionWith unionUnVarSet e1 e2
     
@@ -165,37 +178,40 @@ unionUnVarGraphs = foldr unionUnVarGraph emptyUnVarGraph
 -- completeBipartiteGraph A B = { {a,b} | a ∈ A, b ∈ B }
 completeBipartiteGraph :: UnVarSet -> UnVarSet -> UnVarGraph
 completeBipartiteGraph u1@(UnVarSet s1) u2@(UnVarSet s2) 
-    = balance (UnVarGraph Additive (2*a*b, 2*a*b) edges)
-    where
-      dom@(UnVarSet s) = unionUnVarSet u1 u2
-      (UnVarSet s3) = intersectionUnVarSet u1 u2 -- common elements
-      a = sizeUnVarSet u1
-      b = sizeUnVarSet u2
-      edges = IntMap.fromSet neighbors_of s
-      neighbors_of k
-        | k `IntSet.member` s3 = dom
-        | k `IntSet.member` s1 = u2
-        | k `IntSet.member` s2 = u1
+  = balance (UnVarGraph Additive edges (ec, ec) ec)
+  where
+    dom@(UnVarSet s) = unionUnVarSet u1 u2
+    (UnVarSet s3) = intersectionUnVarSet u1 u2 -- common elements
+    a = sizeUnVarSet u1
+    b = sizeUnVarSet u2
+    ec = 2*a*b
+    edges = IntMap.fromSet neighbors_of s
+    neighbors_of k
+      | k `IntSet.member` s3 = dom
+      | k `IntSet.member` s1 = u2
+      | k `IntSet.member` s2 = u1
         
 completeGraph :: UnVarSet -> UnVarGraph
-completeGraph (UnVarSet s) = UnVarGraph Subtractive (0, 0) (IntMap.fromSet (const emptyUnVarSet) s)
+completeGraph (UnVarSet s) 
+  = mkUnVarGraph Subtractive (IntMap.fromSet (const emptyUnVarSet) s) (0, 0)
 
 isCompleteGraph_maybe :: UnVarGraph -> Maybe UnVarSet
-isCompleteGraph_maybe (UnVarGraph Subtractive (0, 0) e) 
+isCompleteGraph_maybe (UnVarGraph Subtractive e (0, 0) _) 
   = Just (UnVarSet (IntMap.keysSet e))
 isCompleteGraph_maybe _ = Nothing
 
 neighbors :: UnVarGraph -> Var -> UnVarSet
-neighbors (UnVarGraph res _ edges) v 
+neighbors (UnVarGraph ie edges _ _) v 
   = fromMaybe emptyUnVarSet (interpret_edge <$> IntMap.lookup (k v) edges)
-  where dom = UnVarSet $ IntMap.keysSet edges
-        interpret_edge 
-          | res == Additive = id
-          | otherwise = differenceUnVarSet dom
+  where 
+    dom = UnVarSet $ IntMap.keysSet edges
+    interpret_edge 
+      | ie == Additive = id
+      | otherwise = differenceUnVarSet dom
 
 delNode :: UnVarGraph -> Var -> UnVarGraph
-delNode (UnVarGraph ei (lb, ub) g) v 
-  = UnVarGraph ei (lb', ub') g2 -- No rebalance here, since the graph gets smaller anyway
+delNode (UnVarGraph ei g (lb, ub) _) v 
+  = mkUnVarGraph ei g2 (lb', ub') -- No rebalance here, since the graph gets smaller anyway
   where 
     -- Note that we need to delete all mentioned edges, regardless of `ei`.
     (neighbors_maybe, g1) = IntMap.updateLookupWithKey (\_ _ -> Nothing) (k v) g
@@ -213,6 +229,6 @@ delNode (UnVarGraph ei (lb, ub) g) v
     ub' = ub - del_edge_count
 
 instance Outputable UnVarGraph where
-    ppr u@(UnVarGraph ei _ g) 
+    ppr u@(UnVarGraph ei g _ _) 
       | ei == Additive = ppr g
       | otherwise = ppr (complementUnVarGraph u)
-- 
2.12.1


From 429321c3a149136b8608280f90c1ba73c0896e11 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 30 May 2017 15:39:24 +0200
Subject: [PATCH 070/117] Change detection based on edgeCount. Has issues with
 annotated expressions

---
 compiler/simplCore/CallArity/Analysis.hs         | 194 ++++++++++-------------
 compiler/simplCore/CallArity/FrameworkBuilder.hs |  11 +-
 compiler/utils/UnVarGraph.hs                     |   6 +-
 3 files changed, 96 insertions(+), 115 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 23263f3946..7b7417fa9a 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -483,10 +483,11 @@ callArityExpr
   -> FrameworkBuilder (SingleUse -> TransferFunction AnalResult)
 
 callArityExprTrivial
-  :: CoreExpr
+  :: UsageType
+  -> CoreExpr
   -> FrameworkBuilder (SingleUse -> TransferFunction AnalResult)
-callArityExprTrivial e
-  = return (\_ -> return (emptyUsageType, e))
+callArityExprTrivial ut e
+  = return (const (return (ut, e)))
 
 callArityExprMap
   :: AnalEnv
@@ -501,12 +502,12 @@ callArityExprMap env f e
       return (ut, f e')
 
 callArityExpr _ e@(Lit _)
-  = callArityExprTrivial e
+  = callArityExprTrivial emptyUsageType e 
 callArityExpr _ e@(Type _)
-  = callArityExprTrivial e
+  = callArityExprTrivial emptyUsageType e
 
 callArityExpr _ e@(Coercion co)
-  = return (\_ -> return (coercionUsageType co, e))
+  = callArityExprTrivial (coercionUsageType co) e
 
 callArityExpr env (Tick t e)
   = callArityExprMap env (Tick t) e
@@ -622,76 +623,47 @@ callArityExpr env (Case scrut case_bndr ty alts) = do
     --pprTrace "Case" (vcat [text "ut_scrut:" <+> ppr ut_scrut, text "ut_alts:" <+> ppr ut_alts, text "ut:" <+> ppr ut]) (return ())
     return (ut, Case scrut' case_bndr' ty alts')
 
-callArityExpr env (Let bind e) = do
-  let initial_binds = flattenBinds [bind]
-  let ids = map fst initial_binds
-  (env', nodes) <- registerBindingGroup env initial_binds
-  let lookup_node id =
-        expectJust ": the RHS of id wasn't registered" (lookupVarEnv nodes id)
-  let transfer_rhs (id, rhs) use =
-        dependOnWithDefault (botUsageType, rhs) (lookup_node id, use)
-  let transferred_bind b@(id, rhs) = (id, (rhs, transfer_rhs b))
-  transfer_body <- callArityExpr env' e
-
-  case bind of
-    NonRec _ _ ->
-      -- We don't need to dependOn ourselves here, because only the let body can't
-      -- call id. Thus we also can spare to allocate a new @FrameworkNode@.
-      return $ \use -> do
-        (ut_body, e') <- transfer_body use
-        let transferred_binds = map transferred_bind initial_binds
-        (ut, [(id', rhs')]) <- unleashLet env NonRecursive transferred_binds ut_body ut_body
-        return (delUsageTypes (bindersOf bind) ut, Let (NonRec id' rhs') e')
-    Rec _ -> do -- The binding group stored in the @Rec@ constructor is always the initial one!
-      -- This is a little more complicated, as we'll introduce a new FrameworkNode
-      -- which we'll depend on ourselves.
-      node <- registerTransferFunction (LowerThan (minimum (eltsUFM nodes))) $ \node -> do
-        let transfer :: SingleUse -> TransferFunction AnalResult
-            transfer use = do
-              --use <- pprTrace "Rec:begin" (ppr ids) $ return use
-              (ut_body, e') <- transfer_body use
-              -- This is the actual fixed-point iteration: we depend on usage
-              -- results from the previous iteration, defaulting to just the body.
-              (ut_usage, Let (Rec old_bind) _) <- dependOnWithDefault (ut_body, Let bind e') (node, use)
-              let transferred_binds = map transferred_bind old_bind
-              (ut, bind') <- unleashLet env Recursive transferred_binds ut_usage ut_body
-              let ut' = lubUsageType ut ut_usage
-              let lookup_old = lookupUsage Recursive ut_usage
-              let lookup_new = lookupUsage Recursive ut'
-              let ut'' | all (\id -> lookup_old id == lookup_new id) ids = markStable ut'
-                       | otherwise = ut'
-              --ut'' <- pprTrace "Rec:end" (ppr ids) $ return ut''
-              return (ut'', Let (Rec bind') e')
-
-        let change_detector :: ChangeDetector
-            change_detector changed_refs (old, _) (new, _) =
-              -- since we only care for arity and called once information of the
-              -- previous iteration, we can efficiently test for changes.
-              --pprTrace "change_detector" (vcat[ppr ids, ppr node, ppr changed_refs]) $
-              --pprTrace "change_detector" (vcat[ppr node, ppr changed_refs, ppr old, ppr new]) $
-              ASSERT2( old_sig `leqUsageSig` new_sig, text "CallArity.change_detector: usage sig not monotone")
-              old_sig == new_sig &&
-              ASSERT2( sizeUFM old_uses <= sizeUFM new_uses, text "CallArity.change_detector: uses not monotone")
-              sizeUFM old_uses == sizeUFM new_uses &&
-              old_uses == new_uses &&
-              ASSERT2( edgeCount old_cocalled <= edgeCount new_cocalled, text "CallArity.change_detector: edgeCount not monotone")
-              edgeCount old_cocalled == edgeCount new_cocalled
-              where
-                old_sig = ut_args old
-                new_sig = ut_args new
-                old_uses = ut_uses old
-                new_uses = ut_uses new
-                old_cocalled = ut_cocalled old
-                new_cocalled = ut_cocalled new
-                leqUsageSig a b = lubUsageSig a b == b
-
-        return (node, (transfer, change_detector))
-
-      -- Now for the actual TransferFunction of this expr...
-      return $ \use -> do
-        (ut, let') <- dependOnWithDefault (botUsageType, Let bind e) (node, use)
-        --pprTrace "Let" (ppr (ut, let')) $ return ()
-        return (delUsageTypes (bindersOf bind) ut, let')
+callArityExpr env (Let bind e) 
+  = registerTransferFunction HighestAvailable register >>= reference
+  where
+    reference node = return $ \use -> do
+      (ut, let') <- dependOnWithDefault (botUsageType, Let bind e) (node, use)
+      --pprTrace "Let" (ppr (ut, let')) $ return ()
+      return (delUsageTypes (bindersOf bind) ut, let')
+    register node = do
+      let initial_binds = flattenBinds [bind]
+      let ids = map fst initial_binds
+      env' <- registerBindingGroup env initial_binds
+      let lookup_node id =
+            expectJust ": the RHS of id wasn't registered" (lookupVarEnv (ae_sigs env') id)
+      let transfer_rhs (id, rhs) use =
+            dependOnWithDefault (botUsageType, rhs) (lookup_node id, use)
+      let transferred_bind b@(id, rhs) = (id, (rhs, transfer_rhs b))
+      transfer_body <- callArityExpr env' e
+      let rec_flag = recFlagOf bind
+      let transfer :: SingleUse -> TransferFunction AnalResult
+          transfer = monotonize node $ \use -> do
+            --use <- pprTrace "Rec:begin" (ppr ids) $ return use
+            (ut_body, e') <- transfer_body use
+            (ut_usage, old_binds) <- case rec_flag of
+              NonRecursive -> 
+                -- We don't need to dependOn ourselves here, because only the let body can't
+                -- call id.
+                return (ut_body, initial_binds)
+              Recursive -> do
+                -- This is the actual fixed-point iteration: we depend on usage
+                -- results from the previous iteration, defaulting to just the body.
+                (ut_usage, Let (Rec old_binds) _) <- dependOnWithDefault (ut_body, Let bind e) (node, use)
+                return (ut_usage, old_binds)
+            let transferred_binds = map transferred_bind old_binds
+            (ut, binds') <- unleashLet env rec_flag transferred_binds ut_usage ut_body
+            --ut <- pprTrace "Rec:end" (ppr ids) $ return ut
+            case rec_flag of
+              NonRecursive 
+                | [(id', rhs')] <- binds'
+                -> return (ut, Let (NonRec id' rhs') e')
+              _ -> return (ut, Let (Rec binds') e')
+      return (node, (transfer, changeDetector))
 
 coercionUsageType :: Coercion -> UsageType
 coercionUsageType co = multiplyUsages Many ut
@@ -882,47 +854,43 @@ addDataConStrictness dc
       | isMarkedStrict str = usage `bothUsage` u'1HU -- head usage imposed by `seq`
       | otherwise = usage
 
+recFlagOf :: CoreBind -> RecFlag
+recFlagOf Rec{} = Recursive
+recFlagOf NonRec{} = NonRecursive
+
 registerBindingGroup
   :: AnalEnv
   -> [(Id, CoreExpr)]
-  -> FrameworkBuilder (AnalEnv, VarEnv FrameworkNode)
-registerBindingGroup env = go env emptyVarEnv
+  -> FrameworkBuilder AnalEnv
+registerBindingGroup env [] = return env
+registerBindingGroup env ((id, rhs):binds) =
+  registerTransferFunction HighestAvailable $ \node -> do
+    env' <- registerBindingGroup (extendAnalEnv env id node) binds
+    transfer <- callArityExpr env' rhs
+    let transfer' = monotonize node $ \use -> do
+          --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
+          ret@(ut_rhs, rhs') <- transfer use 
+          --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut_rhs)]) $ return ret
+          return ret
+    return (env', (transfer', changeDetector)) -- registerTransferFunction  will peel `snd`s away for registration
+
+changeDetector :: ChangeDetector
+changeDetector _ (old, e) (new, e') =
+  ASSERT2( old_sig `leqUsageSig` new_sig, text "CallArity.changeDetector: usage sig not monotone")
+  pprTrace "usage sig" empty (old_sig /= new_sig) ||
+  ASSERT2( sizeUFM old_uses <= sizeUFM new_uses, text "CallArity.changeDetector: uses not monotone")
+  pprTrace "uses count" empty (sizeUFM old_uses /= sizeUFM new_uses) ||
+  pprTrace "uses" empty (old_uses /= new_uses) ||
+  ASSERT2( edgeCount old_cocalled <= edgeCount new_cocalled, text "CallArity.changeDetector: edgeCount not monotone")
+  pprTrace "edgeCount" (ppr (edgeCount old_cocalled) <+> ppr (edgeCount new_cocalled)) (edgeCount old_cocalled /= edgeCount new_cocalled)
   where
-    go env nodes [] = return (env, nodes)
-    go env nodes ((id, rhs):binds) =
-      registerTransferFunction HighestAvailable $ \node ->
-        registerTransferFunction HighestAvailable $ \args_node -> do
-          (env', nodes') <- go
-            (extendAnalEnv env id args_node)
-            (extendVarEnv nodes id node)
-            binds
-          transfer <- callArityExpr env' rhs
-          let transfer' use = do
-                --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
-                (prev_ut_rhs, _) <- fromMaybe (botUsageType, rhs) <$> unsafePeekValue (node, use)
-                (ut_rhs, rhs') <- transfer use 
-                let ret = (lubUsageType ut_rhs prev_ut_rhs, rhs')
-                --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut_rhs)]) $ return ret
-                return ret
-          let transfer_args use = do
-                --use <- pprTrace "args:begin" (ppr id <+> text "::" <+> ppr use) $ return use
-                ret@(ut, _) <- dependOnWithDefault (botUsageType, rhs) (node, use)
-                --ret <- pprTrace "args:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut)]) $ return ret
-                return ret
-          let change_detector_args nodes (old, _) (new, _) =
-                -- The only reason we split the transfer fuctions up is cheap
-                -- change detection for the arg usage case. This implies that
-                -- use sites of these sig nodes may only use the ut_args
-                -- component!
-                --pprTrace "change_detector_down" (vcat [ppr node, ppr id, ppr (ut_args old <= ut_args new), ppr (ut_args old), ppr (ut_args new), ppr (ut_args old /= ut_args new)]) $
-                ASSERT2( ut_args old <= ut_args new, text "CallArity.change_detector_down: Not monotone" $$ ppr id $$ ppr (ut_args old) $$ ppr (ut_args new) )
-                ut_args old /= ut_args new
-                  where
-                    a <= b = lubUsageSig a b == b
-          let ret = (env', nodes') -- What we return from 'registerBindingGroup'
-          let full = (transfer', alwaysChangeDetector) -- What we register for @node@
-          let args = (transfer_args, change_detector_args) -- What we register for @arg_node@
-          return ((ret, full), args) -- registerTransferFunction  will peel `snd`s away for registration
+    old_sig = ut_args old
+    new_sig = ut_args new
+    old_uses = ut_uses old
+    new_uses = ut_uses new
+    old_cocalled = ut_cocalled old
+    new_cocalled = ut_cocalled new
+    leqUsageSig a b = lubUsageSig a b == b
 
 unleashLet
   :: AnalEnv 
diff --git a/compiler/simplCore/CallArity/FrameworkBuilder.hs b/compiler/simplCore/CallArity/FrameworkBuilder.hs
index 17f55b61da..c248e35b90 100644
--- a/compiler/simplCore/CallArity/FrameworkBuilder.hs
+++ b/compiler/simplCore/CallArity/FrameworkBuilder.hs
@@ -9,8 +9,8 @@ module CallArity.FrameworkBuilder
   , FrameworkBuilder
   , RequestedPriority (..)
   , registerTransferFunction
+  , monotonize
   , dependOnWithDefault
-  , Worklist.unsafePeekValue
   , buildAndRun
   ) where
 
@@ -75,6 +75,15 @@ registerTransferFunction prio f = FB $ do
     unFB (f (FrameworkNode node))
   return result
 
+monotonize
+  :: FrameworkNode
+  -> (SingleUse -> TransferFunction AnalResult)
+  -> SingleUse -> TransferFunction AnalResult
+monotonize node transfer use = do
+  (ut_new, e') <- transfer use 
+  (ut_old, _) <- fromMaybe (botUsageType, undefined) <$> Worklist.unsafePeekValue (node, use)
+  return (lubUsageType ut_new ut_old, e')
+
 dependOnWithDefault :: AnalResult -> (FrameworkNode, SingleUse) -> TransferFunction AnalResult
 dependOnWithDefault def which = do
   --which <- pprTrace "dependOnWithDefault:before" (ppr which) (return which)
diff --git a/compiler/utils/UnVarGraph.hs b/compiler/utils/UnVarGraph.hs
index 4449d7bb75..a7b31132b0 100644
--- a/compiler/utils/UnVarGraph.hs
+++ b/compiler/utils/UnVarGraph.hs
@@ -114,7 +114,11 @@ data UnVarGraph
   }
 
 edgeCount :: UnVarGraph -> Int
-edgeCount = edge_count
+edgeCount g 
+  | Additive <- edge_interpretation g = edge_count g
+  | otherwise = nodes*nodes - edge_count g
+  where
+    nodes = IntMap.size (edges g)
 
 mkUnVarGraph :: OverlayResolution -> IntMap UnVarSet -> (Int, Int) -> UnVarGraph
 mkUnVarGraph ei edges ec_estimate 
-- 
2.12.1


From e1ffbaefaef90d2ce24b34b10e3bf8ac6d93b2f7 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 30 May 2017 18:27:00 +0200
Subject: [PATCH 071/117] The new change detection seems to work now

---
 compiler/simplCore/CallArity/Analysis.hs         | 93 ++++++++++++++++--------
 compiler/simplCore/CallArity/FrameworkBuilder.hs | 25 ++-----
 2 files changed, 70 insertions(+), 48 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 7b7417fa9a..bae6869a5a 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -45,6 +45,12 @@ import qualified Data.Set as Set
 %*                                                                      *
 %************************************************************************
 
+Note [Notes are out of date]
+~~~~~~~~~~~~~~~~~~~~~~~~~~~
+
+While the general concept of the Co-Call Analysis still holds, much has
+changed at isn't yet on par with the implementation.
+
 Note [Call Arity: The goal]
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
@@ -408,8 +414,8 @@ data AnalEnv
   --
   --     - `Opt_DmdTxDictSel`: Control analysis of dictionary selectors.
   --
-  , ae_sigs :: VarEnv FrameworkNode
-  -- ^ 'FrameworkNode's of visible local let-bound identifiers. It is crucial
+  , ae_sigs :: VarEnv (SingleUse -> TransferFunction UsageType)
+  -- ^ 'TransferFunction's of visible local let-bound identifiers. It is crucial
   -- that only the 'UsageSig' component is used, as the usage on free vars might
   -- be unstable and thus too optimistic.
   , ae_fam_envs :: FamInstEnvs
@@ -429,8 +435,13 @@ initialAnalEnv dflags fam_envs need_sigs
   , ae_need_sig_annotation = need_sigs
   }
 
-extendAnalEnv :: AnalEnv -> Id -> FrameworkNode -> AnalEnv
-extendAnalEnv env id node = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
+extendAnalEnv 
+  :: AnalEnv 
+  -> Id 
+  -> (SingleUse -> TransferFunction UsageType) 
+  -> AnalEnv
+extendAnalEnv env id node 
+  = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
 
 -- | See Note [Analysing top-level-binds]
 -- `moduleToExpr` returns a pair of externally visible top-level `Id`s
@@ -524,10 +535,10 @@ callArityExpr env (Cast e co)
 callArityExpr env e@(Var id) = return transfer
   where
     transfer use
-      | Just node <- lookupVarEnv (ae_sigs env) id
+      | Just transfer_callee <- lookupVarEnv (ae_sigs env) id
       -- A local let-binding, e.g. a binding from this module.
       = do
-        (ut_callee, _) <- dependOnWithDefault (botUsageType, e) (node, use)
+        ut_callee <- transfer_callee use
         -- It is crucial that we only use ut_args here, as every other field
         -- might be unstable and thus too optimistic.
         --pprTrace "callArityExpr:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
@@ -624,21 +635,22 @@ callArityExpr env (Case scrut case_bndr ty alts) = do
     return (ut, Case scrut' case_bndr' ty alts')
 
 callArityExpr env (Let bind e) 
-  = registerTransferFunction HighestAvailable register >>= reference
+  = registerTransferFunction register >>= deref_node
   where
-    reference node = return $ \use -> do
+    deref_node node = return $ \use -> do
       (ut, let') <- dependOnWithDefault (botUsageType, Let bind e) (node, use)
       --pprTrace "Let" (ppr (ut, let')) $ return ()
       return (delUsageTypes (bindersOf bind) ut, let')
     register node = do
       let initial_binds = flattenBinds [bind]
       let ids = map fst initial_binds
-      env' <- registerBindingGroup env initial_binds
+      (env', rhs_env) <- registerBindingGroup env initial_binds
       let lookup_node id =
-            expectJust ": the RHS of id wasn't registered" (lookupVarEnv (ae_sigs env') id)
-      let transfer_rhs (id, rhs) use =
-            dependOnWithDefault (botUsageType, rhs) (lookup_node id, use)
-      let transferred_bind b@(id, rhs) = (id, (rhs, transfer_rhs b))
+            expectJust ": the RHS of id wasn't registered" (lookupVarEnv rhs_env id)
+      let transferred_bind b@(id, rhs) = (id, (rhs, lookup_node id))
+      -- Ideally we'd want the body to have a lower priority than the RHSs,
+      -- but we need to access env' with the new sigs in the body, so we
+      -- can't register it earlier.
       transfer_body <- callArityExpr env' e
       let rec_flag = recFlagOf bind
       let transfer :: SingleUse -> TransferFunction AnalResult
@@ -663,7 +675,7 @@ callArityExpr env (Let bind e)
                 | [(id', rhs')] <- binds'
                 -> return (ut, Let (NonRec id' rhs') e')
               _ -> return (ut, Let (Rec binds') e')
-      return (node, (transfer, changeDetector))
+      return (node, (transfer, changeDetectorAnalResult node))
 
 coercionUsageType :: Coercion -> UsageType
 coercionUsageType co = multiplyUsages Many ut
@@ -861,21 +873,38 @@ recFlagOf NonRec{} = NonRecursive
 registerBindingGroup
   :: AnalEnv
   -> [(Id, CoreExpr)]
-  -> FrameworkBuilder AnalEnv
-registerBindingGroup env [] = return env
-registerBindingGroup env ((id, rhs):binds) =
-  registerTransferFunction HighestAvailable $ \node -> do
-    env' <- registerBindingGroup (extendAnalEnv env id node) binds
-    transfer <- callArityExpr env' rhs
-    let transfer' = monotonize node $ \use -> do
-          --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
-          ret@(ut_rhs, rhs') <- transfer use 
-          --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut_rhs)]) $ return ret
-          return ret
-    return (env', (transfer', changeDetector)) -- registerTransferFunction  will peel `snd`s away for registration
-
-changeDetector :: ChangeDetector
-changeDetector _ (old, e) (new, e') =
+  -> FrameworkBuilder (AnalEnv, VarEnv (SingleUse -> TransferFunction AnalResult))
+registerBindingGroup env = go env emptyVarEnv
+  where
+    go env nodes [] = return (env, nodes)
+    go env nodes ((id, rhs):binds) =
+      registerTransferFunction $ \node ->
+        registerTransferFunction $ \args_node -> do
+          let deref_node node def_e use = dependOnWithDefault (botUsageType, def_e) (node, use)
+          let expr_forced_error = error "Expression component may not be used"
+          (env', nodes') <- go
+            (extendAnalEnv env id (fmap fst . deref_node args_node expr_forced_error))
+            (extendVarEnv nodes id (deref_node node rhs))
+            binds
+          transfer <- callArityExpr env' rhs
+          let transfer' = monotonize node $ \use -> do
+                --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
+                ret@(ut, rhs') <- transfer use 
+                --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut_rhs)]) $ return ret
+                return ret
+          let transfer_args use = do
+                --use <- pprTrace "args:begin" (ppr id <+> text "::" <+> ppr use) $ return use
+                (ut, _) <- dependOnWithDefault (botUsageType, undefined) (node, use)
+                --ut <- pprTrace "args:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut)]) $ return ut
+                return (ut, expr_forced_error)
+          let ret = (env', nodes') -- What we return from 'registerBindingGroup'
+          let full = (transfer', changeDetectorAnalResult node) -- What we register for @node@
+          let args = (transfer_args, changeDetectorUsageType) -- What we register for @arg_node@
+          return ((ret, full), args) -- registerTransferFunction  will peel `snd`s away for registration
+
+changeDetectorUsageType :: ChangeDetector
+changeDetectorUsageType changed_refs (old, _) (new, _) =
+  -- It's crucial that we don't have to check the annotated expressions.
   ASSERT2( old_sig `leqUsageSig` new_sig, text "CallArity.changeDetector: usage sig not monotone")
   pprTrace "usage sig" empty (old_sig /= new_sig) ||
   ASSERT2( sizeUFM old_uses <= sizeUFM new_uses, text "CallArity.changeDetector: uses not monotone")
@@ -892,6 +921,12 @@ changeDetector _ (old, e) (new, e') =
     new_cocalled = ut_cocalled new
     leqUsageSig a b = lubUsageSig a b == b
 
+changeDetectorAnalResult :: FrameworkNode -> ChangeDetector
+changeDetectorAnalResult self_node changed_refs (old, e) (new, e') =
+  pprTrace "changeDetector" (ppr $ Set.map fst changed_refs) $
+  not (Set.map fst changed_refs `Set.isSubsetOf` Set.singleton self_node) || 
+  changeDetectorUsageType changed_refs (old, e) (new, e')
+
 unleashLet
   :: AnalEnv 
   -> RecFlag
diff --git a/compiler/simplCore/CallArity/FrameworkBuilder.hs b/compiler/simplCore/CallArity/FrameworkBuilder.hs
index c248e35b90..33c5731661 100644
--- a/compiler/simplCore/CallArity/FrameworkBuilder.hs
+++ b/compiler/simplCore/CallArity/FrameworkBuilder.hs
@@ -7,7 +7,6 @@ module CallArity.FrameworkBuilder
   , Worklist.alwaysChangeDetector
   , DataFlowFramework
   , FrameworkBuilder
-  , RequestedPriority (..)
   , registerTransferFunction
   , monotonize
   , dependOnWithDefault
@@ -50,23 +49,12 @@ buildFramework (FB state) = (res, Worklist.DFF dff)
       Nothing -> pprPanic "CallArity.FrameworkBuilder.buildFramework" (ppr node)
       Just (transfer, detectChange) -> (transfer use, detectChange)
 
-data RequestedPriority
-  = LowerThan !FrameworkNode
-  | HighestAvailable
-
 registerTransferFunction
-  :: RequestedPriority
-  -> (FrameworkNode -> FrameworkBuilder (a, (SingleUse -> TransferFunction AnalResult, ChangeDetector)))
+  :: (FrameworkNode -> FrameworkBuilder (a, (SingleUse -> TransferFunction AnalResult, ChangeDetector)))
   -> FrameworkBuilder a
-registerTransferFunction prio f = FB $ do
+registerTransferFunction f = FB $ do
   nodes <- get
-  let node = case prio of
-        HighestAvailable -> 2 * IntMap.size nodes
-        LowerThan (FrameworkNode node)
-          | not (IntMap.member (node - 1) nodes) -> node - 1
-          | otherwise -> pprPanic
-            "CallArity.FrameworkBuilder.registerTransferFunction"
-            (text "There was already a node registered with priority" <+> ppr (node - 1))
+  let node = IntMap.size nodes
   (result, _) <- mfix $ \ ~(_, entry) -> do
     -- Using mfix so that we can spare an unnecessary Int counter in the state.
     -- Also because @f@ needs to see its own node in order to define its
@@ -94,10 +82,9 @@ dependOnWithDefault def which = do
 buildAndRun :: FrameworkBuilder (SingleUse -> TransferFunction AnalResult) -> SingleUse -> AnalResult
 buildAndRun buildTransfer use = lookup_result (Worklist.runFramework fw (Set.singleton (node, use)))
   where
-    (node, fw) = buildFramework $
-      registerTransferFunction (LowerThan (FrameworkNode 0)) $ \node -> do
-        transfer <- buildTransfer
-        return (node, (transfer, Worklist.alwaysChangeDetector))
+    (node, fw) = buildFramework $ registerTransferFunction $ \node -> do
+      transfer <- buildTransfer
+      return (node, (transfer, Worklist.alwaysChangeDetector))
 
     lookup_result :: Map (FrameworkNode, SingleUse) AnalResult -> AnalResult
     lookup_result result_map = case Map.lookup (node, use) result_map of
-- 
2.12.1


From 6710fa65b2ee2410f178e9866e910e2a4312050a Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Wed, 31 May 2017 21:48:28 +0200
Subject: [PATCH 072/117] Using all top-level bindings now. Also an attempt at
 better worklist priorities

---
 compiler/simplCore/CallArity/Analysis.hs         | 38 ++++++++++++--------
 compiler/simplCore/CallArity/FrameworkBuilder.hs | 45 +++++++++++++++++++-----
 2 files changed, 60 insertions(+), 23 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index bae6869a5a..1a828d7d08 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -444,7 +444,7 @@ extendAnalEnv env id node
   = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
 
 -- | See Note [Analysing top-level-binds]
--- `moduleToExpr` returns a pair of externally visible top-level `Id`s
+-- `programToExpr` returns a pair of externally visible top-level `Id`s
 -- (including at least exports and mentions in RULEs) and a nested
 -- `let` expression to be analysed by `callArityRHS`.
 --
@@ -452,13 +452,15 @@ extendAnalEnv env id node
 -- nested lets, where the external visible ids are returned in the inner-most let
 -- as a tuple. As a result, all exported identifiers are handled as called
 -- with each other, with `topUsage`.
-moduleToExpr :: CoreProgram -> (VarSet, CoreExpr)
-moduleToExpr = first (\it -> pprTrace "moduleToExpr" (ppr (sizeVarSet it)) it) . impl []
+programToExpr 
+  :: CoreProgram 
+  -> (VarSet, CoreExpr)
+programToExpr = first (\it -> pprTrace "programToExpr" (ppr (sizeVarSet it)) it) . impl []
   where
     impl exposed []
       = (mkVarSet exposed, mkBigCoreVarTup exposed)
     impl exposed (bind:prog)
-      = second (Let bind) (impl (exposed_ids' bind ++ exposed) prog)
+      = second (Let bind) (impl (exposed_ids bind ++ exposed) prog)
     -- We are too conservative here, but we need *at least*  
     -- 
     --   * exported `Id`s (`isExportedId`)
@@ -468,17 +470,25 @@ moduleToExpr = first (\it -> pprTrace "moduleToExpr" (ppr (sizeVarSet it)) it) .
     -- with any of the binders, so we just blindly assume all top-level
     -- `Id`s as exported (as does the demand analyzer).
     exposed_ids bind = bindersOf bind
-    exposed_ids' bind = filter isExportedId (bindersOf bind)
 
--- | The left inverse to `moduleToExpr`: `exprToModule . snd . moduleToExpr = id \@CoreProgram`
-exprToModule :: CoreExpr -> CoreProgram
-exprToModule (Let bind e) = bind : exprToModule e
-exprToModule _ = []
+-- | The left inverse to `programToExpr`: `exprToProgram . snd . programToExpr = id \@CoreProgram`
+exprToProgram :: CoreExpr -> CoreProgram
+exprToProgram (Let bind e) = bind : exprToProgram e
+exprToProgram _ = []
 
 -- Main entry point
-callArityAnalProgram :: DynFlags -> FamInstEnvs -> CoreProgram -> IO CoreProgram
+callArityAnalProgram 
+  :: DynFlags 
+  -> FamInstEnvs 
+  -> CoreProgram 
+  -> IO CoreProgram
 callArityAnalProgram dflags fam_envs
-  = return . (\it -> pprTrace "callArity:end" (ppr (length it)) it) . exprToModule . uncurry (callArityRHS dflags fam_envs) . moduleToExpr . (\it -> pprTrace "callArity:begin" (ppr (length it)) it)
+  = return 
+  . (\it -> pprTrace "callArity:end" (ppr (length it)) it) 
+  . exprToProgram 
+  . uncurry (callArityRHS dflags fam_envs) 
+  . programToExpr 
+  . (\it -> pprTrace "callArity:begin" (ppr (length it)) it)
   -- . (\prog -> pprTrace "CallArity:Program" (ppr prog) prog)
 
 callArityRHS :: DynFlags -> FamInstEnvs -> VarSet -> CoreExpr -> CoreExpr
@@ -635,7 +645,7 @@ callArityExpr env (Case scrut case_bndr ty alts) = do
     return (ut, Case scrut' case_bndr' ty alts')
 
 callArityExpr env (Let bind e) 
-  = registerTransferFunction register >>= deref_node
+  = registerTransferFunction LowestPriority register >>= deref_node
   where
     deref_node node = return $ \use -> do
       (ut, let') <- dependOnWithDefault (botUsageType, Let bind e) (node, use)
@@ -878,8 +888,8 @@ registerBindingGroup env = go env emptyVarEnv
   where
     go env nodes [] = return (env, nodes)
     go env nodes ((id, rhs):binds) =
-      registerTransferFunction $ \node ->
-        registerTransferFunction $ \args_node -> do
+      registerTransferFunction HighestPriority $ \node ->
+        registerTransferFunction HighestPriority $ \args_node -> do
           let deref_node node def_e use = dependOnWithDefault (botUsageType, def_e) (node, use)
           let expr_forced_error = error "Expression component may not be used"
           (env', nodes') <- go
diff --git a/compiler/simplCore/CallArity/FrameworkBuilder.hs b/compiler/simplCore/CallArity/FrameworkBuilder.hs
index 33c5731661..9f9390949b 100644
--- a/compiler/simplCore/CallArity/FrameworkBuilder.hs
+++ b/compiler/simplCore/CallArity/FrameworkBuilder.hs
@@ -7,6 +7,7 @@ module CallArity.FrameworkBuilder
   , Worklist.alwaysChangeDetector
   , DataFlowFramework
   , FrameworkBuilder
+  , RequestedPriority (..)
   , registerTransferFunction
   , monotonize
   , dependOnWithDefault
@@ -37,29 +38,55 @@ type DataFlowFramework = Worklist.DataFlowFramework (FrameworkNode, SingleUse) A
 -- | Maps @FrameworkNode@ to incoming usage dependent @TransferFunction@s
 type NodeTransferEnv = IntMap (SingleUse -> TransferFunction AnalResult, ChangeDetector)
 
+data BuilderState
+  = BS 
+  { bs_env :: !NodeTransferEnv
+  , bs_lowest :: !Int 
+  , bs_highest :: !Int
+  }
+
+initialBuilderState :: BuilderState
+initialBuilderState = BS IntMap.empty 0 maxBound
+
+modifyNodes :: (NodeTransferEnv -> NodeTransferEnv) -> BuilderState -> BuilderState
+modifyNodes f bs = bs { bs_env = f (bs_env bs) }
+
 newtype FrameworkBuilder a
-  = FB { unFB :: State NodeTransferEnv a }
+  = FB { unFB :: State BuilderState a }
   deriving (Functor, Applicative, Monad)
 
 buildFramework :: FrameworkBuilder a -> (a, DataFlowFramework)
 buildFramework (FB state) = (res, Worklist.DFF dff)
   where
-    (res, env) = runState state IntMap.empty -- NodeTransferEnv
-    dff (FrameworkNode node, use) = case IntMap.lookup node env of
+    (res, bs) = runState state initialBuilderState
+    dff (FrameworkNode node, use) = case IntMap.lookup node (bs_env bs) of
       Nothing -> pprPanic "CallArity.FrameworkBuilder.buildFramework" (ppr node)
       Just (transfer, detectChange) -> (transfer use, detectChange)
 
+data RequestedPriority
+  = HighestPriority
+  | LowestPriority
+
+popNodeWithRequestedPriority :: RequestedPriority -> State BuilderState Int
+popNodeWithRequestedPriority prio = state impl
+  where
+    impl bs 
+      | HighestPriority <- prio
+      = (bs_highest bs, bs { bs_highest = bs_highest bs - 1 })
+      | otherwise
+      = (bs_lowest bs, bs { bs_lowest = bs_lowest bs + 1 }) 
+
 registerTransferFunction
-  :: (FrameworkNode -> FrameworkBuilder (a, (SingleUse -> TransferFunction AnalResult, ChangeDetector)))
+  :: RequestedPriority
+  -> (FrameworkNode -> FrameworkBuilder (a, (SingleUse -> TransferFunction AnalResult, ChangeDetector)))
   -> FrameworkBuilder a
-registerTransferFunction f = FB $ do
-  nodes <- get
-  let node = IntMap.size nodes
+registerTransferFunction prio f = FB $ do
+  node <- popNodeWithRequestedPriority prio
   (result, _) <- mfix $ \ ~(_, entry) -> do
     -- Using mfix so that we can spare an unnecessary Int counter in the state.
     -- Also because @f@ needs to see its own node in order to define its
     -- transfer function in case of letrec.
-    modify' (IntMap.insert node entry)
+    modify' (modifyNodes (IntMap.insert node entry))
     unFB (f (FrameworkNode node))
   return result
 
@@ -82,7 +109,7 @@ dependOnWithDefault def which = do
 buildAndRun :: FrameworkBuilder (SingleUse -> TransferFunction AnalResult) -> SingleUse -> AnalResult
 buildAndRun buildTransfer use = lookup_result (Worklist.runFramework fw (Set.singleton (node, use)))
   where
-    (node, fw) = buildFramework $ registerTransferFunction $ \node -> do
+    (node, fw) = buildFramework $ registerTransferFunction LowestPriority $ \node -> do
       transfer <- buildTransfer
       return (node, (transfer, Worklist.alwaysChangeDetector))
 
-- 
2.12.1


From afdbf8c28365452add888d87137ee7c2ab3f61dc Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 1 Jun 2017 16:27:15 +0200
Subject: [PATCH 073/117] Change in iteration order and more efficient
 unionUnVarGraph gave significant speed boost

---
 compiler/simplCore/CallArity/Analysis.hs         |  56 +++++++----
 compiler/simplCore/CallArity/FrameworkBuilder.hs | 119 +++++++++++++++++------
 compiler/utils/UnVarGraph.hs                     |  32 ++++--
 3 files changed, 155 insertions(+), 52 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 1a828d7d08..a15689c156 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -36,6 +36,7 @@ import WwLib ( findTypeShape )
 import Control.Arrow ( first, second )
 import Control.Monad ( forM )
 import qualified Data.Set as Set
+import Data.Tree
 
 
 {-
@@ -424,17 +425,31 @@ data AnalEnv
   -- ^ `Id`s which need to be annotated with a signature, e.g. because
   -- they are visible beyond this module. These are probably top-level
   -- ids only, including exports and mentions in RULEs.
+  , ae_predicted_nodes :: Tree Int
+  -- ^ A prediction of how many `FrameworkNode`s need to be allocated for
+  -- the expression to be analyzed. We need these for allocating
+  -- `FrameworkNode`s in a particular order that guarantees fast
+  -- stabilization.
   }
 
-initialAnalEnv :: DynFlags -> FamInstEnvs -> VarSet -> AnalEnv
-initialAnalEnv dflags fam_envs need_sigs
+initialAnalEnv :: DynFlags -> FamInstEnvs -> VarSet -> Tree Int -> AnalEnv
+initialAnalEnv dflags fam_envs need_sigs predicted_nodes
   = AE
   { ae_dflags = dflags
   , ae_sigs = emptyVarEnv
   , ae_fam_envs = fam_envs
   , ae_need_sig_annotation = need_sigs
+  , ae_predicted_nodes = predicted_nodes
   }
 
+descend :: Int -> AnalEnv -> AnalEnv
+descend n env 
+  = env { ae_predicted_nodes = subForest (ae_predicted_nodes env) !! n }
+
+predictSizeOfLetBody :: AnalEnv -> Int
+-- The body is always the first child
+predictSizeOfLetBody = rootLabel . ae_predicted_nodes . descend 0 
+
 extendAnalEnv 
   :: AnalEnv 
   -> Id 
@@ -495,7 +510,8 @@ callArityRHS :: DynFlags -> FamInstEnvs -> VarSet -> CoreExpr -> CoreExpr
 callArityRHS dflags fam_envs need_sigs e
   = ASSERT2( isEmptyUnVarSet (domType ut), text "Free vars in UsageType:" $$ ppr ut ) e'
   where
-    (ut, e') = buildAndRun (callArityExpr (initialAnalEnv dflags fam_envs need_sigs) e) topSingleUse
+    env = initialAnalEnv dflags fam_envs need_sigs (predictAllocatedNodes e)
+    (ut, e') = buildAndRun (callArityExpr env e) topSingleUse
 
 -- | The main analysis function. See Note [Analysis type signature]
 callArityExpr
@@ -606,11 +622,11 @@ callArityExpr env (Lam id body)
           --pprTrace "callArityExpr:Lam" (vcat [text "id:" <+> ppr id, text "relative body usage:" <+> ppr u, text "id usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
           return (ut, Lam id' body')
 
-callArityExpr env (App f (Type t)) = callArityExprMap env (flip App (Type t)) f
-
+callArityExpr env (App f (Type t)) 
+  = callArityExprMap (descend 0 env) (flip App (Type t)) f
 callArityExpr env (App f a) = do
-  transfer_f <- callArityExpr env f
-  transfer_a <- callArityExpr env a
+  transfer_f <- callArityExpr (descend 0 env) f
+  transfer_a <- callArityExpr (descend 1 env) a
   return $ \result_use -> do
     (ut_f, f') <- transfer_f (mkCallUse Once result_use)
     --pprTrace "App:f'" (ppr f') $ return ()
@@ -631,8 +647,10 @@ callArityExpr env (App f a) = do
           return (ut_f' `bothUsageType` ut_a, App f' a')
 
 callArityExpr env (Case scrut case_bndr ty alts) = do
-  transfer_scrut <- callArityExpr env scrut
-  transfer_alts <- mapM (analyseCaseAlternative env case_bndr) alts
+  transfer_scrut <- callArityExpr (descend 0 env) scrut
+  -- We zip the index of the child in the ae_predicted_nodes tree
+  transfer_alts <- forM (zip [1..] alts) $ \(n, alt) -> 
+    analyseCaseAlternative (descend n env) case_bndr alt
   return $ \use -> do
     (ut_alts, alts', scrut_uses) <- unzip3 <$> mapM ($ use) transfer_alts
     let ut_alt = lubUsageTypes ut_alts
@@ -645,7 +663,7 @@ callArityExpr env (Case scrut case_bndr ty alts) = do
     return (ut, Case scrut' case_bndr' ty alts')
 
 callArityExpr env (Let bind e) 
-  = registerTransferFunction LowestPriority register >>= deref_node
+  = registerTransferFunction register >>= deref_node
   where
     deref_node node = return $ \use -> do
       (ut, let') <- dependOnWithDefault (botUsageType, Let bind e) (node, use)
@@ -654,14 +672,18 @@ callArityExpr env (Let bind e)
     register node = do
       let initial_binds = flattenBinds [bind]
       let ids = map fst initial_binds
+      -- We retain nodes we need for the body, so that they have lower
+      -- priority than the bindings.
+      retained <- retainNodes (predictSizeOfLetBody env)
       (env', rhs_env) <- registerBindingGroup env initial_binds
+      freeRetainedNodes retained
       let lookup_node id =
             expectJust ": the RHS of id wasn't registered" (lookupVarEnv rhs_env id)
       let transferred_bind b@(id, rhs) = (id, (rhs, lookup_node id))
       -- Ideally we'd want the body to have a lower priority than the RHSs,
       -- but we need to access env' with the new sigs in the body, so we
       -- can't register it earlier.
-      transfer_body <- callArityExpr env' e
+      transfer_body <- callArityExpr (descend 0 env') e
       let rec_flag = recFlagOf bind
       let transfer :: SingleUse -> TransferFunction AnalResult
           transfer = monotonize node $ \use -> do
@@ -884,19 +906,19 @@ registerBindingGroup
   :: AnalEnv
   -> [(Id, CoreExpr)]
   -> FrameworkBuilder (AnalEnv, VarEnv (SingleUse -> TransferFunction AnalResult))
-registerBindingGroup env = go env emptyVarEnv
+registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`ing
   where
     go env nodes [] = return (env, nodes)
-    go env nodes ((id, rhs):binds) =
-      registerTransferFunction HighestPriority $ \node ->
-        registerTransferFunction HighestPriority $ \args_node -> do
+    go env nodes ((n, (id, rhs)):binds) =
+      registerTransferFunction $ \node ->
+        registerTransferFunction $ \args_node -> do
           let deref_node node def_e use = dependOnWithDefault (botUsageType, def_e) (node, use)
           let expr_forced_error = error "Expression component may not be used"
           (env', nodes') <- go
             (extendAnalEnv env id (fmap fst . deref_node args_node expr_forced_error))
             (extendVarEnv nodes id (deref_node node rhs))
             binds
-          transfer <- callArityExpr env' rhs
+          transfer <- callArityExpr (descend n env') rhs
           let transfer' = monotonize node $ \use -> do
                 --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
                 ret@(ut, rhs') <- transfer use 
@@ -918,7 +940,7 @@ changeDetectorUsageType changed_refs (old, _) (new, _) =
   ASSERT2( old_sig `leqUsageSig` new_sig, text "CallArity.changeDetector: usage sig not monotone")
   pprTrace "usage sig" empty (old_sig /= new_sig) ||
   ASSERT2( sizeUFM old_uses <= sizeUFM new_uses, text "CallArity.changeDetector: uses not monotone")
-  pprTrace "uses count" empty (sizeUFM old_uses /= sizeUFM new_uses) ||
+  pprTrace "uses count" (ppr (sizeUFM old_uses) <+> ppr (sizeUFM new_uses)) (sizeUFM old_uses /= sizeUFM new_uses) ||
   pprTrace "uses" empty (old_uses /= new_uses) ||
   ASSERT2( edgeCount old_cocalled <= edgeCount new_cocalled, text "CallArity.changeDetector: edgeCount not monotone")
   pprTrace "edgeCount" (ppr (edgeCount old_cocalled) <+> ppr (edgeCount new_cocalled)) (edgeCount old_cocalled /= edgeCount new_cocalled)
diff --git a/compiler/simplCore/CallArity/FrameworkBuilder.hs b/compiler/simplCore/CallArity/FrameworkBuilder.hs
index 9f9390949b..9fe4d96ee8 100644
--- a/compiler/simplCore/CallArity/FrameworkBuilder.hs
+++ b/compiler/simplCore/CallArity/FrameworkBuilder.hs
@@ -1,13 +1,16 @@
 {-# LANGUAGE GeneralizedNewtypeDeriving #-}
 
 module CallArity.FrameworkBuilder
-  ( FrameworkNode
+  ( predictAllocatedNodes
+  , FrameworkNode
   , TransferFunction
   , ChangeDetector
   , Worklist.alwaysChangeDetector
   , DataFlowFramework
   , FrameworkBuilder
-  , RequestedPriority (..)
+  , RetainedChunk
+  , retainNodes
+  , freeRetainedNodes
   , registerTransferFunction
   , monotonize
   , dependOnWithDefault
@@ -15,18 +18,37 @@ module CallArity.FrameworkBuilder
   ) where
 
 import CallArity.Types
+import CoreSyn
 import Outputable
 import Usage
 import qualified Worklist
 
+import Control.Monad.Fix
+import Control.Monad.Trans.State.Strict
 import Data.IntMap.Lazy (IntMap)
 import qualified Data.IntMap.Lazy as IntMap
 import Data.Map.Strict   (Map)
 import qualified Data.Map.Strict as Map
-import qualified Data.Set as Set
 import Data.Maybe
-import Control.Monad.Fix
-import Control.Monad.Trans.State.Strict
+import qualified Data.Set as Set
+import Data.Tree
+
+predictAllocatedNodes :: Expr b -> Tree Int
+predictAllocatedNodes = expr
+  where
+    expr (App f a) = mk_parent . map expr $ [f, a]
+    expr (Lam _ e) = expr e
+    expr (Let bs body) = map_lbl (+1) . mk_parent $ expr body:bind bs
+    expr (Case scrut _ _ alts) = mk_parent (expr scrut:alt alts)
+    expr (Cast e _) = expr e
+    expr (Tick _ e) = expr e
+    expr _ = empty_node
+    bind = map (map_lbl (+2) . expr) . rhssOfBind
+    alt = map expr . rhssOfAlts
+    map_lbl f (Node l cs) = Node (f l) cs -- Can't fmap, as that also increments children
+    add_child c (Node p cs) = Node (rootLabel c + p) (c:cs)
+    empty_node = Node 0 []
+    mk_parent = foldr add_child empty_node
 
 newtype FrameworkNode
   = FrameworkNode Int
@@ -41,15 +63,25 @@ type NodeTransferEnv = IntMap (SingleUse -> TransferFunction AnalResult, ChangeD
 data BuilderState
   = BS 
   { bs_env :: !NodeTransferEnv
-  , bs_lowest :: !Int 
-  , bs_highest :: !Int
+  -- ^ Maps allocated `FrameworkNode`s to `TransferFunction`s.
+  , bs_free :: IntMap Int
+  -- ^ Begin of next free node and size of the free chunk.
   }
 
-initialBuilderState :: BuilderState
-initialBuilderState = BS IntMap.empty 0 maxBound
+modifyFree :: (IntMap Int -> IntMap Int) -> BuilderState -> BuilderState
+modifyFree f bs = bs { bs_free = f (bs_free bs) }
+
+modifyEnv :: (NodeTransferEnv -> NodeTransferEnv) -> BuilderState -> BuilderState
+modifyEnv f bs = bs { bs_env = f (bs_env bs) }
+
+data RetainedChunk 
+  = RC 
+  { rc_start :: !Int 
+  , rc_end :: !Int
+  }
 
-modifyNodes :: (NodeTransferEnv -> NodeTransferEnv) -> BuilderState -> BuilderState
-modifyNodes f bs = bs { bs_env = f (bs_env bs) }
+initialBuilderState :: BuilderState
+initialBuilderState = BS IntMap.empty (IntMap.singleton 0 maxBound)
 
 newtype FrameworkBuilder a
   = FB { unFB :: State BuilderState a }
@@ -63,30 +95,61 @@ buildFramework (FB state) = (res, Worklist.DFF dff)
       Nothing -> pprPanic "CallArity.FrameworkBuilder.buildFramework" (ppr node)
       Just (transfer, detectChange) -> (transfer use, detectChange)
 
-data RequestedPriority
-  = HighestPriority
-  | LowestPriority
-
-popNodeWithRequestedPriority :: RequestedPriority -> State BuilderState Int
-popNodeWithRequestedPriority prio = state impl
+viewAt :: Int -> IntMap a -> Maybe (a, IntMap a)
+viewAt n m = case IntMap.updateLookupWithKey (\_ _ -> Nothing) n m of
+  (Just v, m') -> Just (v, m')
+  _ -> Nothing
+
+mergeAt :: Int -> IntMap Int -> IntMap Int
+mergeAt split free
+  | Just (start, split') <- IntMap.lookupLT split free
+  , split == split'
+  , Just (end, free') <- viewAt split free
+  = IntMap.insert start end free'
+  | otherwise
+  = free
+
+freeChunk :: RetainedChunk -> IntMap Int -> IntMap Int
+freeChunk (RC start end)
+  | start == end
+  = id
+freeChunk (RC start end)
+  = mergeAt start . mergeAt end . IntMap.insert start end
+
+requestChunk :: Int -> IntMap Int -> (RetainedChunk, IntMap Int)
+requestChunk req_size free
+  | Just ((start, end), free') <- IntMap.minViewWithKey free
+  , split <- start + req_size
+  , split <= end
+  = (RC start split, freeChunk (RC split end) free')
+  | Just ((start, end), _) <- IntMap.minViewWithKey free
+  = pprPanic "requestChunk: requested chunk size too big" (ppr req_size <+> ppr (end - start))
+  | otherwise
+  = pprPanic "requestChunk: no chunks available (?)" empty
+
+retainNodes :: Int -> FrameworkBuilder RetainedChunk
+retainNodes req_size = FB (state impl)
   where
-    impl bs 
-      | HighestPriority <- prio
-      = (bs_highest bs, bs { bs_highest = bs_highest bs - 1 })
-      | otherwise
-      = (bs_lowest bs, bs { bs_lowest = bs_lowest bs + 1 }) 
+    impl bs
+      | (rc, free') <- requestChunk req_size (bs_free bs)
+      = (rc, bs { bs_free = free' })
+
+freeRetainedNodes :: RetainedChunk -> FrameworkBuilder ()
+freeRetainedNodes rc = FB (modify' (modifyFree (freeChunk rc))) 
+
+popNextFreeNode :: State BuilderState Int
+popNextFreeNode = rc_start <$> unFB (retainNodes 1)
 
 registerTransferFunction
-  :: RequestedPriority
-  -> (FrameworkNode -> FrameworkBuilder (a, (SingleUse -> TransferFunction AnalResult, ChangeDetector)))
+  :: (FrameworkNode -> FrameworkBuilder (a, (SingleUse -> TransferFunction AnalResult, ChangeDetector)))
   -> FrameworkBuilder a
-registerTransferFunction prio f = FB $ do
-  node <- popNodeWithRequestedPriority prio
+registerTransferFunction f = FB $ do
+  node <- popNextFreeNode
   (result, _) <- mfix $ \ ~(_, entry) -> do
     -- Using mfix so that we can spare an unnecessary Int counter in the state.
     -- Also because @f@ needs to see its own node in order to define its
     -- transfer function in case of letrec.
-    modify' (modifyNodes (IntMap.insert node entry))
+    modify' (modifyEnv (IntMap.insertWith (pprPanic "Overwriting TransferFunction" (ppr node)) node entry))
     unFB (f (FrameworkNode node))
   return result
 
@@ -109,7 +172,7 @@ dependOnWithDefault def which = do
 buildAndRun :: FrameworkBuilder (SingleUse -> TransferFunction AnalResult) -> SingleUse -> AnalResult
 buildAndRun buildTransfer use = lookup_result (Worklist.runFramework fw (Set.singleton (node, use)))
   where
-    (node, fw) = buildFramework $ registerTransferFunction LowestPriority $ \node -> do
+    (node, fw) = buildFramework $ registerTransferFunction $ \node -> do
       transfer <- buildTransfer
       return (node, (transfer, Worklist.alwaysChangeDetector))
 
diff --git a/compiler/utils/UnVarGraph.hs b/compiler/utils/UnVarGraph.hs
index a7b31132b0..1e23b84ed2 100644
--- a/compiler/utils/UnVarGraph.hs
+++ b/compiler/utils/UnVarGraph.hs
@@ -131,7 +131,6 @@ mkUnVarGraph ei edges ec_estimate
 
 balance :: UnVarGraph -> UnVarGraph
 balance g@(UnVarGraph ei edges (_, ub) ec)
-  | ub_ratio < 0.6 = g
   | precise_ratio < 0.6 = precise_g
   | otherwise = complementUnVarGraph precise_g
   where
@@ -152,10 +151,10 @@ complementUnVarGraph (UnVarGraph res edges (lb, ub) _)
     ec_est = (max_edges - ub, max_edges - lb)
 
 complementEdges :: IntMap UnVarSet -> IntMap UnVarSet
-complementEdges edges = edges'
+complementEdges !edges = edges'
   where
     dom = UnVarSet (IntMap.keysSet edges)
-    edges' = fmap complement_neighbors edges
+    !edges' = fmap complement_neighbors edges
     complement_neighbors neighbors
       -- Very common cases are an empty neighbor set and the full neighbor set,
       -- in which case we want to be pretty cheap.
@@ -167,14 +166,33 @@ emptyUnVarGraph :: UnVarGraph
 emptyUnVarGraph = mkUnVarGraph Subtractive IntMap.empty (0, 0)
 
 unionUnVarGraph :: UnVarGraph -> UnVarGraph -> UnVarGraph
-unionUnVarGraph u1@(UnVarGraph Subtractive _ _ _) u2
-  = unionUnVarGraph (complementUnVarGraph u1) u2
-unionUnVarGraph u1 u2@(UnVarGraph Subtractive _ _ _)
-  = unionUnVarGraph u1 (complementUnVarGraph u2)
 unionUnVarGraph (UnVarGraph Additive e1 (l1, u1) _) (UnVarGraph Additive e2 (l2, u2) _)
   = balance $ mkUnVarGraph Additive e (max l1 l2, u1 + u2) 
   where
     e = IntMap.unionWith unionUnVarSet e1 e2
+unionUnVarGraph (UnVarGraph Subtractive e1 (l1, u1) _) (UnVarGraph Subtractive e2 (l2, u2) _)
+  = balance $ mkUnVarGraph Subtractive e (l, u)
+  where
+    diff1 = IntMap.keysSet e2 `IntSet.difference` IntMap.keysSet e1
+    diff2 = IntMap.keysSet e1 `IntSet.difference` IntMap.keysSet e2
+    e = IntMap.unionWithKey merger e1 e2
+    nodes = IntMap.size e
+    d1 = IntSet.size diff1
+    d2 = IntSet.size diff2
+    l = min l1 l2 + 2*d1*d2 -- assumes missing edges repeal themselves
+    u = u1 + u2 + 2*d1*d2 -- assumes missing edges in the non-shared component
+    merger n s1 s2
+      | n `IntSet.member` diff1 = s1 `unionUnVarSet` UnVarSet diff2
+      | n `IntSet.member` diff2 = s2 `unionUnVarSet` UnVarSet diff1
+      | otherwise = intersectionUnVarSet s1 s2 
+unionUnVarGraph u1 u2
+  = unionUnVarGraph u1' u2' -- we could be smarter here
+  where
+    nodes1 = IntMap.size (edges u1)
+    nodes2 = IntMap.size (edges u2)
+    (u1', u2')
+      | nodes1 < nodes2 = (complementUnVarGraph u1, u2)
+      | otherwise = (u1, complementUnVarGraph u2)
     
 unionUnVarGraphs :: [UnVarGraph] -> UnVarGraph
 unionUnVarGraphs = foldr unionUnVarGraph emptyUnVarGraph
-- 
2.12.1


From aa8890cdc7c970ddea66d4dff7aa8c12dc491940 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 1 Jun 2017 18:37:58 +0200
Subject: [PATCH 074/117] Got rid of some left-overs

---
 compiler/simplCore/CallArity/Analysis.hs | 16 ++++----
 compiler/simplCore/CallArity/Types.hs    | 62 ++++++++----------------------
 compiler/utils/UnVarGraph.hs             | 66 +++++++++++---------------------
 3 files changed, 48 insertions(+), 96 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index a15689c156..2e2071a280 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -470,7 +470,7 @@ extendAnalEnv env id node
 programToExpr 
   :: CoreProgram 
   -> (VarSet, CoreExpr)
-programToExpr = first (\it -> pprTrace "programToExpr" (ppr (sizeVarSet it)) it) . impl []
+programToExpr = impl []
   where
     impl exposed []
       = (mkVarSet exposed, mkBigCoreVarTup exposed)
@@ -499,11 +499,11 @@ callArityAnalProgram
   -> IO CoreProgram
 callArityAnalProgram dflags fam_envs
   = return 
-  . (\it -> pprTrace "callArity:end" (ppr (length it)) it) 
+  -- . (\it -> pprTrace "callArity:end" (ppr (length it)) it) 
   . exprToProgram 
   . uncurry (callArityRHS dflags fam_envs) 
   . programToExpr 
-  . (\it -> pprTrace "callArity:begin" (ppr (length it)) it)
+  -- . (\it -> pprTrace "callArity:begin" (ppr (length it)) it)
   -- . (\prog -> pprTrace "CallArity:Program" (ppr prog) prog)
 
 callArityRHS :: DynFlags -> FamInstEnvs -> VarSet -> CoreExpr -> CoreExpr
@@ -938,12 +938,12 @@ changeDetectorUsageType :: ChangeDetector
 changeDetectorUsageType changed_refs (old, _) (new, _) =
   -- It's crucial that we don't have to check the annotated expressions.
   ASSERT2( old_sig `leqUsageSig` new_sig, text "CallArity.changeDetector: usage sig not monotone")
-  pprTrace "usage sig" empty (old_sig /= new_sig) ||
+  old_sig /= new_sig ||
   ASSERT2( sizeUFM old_uses <= sizeUFM new_uses, text "CallArity.changeDetector: uses not monotone")
-  pprTrace "uses count" (ppr (sizeUFM old_uses) <+> ppr (sizeUFM new_uses)) (sizeUFM old_uses /= sizeUFM new_uses) ||
-  pprTrace "uses" empty (old_uses /= new_uses) ||
+  sizeUFM old_uses /= sizeUFM new_uses ||
+  old_uses /= new_uses ||
   ASSERT2( edgeCount old_cocalled <= edgeCount new_cocalled, text "CallArity.changeDetector: edgeCount not monotone")
-  pprTrace "edgeCount" (ppr (edgeCount old_cocalled) <+> ppr (edgeCount new_cocalled)) (edgeCount old_cocalled /= edgeCount new_cocalled)
+  edgeCount old_cocalled /= edgeCount new_cocalled
   where
     old_sig = ut_args old
     new_sig = ut_args new
@@ -955,7 +955,7 @@ changeDetectorUsageType changed_refs (old, _) (new, _) =
 
 changeDetectorAnalResult :: FrameworkNode -> ChangeDetector
 changeDetectorAnalResult self_node changed_refs (old, e) (new, e') =
-  pprTrace "changeDetector" (ppr $ Set.map fst changed_refs) $
+  --pprTrace "changeDetector" (ppr $ Set.map fst changed_refs) $
   not (Set.map fst changed_refs `Set.isSubsetOf` Set.singleton self_node) || 
   changeDetectorUsageType changed_refs (old, e) (new, e')
 
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index a83f8da751..edadde7be7 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -3,14 +3,13 @@ module CallArity.Types where
 import BasicTypes
 import CoreSyn
 import Id
-import Maybes
 import Outputable
 import UnVarGraph
 import Usage
 import VarEnv
 
 import Control.Monad ( guard )
-import Data.List ( tails, partition )
+import Data.List ( foldl1' )
 
 ---------------------------------------
 -- Functions related to UsageType    --
@@ -27,9 +26,6 @@ data UsageType
   -- ^ Models how an Id was used, if at all
   , ut_args :: !UsageSig
   -- ^ Collects the signature for captured lambda binders
-  , ut_stable :: Bool
-  -- ^ Entirely irrelevant for Usage information, but needed for detecting
-  -- stabilization of fixed-point iteration.
   }
 
 modifyArgs :: (UsageSig -> UsageSig) -> UsageType -> UsageType
@@ -43,7 +39,7 @@ modifyCoCalls modifier ut = ut { ut_cocalled = modifier (ut_cocalled ut) }
 type AnalResult = (UsageType, CoreExpr)
 
 emptyUsageType :: UsageType
-emptyUsageType = UT emptyUnVarGraph emptyVarEnv topUsageSig False
+emptyUsageType = UT emptyUnVarGraph emptyVarEnv topUsageSig
 
 botUsageType :: UsageType
 botUsageType = unusedArgs emptyUsageType
@@ -58,7 +54,7 @@ delUsageTypes :: [Id] -> UsageType -> UsageType
 delUsageTypes ids ae = foldr delUsageType ae ids
 
 delUsageType :: Id -> UsageType -> UsageType
-delUsageType id (UT g ae args s) = UT (g `delNode` id) (ae `delVarEnv` id) args s
+delUsageType id (UT g ae args) = UT (g `delNode` id) (ae `delVarEnv` id) args
 
 domType :: UsageType -> UnVarSet
 domType ut = varEnvDom (ut_uses ut)
@@ -72,7 +68,7 @@ makeIdArg id ut = delUsageType id (modifyArgs (consUsageSig (lookupUsage NonRecu
 -- In the result, find out the minimum arity and whether the variable is called
 -- at most once.
 lookupUsage :: RecFlag -> UsageType -> Id -> Usage
-lookupUsage rec (UT g ae _ _) id = case lookupVarEnv ae id of
+lookupUsage rec (UT g ae _) id = case lookupVarEnv ae id of
   Just use
     -- we assume recursive bindings to be called multiple times, what's the
     -- point otherwise? It's a little sad we don't encode it in the co-call
@@ -89,12 +85,11 @@ calledWith ut id = neighbors (ut_cocalled ut) id
 -- Replaces the co-call graph by a complete graph (i.e. no information)
 multiplyUsages :: Multiplicity -> UsageType -> UsageType
 multiplyUsages Once ut = ut
-multiplyUsages Many ut@(UT _ u args _)
+multiplyUsages Many ut@(UT _ u args)
   = UT
   { ut_cocalled = completeGraph (domType ut)
   , ut_uses = mapVarEnv (\use -> bothSingleUse use use) u
   , ut_args = manifyUsageSig args
-  , ut_stable = False
   }
 
 asCompleteGraph :: UsageType -> Maybe UnVarSet
@@ -104,49 +99,29 @@ asCompleteGraph ut = do
   return s
 
 bothUsageTypes :: [UsageType] -> UsageType
-bothUsageTypes uts 
-  = UT cocalled uses args False
-  where
-    uses = foldr bothUseEnv emptyVarEnv (map ut_uses uts)
-    args 
-      = ut_args 
-      . expectJust "bothUsageTypes: argument list empty" 
-      . listToMaybe
-      $ uts
-    -- Cross calls between complete graphs yield another complete graph.
-    -- This is an important optimization for large tuples, like occuring
-    -- when analysing top-level binds as let bindings
-    (completes, incompletes) 
-      = ([], uts)
-      -- = partition (isJust . asCompleteGraph) uts
-    completeDom
-      = unionUnVarSets 
-      . map (fromJust . asCompleteGraph) 
-      $ completes
-    completePart = completeGraph completeDom
-    graphs = completePart : map ut_cocalled incompletes
-    doms = completeDom : map domType incompletes
-    -- all tails, beginning with a two element list
-    pairings = drop 2 . reverse . tails $ doms
-    crossCalls = flip map pairings $ \(dom:others) -> 
-      -- There room for improvement by reusing the result of `unionUnVarSets`
-      completeBipartiteGraph dom (unionUnVarSets others) 
-    cocalled = unionUnVarGraphs (graphs ++ crossCalls)
+bothUsageTypes = foldl1' bothUsageType
 
 -- | Corresponds to sequential composition of expressions.
 -- Used for application and cases.
 -- Note this returns the @UsageSig@ from the first argument.
 bothUsageType :: UsageType -> UsageType -> UsageType
-bothUsageType ut1 ut2 = bothUsageTypes [ut1, ut2]
+bothUsageType ut1@(UT g1 u1 args) ut2@(UT g2 u2 _)
+  = UT
+  -- it might make sense to have an optimized version of the UnVarGraph expression, since
+  -- `completeBipartiteGraph` might return an `Additive` graph which will probably flipped
+  -- immediately thereafter.
+  { ut_cocalled = unionUnVarGraphs [g1, completeBipartiteGraph (domType ut1) (domType ut2), g2]
+  , ut_uses = bothUseEnv u1 u2
+  , ut_args = args
+  }
 
 -- | Used when combining results from alternative cases
 lubUsageType :: UsageType -> UsageType -> UsageType
-lubUsageType (UT g1 u1 args1 _) (UT g2 u2 args2 _)
+lubUsageType (UT g1 u1 args1) (UT g2 u2 args2)
   = UT
   { ut_cocalled = unionUnVarGraph g1 g2
   , ut_uses = lubUseEnv u1 u2
   , ut_args = lubUsageSig args1 args2
-  , ut_stable = False
   }
 
 lubUseEnv :: VarEnv SingleUse -> VarEnv SingleUse -> VarEnv SingleUse
@@ -165,13 +140,10 @@ peelArgUsage ut = (usg, ut { ut_args = args' })
   where
     (usg, args') = unconsUsageSig (ut_args ut)
 
-markStable :: UsageType -> UsageType
-markStable ut = ut { ut_stable = True }
-
 -- * Pretty-printing
 
 instance Outputable UsageType where
-  ppr (UT cocalled arities args _) = vcat
+  ppr (UT cocalled arities args) = vcat
     [ text "arg usages:" <+> ppr args
     , text "co-calls:" <+> ppr cocalled
     , text "uses:" <+> ppr arities
diff --git a/compiler/utils/UnVarGraph.hs b/compiler/utils/UnVarGraph.hs
index 1e23b84ed2..c234697334 100644
--- a/compiler/utils/UnVarGraph.hs
+++ b/compiler/utils/UnVarGraph.hs
@@ -109,7 +109,6 @@ data UnVarGraph
   = UnVarGraph
   { edge_interpretation :: !OverlayResolution
   , edges :: !(IntMap UnVarSet)
-  , edge_count_estimate :: !(Int, Int)
   , edge_count :: Int -- Intentionally lazy!
   }
 
@@ -120,41 +119,33 @@ edgeCount g
   where
     nodes = IntMap.size (edges g)
 
-mkUnVarGraph :: OverlayResolution -> IntMap UnVarSet -> (Int, Int) -> UnVarGraph
-mkUnVarGraph ei edges ec_estimate 
+mkUnVarGraph :: OverlayResolution -> IntMap UnVarSet -> UnVarGraph
+mkUnVarGraph ei edges
   = UnVarGraph
   { edge_interpretation = ei
   , edges = edges
-  , edge_count_estimate = ec_estimate
   , edge_count = foldr ((+) . sizeUnVarSet) 0 edges
   }
 
 balance :: UnVarGraph -> UnVarGraph
-balance g@(UnVarGraph ei edges (_, ub) ec)
-  | precise_ratio < 0.6 = precise_g
-  | otherwise = complementUnVarGraph precise_g
+balance g@(UnVarGraph _ edges ec)
+  | ratio < 0.6 = g
+  | otherwise = complementUnVarGraph g
   where
     nodes = IntMap.size edges
     max_edges = nodes * nodes
-    ub_ratio :: Double
-    ub_ratio = fromIntegral ub / fromIntegral max_edges
-    precise_ratio :: Double
-    precise_ratio = fromIntegral ec / fromIntegral max_edges
-    precise_g = UnVarGraph ei edges (ec, ec) ec
+    ratio :: Double
+    ratio = fromIntegral ec / fromIntegral max_edges
 
 complementUnVarGraph :: UnVarGraph -> UnVarGraph
-complementUnVarGraph (UnVarGraph res edges (lb, ub) _) 
-  = mkUnVarGraph (complementOverlayResolution res) (complementEdges edges) ec_est
-  where
-    nodes = IntMap.size edges
-    max_edges = nodes*nodes
-    ec_est = (max_edges - ub, max_edges - lb)
+complementUnVarGraph (UnVarGraph res edges _) 
+  = mkUnVarGraph (complementOverlayResolution res) (complementEdges edges)
 
 complementEdges :: IntMap UnVarSet -> IntMap UnVarSet
-complementEdges !edges = edges'
+complementEdges edges = edges'
   where
     dom = UnVarSet (IntMap.keysSet edges)
-    !edges' = fmap complement_neighbors edges
+    edges' = fmap complement_neighbors edges
     complement_neighbors neighbors
       -- Very common cases are an empty neighbor set and the full neighbor set,
       -- in which case we want to be pretty cheap.
@@ -163,24 +154,16 @@ complementEdges !edges = edges'
       | otherwise = differenceUnVarSet dom neighbors
 
 emptyUnVarGraph :: UnVarGraph
-emptyUnVarGraph = mkUnVarGraph Subtractive IntMap.empty (0, 0)
+emptyUnVarGraph = mkUnVarGraph Subtractive IntMap.empty
 
 unionUnVarGraph :: UnVarGraph -> UnVarGraph -> UnVarGraph
-unionUnVarGraph (UnVarGraph Additive e1 (l1, u1) _) (UnVarGraph Additive e2 (l2, u2) _)
-  = balance $ mkUnVarGraph Additive e (max l1 l2, u1 + u2) 
-  where
-    e = IntMap.unionWith unionUnVarSet e1 e2
-unionUnVarGraph (UnVarGraph Subtractive e1 (l1, u1) _) (UnVarGraph Subtractive e2 (l2, u2) _)
-  = balance $ mkUnVarGraph Subtractive e (l, u)
+unionUnVarGraph (UnVarGraph Additive e1 _) (UnVarGraph Additive e2 _)
+  = balance $ mkUnVarGraph Additive $ IntMap.unionWith unionUnVarSet e1 e2
+unionUnVarGraph (UnVarGraph Subtractive e1 _) (UnVarGraph Subtractive e2 _)
+  = balance $ mkUnVarGraph Subtractive $ IntMap.unionWithKey merger e1 e2
   where
     diff1 = IntMap.keysSet e2 `IntSet.difference` IntMap.keysSet e1
     diff2 = IntMap.keysSet e1 `IntSet.difference` IntMap.keysSet e2
-    e = IntMap.unionWithKey merger e1 e2
-    nodes = IntMap.size e
-    d1 = IntSet.size diff1
-    d2 = IntSet.size diff2
-    l = min l1 l2 + 2*d1*d2 -- assumes missing edges repeal themselves
-    u = u1 + u2 + 2*d1*d2 -- assumes missing edges in the non-shared component
     merger n s1 s2
       | n `IntSet.member` diff1 = s1 `unionUnVarSet` UnVarSet diff2
       | n `IntSet.member` diff2 = s2 `unionUnVarSet` UnVarSet diff1
@@ -200,7 +183,7 @@ unionUnVarGraphs = foldr unionUnVarGraph emptyUnVarGraph
 -- completeBipartiteGraph A B = { {a,b} | a ∈ A, b ∈ B }
 completeBipartiteGraph :: UnVarSet -> UnVarSet -> UnVarGraph
 completeBipartiteGraph u1@(UnVarSet s1) u2@(UnVarSet s2) 
-  = balance (UnVarGraph Additive edges (ec, ec) ec)
+  = balance $ UnVarGraph Additive edges ec
   where
     dom@(UnVarSet s) = unionUnVarSet u1 u2
     (UnVarSet s3) = intersectionUnVarSet u1 u2 -- common elements
@@ -215,15 +198,15 @@ completeBipartiteGraph u1@(UnVarSet s1) u2@(UnVarSet s2)
         
 completeGraph :: UnVarSet -> UnVarGraph
 completeGraph (UnVarSet s) 
-  = mkUnVarGraph Subtractive (IntMap.fromSet (const emptyUnVarSet) s) (0, 0)
+  = UnVarGraph Subtractive (IntMap.fromSet (const emptyUnVarSet) s) 0
 
 isCompleteGraph_maybe :: UnVarGraph -> Maybe UnVarSet
-isCompleteGraph_maybe (UnVarGraph Subtractive e (0, 0) _) 
+isCompleteGraph_maybe (UnVarGraph Subtractive e _) 
   = Just (UnVarSet (IntMap.keysSet e))
 isCompleteGraph_maybe _ = Nothing
 
 neighbors :: UnVarGraph -> Var -> UnVarSet
-neighbors (UnVarGraph ie edges _ _) v 
+neighbors (UnVarGraph ie edges _) v 
   = fromMaybe emptyUnVarSet (interpret_edge <$> IntMap.lookup (k v) edges)
   where 
     dom = UnVarSet $ IntMap.keysSet edges
@@ -232,8 +215,8 @@ neighbors (UnVarGraph ie edges _ _) v
       | otherwise = differenceUnVarSet dom
 
 delNode :: UnVarGraph -> Var -> UnVarGraph
-delNode (UnVarGraph ei g (lb, ub) _) v 
-  = mkUnVarGraph ei g2 (lb', ub') -- No rebalance here, since the graph gets smaller anyway
+delNode (UnVarGraph ei g _) v 
+  = mkUnVarGraph ei g2 -- No rebalance here, since the graph gets smaller anyway
   where 
     -- Note that we need to delete all mentioned edges, regardless of `ei`.
     (neighbors_maybe, g1) = IntMap.updateLookupWithKey (\_ _ -> Nothing) (k v) g
@@ -246,11 +229,8 @@ delNode (UnVarGraph ei g (lb, ub) _) v
       | sizeUnVarSet s <= 1 = emptyUnVarSet -- This assumes that v is in s
       | sizeUnVarSet s == sizeUnVarSet dom = new_dom
       | otherwise = delUnVarSet s v
-    del_edge_count = IntSet.size neighbors
-    lb' = lb - del_edge_count
-    ub' = ub - del_edge_count
 
 instance Outputable UnVarGraph where
-    ppr u@(UnVarGraph ei g _ _) 
+    ppr u@(UnVarGraph ei g _) 
       | ei == Additive = ppr g
       | otherwise = ppr (complementUnVarGraph u)
-- 
2.12.1


From 4b6b473c5a69c1995c0b2d1c717a70916d3651f3 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 1 Jun 2017 18:38:17 +0200
Subject: [PATCH 075/117] Fixed CallArity1 and spec-inline

---
 testsuite/tests/callarity/unittest/CallArity1.hs            | 2 +-
 testsuite/tests/simplCore/should_compile/spec-inline.stderr | 2 +-
 2 files changed, 2 insertions(+), 2 deletions(-)

diff --git a/testsuite/tests/callarity/unittest/CallArity1.hs b/testsuite/tests/callarity/unittest/CallArity1.hs
index b12f076e5d..bdaa4eb82d 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.hs
+++ b/testsuite/tests/callarity/unittest/CallArity1.hs
@@ -198,7 +198,7 @@ main = do
                 Nothing -> return ()
             putMsg dflags (text n <> char ':')
             -- liftIO $ putMsg dflags (ppr e)
-            let e' = callArityRHS dflags emptyFamInstEnvs e
+            let e' = callArityRHS dflags emptyFamInstEnvs emptyVarSet e
             let bndrs = nonDetEltsUniqSet (allBoundIds e')
               -- It should be OK to use nonDetEltsUniqSet here, if it becomes a
               -- problem we should use DVarSet
diff --git a/testsuite/tests/simplCore/should_compile/spec-inline.stderr b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
index 17426f55ff..4fb1ef09b2 100644
--- a/testsuite/tests/simplCore/should_compile/spec-inline.stderr
+++ b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
@@ -103,7 +103,7 @@ Roman.$wgo =
       Just x ->
         case x of { GHC.Types.I# ipv ->
         let {
-          m :: GHC.Prim.Int#
+          m [Dmd=<L,A>, Usg=A] :: GHC.Prim.Int#
           [LclId]
           m =
             GHC.Prim.+#
-- 
2.12.1


From 99be370ee7a65c8edc24ed0e839327b33138bdb5 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 2 Jun 2017 09:51:18 +0200
Subject: [PATCH 076/117] Fixed spec-inline

---
 compiler/coreSyn/PprCore.hs                                 | 4 ----
 testsuite/tests/simplCore/should_compile/spec-inline.stderr | 6 ++++--
 2 files changed, 4 insertions(+), 6 deletions(-)

diff --git a/compiler/coreSyn/PprCore.hs b/compiler/coreSyn/PprCore.hs
index 042a1fef89..4dee904deb 100644
--- a/compiler/coreSyn/PprCore.hs
+++ b/compiler/coreSyn/PprCore.hs
@@ -464,7 +464,6 @@ ppIdInfo id info
     , (has_arity,        text "Arity=" <> int arity)
     , (has_caf_info,     text "Caf=" <> ppr caf_info)
     , (has_str_info,     text "Str=" <> pprStrictness str_info)
-    , (has_usg,          text "Usg=" <> ppr usg_info)
     , (has_arg_usage,    text "ArgUsg=" <> ppr arg_usage)
     , (has_unf,          text "Unf=" <> ppr unf_info)
     , (not (null rules), text "RULES:" <+> vcat (map pprRule rules))
@@ -479,9 +478,6 @@ ppIdInfo id info
     arity = arityInfo info
     has_arity = arity /= 0
 
-    usg_info = callArityInfo info
-    has_usg = usg_info /= topUsage
-
     arg_usage = argUsageInfo info
     has_arg_usage = arg_usage /= topUsageSig
 
diff --git a/testsuite/tests/simplCore/should_compile/spec-inline.stderr b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
index 4fb1ef09b2..ee372e4762 100644
--- a/testsuite/tests/simplCore/should_compile/spec-inline.stderr
+++ b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
@@ -62,9 +62,9 @@ Rec {
 -- RHS size: {terms: 55, types: 9, coercions: 0, joins: 0/1}
 Roman.foo_$s$wgo [Occ=LoopBreaker]
   :: GHC.Prim.Int# -> GHC.Prim.Int# -> GHC.Prim.Int#
-[GblId, Arity=2, Caf=NoCafRefs, Str=<S,U><S,U>]
+[GblId, Arity=2, Caf=NoCafRefs, Str=<S,U><S,U>, ArgUsg=A,w*U,w*U..]
 Roman.foo_$s$wgo =
-  \ (sc :: GHC.Prim.Int#) (sc1 [OS=OneShot] :: GHC.Prim.Int#) ->
+  \ (sc :: GHC.Prim.Int#) (sc1 :: GHC.Prim.Int#) ->
     let {
       m [Dmd=<L,A>, Usg=A] :: GHC.Prim.Int#
       [LclId]
@@ -94,6 +94,7 @@ Roman.$wgo [InlPrag=[0]] :: Maybe Int -> Maybe Int -> GHC.Prim.Int#
 [GblId,
  Arity=2,
  Str=<S,1*U><S,1*U>,
+ ArgUsg=1*U,1*U,w*U,w*U..,
  Unf=Unf{Src=<vanilla>, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True, Guidance=IF_ARGS [60 30] 256 0}]
 Roman.$wgo =
@@ -138,6 +139,7 @@ Roman.foo_go [InlPrag=INLINE[0]] :: Maybe Int -> Maybe Int -> Int
 [GblId,
  Arity=2,
  Str=<S,1*U><S,1*U>m,
+ ArgUsg=1*U,1*U,w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=2,unsat_ok=True,boring_ok=False)
-- 
2.12.1


From 49a5720d27eeca9ff83d8cb6fe7b0bc15dcdba17 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 2 Jun 2017 10:32:09 +0200
Subject: [PATCH 077/117] Fixed T3717 (handling empty products as HU now),
 T4201 and T4908

---
 compiler/basicTypes/Usage.hs                          |  1 +
 testsuite/tests/simplCore/should_compile/Makefile     |  2 +-
 testsuite/tests/simplCore/should_compile/T3717.stderr |  3 ++-
 testsuite/tests/simplCore/should_compile/T4201.stdout |  3 ++-
 testsuite/tests/simplCore/should_compile/T4908.stderr | 13 ++++++++-----
 5 files changed, 14 insertions(+), 8 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index e17b43176a..201a47e35c 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -260,6 +260,7 @@ trimSingleUse (TsFun shape) (Call m body)
 trimSingleUse (TsProd shapes) (Product comps)
   | equalLength shapes comps
   = mkProductUse (zipWith trimUsage shapes comps)
+trimSingleUse (TsProd []) UnknownUse = HeadUse
 trimSingleUse _ _ = topSingleUse
 
 trimUsage :: TypeShape -> Usage -> Usage
diff --git a/testsuite/tests/simplCore/should_compile/Makefile b/testsuite/tests/simplCore/should_compile/Makefile
index 779e7f2ef6..2e7a31c9ff 100644
--- a/testsuite/tests/simplCore/should_compile/Makefile
+++ b/testsuite/tests/simplCore/should_compile/Makefile
@@ -88,7 +88,7 @@ T4201:
 	'$(TEST_HC)' $(TEST_HC_OPTS) -c -O T4201.hs
 	'$(TEST_HC)' $(TEST_HC_OPTS) --show-iface T4201.hi > T4201.list
 	# poor man idea about how to replace GNU grep -B2 "Sym" invocation with pure POSIX tools
-	for i in `grep -n "Sym" T4201.list |cut -d ':' -f -1`; do head -$$i T4201.list | tail -3 ; done
+	for i in `grep -n "Sym" T4201.list |cut -d ':' -f -1`; do head -$$i T4201.list | tail -4 ; done
 	$(RM) -f T4201.list
 
 # This one looped as a result of bogus specialisation
diff --git a/testsuite/tests/simplCore/should_compile/T3717.stderr b/testsuite/tests/simplCore/should_compile/T3717.stderr
index 9bcc4f31ac..0aa4d08ee4 100644
--- a/testsuite/tests/simplCore/should_compile/T3717.stderr
+++ b/testsuite/tests/simplCore/should_compile/T3717.stderr
@@ -51,7 +51,7 @@ Rec {
 -- RHS size: {terms: 10, types: 2, coercions: 0, joins: 0/0}
 T3717.$wfoo [InlPrag=[0], Occ=LoopBreaker]
   :: GHC.Prim.Int# -> GHC.Prim.Int#
-[GblId, Arity=1, Caf=NoCafRefs, Str=<S,1*U>]
+[GblId, Arity=1, Caf=NoCafRefs, Str=<S,1*U>, ArgUsg=1*U,w*U,w*U..]
 T3717.$wfoo =
   \ (ww :: GHC.Prim.Int#) ->
     case ww of ds {
@@ -66,6 +66,7 @@ foo [InlPrag=INLINE[0]] :: Int -> Int
  Arity=1,
  Caf=NoCafRefs,
  Str=<S(S),1*U(1*U)>m,
+ ArgUsg=1*U(1*U),w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
diff --git a/testsuite/tests/simplCore/should_compile/T4201.stdout b/testsuite/tests/simplCore/should_compile/T4201.stdout
index 9a4b157e53..efb6a8c172 100644
--- a/testsuite/tests/simplCore/should_compile/T4201.stdout
+++ b/testsuite/tests/simplCore/should_compile/T4201.stdout
@@ -1,3 +1,4 @@
-  {- Arity: 1, HasNoCafRefs, Strictness: <S,1*U>m,
+  {- Arity: 1, HasNoCafRefs, Strictness: <S,1*H>m,
+     Usage: 1*HU,w*U,w*U..,
      Unfolding: InlineRule (0, True, True)
                 bof `cast` (Sym (N:Foo[0]) ->_R <T>_R) -}
diff --git a/testsuite/tests/simplCore/should_compile/T4908.stderr b/testsuite/tests/simplCore/should_compile/T4908.stderr
index a0a6008389..f351dae231 100644
--- a/testsuite/tests/simplCore/should_compile/T4908.stderr
+++ b/testsuite/tests/simplCore/should_compile/T4908.stderr
@@ -50,11 +50,13 @@ T4908.$trModule =
 Rec {
 -- RHS size: {terms: 19, types: 5, coercions: 0, joins: 0/0}
 T4908.f_$s$wf [Occ=LoopBreaker] :: Int -> Int# -> Int# -> Bool
-[GblId, Arity=3, Caf=NoCafRefs, Str=<L,A><L,1*U><S,1*U>]
+[GblId,
+ Arity=3,
+ Caf=NoCafRefs,
+ Str=<L,A><L,1*U><S,1*U>,
+ ArgUsg=A,1*U,1*U,w*U,w*U..]
 T4908.f_$s$wf =
-  \ (sc :: Int) 
-    (sc1 [OS=OneShot] :: Int#) 
-    (sc2 [OS=OneShot] :: Int#) ->
+  \ (sc :: Int) (sc1 :: Int#) (sc2 :: Int#) ->
     case sc2 of ds {
       __DEFAULT ->
         case sc1 of ds1 {
@@ -71,10 +73,11 @@ T4908.$wf [InlPrag=[0]] :: Int# -> (Int, Int) -> Bool
  Arity=2,
  Caf=NoCafRefs,
  Str=<S,1*U><L,1*U(A,1*U(1*U))>,
+ ArgUsg=1*U,1*U(A,1*U(1*U)),w*U,w*U..,
  Unf=Unf{Src=<vanilla>, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True, Guidance=IF_ARGS [30 20] 101 20}]
 T4908.$wf =
-  \ (ww :: Int#) (w [OS=OneShot] :: (Int, Int)) ->
+  \ (ww :: Int#) (w :: (Int, Int)) ->
     case ww of ds {
       __DEFAULT ->
         case w of { (a, b) ->
-- 
2.12.1


From 2ec25b48648d028a467ca52966654cf9ea3e4c08 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 2 Jun 2017 12:37:57 +0200
Subject: [PATCH 078/117] Regarding all top-level binders as exposed uncovered
 severe regressions. Now it's exports + RULE mentions

---
 compiler/simplCore/CallArity/Analysis.hs           | 45 +++++++++++++++-------
 compiler/simplCore/DmdAnalWrapper.hs               |  8 ++--
 compiler/simplCore/SimplCore.hs                    | 17 +++++---
 .../tests/simplCore/should_compile/T3717.stderr    |  2 +-
 .../tests/simplCore/should_compile/T3772.stdout    |  1 +
 .../tests/simplCore/should_compile/T4908.stderr    |  3 +-
 .../tests/simplCore/should_compile/T7360.stderr    |  2 +
 .../simplCore/should_compile/noinline01.stderr     | 14 ++++++-
 8 files changed, 63 insertions(+), 29 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 2e2071a280..4f8923471e 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -14,6 +14,7 @@ import CallArity.FrameworkBuilder
 import BasicTypes
 import Class
 import Coercion ( Coercion, coVarsOfCo )
+import CoreFVs ( idRuleRhsVars, rulesFreeVars )
 import CoreSyn
 import CoreUtils ( exprIsTrivial )
 import DataCon
@@ -468,23 +469,39 @@ extendAnalEnv env id node
 -- as a tuple. As a result, all exported identifiers are handled as called
 -- with each other, with `topUsage`.
 programToExpr 
-  :: CoreProgram 
+  :: (Activation -> Bool)
+  -> [CoreRule]
+  -> CoreProgram 
   -> (VarSet, CoreExpr)
-programToExpr = impl []
+programToExpr is_active_rule orphan_rules = impl (rulesFreeVars orphan_rules)
   where
+    impl :: VarSet -> CoreProgram -> (VarSet, CoreExpr)
     impl exposed []
-      = (mkVarSet exposed, mkBigCoreVarTup exposed)
+      = (exposed, mkBigCoreVarTup (nonDetEltsUFM exposed))
+        -- nonDetEltsUFM is OK, because all product components will
+        -- used in the same way anyway.
     impl exposed (bind:prog)
-      = second (Let bind) (impl (exposed_ids bind ++ exposed) prog)
-    -- We are too conservative here, but we need *at least*  
+      = second (Let bind) (impl (exposed_ids bind `unionVarSet` exposed) prog)
+    -- We need *at least*  
     -- 
     --   * exported `Id`s (`isExportedId`)
-    --   * `Id`s mentioned in RULEs of this module
+    --   * `Id`s mentioned in any RULE's RHS of this module
+    --   * Manually (through a VECTORISE pragma) vectorized `Id`s.
+    --     No need for RHSs of VECTORISE pragmas since we run after
+    --     the initial phase of the simplifier.
+    --     (See Note [Vectorisation declarations and occurrences] in SimplCore.hs)
+    --     TODO: We ignore these altogether for now, since collecting 
+    --           the needed info is really tedious.
     --
-    -- I'm not sure it's enough to just look into RULEs associated
-    -- with any of the binders, so we just blindly assume all top-level
-    -- `Id`s as exported (as does the demand analyzer).
-    exposed_ids bind = bindersOf bind
+    -- This essentially does the same as the Occurence Analyser,
+    -- but we are more conservative in that we don't try to follow
+    -- transitive RULE mentions and just take into account all free vars
+    -- of any binder instead of starting to trace from exported ones.
+    exposed_ids bind = unionVarSets (exported:rules)
+      where
+        bs = bindersOf bind
+        exported = mkVarSet (filter isExportedId bs)
+        rules = map (idRuleRhsVars is_active_rule) bs
 
 -- | The left inverse to `programToExpr`: `exprToProgram . snd . programToExpr = id \@CoreProgram`
 exprToProgram :: CoreExpr -> CoreProgram
@@ -495,14 +512,16 @@ exprToProgram _ = []
 callArityAnalProgram 
   :: DynFlags 
   -> FamInstEnvs 
+  -> (Activation -> Bool)
+  -> [CoreRule]
   -> CoreProgram 
   -> IO CoreProgram
-callArityAnalProgram dflags fam_envs
+callArityAnalProgram dflags fam_envs is_active_rule orphan_rules
   = return 
   -- . (\it -> pprTrace "callArity:end" (ppr (length it)) it) 
   . exprToProgram 
   . uncurry (callArityRHS dflags fam_envs) 
-  . programToExpr 
+  . programToExpr is_active_rule orphan_rules
   -- . (\it -> pprTrace "callArity:begin" (ppr (length it)) it)
   -- . (\prog -> pprTrace "CallArity:Program" (ppr prog) prog)
 
@@ -935,7 +954,7 @@ registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`
           return ((ret, full), args) -- registerTransferFunction  will peel `snd`s away for registration
 
 changeDetectorUsageType :: ChangeDetector
-changeDetectorUsageType changed_refs (old, _) (new, _) =
+changeDetectorUsageType _ (old, _) (new, _) =
   -- It's crucial that we don't have to check the annotated expressions.
   ASSERT2( old_sig `leqUsageSig` new_sig, text "CallArity.changeDetector: usage sig not monotone")
   old_sig /= new_sig ||
diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index ed3ab349df..88a00a3a1e 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -7,21 +7,19 @@ module DmdAnalWrapper (combinedDmdAnalProgram) where
 import BasicTypes
 import CallArity
 import CoreSyn
-import Demand
 import DmdAnal
 import DynFlags
 import FamInstEnv
 import Id
 import Outputable
-import Util
 import Usage
 import Var
 
-combinedDmdAnalProgram :: DynFlags -> FamInstEnvs -> CoreProgram -> IO CoreProgram
-combinedDmdAnalProgram dflags fams prog = do
+combinedDmdAnalProgram :: DynFlags -> FamInstEnvs -> (Activation -> Bool) -> [CoreRule] -> CoreProgram -> IO CoreProgram
+combinedDmdAnalProgram dflags fams is_active_rule orphan_rules prog = do
   -- Call Arity first, suggesting the fact that there's no information flow
   -- from DA to CA. There isn't from CA to DA either, of course.
-  prog' <- callArityAnalProgram dflags fams prog
+  prog' <- callArityAnalProgram dflags fams is_active_rule orphan_rules prog
   prog'' <- dmdAnalProgram dflags fams prog'
   --pprTrace "Program" (ppr prog'') $ pure ()
   return (mapBndrsProgram mergeInfo prog'')
diff --git a/compiler/simplCore/SimplCore.hs b/compiler/simplCore/SimplCore.hs
index a6a6bf799c..39a0a4c5d1 100644
--- a/compiler/simplCore/SimplCore.hs
+++ b/compiler/simplCore/SimplCore.hs
@@ -34,7 +34,7 @@ import FloatOut         ( floatOutwards )
 import FamInstEnv
 import Id
 import ErrUtils         ( withTiming )
-import BasicTypes       ( CompilerPhase(..), isDefaultInlinePragma )
+import BasicTypes       ( Activation, CompilerPhase(..), isDefaultInlinePragma )
 import VarSet
 import VarEnv
 import LiberateCase     ( liberateCase )
@@ -471,10 +471,10 @@ doCorePass CoreDoStaticArgs          = {-# SCC "StaticArgs" #-}
                                        doPassU doStaticArgs
 
 doCorePass CoreDoCallArity           = {-# SCC "CallArity" #-}
-                                       doPassDFM callArityAnalProgram
+                                       doPassDFRM callArityAnalProgram
 
 doCorePass CoreDoStrictness          = {-# SCC "NewStranal" #-}
-                                       doPassDFM combinedDmdAnalProgram
+                                       doPassDFRM combinedDmdAnalProgram
 
 doCorePass CoreDoWorkerWrapper       = {-# SCC "WorkWrap" #-}
                                        doPassDFU wwTopBinds
@@ -543,12 +543,17 @@ doPassDU do_pass = doPassDUM (\dflags us -> return . do_pass dflags us)
 doPassU :: (UniqSupply -> CoreProgram -> CoreProgram) -> ModGuts -> CoreM ModGuts
 doPassU do_pass = doPassDU (const do_pass)
 
-doPassDFM :: (DynFlags -> FamInstEnvs -> CoreProgram -> IO CoreProgram) -> ModGuts -> CoreM ModGuts
-doPassDFM do_pass guts = do
+doPassDFRM :: (DynFlags -> FamInstEnvs -> (Activation -> Bool) -> [CoreRule] -> CoreProgram -> IO CoreProgram) -> ModGuts -> CoreM ModGuts
+doPassDFRM do_pass guts = do
     dflags <- getDynFlags
     p_fam_env <- getPackageFamInstEnv
     let fam_envs = (p_fam_env, mg_fam_inst_env guts)
-    doPassM (liftIO . do_pass dflags fam_envs) guts
+    -- No idea how to get at the SimplifierMode mode here,
+    -- or what else to choose as is_active_rule predicate.
+    -- let is_active_rule = activeRule (mkSimplEnv mode)
+    let is_active_rule = const True 
+    let orphan_rules = mg_rules guts
+    doPassM (liftIO . do_pass dflags fam_envs is_active_rule orphan_rules) guts
 
 doPassDFU :: (DynFlags -> FamInstEnvs -> UniqSupply -> CoreProgram -> CoreProgram) -> ModGuts -> CoreM ModGuts
 doPassDFU do_pass guts = do
diff --git a/testsuite/tests/simplCore/should_compile/T3717.stderr b/testsuite/tests/simplCore/should_compile/T3717.stderr
index 0aa4d08ee4..b98170d802 100644
--- a/testsuite/tests/simplCore/should_compile/T3717.stderr
+++ b/testsuite/tests/simplCore/should_compile/T3717.stderr
@@ -51,7 +51,7 @@ Rec {
 -- RHS size: {terms: 10, types: 2, coercions: 0, joins: 0/0}
 T3717.$wfoo [InlPrag=[0], Occ=LoopBreaker]
   :: GHC.Prim.Int# -> GHC.Prim.Int#
-[GblId, Arity=1, Caf=NoCafRefs, Str=<S,1*U>, ArgUsg=1*U,w*U,w*U..]
+[GblId, Arity=1, Caf=NoCafRefs, Str=<S,1*U>]
 T3717.$wfoo =
   \ (ww :: GHC.Prim.Int#) ->
     case ww of ds {
diff --git a/testsuite/tests/simplCore/should_compile/T3772.stdout b/testsuite/tests/simplCore/should_compile/T3772.stdout
index 4845f398cb..a6a63430fe 100644
--- a/testsuite/tests/simplCore/should_compile/T3772.stdout
+++ b/testsuite/tests/simplCore/should_compile/T3772.stdout
@@ -75,6 +75,7 @@ foo [InlPrag=INLINE[0]] :: Int -> ()
  Arity=1,
  Caf=NoCafRefs,
  Str=<S(S),1*U>,
+ ArgUsg=1*U,w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
diff --git a/testsuite/tests/simplCore/should_compile/T4908.stderr b/testsuite/tests/simplCore/should_compile/T4908.stderr
index f351dae231..2d02420bf6 100644
--- a/testsuite/tests/simplCore/should_compile/T4908.stderr
+++ b/testsuite/tests/simplCore/should_compile/T4908.stderr
@@ -73,11 +73,10 @@ T4908.$wf [InlPrag=[0]] :: Int# -> (Int, Int) -> Bool
  Arity=2,
  Caf=NoCafRefs,
  Str=<S,1*U><L,1*U(A,1*U(1*U))>,
- ArgUsg=1*U,1*U(A,1*U(1*U)),w*U,w*U..,
  Unf=Unf{Src=<vanilla>, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True, Guidance=IF_ARGS [30 20] 101 20}]
 T4908.$wf =
-  \ (ww :: Int#) (w :: (Int, Int)) ->
+  \ (ww :: Int#) (w [OS=OneShot] :: (Int, Int)) ->
     case ww of ds {
       __DEFAULT ->
         case w of { (a, b) ->
diff --git a/testsuite/tests/simplCore/should_compile/T7360.stderr b/testsuite/tests/simplCore/should_compile/T7360.stderr
index 118ebbe886..a190c835e7 100644
--- a/testsuite/tests/simplCore/should_compile/T7360.stderr
+++ b/testsuite/tests/simplCore/should_compile/T7360.stderr
@@ -24,6 +24,7 @@ fun1 [InlPrag=NOINLINE] :: Foo -> ()
  Arity=1,
  Caf=NoCafRefs,
  Str=<S,1*U>,
+ ArgUsg=1*U,w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
@@ -52,6 +53,7 @@ fun2 :: forall a. [a] -> ((), Int)
 [GblId,
  Arity=1,
  Str=<L,1*U>m,
+ ArgUsg=1*U,w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=False)
diff --git a/testsuite/tests/simplCore/should_compile/noinline01.stderr b/testsuite/tests/simplCore/should_compile/noinline01.stderr
index 1bb98e57b4..ebbbafd5c1 100644
--- a/testsuite/tests/simplCore/should_compile/noinline01.stderr
+++ b/testsuite/tests/simplCore/should_compile/noinline01.stderr
@@ -2,7 +2,12 @@
 ==================== Pre unarise: ====================
 Noinline01.f [InlPrag=INLINE (sat-args=1)]
   :: forall p. p -> GHC.Types.Bool
-[GblId, Arity=1, Caf=NoCafRefs, Str=<L,A>, Unf=OtherCon []] =
+[GblId,
+ Arity=1,
+ Caf=NoCafRefs,
+ Str=<L,A>,
+ ArgUsg=A,w*U,w*U..,
+ Unf=OtherCon []] =
     \r [eta] GHC.Types.True [];
 
 Noinline01.g :: GHC.Types.Bool
@@ -35,7 +40,12 @@ Noinline01.$trModule :: GHC.Types.Module
 ==================== STG syntax: ====================
 Noinline01.f [InlPrag=INLINE (sat-args=1)]
   :: forall p. p -> GHC.Types.Bool
-[GblId, Arity=1, Caf=NoCafRefs, Str=<L,A>, Unf=OtherCon []] =
+[GblId,
+ Arity=1,
+ Caf=NoCafRefs,
+ Str=<L,A>,
+ ArgUsg=A,w*U,w*U..,
+ Unf=OtherCon []] =
     \r [eta] GHC.Types.True [];
 
 Noinline01.g :: GHC.Types.Bool
-- 
2.12.1


From 066496eb318e04711ffa9392ea0e4226111d22a7 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 2 Jun 2017 13:15:39 +0200
Subject: [PATCH 079/117] ... and T3772

---
 testsuite/tests/simplCore/should_compile/T3772.stdout       | 2 +-
 testsuite/tests/simplCore/should_compile/spec-inline.stderr | 4 +---
 2 files changed, 2 insertions(+), 4 deletions(-)

diff --git a/testsuite/tests/simplCore/should_compile/T3772.stdout b/testsuite/tests/simplCore/should_compile/T3772.stdout
index a6a63430fe..fb9551d11b 100644
--- a/testsuite/tests/simplCore/should_compile/T3772.stdout
+++ b/testsuite/tests/simplCore/should_compile/T3772.stdout
@@ -50,7 +50,7 @@ T3772.$trModule
 Rec {
 -- RHS size: {terms: 10, types: 2, coercions: 0, joins: 0/0}
 $wxs :: GHC.Prim.Int# -> ()
-[GblId, Arity=1, Caf=NoCafRefs, Str=<S,1*U>]
+[GblId, Arity=1, Caf=NoCafRefs, Str=<S,1*U>, ArgUsg=1*U,w*U,w*U..]
 $wxs
   = \ (ww :: GHC.Prim.Int#) ->
       case ww of ds1 {
diff --git a/testsuite/tests/simplCore/should_compile/spec-inline.stderr b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
index ee372e4762..84278cd982 100644
--- a/testsuite/tests/simplCore/should_compile/spec-inline.stderr
+++ b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
@@ -94,7 +94,6 @@ Roman.$wgo [InlPrag=[0]] :: Maybe Int -> Maybe Int -> GHC.Prim.Int#
 [GblId,
  Arity=2,
  Str=<S,1*U><S,1*U>,
- ArgUsg=1*U,1*U,w*U,w*U..,
  Unf=Unf{Src=<vanilla>, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True, Guidance=IF_ARGS [60 30] 256 0}]
 Roman.$wgo =
@@ -104,7 +103,7 @@ Roman.$wgo =
       Just x ->
         case x of { GHC.Types.I# ipv ->
         let {
-          m [Dmd=<L,A>, Usg=A] :: GHC.Prim.Int#
+          m :: GHC.Prim.Int#
           [LclId]
           m =
             GHC.Prim.+#
@@ -139,7 +138,6 @@ Roman.foo_go [InlPrag=INLINE[0]] :: Maybe Int -> Maybe Int -> Int
 [GblId,
  Arity=2,
  Str=<S,1*U><S,1*U>m,
- ArgUsg=1*U,1*U,w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=2,unsat_ok=True,boring_ok=False)
-- 
2.12.1


From 1144841fd19a06f64b98eab93b7d5d7bc5ebbab9 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 2 Jun 2017 14:56:42 +0200
Subject: [PATCH 080/117] Crude fix for T11770

---
 testsuite/tests/stranal/should_compile/T11770.hs | 17 ++++++++++++-----
 1 file changed, 12 insertions(+), 5 deletions(-)

diff --git a/testsuite/tests/stranal/should_compile/T11770.hs b/testsuite/tests/stranal/should_compile/T11770.hs
index 6b669f903b..d49321bf1f 100644
--- a/testsuite/tests/stranal/should_compile/T11770.hs
+++ b/testsuite/tests/stranal/should_compile/T11770.hs
@@ -1,11 +1,18 @@
+{-# LANGUAGE MagicHash #-}
+
 module T11770 where
 
+import GHC.Prim
+
 
-foo :: Int -> Int ->  Int
-foo 10 c = 0
+-- Manually WW'd, so that we explicitly export the worker.
+-- This is so that the non-exported worker won't get one-shot
+-- annotations.
+foo :: Int# -> Int# ->  Int#
+foo 10# c = 0#
 foo n c =
         -- Bar should not be marked as one-shot
-    let bar :: Int -> Int
-        bar n = n + c
+    let bar :: Int# -> Int#
+        bar n = n +# c
         {-# NOINLINE bar #-}
-    in bar n + foo (bar (n+1)) c
+    in bar n +# foo (bar (n+#1#)) c
-- 
2.12.1


From 6da962e8f8dce57913293156991b27fe750645d7 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 2 Jun 2017 15:02:29 +0200
Subject: [PATCH 081/117] Implemented LetDown

---
 compiler/simplCore/CallArity/Analysis.hs | 71 +++++++++++++++++++++-----------
 compiler/simplCore/CallArity/Types.hs    |  9 ++--
 2 files changed, 53 insertions(+), 27 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 4f8923471e..dfe5acb380 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -50,7 +50,7 @@ import Data.Tree
 Note [Notes are out of date]
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-While the general concept of the Co-Call Analysis still holds, much has
+While the general concept of the Co-Call Analysis still applies, much has
 changed at isn't yet on par with the implementation.
 
 Note [Call Arity: The goal]
@@ -582,12 +582,12 @@ callArityExpr env e@(Var id) = return transfer
     transfer use
       | Just transfer_callee <- lookupVarEnv (ae_sigs env) id
       -- A local let-binding, e.g. a binding from this module.
+      -- We apply either the LetUp or LetDown rule, which is handled
+      -- transparently in `registerBindingGroups`.
       = do
         ut_callee <- transfer_callee use
-        -- It is crucial that we only use ut_args here, as every other field
-        -- might be unstable and thus too optimistic.
         --pprTrace "callArityExpr:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
-        return ((unitUsageType id use) { ut_args = ut_args ut_callee }, e)
+        return (ut_callee `bothUsageType` unitUsageType id use, e)
 
       | isLocalId id
       -- A LocalId not present in @nodes@, e.g. a lambda or case-bound variable.
@@ -728,6 +728,9 @@ callArityExpr env (Let bind e)
               _ -> return (ut, Let (Rec binds') e')
       return (node, (transfer, changeDetectorAnalResult node))
 
+useLetUp :: Id -> Bool
+useLetUp id = idArity id == 0
+
 coercionUsageType :: Coercion -> UsageType
 coercionUsageType co = multiplyUsages Many ut
   where
@@ -921,41 +924,61 @@ recFlagOf :: CoreBind -> RecFlag
 recFlagOf Rec{} = Recursive
 recFlagOf NonRec{} = NonRecursive
 
+exprForcedError :: CoreExpr
+exprForcedError = error "Expression component may not be used"
+
+transferUp :: Id -> CoreExpr -> FrameworkNode -> SingleUse -> TransferFunction AnalResult
+transferUp id rhs node use = do
+  (ut, rhs') <- dependOnWithDefault (botUsageType, rhs) (node, use)
+  if useLetUp id
+    then return (ut, rhs')
+    else return (botUsageType, rhs')
+
+transferDown :: Id -> FrameworkNode -> SingleUse -> TransferFunction UsageType
+transferDown id node use = do
+  (ut, _) <- dependOnWithDefault (botUsageType, exprForcedError) (node, use)
+  if useLetUp id
+    then return (forgetFreeVarUsages ut)
+    else return ut
+
 registerBindingGroup
   :: AnalEnv
   -> [(Id, CoreExpr)]
   -> FrameworkBuilder (AnalEnv, VarEnv (SingleUse -> TransferFunction AnalResult))
 registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`ing
   where
-    go env nodes [] = return (env, nodes)
-    go env nodes ((n, (id, rhs)):binds) =
-      registerTransferFunction $ \node ->
-        registerTransferFunction $ \args_node -> do
-          let deref_node node def_e use = dependOnWithDefault (botUsageType, def_e) (node, use)
-          let expr_forced_error = error "Expression component may not be used"
-          (env', nodes') <- go
-            (extendAnalEnv env id (fmap fst . deref_node args_node expr_forced_error))
-            (extendVarEnv nodes id (deref_node node rhs))
+    go env transfer_ups [] = return (env, transfer_ups)
+    go env transfer_ups ((n, (id, rhs)):binds) =
+      registerTransferFunction $ \up_node ->
+        registerTransferFunction $ \down_node -> do
+          ret@(env', _) <- go
+            (extendAnalEnv env id (transferDown id down_node))
+            (extendVarEnv transfer_ups id (transferUp id rhs up_node))
             binds
+          -- Now that the whole binding group is in scope in `env'`,
+          -- we actually have to attend to our duty and register the
+          -- transfer functions associated with `up_node` and `down_node`
           transfer <- callArityExpr (descend n env') rhs
-          let transfer' = monotonize node $ \use -> do
+          let transfer_annotate = monotonize up_node $ \use -> do
                 --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
-                ret@(ut, rhs') <- transfer use 
+                ret@(ut, rhs') <- transfer_rhs use 
                 --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut_rhs)]) $ return ret
                 return ret
-          let transfer_args use = do
+          let transfer_args_only use = do
+                -- This makes sure to forget the annotated expression from the up_node, 
+                -- in order to have a more forgiving change detector. That's essential for 
+                -- termination of the analysis.
                 --use <- pprTrace "args:begin" (ppr id <+> text "::" <+> ppr use) $ return use
-                (ut, _) <- dependOnWithDefault (botUsageType, undefined) (node, use)
-                --ut <- pprTrace "args:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut)]) $ return ut
-                return (ut, expr_forced_error)
-          let ret = (env', nodes') -- What we return from 'registerBindingGroup'
-          let full = (transfer', changeDetectorAnalResult node) -- What we register for @node@
-          let args = (transfer_args, changeDetectorUsageType) -- What we register for @arg_node@
-          return ((ret, full), args) -- registerTransferFunction  will peel `snd`s away for registration
+                (ut, _) <- dependOnWithDefault (botUsageType, exprForcedError) (up_node, use)
+                --ut_callee <- pprTrace "args:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut_callee)]) $ return ut_calle
+                return (ut, exprForcedError)
+          let annotate = (transfer_annotate, changeDetectorAnalResult up_node) -- What we register for `up_node`
+          let args_only = (transfer_args_only, changeDetectorUsageType)        -- What we register for `down_node`
+          return ((ret, annotate), args_only) -- `registerTransferFunction`  will peel `snd`s away for registration
 
 changeDetectorUsageType :: ChangeDetector
 changeDetectorUsageType _ (old, _) (new, _) =
-  -- It's crucial that we don't have to check the annotated expressions.
+  -- It's crucial for termination that we don't have to check the annotated expressions.
   ASSERT2( old_sig `leqUsageSig` new_sig, text "CallArity.changeDetector: usage sig not monotone")
   old_sig /= new_sig ||
   ASSERT2( sizeUFM old_uses <= sizeUFM new_uses, text "CallArity.changeDetector: uses not monotone")
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index edadde7be7..180db0f550 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -22,9 +22,9 @@ data UsageType
   = UT
   { ut_cocalled :: !UnVarGraph
   -- ^ Models cardinality, e.g. at most {1, many} via the co-call relation
-  , ut_uses :: !(VarEnv SingleUse)
-  -- ^ Models how an Id was used, if at all
-  , ut_args :: !UsageSig
+  , ut_uses     :: !(VarEnv SingleUse)
+  -- ^ Models how an `Id` was used, if at all
+  , ut_args     :: !UsageSig
   -- ^ Collects the signature for captured lambda binders
   }
 
@@ -50,6 +50,9 @@ unitUsageType id use = emptyUsageType { ut_uses = unitVarEnv id use }
 unusedArgs :: UsageType -> UsageType
 unusedArgs ut = ut { ut_args = botUsageSig }
 
+forgetFreeVarUsages :: UsageType -> UsageType
+forgetFreeVarUsages ut = botUsageType { ut_args = ut_args ut }
+
 delUsageTypes :: [Id] -> UsageType -> UsageType
 delUsageTypes ids ae = foldr delUsageType ae ids
 
-- 
2.12.1


From 2558fdf0f44fef2c132cfc1b48734eb84074a2a8 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 2 Jun 2017 17:43:18 +0200
Subject: [PATCH 082/117] Fixed ArgUse annotations

---
 compiler/simplCore/CallArity/Analysis.hs | 56 ++++++++++++++++----------------
 compiler/simplCore/DmdAnalWrapper.hs     |  5 +--
 2 files changed, 31 insertions(+), 30 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index dfe5acb380..416bdc18e7 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -630,8 +630,8 @@ callArityExpr env (Lam id body)
         u@(Used multi body_use) -> do
           (ut_body, body') <- transfer_body body_use
           let (ut_body', usage_id) = findBndrUsage NonRecursive (ae_fam_envs env) ut_body id
-          let id' = applyWhen (multi == Once) (flip setIdOneShotInfo OneShotLam)
-                  . flip setIdCallArity usage_id
+          let id' = applyWhen (multi == Once) (`setIdOneShotInfo` OneShotLam)
+                  . (`setIdCallArity` usage_id)
                   $ id
           -- Free vars are manified, closed vars are not. The usage of the current
           -- argument `id` is *not* manified.
@@ -654,16 +654,16 @@ callArityExpr env (App f a) = do
     case considerThunkSharing a arg_usage of
       Absent -> return (ut_f', App f' a)
       Used m arg_use -> do
-          -- `m` will be `Once` most of the time (see `considerThunkSharing`),
-          -- so that all work before the lambda is uncovered will be shared 
-          -- (call-by-need!). This is the same argument as for let-bound 
-          -- right hand sides.
-          -- We could also use the multiplicity in the same way we do for
-          -- let-bindings: An argument only used once does not need to be
-          -- memoized.
-          (ut_a, a') <- first (multiplyUsages m) <$> transfer_a arg_use
-          --pprTrace "App:a'" (text "arg_use:" <+> ppr arg_use <+> ppr (ut_a, a')) $ return ()
-          return (ut_f' `bothUsageType` ut_a, App f' a')
+        -- `m` will be `Once` most of the time (see `considerThunkSharing`),
+        -- so that all work before the lambda is uncovered will be shared 
+        -- (call-by-need!). This is the same argument as for let-bound 
+        -- right hand sides.
+        -- We could also use the multiplicity in the same way we do for
+        -- let-bindings: An argument only used once does not need to be
+        -- memoized.
+        (ut_a, a') <- first (multiplyUsages m) <$> transfer_a arg_use
+        --pprTrace "App:a'" (text "arg_use:" <+> ppr arg_use <+> ppr (ut_a, a')) $ return ()
+        return (ut_f' `bothUsageType` ut_a, App f' a')
 
 callArityExpr env (Case scrut case_bndr ty alts) = do
   transfer_scrut <- callArityExpr (descend 0 env) scrut
@@ -719,7 +719,7 @@ callArityExpr env (Let bind e)
                 (ut_usage, Let (Rec old_binds) _) <- dependOnWithDefault (ut_body, Let bind e) (node, use)
                 return (ut_usage, old_binds)
             let transferred_binds = map transferred_bind old_binds
-            (ut, binds') <- unleashLet env rec_flag transferred_binds ut_usage ut_body
+            (ut, binds') <- unleashLet env' rec_flag transferred_binds ut_usage ut_body
             --ut <- pprTrace "Rec:end" (ppr ids) $ return ut
             case rec_flag of
               NonRecursive 
@@ -728,9 +728,6 @@ callArityExpr env (Let bind e)
               _ -> return (ut, Let (Rec binds') e')
       return (node, (transfer, changeDetectorAnalResult node))
 
-useLetUp :: Id -> Bool
-useLetUp id = idArity id == 0
-
 coercionUsageType :: Coercion -> UsageType
 coercionUsageType co = multiplyUsages Many ut
   where
@@ -927,6 +924,9 @@ recFlagOf NonRec{} = NonRecursive
 exprForcedError :: CoreExpr
 exprForcedError = error "Expression component may not be used"
 
+useLetUp :: Id -> Bool
+useLetUp id = idArity id == 0
+
 transferUp :: Id -> CoreExpr -> FrameworkNode -> SingleUse -> TransferFunction AnalResult
 transferUp id rhs node use = do
   (ut, rhs') <- dependOnWithDefault (botUsageType, rhs) (node, use)
@@ -958,11 +958,11 @@ registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`
           -- Now that the whole binding group is in scope in `env'`,
           -- we actually have to attend to our duty and register the
           -- transfer functions associated with `up_node` and `down_node`
-          transfer <- callArityExpr (descend n env') rhs
+          transfer_rhs <- callArityExpr (descend n env') rhs
           let transfer_annotate = monotonize up_node $ \use -> do
                 --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
                 ret@(ut, rhs') <- transfer_rhs use 
-                --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut_rhs)]) $ return ret
+                --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr ut]) $ return ret
                 return ret
           let transfer_args_only use = do
                 -- This makes sure to forget the annotated expression from the up_node, 
@@ -970,7 +970,7 @@ registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`
                 -- termination of the analysis.
                 --use <- pprTrace "args:begin" (ppr id <+> text "::" <+> ppr use) $ return use
                 (ut, _) <- dependOnWithDefault (botUsageType, exprForcedError) (up_node, use)
-                --ut_callee <- pprTrace "args:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr (ut_args ut_callee)]) $ return ut_calle
+                --ut <- pprTrace "args:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr ut]) $ return ut
                 return (ut, exprForcedError)
           let annotate = (transfer_annotate, changeDetectorAnalResult up_node) -- What we register for `up_node`
           let args_only = (transfer_args_only, changeDetectorUsageType)        -- What we register for `down_node`
@@ -1010,7 +1010,6 @@ unleashLet
   -> TransferFunction (UsageType, [(Id, CoreExpr)])
 unleashLet env rec_flag transferred_binds ut_usage ut_body = do
   let fam_envs = ae_fam_envs env
-  let need_sigs = ae_need_sig_annotation env
   let (ids, transferred_rhss) = unzip transferred_binds
   (ut_rhss, rhss') <- fmap unzip $ forM transferred_binds $ \(id, (rhs, transfer)) ->
     unleashUsage rhs transfer (lookupUsage rec_flag ut_usage id)
@@ -1020,21 +1019,20 @@ unleashLet env rec_flag transferred_binds ut_usage ut_body = do
   -- Now use that information to annotate binders.
   let (_, usages) = findBndrsUsages rec_flag fam_envs ut_final ids
   let ids' = setBndrsUsageInfo ids usages
-  ids'' <- forM (zip ids' transferred_rhss) $ \(id, (_, transfer)) ->
-    annotateIdArgUsage need_sigs id transfer
+  ids'' <- forM ids' (annotateIdArgUsage env) 
 
   -- This intentionally still contains the @Id@s of the binding group, because
   -- the recursive rule looks at their usages to determine stability.
   return (ut_final, zip ids'' rhss')
 
 annotateIdArgUsage
-  :: VarSet
+  :: AnalEnv
   -> Id
-  -> (SingleUse -> TransferFunction AnalResult)
   -> TransferFunction Id
-annotateIdArgUsage need_sigs id transfer_rhs
-  | not (id `elemVarSet` need_sigs) = return id
-  | otherwise = do
+annotateIdArgUsage env id
+  | id `elemVarSet` (ae_need_sig_annotation env)
+  , Just transfer_callee <- lookupVarEnv (ae_sigs env) id
+  = do
     -- We can't eta-expand beyond idArity anyway (exported!), so our best
     -- bet is a single call with idArity.
     -- Note that in the case where idArity id == 0, there is no interesting
@@ -1042,8 +1040,10 @@ annotateIdArgUsage need_sigs id transfer_rhs
     -- In that case we *could* try to analyze with arity 1, just for the
     -- signature.
     let single_call = iterate (mkCallUse Once) topSingleUse !! idArity id
-    usage_sig <- ut_args . fst <$> transfer_rhs single_call
+    usage_sig <- ut_args <$> transfer_callee single_call
     return (id `setIdArgUsage` usage_sig)
+  | otherwise
+  = return id
 
 unleashUsage
   :: CoreExpr
diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index 88a00a3a1e..5df1a11055 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -13,6 +13,7 @@ import FamInstEnv
 import Id
 import Outputable
 import Usage
+import Util
 import Var
 
 combinedDmdAnalProgram :: DynFlags -> FamInstEnvs -> (Activation -> Bool) -> [CoreRule] -> CoreProgram -> IO CoreProgram
@@ -33,8 +34,8 @@ mergeInfo is_lam_bndr id
   -- instead of the whole expression, we get more conservative results in our
   -- new analysis, where there might be multiplied uses on lambda binders if
   -- it has more than one lambda. In that case we have to relax the assert.
-  = WARN( not (is_lam_bndr || isExportedId id || ca_usage `leqUsage` old_usage), text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
-    WARN( not (not (isExportedId id) || ca_usg_sig `leqUsageSig` old_usg_sig), text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
+  = ASSERT2( (is_lam_bndr || isExportedId id || ca_usage `leqUsage` old_usage), text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
+    ASSERT2( (not (isExportedId id) || ca_usg_sig `leqUsageSig` old_usg_sig), text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
     --pprTrace "mergeInfo" (ppr id <+> text "Demand:" <+> ppr old_demand <+> ppr ca_usage <+> ppr new_demand <+> text "Strictness" <+> ppr old_str_sig <+> ppr ca_usg_sig <+> ppr new_str_sig) $
     id'
   where
-- 
2.12.1


From bc1a73119bebc09fa1f73da8c19583e65ba1f9cc Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 2 Jun 2017 23:22:44 +0200
Subject: [PATCH 083/117] Ignoring unfoldings again and annotating all
 top-level binders with their ArgUsage

---
 compiler/basicTypes/IdInfo.hs            | 43 ++--------------------------
 compiler/basicTypes/MkId.hs              |  4 +--
 compiler/basicTypes/Usage.hs             |  5 +++-
 compiler/coreSyn/MkCore.hs               |  4 ++-
 compiler/main/TidyPgm.hs                 |  5 ++--
 compiler/simplCore/CallArity/Analysis.hs | 48 +++++++++++++++-----------------
 compiler/simplCore/DmdAnalWrapper.hs     |  7 ++---
 compiler/simplCore/SimplCore.hs          | 10 ++-----
 testsuite/tests/lib/integer/Makefile     |  6 ++--
 9 files changed, 45 insertions(+), 87 deletions(-)

diff --git a/compiler/basicTypes/IdInfo.hs b/compiler/basicTypes/IdInfo.hs
index ca9ff1f121..b7f5410c32 100644
--- a/compiler/basicTypes/IdInfo.hs
+++ b/compiler/basicTypes/IdInfo.hs
@@ -252,50 +252,11 @@ data IdInfo
         strictnessInfo  :: !StrictSig,
         demandInfo      :: !Demand,
         argUsageInfo    :: !UsageSig,
-        callArityInfo   :: !Usage
+        callArityInfo   :: !Usage,
 
-        levityInfo      :: LevityInfo    -- ^ when applied, will this Id ever have a levity-polymorphic type?
-        --cardinalityInfo :: CardinalityInfo      -- ^ Evaluation cardinality of the binder and its arguments
+        levityInfo      :: LevityInfo           -- ^ when applied, will this Id ever have a levity-polymorphic type?
     }
 
--- | Cardinality information about a binder.
---
--- The cardinality of a binder represents how often it is evaluated/called.
--- Interesting cardinalities are {0, 1, $\omega$}, where $\omega$ means
--- multiple times.
---
--- Strictness and usage analysis compute approximations to the
--- actual runtime cardinality: Strictness analysis will compute a *lower* bound
--- for the cadinality (e.g. 'is this evaluated at least once?'), whereas
--- usage analysis computes upper bounds for cardinality (e.g. 'not used at all',
--- 'used at most once'). The results are saved in @ci_demanded@ and @ci_used@.
---
--- For second-order strictness and usage analysis, we also store signatures of
--- how the binder evaluates *its arguments* on evaluation. These signatures are
--- stored in @ci_argStrictness@ and @ci_argUsage@ and persisted in interface
--- files for analysis information flow across module boundaries.
-data CardinalityInfo
-  = CardinalityInfo {
-        ci_argStrictness :: !StrictSig,
-        -- ^ What strictness is unleashed upon *arguments* if this @Id@ is called
-        ci_argUsage      :: !UsageSig,
-        -- ^ What usage is unleashed upon *arguments* if this @Id@ is called
-        ci_demanded      :: !Demand,
-        -- ^ Is this binding used *at least* once (e.g. strict)?
-        ci_used          :: !Usage
-        -- ^ Is this binding used *at most* never, once or multiple times?
-        -- What is the minimum number of arguments it was called with?
-  }
-
-emptyCardinalityInfo :: CardinalityInfo
-emptyCardinalityInfo
-  = CardinalityInfo {
-        ci_argStrictness = nopSig,
-        ci_argUsage      = topUsageSig,
-        ci_demanded      = topDmd,
-        ci_used          = topUsage
-  }
-
 -- Setters
 
 setRuleInfo :: IdInfo -> RuleInfo -> IdInfo
diff --git a/compiler/basicTypes/MkId.hs b/compiler/basicTypes/MkId.hs
index 02b5797732..45ff88cedb 100644
--- a/compiler/basicTypes/MkId.hs
+++ b/compiler/basicTypes/MkId.hs
@@ -323,7 +323,7 @@ mkDictSelId name clas
             | otherwise = mkManyUsedDmd $
                           mkProdDmd [ if name == sel_name then evalDmd else absDmd
                                     | sel_name <- sel_names ]
-    usage_sig = consUsageSig arg_usg topUsageSig
+    usage_sig = usageSigFromUsages [arg_usg]
     arg_usg | new_tycon = topUsage
             | otherwise = Usage.Used Usage.Many $ 
                             mkProductUse [ if name == sel_name then topUsage else botUsage
@@ -1241,7 +1241,7 @@ runRWId = pcMiscPrelId runRWName ty info
       -- Important to express its strictness,
       -- since it is not inlined until CorePrep
       -- Also see Note [runRW arg] in CorePrep
-    usage_sig = consUsageSig u'1C1U topUsageSig
+    usage_sig = usageSigFromUsages [u'1C1U]
 
     -- State# RealWorld
     stateRW = mkTyConApp statePrimTyCon [realWorldTy]
diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 201a47e35c..6d3a63a28a 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -9,7 +9,7 @@ module Usage
   , multiplicity, botUsage, topUsage, lubUsage, bothUsage
   , manifyUsage, oneifyUsage, expandArity
   , UsageSig
-  , botUsageSig, topUsageSig, lubUsageSig
+  , botUsageSig, topUsageSig, lubUsageSig, leqUsageSig
   , consUsageSig, unconsUsageSig, usageSigFromUsages, manifyUsageSig
   , trimSingleUse, trimUsage, trimUsageSig
   , u'1HU, u'1C1U
@@ -192,6 +192,9 @@ lubUsageSig TopUsageSig _ = TopUsageSig
 lubUsageSig _ TopUsageSig = TopUsageSig
 lubUsageSig (ArgUsage u1 s1) (ArgUsage u2 s2) = consUsageSig (lubUsage u1 u2) (lubUsageSig s1 s2)
 
+leqUsageSig :: UsageSig -> UsageSig -> Bool
+leqUsageSig u1 u2 = lubUsageSig u1 u2 == u2
+
 -- * Working with `SingleUse`, `Usage` and `UsageSig`
 
 -- | Eliminates a `Call`. This will return the `Usage` of the lambda body,
diff --git a/compiler/coreSyn/MkCore.hs b/compiler/coreSyn/MkCore.hs
index 5a29994d0e..b7ad5c8c40 100644
--- a/compiler/coreSyn/MkCore.hs
+++ b/compiler/coreSyn/MkCore.hs
@@ -69,8 +69,9 @@ import Coercion         ( isCoVar )
 import TysPrim
 import DataCon          ( DataCon, dataConWorkId )
 import IdInfo           ( vanillaIdInfo, setStrictnessInfo,
-                          setArityInfo )
+                          setArgUsageInfo, setArityInfo )
 import Demand
+import Usage
 import Name      hiding ( varName )
 import Outputable
 import FastString
@@ -741,6 +742,7 @@ mkRuntimeErrorId name
  = mkVanillaGlobalWithInfo name runtime_err_ty bottoming_info
  where
     bottoming_info = vanillaIdInfo `setStrictnessInfo`    strict_sig
+                                   `setArgUsageInfo`      topUsageSig
                                    `setArityInfo`         1
                         -- Make arity and strictness agree
 
diff --git a/compiler/main/TidyPgm.hs b/compiler/main/TidyPgm.hs
index fa0577d486..0c1e62051f 100644
--- a/compiler/main/TidyPgm.hs
+++ b/compiler/main/TidyPgm.hs
@@ -1242,14 +1242,14 @@ tidyTopIdInfo dflags rhs_tidy_env name orig_rhs tidy_rhs idinfo show_unfold caf_
         `setCafInfo`        caf_info
         `setArityInfo`      arity
         `setStrictnessInfo` final_sig
-        `setArgUsageInfo`   arg_usage
+        `setArgUsageInfo`   (argUsageInfo idinfo)
 
   | otherwise           -- Externally-visible Ids get the whole lot
   = vanillaIdInfo
         `setCafInfo`           caf_info
         `setArityInfo`         arity
         `setStrictnessInfo`    final_sig
-        `setArgUsageInfo`      arg_usage
+        `setArgUsageInfo`      (argUsageInfo idinfo)
         `setOccInfo`           robust_occ_info
         `setInlinePragInfo`    (inlinePragInfo idinfo)
         `setUnfoldingInfo`     unfold_info
@@ -1305,7 +1305,6 @@ tidyTopIdInfo dflags rhs_tidy_env name orig_rhs tidy_rhs idinfo show_unfold caf_
     -- it to the top level. So it seems more robust just to
     -- fix it here.
     arity = exprArity orig_rhs
-    arg_usage = argUsageInfo idinfo
 
 {-
 ************************************************************************
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 416bdc18e7..93b0ebc7dc 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -14,7 +14,7 @@ import CallArity.FrameworkBuilder
 import BasicTypes
 import Class
 import Coercion ( Coercion, coVarsOfCo )
-import CoreFVs ( idRuleRhsVars, rulesFreeVars )
+import CoreFVs ( rulesFreeVars, idRuleRhsVars )
 import CoreSyn
 import CoreUtils ( exprIsTrivial )
 import DataCon
@@ -460,29 +460,27 @@ extendAnalEnv env id node
   = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
 
 -- | See Note [Analysing top-level-binds]
--- `programToExpr` returns a pair of externally visible top-level `Id`s
--- (including at least exports and mentions in RULEs) and a nested
--- `let` expression to be analysed by `callArityRHS`.
+-- `programToExpr` returns a pair of all top-level `Id`s
+-- and a nested `let` expression that uses everything externally visible.
+-- This `let` expression is then to be analysed by `callArityRHS`.
 --
 -- Represents the fact that a `CoreProgram` is like a sequence of
 -- nested lets, where the external visible ids are returned in the inner-most let
--- as a tuple. As a result, all exported identifiers are handled as called
+-- as a tuple. As a result, all visible identifiers are handled as called
 -- with each other, with `topUsage`.
 programToExpr 
-  :: (Activation -> Bool)
-  -> [CoreRule]
+  :: [CoreRule]
   -> CoreProgram 
   -> (VarSet, CoreExpr)
-programToExpr is_active_rule orphan_rules = impl (rulesFreeVars orphan_rules)
+programToExpr orphan_rules = impl [] (rulesFreeVars orphan_rules)
   where
-    impl :: VarSet -> CoreProgram -> (VarSet, CoreExpr)
-    impl exposed []
-      = (exposed, mkBigCoreVarTup (nonDetEltsUFM exposed))
+    impl top_level_ids exposed []
+      = (mkVarSet top_level_ids, mkBigCoreVarTup (nonDetEltsUFM exposed))
         -- nonDetEltsUFM is OK, because all product components will
         -- used in the same way anyway.
-    impl exposed (bind:prog)
-      = second (Let bind) (impl (exposed_ids bind `unionVarSet` exposed) prog)
-    -- We need *at least*  
+    impl top_level_ids exposed (bind:prog)
+      = second (Let bind) (impl (bindersOf bind ++ top_level_ids) (exposed_ids bind `unionVarSet` exposed) prog)
+    -- We need to use *at least*  
     -- 
     --   * exported `Id`s (`isExportedId`)
     --   * `Id`s mentioned in any RULE's RHS of this module
@@ -501,6 +499,7 @@ programToExpr is_active_rule orphan_rules = impl (rulesFreeVars orphan_rules)
       where
         bs = bindersOf bind
         exported = mkVarSet (filter isExportedId bs)
+        is_active_rule _ = True -- Conservative, but we should be fine
         rules = map (idRuleRhsVars is_active_rule) bs
 
 -- | The left inverse to `programToExpr`: `exprToProgram . snd . programToExpr = id \@CoreProgram`
@@ -512,16 +511,15 @@ exprToProgram _ = []
 callArityAnalProgram 
   :: DynFlags 
   -> FamInstEnvs 
-  -> (Activation -> Bool)
   -> [CoreRule]
   -> CoreProgram 
   -> IO CoreProgram
-callArityAnalProgram dflags fam_envs is_active_rule orphan_rules
+callArityAnalProgram dflags fam_envs orphan_rules
   = return 
   -- . (\it -> pprTrace "callArity:end" (ppr (length it)) it) 
   . exprToProgram 
   . uncurry (callArityRHS dflags fam_envs) 
-  . programToExpr is_active_rule orphan_rules
+  . programToExpr orphan_rules
   -- . (\it -> pprTrace "callArity:begin" (ppr (length it)) it)
   -- . (\prog -> pprTrace "CallArity:Program" (ppr prog) prog)
 
@@ -627,7 +625,7 @@ callArityExpr env (Lam id body)
         Absent -> do
           let id' = id `setIdCallArity` Absent
           return (emptyUsageType, Lam id' body)
-        u@(Used multi body_use) -> do
+        Used multi body_use -> do
           (ut_body, body') <- transfer_body body_use
           let (ut_body', usage_id) = findBndrUsage NonRecursive (ae_fam_envs env) ut_body id
           let id' = applyWhen (multi == Once) (`setIdOneShotInfo` OneShotLam)
@@ -690,7 +688,6 @@ callArityExpr env (Let bind e)
       return (delUsageTypes (bindersOf bind) ut, let')
     register node = do
       let initial_binds = flattenBinds [bind]
-      let ids = map fst initial_binds
       -- We retain nodes we need for the body, so that they have lower
       -- priority than the bindings.
       retained <- retainNodes (predictSizeOfLetBody env)
@@ -698,7 +695,7 @@ callArityExpr env (Let bind e)
       freeRetainedNodes retained
       let lookup_node id =
             expectJust ": the RHS of id wasn't registered" (lookupVarEnv rhs_env id)
-      let transferred_bind b@(id, rhs) = (id, (rhs, lookup_node id))
+      let transferred_bind (id, rhs) = (id, (rhs, lookup_node id))
       -- Ideally we'd want the body to have a lower priority than the RHSs,
       -- but we need to access env' with the new sigs in the body, so we
       -- can't register it earlier.
@@ -795,17 +792,18 @@ globalIdUsageSig id use
   | use <= no_call -- @f x `seq` ...@ for a GlobalId `f` with arity > 1
   = botUsageSig
   | use <= single_call
-  = arg_usage
+  = ASSERT2( usg_sig `leqUsageSig` str_sig, text "usg_sig:" <+> ppr usg_sig <+> text "str_sig:" <+> ppr str_sig ) usg_sig
   | otherwise
   = --pprTrace "many" (ppr arg_usage <+> ppr (idStrictness id) <+> ppr (manifyUsageSig arg_usage)) $ 
-    manifyUsageSig arg_usage
+    manifyUsageSig usg_sig
   where
     (<=) = leqSingleUse
     arity = idArity id
     mk_one_shot = mkCallUse Once
     no_call = iterate mk_one_shot botSingleUse !! max 0 (arity - 1)
     single_call = iterate mk_one_shot topSingleUse !! arity
-    arg_usage = idArgUsage id
+    usg_sig = idArgUsage id
+    str_sig = usageSigFromStrictSig (idStrictness id)
 
 -- | Evaluation of a non-trivial RHS of a let-binding or argument 
 -- is shared (call-by-need!). GHC however doesn't allocate a new thunk
@@ -993,7 +991,6 @@ changeDetectorUsageType _ (old, _) (new, _) =
     new_uses = ut_uses new
     old_cocalled = ut_cocalled old
     new_cocalled = ut_cocalled new
-    leqUsageSig a b = lubUsageSig a b == b
 
 changeDetectorAnalResult :: FrameworkNode -> ChangeDetector
 changeDetectorAnalResult self_node changed_refs (old, e) (new, e') =
@@ -1010,7 +1007,7 @@ unleashLet
   -> TransferFunction (UsageType, [(Id, CoreExpr)])
 unleashLet env rec_flag transferred_binds ut_usage ut_body = do
   let fam_envs = ae_fam_envs env
-  let (ids, transferred_rhss) = unzip transferred_binds
+  let ids = fst . unzip $ transferred_binds
   (ut_rhss, rhss') <- fmap unzip $ forM transferred_binds $ \(id, (rhs, transfer)) ->
     unleashUsage rhs transfer (lookupUsage rec_flag ut_usage id)
   let ut_final = callArityLetEnv (zip ids ut_rhss) ut_body
@@ -1041,6 +1038,7 @@ annotateIdArgUsage env id
     -- signature.
     let single_call = iterate (mkCallUse Once) topSingleUse !! idArity id
     usage_sig <- ut_args <$> transfer_callee single_call
+    --pprTrace "annotating" (ppr id <+> ppr usage_sig) $ return ()
     return (id `setIdArgUsage` usage_sig)
   | otherwise
   = return id
diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index 5df1a11055..82f062da7d 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -4,7 +4,6 @@ module DmdAnalWrapper (combinedDmdAnalProgram) where
 
 #include "HsVersions.h"
 
-import BasicTypes
 import CallArity
 import CoreSyn
 import DmdAnal
@@ -16,11 +15,11 @@ import Usage
 import Util
 import Var
 
-combinedDmdAnalProgram :: DynFlags -> FamInstEnvs -> (Activation -> Bool) -> [CoreRule] -> CoreProgram -> IO CoreProgram
-combinedDmdAnalProgram dflags fams is_active_rule orphan_rules prog = do
+combinedDmdAnalProgram :: DynFlags -> FamInstEnvs -> [CoreRule] -> CoreProgram -> IO CoreProgram
+combinedDmdAnalProgram dflags fams orphan_rules prog = do
   -- Call Arity first, suggesting the fact that there's no information flow
   -- from DA to CA. There isn't from CA to DA either, of course.
-  prog' <- callArityAnalProgram dflags fams is_active_rule orphan_rules prog
+  prog' <- callArityAnalProgram dflags fams orphan_rules prog
   prog'' <- dmdAnalProgram dflags fams prog'
   --pprTrace "Program" (ppr prog'') $ pure ()
   return (mapBndrsProgram mergeInfo prog'')
diff --git a/compiler/simplCore/SimplCore.hs b/compiler/simplCore/SimplCore.hs
index 39a0a4c5d1..c25e99d6ee 100644
--- a/compiler/simplCore/SimplCore.hs
+++ b/compiler/simplCore/SimplCore.hs
@@ -34,7 +34,7 @@ import FloatOut         ( floatOutwards )
 import FamInstEnv
 import Id
 import ErrUtils         ( withTiming )
-import BasicTypes       ( Activation, CompilerPhase(..), isDefaultInlinePragma )
+import BasicTypes       ( CompilerPhase(..), isDefaultInlinePragma )
 import VarSet
 import VarEnv
 import LiberateCase     ( liberateCase )
@@ -543,17 +543,13 @@ doPassDU do_pass = doPassDUM (\dflags us -> return . do_pass dflags us)
 doPassU :: (UniqSupply -> CoreProgram -> CoreProgram) -> ModGuts -> CoreM ModGuts
 doPassU do_pass = doPassDU (const do_pass)
 
-doPassDFRM :: (DynFlags -> FamInstEnvs -> (Activation -> Bool) -> [CoreRule] -> CoreProgram -> IO CoreProgram) -> ModGuts -> CoreM ModGuts
+doPassDFRM :: (DynFlags -> FamInstEnvs -> [CoreRule] -> CoreProgram -> IO CoreProgram) -> ModGuts -> CoreM ModGuts
 doPassDFRM do_pass guts = do
     dflags <- getDynFlags
     p_fam_env <- getPackageFamInstEnv
     let fam_envs = (p_fam_env, mg_fam_inst_env guts)
-    -- No idea how to get at the SimplifierMode mode here,
-    -- or what else to choose as is_active_rule predicate.
-    -- let is_active_rule = activeRule (mkSimplEnv mode)
-    let is_active_rule = const True 
     let orphan_rules = mg_rules guts
-    doPassM (liftIO . do_pass dflags fam_envs is_active_rule orphan_rules) guts
+    doPassM (liftIO . do_pass dflags fam_envs orphan_rules) guts
 
 doPassDFU :: (DynFlags -> FamInstEnvs -> UniqSupply -> CoreProgram -> CoreProgram) -> ModGuts -> CoreM ModGuts
 doPassDFU do_pass guts = do
diff --git a/testsuite/tests/lib/integer/Makefile b/testsuite/tests/lib/integer/Makefile
index aa2704ab6d..f7004ef675 100644
--- a/testsuite/tests/lib/integer/Makefile
+++ b/testsuite/tests/lib/integer/Makefile
@@ -7,7 +7,7 @@ CHECK = grep -q -- '$1' integerConstantFolding.simpl || \
 
 .PHONY: integerConstantFolding
 integerConstantFolding:
-	'$(TEST_HC)' -Wall -v0 -O --make integerConstantFolding -fforce-recomp -ddump-simpl > integerConstantFolding.simpl
+	'$(TEST_HC)' -Wall -v0 -O --make integerConstantFolding -fforce-recomp -dno-debug-output -ddump-simpl > integerConstantFolding.simpl
 # All the 100nnn values should be constant-folded away
 	! grep -q '\<100[0-9][0-9][0-9]\>' integerConstantFolding.simpl || { echo "Unfolded values found"; grep '\<100[0-9][0-9][0-9]\>' integerConstantFolding.simpl; }
 	$(call CHECK,\<200007\>,plusInteger)
@@ -40,7 +40,7 @@ integerConstantFolding:
 
 .PHONY: fromToInteger
 fromToInteger:
-	'$(TEST_HC)' -Wall -v0 -O -c fromToInteger.hs -fforce-recomp -ddump-simpl > fromToInteger.simpl
+	'$(TEST_HC)' -Wall -v0 -O -c fromToInteger.hs -fforce-recomp -dno-debug-output -ddump-simpl > fromToInteger.simpl
 # Rules should eliminate all functions
 	-grep integerToInt fromToInteger.simpl
 	-grep smallInteger fromToInteger.simpl
@@ -49,7 +49,7 @@ fromToInteger:
 
 .PHONY: IntegerConversionRules
 IntegerConversionRules:
-	'$(TEST_HC)' -Wall -v0 -O -c $@.hs -fforce-recomp -ddump-simpl > $@.simpl
+	'$(TEST_HC)' -Wall -v0 -O -c $@.hs -fforce-recomp -dno-debug-output -ddump-simpl > $@.simpl
 	-grep -q smallInteger      $@.simpl && echo "smallInteger present"
 	-grep -q doubleFromInteger $@.simpl && echo "doubleFromInteger present"
 	-grep -q int2Double        $@.simpl || echo "int2Double absent"
-- 
2.12.1


From 6b3b0adfe5bcda288f580bac259511d4a3ce0b3f Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sat, 3 Jun 2017 12:28:36 +0200
Subject: [PATCH 084/117] Fixed T11248.hs, raise# doesn't use any arguments
 beyond the first

---
 compiler/basicTypes/Usage.hs | 12 ++++++++++--
 1 file changed, 10 insertions(+), 2 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 6d3a63a28a..e5455e266e 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -450,9 +450,17 @@ instance Binary UsageSig where
 -- all entries in primops.txt.pp.
 usageSigFromStrictSig :: StrictSig -> UsageSig
 usageSigFromStrictSig sig
-  = usageSigFromUsages (map (usageFromArgUse . Demand.getUseDmd) dmds)
+  = foldr consUsageSig tail_sig
+  . map (usageFromArgUse . Demand.getUseDmd) 
+  $ dmds
   where
-    (dmds, _) = splitStrictSig sig
+    (dmds, res) = splitStrictSig sig
+    tail_sig
+      |  res == Demand.exnRes 
+      || res == Demand.botRes 
+      = botUsageSig -- Diverging or throwing: all other args are unused
+      | otherwise 
+      = topUsageSig 
 
 multiplicityFromCount :: Demand.Count -> Multiplicity
 multiplicityFromCount Demand.One = Once
-- 
2.12.1


From d817f4f667d34abb3feac057b79ab981cbcf0dd7 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sat, 3 Jun 2017 18:04:18 +0200
Subject: [PATCH 085/117] Fixed the usual suspects

---
 compiler/basicTypes/Usage.hs | 5 ++---
 compiler/coreSyn/MkCore.hs   | 2 +-
 compiler/iface/ToIface.hs    | 2 +-
 3 files changed, 4 insertions(+), 5 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index e5455e266e..201baceb66 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -454,10 +454,9 @@ usageSigFromStrictSig sig
   . map (usageFromArgUse . Demand.getUseDmd) 
   $ dmds
   where
-    (dmds, res) = splitStrictSig sig
+    (dmds, _) = splitStrictSig sig
     tail_sig
-      |  res == Demand.exnRes 
-      || res == Demand.botRes 
+      | Demand.isBottomingSig sig
       = botUsageSig -- Diverging or throwing: all other args are unused
       | otherwise 
       = topUsageSig 
diff --git a/compiler/coreSyn/MkCore.hs b/compiler/coreSyn/MkCore.hs
index b7ad5c8c40..9bfab9fa02 100644
--- a/compiler/coreSyn/MkCore.hs
+++ b/compiler/coreSyn/MkCore.hs
@@ -742,7 +742,7 @@ mkRuntimeErrorId name
  = mkVanillaGlobalWithInfo name runtime_err_ty bottoming_info
  where
     bottoming_info = vanillaIdInfo `setStrictnessInfo`    strict_sig
-                                   `setArgUsageInfo`      topUsageSig
+                                   `setArgUsageInfo`      (usageSigFromStrictSig strict_sig)
                                    `setArityInfo`         1
                         -- Make arity and strictness agree
 
diff --git a/compiler/iface/ToIface.hs b/compiler/iface/ToIface.hs
index eed6138f84..4d8880adb9 100644
--- a/compiler/iface/ToIface.hs
+++ b/compiler/iface/ToIface.hs
@@ -374,7 +374,7 @@ toIfaceIdInfo id_info
                     usage_hsinfo, inline_hsinfo,  unfold_hsinfo, levity_hsinfo] of
        []    -> NoInfo
        infos -> HasInfo infos
-               -- NB: strictness and arity must appear in the list before unfolding
+               -- NB: strictness, usage and arity must appear in the list before unfolding
                -- See TcIface.tcUnfolding
   where
     ------------  Arity  --------------
-- 
2.12.1


From 6a132130d9e08a80bbee5759055ee5e9111e3a63 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sat, 3 Jun 2017 18:04:18 +0200
Subject: [PATCH 086/117] Fixed the usual suspects

---
 testsuite/tests/simplCore/should_compile/T3717.stderr       | 2 +-
 testsuite/tests/simplCore/should_compile/T4908.stderr       | 1 +
 testsuite/tests/simplCore/should_compile/spec-inline.stderr | 4 +++-
 3 files changed, 5 insertions(+), 2 deletions(-)

diff --git a/testsuite/tests/simplCore/should_compile/T3717.stderr b/testsuite/tests/simplCore/should_compile/T3717.stderr
index b98170d802..0aa4d08ee4 100644
--- a/testsuite/tests/simplCore/should_compile/T3717.stderr
+++ b/testsuite/tests/simplCore/should_compile/T3717.stderr
@@ -51,7 +51,7 @@ Rec {
 -- RHS size: {terms: 10, types: 2, coercions: 0, joins: 0/0}
 T3717.$wfoo [InlPrag=[0], Occ=LoopBreaker]
   :: GHC.Prim.Int# -> GHC.Prim.Int#
-[GblId, Arity=1, Caf=NoCafRefs, Str=<S,1*U>]
+[GblId, Arity=1, Caf=NoCafRefs, Str=<S,1*U>, ArgUsg=1*U,w*U,w*U..]
 T3717.$wfoo =
   \ (ww :: GHC.Prim.Int#) ->
     case ww of ds {
diff --git a/testsuite/tests/simplCore/should_compile/T4908.stderr b/testsuite/tests/simplCore/should_compile/T4908.stderr
index 2d02420bf6..0b72938373 100644
--- a/testsuite/tests/simplCore/should_compile/T4908.stderr
+++ b/testsuite/tests/simplCore/should_compile/T4908.stderr
@@ -73,6 +73,7 @@ T4908.$wf [InlPrag=[0]] :: Int# -> (Int, Int) -> Bool
  Arity=2,
  Caf=NoCafRefs,
  Str=<S,1*U><L,1*U(A,1*U(1*U))>,
+ ArgUsg=1*U,1*U(A,1*U(1*U)),w*U,w*U..,
  Unf=Unf{Src=<vanilla>, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True, Guidance=IF_ARGS [30 20] 101 20}]
 T4908.$wf =
diff --git a/testsuite/tests/simplCore/should_compile/spec-inline.stderr b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
index 84278cd982..bf52aed635 100644
--- a/testsuite/tests/simplCore/should_compile/spec-inline.stderr
+++ b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
@@ -54,7 +54,7 @@ lvl = "spec-inline.hs:(19,5)-(29,25)|function go"#
 
 -- RHS size: {terms: 2, types: 2, coercions: 0, joins: 0/0}
 Roman.foo3 :: Int
-[GblId, Str=x]
+[GblId, Str=x, ArgUsg=A,A..]
 Roman.foo3 =
   Control.Exception.Base.patError @ 'GHC.Types.LiftedRep @ Int lvl
 
@@ -94,6 +94,7 @@ Roman.$wgo [InlPrag=[0]] :: Maybe Int -> Maybe Int -> GHC.Prim.Int#
 [GblId,
  Arity=2,
  Str=<S,1*U><S,1*U>,
+ ArgUsg=1*U,1*U,w*U,w*U..,
  Unf=Unf{Src=<vanilla>, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True, Guidance=IF_ARGS [60 30] 256 0}]
 Roman.$wgo =
@@ -138,6 +139,7 @@ Roman.foo_go [InlPrag=INLINE[0]] :: Maybe Int -> Maybe Int -> Int
 [GblId,
  Arity=2,
  Str=<S,1*U><S,1*U>m,
+ ArgUsg=1*U,1*U,w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=2,unsat_ok=True,boring_ok=False)
-- 
2.12.1


From 7a032ea486aeac83791038bf9814d447ab4414a5 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sat, 3 Jun 2017 22:32:48 +0200
Subject: [PATCH 087/117] New references are changed references, too

---
 compiler/utils/UnVarGraph.hs | 4 +++-
 compiler/utils/Worklist.hs   | 3 ++-
 2 files changed, 5 insertions(+), 2 deletions(-)

diff --git a/compiler/utils/UnVarGraph.hs b/compiler/utils/UnVarGraph.hs
index c234697334..7c8882534d 100644
--- a/compiler/utils/UnVarGraph.hs
+++ b/compiler/utils/UnVarGraph.hs
@@ -232,5 +232,7 @@ delNode (UnVarGraph ei g _) v
 
 instance Outputable UnVarGraph where
     ppr u@(UnVarGraph ei g _) 
-      | ei == Additive = ppr g
+      | ei == Additive 
+      = brackets . hcat . punctuate comma 
+      $ [ ppr (getUnique k) <+> text ":->" <+> ppr v | (k, v) <- IntMap.toList g ]
       | otherwise = ppr (complementUnVarGraph u)
diff --git a/compiler/utils/Worklist.hs b/compiler/utils/Worklist.hs
index 86f853d71a..8a8287f77b 100644
--- a/compiler/utils/Worklist.hs
+++ b/compiler/utils/Worklist.hs
@@ -159,7 +159,8 @@ recompute node = do
   --pprTrace "recompute:refs" (ppr (length refs)) $ return ()
   oldInfo <- updateGraphNode node newVal refs
   --pprTrace "recompute:referrers" (ppr (length (referrers oldInfo))) $ return ()
-  changedRefs <- fromMaybe Set.empty <$> deleteLookupUnstable node
+  let add_new_refs = Set.union (Set.difference refs (references oldInfo)) -- new refs are changes, too!
+  changedRefs <- add_new_refs . fromMaybe Set.empty <$> deleteLookupUnstable node
   case value oldInfo of
     Just oldVal | not (detectChange changedRefs oldVal newVal) -> return ()
     _ -> do
-- 
2.12.1


From 24225bdb69ef52f0070a2f419416edcce1762b28 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sat, 3 Jun 2017 23:11:00 +0200
Subject: [PATCH 088/117] Marking binders in Absent expressions Absent now

---
 compiler/simplCore/CallArity/Analysis.hs | 24 +++++++++++++++++++++---
 1 file changed, 21 insertions(+), 3 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 93b0ebc7dc..7311e8211f 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -34,7 +34,7 @@ import VarEnv
 import VarSet
 import WwLib ( findTypeShape )
 
-import Control.Arrow ( first, second )
+import Control.Arrow ( first, second, (***) )
 import Control.Monad ( forM )
 import qualified Data.Set as Set
 import Data.Tree
@@ -650,7 +650,7 @@ callArityExpr env (App f a) = do
     -- peel off one argument from the type
     let (arg_usage, ut_f') = peelArgUsage ut_f
     case considerThunkSharing a arg_usage of
-      Absent -> return (ut_f', App f' a)
+      Absent -> return (ut_f', App f' (markAbsent a))
       Used m arg_use -> do
         -- `m` will be `Once` most of the time (see `considerThunkSharing`),
         -- so that all work before the lambda is uncovered will be shared 
@@ -1049,7 +1049,7 @@ unleashUsage
   -> (Usage -> TransferFunction AnalResult)
 unleashUsage rhs transfer_rhs usage
   | Absent <- usage
-  = return (emptyUsageType, rhs)
+  = return (emptyUsageType, markAbsent rhs)
   | Used m use <- considerThunkSharing rhs usage
   -- As with arguments, `m` should be `Once` most of the time 
   -- (e.g. if `rhs` is non-trivial, see `considerThunkSharing`).
@@ -1114,3 +1114,21 @@ callArityLetEnv rhss ut_body
         -- cocalls in the complete graph.
         | length ut_rhss > 25 = bothUsageTypes ut_all
         | otherwise           = lubUsageTypes (ut_all ++ map cross_calls rhss)
+
+markAbsent :: CoreExpr -> CoreExpr
+markAbsent = expr
+  where 
+    abs id = id `setIdCallArity` Absent
+    expr e = case e of
+      App f a -> App (expr f) (expr a)
+      -- I better leave the binder untouched for now... Don't want to break 
+      -- stuff that expects absent closures to be compilable
+      Lam id body -> Lam id (expr body) 
+      Let binds body -> Let (bind binds) (expr body)
+      Case scrut bndr ty alts -> Case (expr scrut) (abs bndr) ty (map alt alts)
+      Cast e co -> Cast (expr e) co
+      Tick t e -> Tick t (expr e)
+      _ -> e
+    bind (NonRec id rhs) = NonRec (abs id) (expr rhs)
+    bind (Rec binds) = Rec (map (abs *** expr) binds)
+    alt (dc, bndrs, body) = (dc, map abs bndrs, expr body)
\ No newline at end of file
-- 
2.12.1


From 6e0cbdf5e050e6bc6d185d3a60b0321c7a7daff0 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 4 Jun 2017 11:55:33 +0200
Subject: [PATCH 089/117] Fixed `unionVarGraph` in the subtractive case

---
 compiler/utils/UnVarGraph.hs | 30 ++++++++++++++++++------------
 1 file changed, 18 insertions(+), 12 deletions(-)

diff --git a/compiler/utils/UnVarGraph.hs b/compiler/utils/UnVarGraph.hs
index 7c8882534d..4728dadb08 100644
--- a/compiler/utils/UnVarGraph.hs
+++ b/compiler/utils/UnVarGraph.hs
@@ -160,14 +160,14 @@ unionUnVarGraph :: UnVarGraph -> UnVarGraph -> UnVarGraph
 unionUnVarGraph (UnVarGraph Additive e1 _) (UnVarGraph Additive e2 _)
   = balance $ mkUnVarGraph Additive $ IntMap.unionWith unionUnVarSet e1 e2
 unionUnVarGraph (UnVarGraph Subtractive e1 _) (UnVarGraph Subtractive e2 _)
-  = balance $ mkUnVarGraph Subtractive $ IntMap.unionWithKey merger e1 e2
+  = balance $ mkUnVarGraph Subtractive $ IntMap.unionWith intersectionUnVarSet e1' e2'
   where
-    diff1 = IntMap.keysSet e2 `IntSet.difference` IntMap.keysSet e1
-    diff2 = IntMap.keysSet e1 `IntSet.difference` IntMap.keysSet e2
-    merger n s1 s2
-      | n `IntSet.member` diff1 = s1 `unionUnVarSet` UnVarSet diff2
-      | n `IntSet.member` diff2 = s2 `unionUnVarSet` UnVarSet diff1
-      | otherwise = intersectionUnVarSet s1 s2 
+    -- diffn = nodes of the union *not* mentioned in graph n
+    diff1 = UnVarSet $ IntMap.keysSet e2 `IntSet.difference` IntMap.keysSet e1 -- 4
+    diff2 = UnVarSet $ IntMap.keysSet e1 `IntSet.difference` IntMap.keysSet e2 -- 0
+    e1' = unionUnVarSet diff1 <$> e1
+    e2' = unionUnVarSet diff2 <$> e2
+
 unionUnVarGraph u1 u2
   = unionUnVarGraph u1' u2' -- we could be smarter here
   where
@@ -231,8 +231,14 @@ delNode (UnVarGraph ei g _) v
       | otherwise = delUnVarSet s v
 
 instance Outputable UnVarGraph where
-    ppr u@(UnVarGraph ei g _) 
-      | ei == Additive 
-      = brackets . hcat . punctuate comma 
-      $ [ ppr (getUnique k) <+> text ":->" <+> ppr v | (k, v) <- IntMap.toList g ]
-      | otherwise = ppr (complementUnVarGraph u)
+    ppr (UnVarGraph Additive g _) = pprEdges "+" g
+    ppr (UnVarGraph _ g _) = pprEdges "-" (complementEdges g)
+
+pprEdges :: String -> IntMap UnVarSet -> SDoc
+pprEdges sign
+  = (text "UnVarGraph" <> text sign <+>) 
+  . brackets 
+  . hcat 
+  . punctuate comma 
+  . map (\(k, v) -> ppr (getUnique k) <+> text ":->" <+> ppr v)
+  . IntMap.toList
-- 
2.12.1


From 5ef62554de9e25a624282a236ca523247daec24d Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 4 Jun 2017 12:07:14 +0200
Subject: [PATCH 090/117] Analysis depth for products matches DmdAnal now +
 only marking Ids as absent

---
 compiler/simplCore/CallArity/Analysis.hs | 6 ++++--
 1 file changed, 4 insertions(+), 2 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 7311e8211f..a7228bcc3d 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -891,7 +891,7 @@ propagateProductUse alts scrut_uses
   -- This is a good place to make sure we don't construct an infinitely deep
   -- use, which can happen when analysing e.g. lazy streams.
   -- Also see Note [Demand on scrutinee of a product case] in DmdAnal.hs.
-  = addDataConStrictness dc (boundDepth 6 scrut_use)
+  = addDataConStrictness dc (boundDepth 9 scrut_use) -- 9 seems to be just enough to match DmdAnal
 
   | otherwise
   -- We *could* lub the uses from the different branches, but there's not much
@@ -1118,7 +1118,9 @@ callArityLetEnv rhss ut_body
 markAbsent :: CoreExpr -> CoreExpr
 markAbsent = expr
   where 
-    abs id = id `setIdCallArity` Absent
+    abs id 
+      | isTyVar id = id
+      | otherwise = id `setIdCallArity` Absent
     expr e = case e of
       App f a -> App (expr f) (expr a)
       -- I better leave the binder untouched for now... Don't want to break 
-- 
2.12.1


From 3de8628dbba93ccf2e8072019d0fbe732aaddd24 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 4 Jun 2017 16:38:04 +0200
Subject: [PATCH 091/117] Fixed spec-inline and most of the other irregular
 tests

---
 compiler/basicTypes/Usage.hs                          | 13 +++++--------
 compiler/simplCore/DmdAnalWrapper.hs                  | 19 +++++++++++++------
 .../tests/simplCore/should_compile/spec-inline.stderr |  2 +-
 3 files changed, 19 insertions(+), 15 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 201baceb66..66be54e830 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -349,18 +349,15 @@ manifyUsageSig TopUsageSig = TopUsageSig
 manifyUsageSig BotUsageSig = BotUsageSig
 manifyUsageSig (ArgUsage u s) = consUsageSig (manifyUsage u) (manifyUsageSig s)
 
--- | Trims a `UsageSig` by looking at how the associated value is used.
+-- | Trims a `UsageSig` by arity, so that any arguments beyond that arity get `topUsage`.
 --
--- The resulting `UsageSig` will only have as many arguments as the `SingleUse` has
--- call nestings.
-trimUsageSig :: SingleUse -> UsageSig -> UsageSig
-trimUsageSig _ BotUsageSig = BotUsageSig
-trimUsageSig HeadUse _ = BotUsageSig -- Since the result isn't forced beyond WHNF, no further argument will
+-- It holds that @forall n. trimUsage n sig `leqUsageSig` sig@.
+trimUsageSig :: Arity -> UsageSig -> UsageSig
+trimUsageSig 0 _ = TopUsageSig
 trimUsageSig _ TopUsageSig = TopUsageSig
-trimUsageSig (Call _ u) sig = consUsageSig head_usage (trimUsageSig u tail_usage)
+trimUsageSig n sig = consUsageSig head_usage (trimUsageSig (n-1) tail_usage)
   where
     (head_usage, tail_usage) = unconsUsageSig sig
-trimUsageSig _ _ = TopUsageSig
 
 -- * Specific `Usage`s/`SingleUse`s
 
diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index 82f062da7d..49ee8f5cf9 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -5,6 +5,7 @@ module DmdAnalWrapper (combinedDmdAnalProgram) where
 #include "HsVersions.h"
 
 import CallArity
+import CoreArity
 import CoreSyn
 import DmdAnal
 import DynFlags
@@ -33,11 +34,12 @@ mergeInfo is_lam_bndr id
   -- instead of the whole expression, we get more conservative results in our
   -- new analysis, where there might be multiplied uses on lambda binders if
   -- it has more than one lambda. In that case we have to relax the assert.
-  = ASSERT2( (is_lam_bndr || isExportedId id || ca_usage `leqUsage` old_usage), text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
-    ASSERT2( (not (isExportedId id) || ca_usg_sig `leqUsageSig` old_usg_sig), text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
+  = ASSERT2( (is_lam_bndr || not has_usage || ca_usage `leqUsage` old_usage), text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
+    ASSERT2( (not has_usg_sig || ca_usg_sig `leqUsageSig` old_usg_sig), text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
     --pprTrace "mergeInfo" (ppr id <+> text "Demand:" <+> ppr old_demand <+> ppr ca_usage <+> ppr new_demand <+> text "Strictness" <+> ppr old_str_sig <+> ppr ca_usg_sig <+> ppr new_str_sig) $
     id'
   where
+    max_arity = length (typeArity (idType id))
     -- We merge idDemandInfo with idCallArity and idStrictness with idArgUsage.
     -- Since Demand.hs doesn't seem to enforce the equivalences from the paper,
     -- we first convert everything to the representation of Usage.hs.
@@ -47,7 +49,10 @@ mergeInfo is_lam_bndr id
     ca_usg_sig = idArgUsage id
 
     old_usage = usageFromDemand old_demand
-    old_usg_sig = usageSigFromStrictSig old_str_sig
+    -- trimming the sig so that we don't care for arguments which aren't there
+    -- as dictated by the types (e.g. when a sig bottoms out after 2 arguments 
+    -- and the id's type only has two arrows).
+    old_usg_sig = trimUsageSig max_arity (usageSigFromStrictSig old_str_sig) 
 
     new_demand 
       | ca_usage `leqUsage` old_usage = overwriteDemandWithUsage ca_usage old_demand
@@ -58,9 +63,11 @@ mergeInfo is_lam_bndr id
 
     leqUsage l r = l `lubUsage` r == r
     leqUsageSig l r = l `lubUsageSig` r == r
-    id'
-      | isExportedId id = id `setIdStrictness` new_str_sig -- Only the sig matters
-      | otherwise = id `setIdDemandInfo` new_demand -- Only use sites matter
+    has_usage = idCallArity id /= topUsage || old_usage /= topUsage
+    has_usg_sig = idArgUsage id /= topUsageSig || old_usg_sig /= topUsageSig
+    id' = id 
+      `setIdDemandInfo` new_demand
+      `setIdStrictness` new_str_sig
 
 
 mapBndrsProgram :: (Bool -> Var -> Var) -> CoreProgram -> CoreProgram
diff --git a/testsuite/tests/simplCore/should_compile/spec-inline.stderr b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
index bf52aed635..ecb42b499c 100644
--- a/testsuite/tests/simplCore/should_compile/spec-inline.stderr
+++ b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
@@ -104,7 +104,7 @@ Roman.$wgo =
       Just x ->
         case x of { GHC.Types.I# ipv ->
         let {
-          m :: GHC.Prim.Int#
+          m [Usg=A] :: GHC.Prim.Int#
           [LclId]
           m =
             GHC.Prim.+#
-- 
2.12.1


From 6d04c66f9ca5c2a64b4c826da42b49bd92614f45 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 4 Jun 2017 17:26:27 +0200
Subject: [PATCH 092/117] More pedantic about trimming usages to types

---
 compiler/simplCore/CallArity/Analysis.hs | 49 +++++++++++++++++++-------------
 compiler/simplCore/CallArity/Types.hs    | 37 ++++++++++++------------
 2 files changed, 47 insertions(+), 39 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index a7228bcc3d..4bc2450480 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -627,9 +627,10 @@ callArityExpr env (Lam id body)
           return (emptyUsageType, Lam id' body)
         Used multi body_use -> do
           (ut_body, body') <- transfer_body body_use
-          let (ut_body', usage_id) = findBndrUsage NonRecursive (ae_fam_envs env) ut_body id
+          let fam_envs = ae_fam_envs env
+          let (ut_body', usage_id) = findBndrUsage NonRecursive fam_envs ut_body id
           let id' = applyWhen (multi == Once) (`setIdOneShotInfo` OneShotLam)
-                  . (`setIdCallArity` usage_id)
+                  . (\id -> setBndrUsageInfo fam_envs id usage_id)
                   $ id
           -- Free vars are manified, closed vars are not. The usage of the current
           -- argument `id` is *not* manified.
@@ -671,7 +672,9 @@ callArityExpr env (Case scrut case_bndr ty alts) = do
   return $ \use -> do
     (ut_alts, alts', scrut_uses) <- unzip3 <$> mapM ($ use) transfer_alts
     let ut_alt = lubUsageTypes ut_alts
-    let case_bndr' = setIdCallArity case_bndr (lookupUsage NonRecursive ut_alt case_bndr)
+    let fam_envs = ae_fam_envs env
+    let case_bndr_usage = lookupUsage NonRecursive fam_envs ut_alt case_bndr
+    let case_bndr' = setBndrUsageInfo fam_envs case_bndr case_bndr_usage
     let ut_alt' = delUsageType case_bndr ut_alt
     let scrut_use = propagateProductUse alts' scrut_uses
     (ut_scrut, scrut') <- transfer_scrut scrut_use
@@ -832,7 +835,7 @@ analyseCaseAlternative env case_bndr (dc, alt_bndrs, e)
       -- around! This means that we later on annotate case_bndr solely based
       -- on how its @Id@ was used, not on how the components were used.
       let alt_bndr_usages' = addCaseBndrUsage case_bndr_usage alt_bndr_usages
-      let alt_bndrs' = setBndrsUsageInfo alt_bndrs alt_bndr_usages
+      let alt_bndrs' = setBndrsUsageInfo fam_envs alt_bndrs alt_bndr_usages
       let product_use = mkProductUse alt_bndr_usages'
       -- product_use doesn't yet take into account strictness annotations of the
       -- constructor. That's to be done when we finally match on dc.
@@ -840,12 +843,7 @@ analyseCaseAlternative env case_bndr (dc, alt_bndrs, e)
 
 findBndrUsage :: RecFlag -> FamInstEnvs -> UsageType -> Id -> (UsageType, Usage)
 findBndrUsage rec_flag fam_envs ut id
-  = (delUsageType id ut, usage')
-  where
-    usage = lookupUsage rec_flag ut id
-    -- See Note [Trimming a demand to a type] in Demand.hs
-    shape = findTypeShape fam_envs (idType id)
-    usage' = trimUsage shape usage
+  = (delUsageType id ut, lookupUsage rec_flag fam_envs ut id)
 
 findBndrsUsages :: RecFlag -> FamInstEnvs -> UsageType -> [Var] -> (UsageType, [Usage])
 findBndrsUsages rec_flag fam_envs ut = foldr step (ut, [])
@@ -865,15 +863,26 @@ addCaseBndrUsage (Used _ use) alt_bndr_usages
   | otherwise
   = topUsage <$ alt_bndr_usages
 
-setBndrsUsageInfo :: [Var] -> [Usage] -> [Var]
-setBndrsUsageInfo [] [] = []
-setBndrsUsageInfo (b:bndrs) (usage:usages)
+-- | We should try avoiding to call `setIdCallArity` directly but rather go
+-- through this function. This makes sure to trim the `Usage`
+-- according to the binder's type before annotating.
+setBndrUsageInfo :: FamInstEnvs -> Var -> Usage -> Var
+setBndrUsageInfo fam_envs id usage
+  | isTyVar id
+  = id 
+  | otherwise
+    -- See Note [Trimming a demand to a type] in Demand.hs
+  = --pprTrace "setBndrUsageInfo" (ppr id <+> ppr usage') 
+    id `setIdCallArity` trimUsageToTypeShape fam_envs id usage
+
+setBndrsUsageInfo :: FamInstEnvs -> [Var] -> [Usage] -> [Var]
+setBndrsUsageInfo _ [] [] = []
+setBndrsUsageInfo fam_envs (b:bndrs) (usage:usages)
   | isId b
-  = --pprTrace "setBndrInfo" (ppr b <+> ppr usage) 
-    (setIdCallArity b usage) : setBndrsUsageInfo bndrs usages
-setBndrsUsageInfo (b:bndrs) usages
-  = b : setBndrsUsageInfo bndrs usages
-setBndrsUsageInfo _ usages
+  = setBndrUsageInfo fam_envs b usage : setBndrsUsageInfo fam_envs bndrs usages
+setBndrsUsageInfo fam_envs (b:bndrs) usages
+  = b : setBndrsUsageInfo fam_envs bndrs usages
+setBndrsUsageInfo _ _ usages
   = pprPanic "No Ids, but a Usage left" (ppr usages)
 
 propagateProductUse
@@ -1009,13 +1018,13 @@ unleashLet env rec_flag transferred_binds ut_usage ut_body = do
   let fam_envs = ae_fam_envs env
   let ids = fst . unzip $ transferred_binds
   (ut_rhss, rhss') <- fmap unzip $ forM transferred_binds $ \(id, (rhs, transfer)) ->
-    unleashUsage rhs transfer (lookupUsage rec_flag ut_usage id)
+    unleashUsage rhs transfer (lookupUsage rec_flag fam_envs ut_usage id)
   let ut_final = callArityLetEnv (zip ids ut_rhss) ut_body
 
   --pprTrace "unleashLet" (ppr ids $$ text "ut_body" <+> ppr ut_body $$ text "ut_final" <+> ppr ut_final) $ return ()
   -- Now use that information to annotate binders.
   let (_, usages) = findBndrsUsages rec_flag fam_envs ut_final ids
-  let ids' = setBndrsUsageInfo ids usages
+  let ids' = setBndrsUsageInfo fam_envs ids usages
   ids'' <- forM ids' (annotateIdArgUsage env) 
 
   -- This intentionally still contains the @Id@s of the binding group, because
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/CallArity/Types.hs
index 180db0f550..48d401ef81 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/CallArity/Types.hs
@@ -2,11 +2,13 @@ module CallArity.Types where
 
 import BasicTypes
 import CoreSyn
+import FamInstEnv
 import Id
 import Outputable
 import UnVarGraph
 import Usage
 import VarEnv
+import WwLib ( findTypeShape )
 
 import Control.Monad ( guard )
 import Data.List ( foldl1' )
@@ -31,9 +33,6 @@ data UsageType
 modifyArgs :: (UsageSig -> UsageSig) -> UsageType -> UsageType
 modifyArgs modifier ut = ut { ut_args = modifier (ut_args ut) }
 
-modifyCoCalls :: (UnVarGraph -> UnVarGraph) -> UsageType -> UsageType
-modifyCoCalls modifier ut = ut { ut_cocalled = modifier (ut_cocalled ut) }
-
 -- | How an expression uses its interesting variables
 -- and the elaborated expression with annotated Ids
 type AnalResult = (UsageType, CoreExpr)
@@ -62,25 +61,25 @@ delUsageType id (UT g ae args) = UT (g `delNode` id) (ae `delVarEnv` id) args
 domType :: UsageType -> UnVarSet
 domType ut = varEnvDom (ut_uses ut)
 
-domTypes :: [UsageType] -> UnVarSet
-domTypes = foldr unionUnVarSet emptyUnVarSet . map domType
-
-makeIdArg :: Id -> UsageType -> UsageType
-makeIdArg id ut = delUsageType id (modifyArgs (consUsageSig (lookupUsage NonRecursive ut id)) ut)
+-- | See Note [Trimming a demand to a type] in Demand.hs.
+trimUsageToTypeShape :: FamInstEnvs -> Id -> Usage -> Usage
+trimUsageToTypeShape fam_envs id = trimUsage (findTypeShape fam_envs (idType id))
 
 -- In the result, find out the minimum arity and whether the variable is called
 -- at most once.
-lookupUsage :: RecFlag -> UsageType -> Id -> Usage
-lookupUsage rec (UT g ae _) id = case lookupVarEnv ae id of
-  Just use
-    -- we assume recursive bindings to be called multiple times, what's the
-    -- point otherwise? It's a little sad we don't encode it in the co-call
-    -- graph directly, though.
-    -- See Note [Thunks in recursive groups]
-    | isRec rec -> manifyUsage (Used Once use)
-    | id `elemUnVarSet` neighbors g id -> Used Many use
-    | otherwise -> Used Once use
-  Nothing -> botUsage
+lookupUsage :: RecFlag -> FamInstEnvs -> UsageType -> Id -> Usage
+lookupUsage rec fam_envs (UT g ae _) id = trimUsageToTypeShape fam_envs id usage 
+  where
+    usage = case lookupVarEnv ae id of
+      Just use
+        -- we assume recursive bindings to be called multiple times, what's the
+        -- point otherwise? It's a little sad we don't encode it in the co-call
+        -- graph directly, though.
+        -- See Note [Thunks in recursive groups]
+        | isRec rec -> manifyUsage (Used Once use)
+        | id `elemUnVarSet` neighbors g id -> Used Many use
+        | otherwise -> Used Once use
+      Nothing -> botUsage
 
 calledWith :: UsageType -> Id -> UnVarSet
 calledWith ut id = neighbors (ut_cocalled ut) id
-- 
2.12.1


From d459e4023231280b8233b6d37723b4a495c581dd Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 4 Jun 2017 17:36:25 +0200
Subject: [PATCH 093/117] Only TopLevel ids have a UsageSig worthy to be merged

---
 compiler/simplCore/DmdAnalWrapper.hs | 36 +++++++++++++++++-------------------
 1 file changed, 17 insertions(+), 19 deletions(-)

diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index 49ee8f5cf9..ebba47d459 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -4,6 +4,7 @@ module DmdAnalWrapper (combinedDmdAnalProgram) where
 
 #include "HsVersions.h"
 
+import BasicTypes
 import CallArity
 import CoreArity
 import CoreSyn
@@ -25,8 +26,10 @@ combinedDmdAnalProgram dflags fams orphan_rules prog = do
   --pprTrace "Program" (ppr prog'') $ pure ()
   return (mapBndrsProgram mergeInfo prog'')
 
-mergeInfo :: Bool -> Var -> Var
-mergeInfo is_lam_bndr id
+type InfoMerger = TopLevelFlag -> Bool -> Var -> Var
+
+mergeInfo :: InfoMerger
+mergeInfo top_lvl is_lam_bndr id
   | isTyVar id
   = id
   | otherwise 
@@ -64,34 +67,29 @@ mergeInfo is_lam_bndr id
     leqUsage l r = l `lubUsage` r == r
     leqUsageSig l r = l `lubUsageSig` r == r
     has_usage = idCallArity id /= topUsage || old_usage /= topUsage
-    has_usg_sig = idArgUsage id /= topUsageSig || old_usg_sig /= topUsageSig
+    has_usg_sig = isTopLevel top_lvl
     id' = id 
       `setIdDemandInfo` new_demand
       `setIdStrictness` new_str_sig
 
 
-mapBndrsProgram :: (Bool -> Var -> Var) -> CoreProgram -> CoreProgram
-mapBndrsProgram f = map (mapBndrsBind f)
-
-mapBndrsBind :: (Bool -> Var -> Var) -> CoreBind -> CoreBind
-mapBndrsBind f (NonRec id e) = NonRec (f False id) (mapBndrsExprIfNotAbsent id f e)
-mapBndrsBind f (Rec bndrs) = Rec (map (\(id, e) -> (f False id, mapBndrsExprIfNotAbsent id f e)) bndrs)
+mapBndrsProgram :: InfoMerger -> CoreProgram -> CoreProgram
+mapBndrsProgram f = map (mapBndrsBind TopLevel f)
 
-mapBndrsExprIfNotAbsent :: Var -> (Bool -> Var -> Var) -> CoreExpr -> CoreExpr
-mapBndrsExprIfNotAbsent id f e
-  | Absent <- idCallArity id = e -- we won't have analysed e in this case.
-  | otherwise = mapBndrsExpr f e
+mapBndrsBind :: TopLevelFlag -> InfoMerger -> CoreBind -> CoreBind
+mapBndrsBind top_lvl f (NonRec id e) = NonRec (f top_lvl False id) (mapBndrsExpr f e)
+mapBndrsBind top_lvl f (Rec bndrs) = Rec (map (\(id, e) -> (f top_lvl False id, mapBndrsExpr f e)) bndrs)
 
-mapBndrsExpr :: (Bool -> Var -> Var) -> CoreExpr -> CoreExpr
+mapBndrsExpr :: InfoMerger -> CoreExpr -> CoreExpr
 mapBndrsExpr f e = case e of
   App func arg -> App (mapBndrsExpr f func) (mapBndrsExpr f arg)
-  Lam id e -> Lam (f True id) (mapBndrsExpr f e)
-  Let bind body -> Let (mapBndrsBind f bind) (mapBndrsExpr f body)
-  Case scrut id ty alts -> Case (mapBndrsExpr f scrut) (f False id) ty (map (mapBndrsAlt f) alts)
+  Lam id e -> Lam (f NotTopLevel True id) (mapBndrsExpr f e)
+  Let bind body -> Let (mapBndrsBind NotTopLevel f bind) (mapBndrsExpr f body)
+  Case scrut id ty alts -> Case (mapBndrsExpr f scrut) (f NotTopLevel False id) ty (map (mapBndrsAlt f) alts)
   Cast e co -> Cast (mapBndrsExpr f e) co
   Tick t e -> Tick t (mapBndrsExpr f e)
   Var _ -> e -- use sites carry no important annotations
   _ -> e
 
-mapBndrsAlt :: (Bool -> Var -> Var) -> Alt CoreBndr -> Alt CoreBndr
-mapBndrsAlt f (con, bndrs, e) = (con, map (f False) bndrs, mapBndrsExpr f e)
+mapBndrsAlt :: InfoMerger -> Alt CoreBndr -> Alt CoreBndr
+mapBndrsAlt f (con, bndrs, e) = (con, map (f NotTopLevel False) bndrs, mapBndrsExpr f e)
-- 
2.12.1


From 7cb7de9d6dfb5b12d63e0e45ab68f00b7099b82f Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 4 Jun 2017 18:24:45 +0200
Subject: [PATCH 094/117] And fixing some regressions in spec-inline and
 joao-circular, again

Testsuite should be finally green now
---
 compiler/simplCore/CallArity/Analysis.hs                    | 2 +-
 testsuite/tests/simplCore/should_compile/spec-inline.stderr | 4 ++--
 2 files changed, 3 insertions(+), 3 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 4bc2450480..3c47458a19 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -900,7 +900,7 @@ propagateProductUse alts scrut_uses
   -- This is a good place to make sure we don't construct an infinitely deep
   -- use, which can happen when analysing e.g. lazy streams.
   -- Also see Note [Demand on scrutinee of a product case] in DmdAnal.hs.
-  = addDataConStrictness dc (boundDepth 9 scrut_use) -- 9 seems to be just enough to match DmdAnal
+  = addDataConStrictness dc (boundDepth 10 scrut_use) -- 10 seems to be just enough to match DmdAnal
 
   | otherwise
   -- We *could* lub the uses from the different branches, but there's not much
diff --git a/testsuite/tests/simplCore/should_compile/spec-inline.stderr b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
index ecb42b499c..a66cd6023e 100644
--- a/testsuite/tests/simplCore/should_compile/spec-inline.stderr
+++ b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
@@ -62,7 +62,7 @@ Rec {
 -- RHS size: {terms: 55, types: 9, coercions: 0, joins: 0/1}
 Roman.foo_$s$wgo [Occ=LoopBreaker]
   :: GHC.Prim.Int# -> GHC.Prim.Int# -> GHC.Prim.Int#
-[GblId, Arity=2, Caf=NoCafRefs, Str=<S,U><S,U>, ArgUsg=A,w*U,w*U..]
+[GblId, Arity=2, Caf=NoCafRefs, Str=<S,A><S,U>, ArgUsg=A,w*U,w*U..]
 Roman.foo_$s$wgo =
   \ (sc :: GHC.Prim.Int#) (sc1 :: GHC.Prim.Int#) ->
     let {
@@ -104,7 +104,7 @@ Roman.$wgo =
       Just x ->
         case x of { GHC.Types.I# ipv ->
         let {
-          m [Usg=A] :: GHC.Prim.Int#
+          m [Dmd=<L,A>, Usg=A] :: GHC.Prim.Int#
           [LclId]
           m =
             GHC.Prim.+#
-- 
2.12.1


From a042877ec951ca3c7c8a0e8b2dbdade0699623b4 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 4 Jun 2017 22:58:53 +0200
Subject: [PATCH 095/117] Only overwriting strictness sigs if analyzed arities
 match

---
 compiler/simplCore/DmdAnalWrapper.hs | 12 +++++++++++-
 1 file changed, 11 insertions(+), 1 deletion(-)

diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index ebba47d459..77d049149f 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -8,6 +8,7 @@ import BasicTypes
 import CallArity
 import CoreArity
 import CoreSyn
+import Demand
 import DmdAnal
 import DynFlags
 import FamInstEnv
@@ -48,6 +49,7 @@ mergeInfo top_lvl is_lam_bndr id
     -- we first convert everything to the representation of Usage.hs.
     old_demand = idDemandInfo id
     old_str_sig = idStrictness id
+    (old_arg_dmds, _) = splitStrictSig old_str_sig
     ca_usage = idCallArity id
     ca_usg_sig = idArgUsage id
 
@@ -61,7 +63,15 @@ mergeInfo top_lvl is_lam_bndr id
       | ca_usage `leqUsage` old_usage = overwriteDemandWithUsage ca_usage old_demand
       | otherwise = old_demand
     new_str_sig 
-      | ca_usg_sig `leqUsageSig` old_usg_sig = overwriteStrictSigWithUsageSig ca_usg_sig old_str_sig
+      | ca_usg_sig `leqUsageSig` old_usg_sig 
+      , idArity id <= length old_arg_dmds
+      -- This is only safe if DmdAnal used the same arity as CallArity.
+      -- Otherwise we get into nasty situations where arity /= #top-level binders,
+      -- like with IO's RealWorld tokens. In that situation we have
+      -- a more precise usage signature, but at the cost of a higher arity.
+      -- Which is OK, since arity analysis determined that there didn't
+      -- happen anything before.
+      = overwriteStrictSigWithUsageSig ca_usg_sig old_str_sig
       | otherwise = old_str_sig
 
     leqUsage l r = l `lubUsage` r == r
-- 
2.12.1


From 1e2c8698e53d4c7ba0f735ecbf75558c5aa7811d Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 4 Jun 2017 23:33:08 +0200
Subject: [PATCH 096/117] The reverse can happen, too

---
 compiler/simplCore/DmdAnalWrapper.hs | 7 ++++++-
 1 file changed, 6 insertions(+), 1 deletion(-)

diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index 77d049149f..6cf64cc9a4 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -39,7 +39,7 @@ mergeInfo top_lvl is_lam_bndr id
   -- new analysis, where there might be multiplied uses on lambda binders if
   -- it has more than one lambda. In that case we have to relax the assert.
   = ASSERT2( (is_lam_bndr || not has_usage || ca_usage `leqUsage` old_usage), text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
-    ASSERT2( (not has_usg_sig || ca_usg_sig `leqUsageSig` old_usg_sig), text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
+    ASSERT2( (not has_usg_sig || not str_sig_comparable_to_usg_sig || ca_usg_sig `leqUsageSig` old_usg_sig), text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
     --pprTrace "mergeInfo" (ppr id <+> text "Demand:" <+> ppr old_demand <+> ppr ca_usage <+> ppr new_demand <+> text "Strictness" <+> ppr old_str_sig <+> ppr ca_usg_sig <+> ppr new_str_sig) $
     id'
   where
@@ -50,6 +50,7 @@ mergeInfo top_lvl is_lam_bndr id
     old_demand = idDemandInfo id
     old_str_sig = idStrictness id
     (old_arg_dmds, _) = splitStrictSig old_str_sig
+    str_sig_comparable_to_usg_sig = idArity id == length old_arg_dmds -- See further below at `new_str_sig`
     ca_usage = idCallArity id
     ca_usg_sig = idArgUsage id
 
@@ -71,6 +72,10 @@ mergeInfo top_lvl is_lam_bndr id
       -- a more precise usage signature, but at the cost of a higher arity.
       -- Which is OK, since arity analysis determined that there didn't
       -- happen anything before.
+      -- The reverse direction can happen, too: if arity is less than what
+      -- DmdAnal sees (something like unsafeCoerce obscures things, DmdAnal will
+      -- just take the str_sig verbatim from the thing being coerced), DmdAnal
+      -- might be more precise. Happens in HpcParser.hs, happyReduction_2
       = overwriteStrictSigWithUsageSig ca_usg_sig old_str_sig
       | otherwise = old_str_sig
 
-- 
2.12.1


From dec9859ce17bf2faada959d8ffc00717e25b3de8 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 5 Jun 2017 11:28:10 +0200
Subject: [PATCH 097/117] Fixed trimSingleUse

For a binary function to the empty product, it should transform `U` into `C^w(C^w(HU)`, like DmdAnal does
---
 compiler/basicTypes/Usage.hs | 8 ++++----
 1 file changed, 4 insertions(+), 4 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index 66be54e830..bb202f4386 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -258,12 +258,12 @@ boundDepth max_height use = snd (boundUse 0 use)
 
 trimSingleUse :: TypeShape -> SingleUse -> SingleUse
 trimSingleUse _ HeadUse = HeadUse
-trimSingleUse (TsFun shape) (Call m body)
+trimSingleUse (TsFun shape) u
+  | Just (Used m body) <- peelCallUse u
   = mkCallUse m (trimSingleUse shape body)
-trimSingleUse (TsProd shapes) (Product comps)
-  | equalLength shapes comps
+trimSingleUse (TsProd shapes) u
+  | Just comps <- peelProductUse (length shapes) u
   = mkProductUse (zipWith trimUsage shapes comps)
-trimSingleUse (TsProd []) UnknownUse = HeadUse
 trimSingleUse _ _ = topSingleUse
 
 trimUsage :: TypeShape -> Usage -> Usage
-- 
2.12.1


From b85e2411e1099a995a6d4f5077eb97353c4ab1f4 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 5 Jun 2017 18:08:36 +0200
Subject: [PATCH 098/117] Now treating Unfoldings as extra RHSs

---
 compiler/simplCore/CallArity/Analysis.hs | 66 ++++++++++++++++++++++++++++----
 1 file changed, 59 insertions(+), 7 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 3c47458a19..070acaf72d 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -22,9 +22,10 @@ import DynFlags      ( DynFlags, gopt, GeneralFlag(Opt_DmdTxDictSel) )
 import FamInstEnv
 import Id
 import Maybes ( expectJust, fromMaybe, isJust )
-import MkCore
+import MkCore 
 import Outputable
 import TyCon ( isDataProductTyCon_maybe, tyConSingleDataCon_maybe )
+import TysWiredIn ( trueDataConId )
 import UniqFM
 import UnVarGraph
 import Usage
@@ -32,7 +33,6 @@ import Util
 import Var ( isId, isTyVar )
 import VarEnv
 import VarSet
-import WwLib ( findTypeShape )
 
 import Control.Arrow ( first, second, (***) )
 import Control.Monad ( forM )
@@ -459,6 +459,50 @@ extendAnalEnv
 extendAnalEnv env id node 
   = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
 
+mapBinds :: (CoreBind -> CoreBind) -> CoreExpr -> CoreExpr
+mapBinds f = expr 
+  where
+    expr e = case e of
+      App fun arg -> App (expr fun) (expr arg)
+      Lam id body -> Lam id (expr body)
+      Let binds body -> Let (bind binds) (expr body)
+      Case scrut bndr ty alts -> Case (expr scrut) bndr ty (map alt alts)
+      Cast e co -> Cast (expr e) co
+      Tick t e -> Tick t (expr e)
+      _ -> e
+    bind (NonRec id rhs) = f (NonRec id (expr rhs))
+    bind (Rec binds) = f (Rec (map (second expr) binds))
+    alt (dc, bndrs, rhs) = (dc, bndrs, expr rhs)
+
+-- | Adds to the RHSs of a binding group an additional `Case` statement
+-- for potential Unfolding templates, so that they are analyzed, too.
+addUnfoldings :: CoreBind -> CoreBind
+addUnfoldings b = case b of
+  NonRec id rhs -> uncurry NonRec (impl (id, rhs))
+  Rec binds -> Rec (map impl binds)
+  where
+    impl (id, rhs)
+      = (,) id
+      . maybe rhs (mkIfThenElse (Var trueDataConId) rhs)
+      . maybeUnfoldingTemplate 
+      . idUnfolding 
+      $ id
+
+-- | Strips away the additional `Case` for a potential Unfolding from the
+-- RHS of a binding group. Left inverse to `addUnfoldings`.
+stripUnfoldings :: CoreBind -> CoreBind
+stripUnfoldings b = case b of
+  NonRec id rhs -> uncurry NonRec (impl (id, rhs))
+  Rec binds -> Rec (map impl binds)
+  where
+    impl (id, rhs)
+      | Just _ <- maybeUnfoldingTemplate (idUnfolding id)
+      , Case (Var true_id) _ _ [(_, _, orig_rhs), _unf_alt] <- rhs
+      , true_id == trueDataConId
+      = (id, orig_rhs)
+      | otherwise -- There should be no Unfolding template!
+      = (id, rhs)
+
 -- | See Note [Analysing top-level-binds]
 -- `programToExpr` returns a pair of all top-level `Id`s
 -- and a nested `let` expression that uses everything externally visible.
@@ -479,7 +523,10 @@ programToExpr orphan_rules = impl [] (rulesFreeVars orphan_rules)
         -- nonDetEltsUFM is OK, because all product components will
         -- used in the same way anyway.
     impl top_level_ids exposed (bind:prog)
-      = second (Let bind) (impl (bindersOf bind ++ top_level_ids) (exposed_ids bind `unionVarSet` exposed) prog)
+      = second (Let bind) (impl top_level_ids' exposed' prog)
+      where
+        top_level_ids' = bindersOf bind ++ top_level_ids
+        exposed' = exposed_ids bind `unionVarSet` exposed
     -- We need to use *at least*  
     -- 
     --   * exported `Id`s (`isExportedId`)
@@ -493,13 +540,14 @@ programToExpr orphan_rules = impl [] (rulesFreeVars orphan_rules)
     --
     -- This essentially does the same as the Occurence Analyser,
     -- but we are more conservative in that we don't try to follow
-    -- transitive RULE mentions and just take into account all free vars
-    -- of any binder instead of starting to trace from exported ones.
+    -- transitive RULE mentions and just take into account 
+    -- all free vars in RULEs Unfoldings of any binder instead of 
+    -- starting to trace from exported ones.
     exposed_ids bind = unionVarSets (exported:rules)
       where
         bs = bindersOf bind
         exported = mkVarSet (filter isExportedId bs)
-        is_active_rule _ = True -- Conservative, but we should be fine
+        is_active_rule _ = True -- Conservative, but negligible
         rules = map (idRuleRhsVars is_active_rule) bs
 
 -- | The left inverse to `programToExpr`: `exprToProgram . snd . programToExpr = id \@CoreProgram`
@@ -518,14 +566,18 @@ callArityAnalProgram dflags fam_envs orphan_rules
   = return 
   -- . (\it -> pprTrace "callArity:end" (ppr (length it)) it) 
   . exprToProgram 
+  . mapBinds stripUnfoldings
   . uncurry (callArityRHS dflags fam_envs) 
+  . second (mapBinds addUnfoldings)
   . programToExpr orphan_rules
   -- . (\it -> pprTrace "callArity:begin" (ppr (length it)) it)
   -- . (\prog -> pprTrace "CallArity:Program" (ppr prog) prog)
 
 callArityRHS :: DynFlags -> FamInstEnvs -> VarSet -> CoreExpr -> CoreExpr
 callArityRHS dflags fam_envs need_sigs e
-  = ASSERT2( isEmptyUnVarSet (domType ut), text "Free vars in UsageType:" $$ ppr ut ) e'
+  -- There might be free vars because of added Unfolding RHSs which mention 
+  -- bogus ids. Unfoldings are crazy.
+  = WARN( not (isEmptyUnVarSet (domType ut)), text "Free vars in UsageType:" $$ ppr ut ) e'
   where
     env = initialAnalEnv dflags fam_envs need_sigs (predictAllocatedNodes e)
     (ut, e') = buildAndRun (callArityExpr env e) topSingleUse
-- 
2.12.1


From b0cd8f345ba30be9e3b2c3d5ab26c1c6fc2546d0 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 5 Jun 2017 18:51:57 +0200
Subject: [PATCH 099/117] Fixed Branch selection for stripping Unfoldings

---
 compiler/simplCore/CallArity/Analysis.hs | 20 ++++++++++++--------
 compiler/utils/Worklist.hs               |  1 -
 2 files changed, 12 insertions(+), 9 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 070acaf72d..124efa2410 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -21,11 +21,11 @@ import DataCon
 import DynFlags      ( DynFlags, gopt, GeneralFlag(Opt_DmdTxDictSel) )
 import FamInstEnv
 import Id
-import Maybes ( expectJust, fromMaybe, isJust )
+import Maybes ( expectJust, fromMaybe, isJust, listToMaybe )
 import MkCore 
 import Outputable
 import TyCon ( isDataProductTyCon_maybe, tyConSingleDataCon_maybe )
-import TysWiredIn ( trueDataConId )
+import TysWiredIn ( trueDataCon, trueDataConId )
 import UniqFM
 import UnVarGraph
 import Usage
@@ -497,10 +497,13 @@ stripUnfoldings b = case b of
   where
     impl (id, rhs)
       | Just _ <- maybeUnfoldingTemplate (idUnfolding id)
-      , Case (Var true_id) _ _ [(_, _, orig_rhs), _unf_alt] <- rhs
-      , true_id == trueDataConId
-      = (id, orig_rhs)
-      | otherwise -- There should be no Unfolding template!
+      = case rhs of
+          Case (Var true_id) _ _ alts
+            | true_id == trueDataConId
+            , Just orig_rhs <- listToMaybe [ rhs | (DataAlt dc, _, rhs) <- alts, dc == trueDataCon ]
+            -> (id, orig_rhs)
+          _ -> pprPanic "Expected Case for Unfolding" empty
+      | otherwise
       = (id, rhs)
 
 -- | See Note [Analysing top-level-binds]
@@ -567,11 +570,12 @@ callArityAnalProgram dflags fam_envs orphan_rules
   -- . (\it -> pprTrace "callArity:end" (ppr (length it)) it) 
   . exprToProgram 
   . mapBinds stripUnfoldings
+  -- . pprTraceIt "CallArity:Program"
   . uncurry (callArityRHS dflags fam_envs) 
   . second (mapBinds addUnfoldings)
   . programToExpr orphan_rules
   -- . (\it -> pprTrace "callArity:begin" (ppr (length it)) it)
-  -- . (\prog -> pprTrace "CallArity:Program" (ppr prog) prog)
+  -- . pprTraceIt "CallArity:Program"
 
 callArityRHS :: DynFlags -> FamInstEnvs -> VarSet -> CoreExpr -> CoreExpr
 callArityRHS dflags fam_envs need_sigs e
@@ -1099,7 +1103,7 @@ annotateIdArgUsage env id
     -- signature.
     let single_call = iterate (mkCallUse Once) topSingleUse !! idArity id
     usage_sig <- ut_args <$> transfer_callee single_call
-    --pprTrace "annotating" (ppr id <+> ppr usage_sig) $ return ()
+    pprTrace "annotating" (ppr id <+> ppr usage_sig) $ return ()
     return (id `setIdArgUsage` usage_sig)
   | otherwise
   = return id
diff --git a/compiler/utils/Worklist.hs b/compiler/utils/Worklist.hs
index 8a8287f77b..f910d3f6ed 100644
--- a/compiler/utils/Worklist.hs
+++ b/compiler/utils/Worklist.hs
@@ -4,7 +4,6 @@
 {-# OPTIONS_GHC -fprof-auto #-}
 module Worklist where
 
-import Control.Arrow (first)
 import Control.Monad (forM_, when, (<=<))
 import Control.Monad.Trans.State.Strict
 import Data.Map (Map)
-- 
2.12.1


From 0ce5bddc7e9623062c83c92da9edad483414e156 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 6 Jun 2017 14:33:18 +0200
Subject: [PATCH 100/117] Reverted handling of Unfoldings, as the results were
 too bad

---
 compiler/simplCore/CallArity/Analysis.hs | 76 +++++---------------------------
 1 file changed, 10 insertions(+), 66 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 124efa2410..3c47458a19 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -21,11 +21,10 @@ import DataCon
 import DynFlags      ( DynFlags, gopt, GeneralFlag(Opt_DmdTxDictSel) )
 import FamInstEnv
 import Id
-import Maybes ( expectJust, fromMaybe, isJust, listToMaybe )
-import MkCore 
+import Maybes ( expectJust, fromMaybe, isJust )
+import MkCore
 import Outputable
 import TyCon ( isDataProductTyCon_maybe, tyConSingleDataCon_maybe )
-import TysWiredIn ( trueDataCon, trueDataConId )
 import UniqFM
 import UnVarGraph
 import Usage
@@ -33,6 +32,7 @@ import Util
 import Var ( isId, isTyVar )
 import VarEnv
 import VarSet
+import WwLib ( findTypeShape )
 
 import Control.Arrow ( first, second, (***) )
 import Control.Monad ( forM )
@@ -459,53 +459,6 @@ extendAnalEnv
 extendAnalEnv env id node 
   = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
 
-mapBinds :: (CoreBind -> CoreBind) -> CoreExpr -> CoreExpr
-mapBinds f = expr 
-  where
-    expr e = case e of
-      App fun arg -> App (expr fun) (expr arg)
-      Lam id body -> Lam id (expr body)
-      Let binds body -> Let (bind binds) (expr body)
-      Case scrut bndr ty alts -> Case (expr scrut) bndr ty (map alt alts)
-      Cast e co -> Cast (expr e) co
-      Tick t e -> Tick t (expr e)
-      _ -> e
-    bind (NonRec id rhs) = f (NonRec id (expr rhs))
-    bind (Rec binds) = f (Rec (map (second expr) binds))
-    alt (dc, bndrs, rhs) = (dc, bndrs, expr rhs)
-
--- | Adds to the RHSs of a binding group an additional `Case` statement
--- for potential Unfolding templates, so that they are analyzed, too.
-addUnfoldings :: CoreBind -> CoreBind
-addUnfoldings b = case b of
-  NonRec id rhs -> uncurry NonRec (impl (id, rhs))
-  Rec binds -> Rec (map impl binds)
-  where
-    impl (id, rhs)
-      = (,) id
-      . maybe rhs (mkIfThenElse (Var trueDataConId) rhs)
-      . maybeUnfoldingTemplate 
-      . idUnfolding 
-      $ id
-
--- | Strips away the additional `Case` for a potential Unfolding from the
--- RHS of a binding group. Left inverse to `addUnfoldings`.
-stripUnfoldings :: CoreBind -> CoreBind
-stripUnfoldings b = case b of
-  NonRec id rhs -> uncurry NonRec (impl (id, rhs))
-  Rec binds -> Rec (map impl binds)
-  where
-    impl (id, rhs)
-      | Just _ <- maybeUnfoldingTemplate (idUnfolding id)
-      = case rhs of
-          Case (Var true_id) _ _ alts
-            | true_id == trueDataConId
-            , Just orig_rhs <- listToMaybe [ rhs | (DataAlt dc, _, rhs) <- alts, dc == trueDataCon ]
-            -> (id, orig_rhs)
-          _ -> pprPanic "Expected Case for Unfolding" empty
-      | otherwise
-      = (id, rhs)
-
 -- | See Note [Analysing top-level-binds]
 -- `programToExpr` returns a pair of all top-level `Id`s
 -- and a nested `let` expression that uses everything externally visible.
@@ -526,10 +479,7 @@ programToExpr orphan_rules = impl [] (rulesFreeVars orphan_rules)
         -- nonDetEltsUFM is OK, because all product components will
         -- used in the same way anyway.
     impl top_level_ids exposed (bind:prog)
-      = second (Let bind) (impl top_level_ids' exposed' prog)
-      where
-        top_level_ids' = bindersOf bind ++ top_level_ids
-        exposed' = exposed_ids bind `unionVarSet` exposed
+      = second (Let bind) (impl (bindersOf bind ++ top_level_ids) (exposed_ids bind `unionVarSet` exposed) prog)
     -- We need to use *at least*  
     -- 
     --   * exported `Id`s (`isExportedId`)
@@ -543,14 +493,13 @@ programToExpr orphan_rules = impl [] (rulesFreeVars orphan_rules)
     --
     -- This essentially does the same as the Occurence Analyser,
     -- but we are more conservative in that we don't try to follow
-    -- transitive RULE mentions and just take into account 
-    -- all free vars in RULEs Unfoldings of any binder instead of 
-    -- starting to trace from exported ones.
+    -- transitive RULE mentions and just take into account all free vars
+    -- of any binder instead of starting to trace from exported ones.
     exposed_ids bind = unionVarSets (exported:rules)
       where
         bs = bindersOf bind
         exported = mkVarSet (filter isExportedId bs)
-        is_active_rule _ = True -- Conservative, but negligible
+        is_active_rule _ = True -- Conservative, but we should be fine
         rules = map (idRuleRhsVars is_active_rule) bs
 
 -- | The left inverse to `programToExpr`: `exprToProgram . snd . programToExpr = id \@CoreProgram`
@@ -569,19 +518,14 @@ callArityAnalProgram dflags fam_envs orphan_rules
   = return 
   -- . (\it -> pprTrace "callArity:end" (ppr (length it)) it) 
   . exprToProgram 
-  . mapBinds stripUnfoldings
-  -- . pprTraceIt "CallArity:Program"
   . uncurry (callArityRHS dflags fam_envs) 
-  . second (mapBinds addUnfoldings)
   . programToExpr orphan_rules
   -- . (\it -> pprTrace "callArity:begin" (ppr (length it)) it)
-  -- . pprTraceIt "CallArity:Program"
+  -- . (\prog -> pprTrace "CallArity:Program" (ppr prog) prog)
 
 callArityRHS :: DynFlags -> FamInstEnvs -> VarSet -> CoreExpr -> CoreExpr
 callArityRHS dflags fam_envs need_sigs e
-  -- There might be free vars because of added Unfolding RHSs which mention 
-  -- bogus ids. Unfoldings are crazy.
-  = WARN( not (isEmptyUnVarSet (domType ut)), text "Free vars in UsageType:" $$ ppr ut ) e'
+  = ASSERT2( isEmptyUnVarSet (domType ut), text "Free vars in UsageType:" $$ ppr ut ) e'
   where
     env = initialAnalEnv dflags fam_envs need_sigs (predictAllocatedNodes e)
     (ut, e') = buildAndRun (callArityExpr env e) topSingleUse
@@ -1103,7 +1047,7 @@ annotateIdArgUsage env id
     -- signature.
     let single_call = iterate (mkCallUse Once) topSingleUse !! idArity id
     usage_sig <- ut_args <$> transfer_callee single_call
-    pprTrace "annotating" (ppr id <+> ppr usage_sig) $ return ()
+    --pprTrace "annotating" (ppr id <+> ppr usage_sig) $ return ()
     return (id `setIdArgUsage` usage_sig)
   | otherwise
   = return id
-- 
2.12.1


From 78ae992bfc2ac729f1dd557f6a9d5603ef650a17 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 6 Jun 2017 14:40:51 +0200
Subject: [PATCH 101/117] Not descending into RHSs when marking bindings
 absent, to avoid CoreLint errors

---
 compiler/simplCore/CallArity/Analysis.hs | 5 +++++
 compiler/simplCore/DmdAnalWrapper.hs     | 9 +++++++--
 2 files changed, 12 insertions(+), 2 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 3c47458a19..7cc178f955 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -1124,6 +1124,11 @@ callArityLetEnv rhss ut_body
         | length ut_rhss > 25 = bothUsageTypes ut_all
         | otherwise           = lubUsageTypes (ut_all ++ map cross_calls rhss)
 
+-- | Marks every binder it reaches as absent, but does *not* descend into absent
+-- RHSs. These are implicitly assumed as absent. This is so that we don't trigger
+-- CoreLint warnings on stuff the Occurence Anaylzer deems reachable but we do not.
+-- Examples are bindings only reachable through unoptimized Unfolding templates,
+-- which are just too much trouble to deal with ATM. FIXME!
 markAbsent :: CoreExpr -> CoreExpr
 markAbsent = expr
   where 
diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index 6cf64cc9a4..1adc554482 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -92,8 +92,13 @@ mapBndrsProgram :: InfoMerger -> CoreProgram -> CoreProgram
 mapBndrsProgram f = map (mapBndrsBind TopLevel f)
 
 mapBndrsBind :: TopLevelFlag -> InfoMerger -> CoreBind -> CoreBind
-mapBndrsBind top_lvl f (NonRec id e) = NonRec (f top_lvl False id) (mapBndrsExpr f e)
-mapBndrsBind top_lvl f (Rec bndrs) = Rec (map (\(id, e) -> (f top_lvl False id, mapBndrsExpr f e)) bndrs)
+mapBndrsBind top_lvl f (NonRec id e) = NonRec (f top_lvl False id) (mapBndrsExprIfNotAbsent id f e)
+mapBndrsBind top_lvl f (Rec bndrs) = Rec (map (\(id, e) -> (f top_lvl False id, mapBndrsExprIfNotAbsent id f e)) bndrs)
+
+mapBndrsExprIfNotAbsent :: Var -> InfoMerger -> CoreExpr -> CoreExpr
+mapBndrsExprIfNotAbsent id f e
+  | Absent <- idCallArity id = e -- we won't have annotated e in this case.
+  | otherwise = mapBndrsExpr f e
 
 mapBndrsExpr :: InfoMerger -> CoreExpr -> CoreExpr
 mapBndrsExpr f e = case e of
-- 
2.12.1


From 9461dcd1fb95bfcadfd8c6bd13b8ad601706571e Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 6 Jun 2017 15:58:21 +0200
Subject: [PATCH 102/117] Fixed a stack overflow caused by an infinite deep
 TypeShape

---
 compiler/basicTypes/Usage.hs | 29 +++++++++++++++++++----------
 1 file changed, 19 insertions(+), 10 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index bb202f4386..fcb7bb17d1 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -256,19 +256,28 @@ boundDepth max_height use = snd (boundUse 0 use)
         impl height (Call m u) = second (mkCallUse m) (boundUse height u)
         impl _ u = (False, u)
 
-trimSingleUse :: TypeShape -> SingleUse -> SingleUse
-trimSingleUse _ HeadUse = HeadUse
-trimSingleUse (TsFun shape) u
+trimSingleUseBounded :: Int -> TypeShape -> SingleUse -> SingleUse
+trimSingleUseBounded _ _ HeadUse = HeadUse
+trimSingleUseBounded d (TsFun shape) u
+  -- Infinite arity is prohibited by the type system, so we don't have to modify d here
   | Just (Used m body) <- peelCallUse u
-  = mkCallUse m (trimSingleUse shape body)
-trimSingleUse (TsProd shapes) u
-  | Just comps <- peelProductUse (length shapes) u
-  = mkProductUse (zipWith trimUsage shapes comps)
-trimSingleUse _ _ = topSingleUse
+  = mkCallUse m (trimSingleUseBounded d shape body)
+trimSingleUseBounded d (TsProd shapes) u
+  -- TsProd may be infinitely deep, so we have to cut off at some point
+  | d < 10
+  , Just comps <- peelProductUse (length shapes) u
+  = mkProductUse (zipWith (trimUsageBounded (d+1)) shapes comps)
+trimSingleUseBounded _ _ _ = topSingleUse 
+    
+trimUsageBounded :: Int -> TypeShape -> Usage -> Usage
+trimUsageBounded d shape (Used m use) = Used m (trimSingleUseBounded d shape use)
+trimUsageBounded _ _ usg = usg
+
+trimSingleUse :: TypeShape -> SingleUse -> SingleUse
+trimSingleUse = trimSingleUseBounded 0 
 
 trimUsage :: TypeShape -> Usage -> Usage
-trimUsage shape (Used m use) = Used m (trimSingleUse shape use)
-trimUsage _ usg = usg
+trimUsage = trimUsageBounded 0
 
 -- | @manifyUsage u = bothUsage u u@. For when an id is used more than once
 -- with the same `Usage`. This is different than just changing the top-level
-- 
2.12.1


From 4e5836b982f8aa580d3f18a815a4c21679045b72 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Wed, 7 Jun 2017 13:07:28 +0200
Subject: [PATCH 103/117] Fixed UnsatFun, T12370 aaand ... spec-inline!

UnsatFun and T12370 just dump signatures. In case of UnsatFun that results in a rather weird output, where half of the products are normalized according to Usage.hs but the other is not.
---
 .../tests/simplCore/should_compile/spec-inline.stderr      |  2 +-
 testsuite/tests/stranal/sigs/T12370.stderr                 |  8 ++++----
 testsuite/tests/stranal/sigs/UnsatFun.stderr               | 14 +++++++-------
 3 files changed, 12 insertions(+), 12 deletions(-)

diff --git a/testsuite/tests/simplCore/should_compile/spec-inline.stderr b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
index a66cd6023e..46f97611b7 100644
--- a/testsuite/tests/simplCore/should_compile/spec-inline.stderr
+++ b/testsuite/tests/simplCore/should_compile/spec-inline.stderr
@@ -104,7 +104,7 @@ Roman.$wgo =
       Just x ->
         case x of { GHC.Types.I# ipv ->
         let {
-          m [Dmd=<L,A>, Usg=A] :: GHC.Prim.Int#
+          m [Usg=A] :: GHC.Prim.Int#
           [LclId]
           m =
             GHC.Prim.+#
diff --git a/testsuite/tests/stranal/sigs/T12370.stderr b/testsuite/tests/stranal/sigs/T12370.stderr
index f8cb839436..0a629ddde4 100644
--- a/testsuite/tests/stranal/sigs/T12370.stderr
+++ b/testsuite/tests/stranal/sigs/T12370.stderr
@@ -1,14 +1,14 @@
 
 ==================== Strictness signatures ====================
 T12370.$trModule: m
-T12370.bar: <S(S),1*U(U)><S(S),1*U(U)>m
-T12370.foo: <S(S(S)S(S)),1*U(1*U(U),1*U(U))>m
+T12370.bar: <S(S),1*U><S(S),1*U>m
+T12370.foo: <S(S(S)S(S)),1*U(1*U,1*U)>m
 
 
 
 ==================== Strictness signatures ====================
 T12370.$trModule: m
-T12370.bar: <S(S),1*U(U)><S(S),1*U(U)>m
-T12370.foo: <S(S(S)S(S)),1*U(1*U(U),1*U(U))>m
+T12370.bar: <S(S),1*U><S(S),1*U>m
+T12370.foo: <S(S(S)S(S)),1*U(1*U,1*U)>m
 
 
diff --git a/testsuite/tests/stranal/sigs/UnsatFun.stderr b/testsuite/tests/stranal/sigs/UnsatFun.stderr
index 1ea2fa4773..050e217696 100644
--- a/testsuite/tests/stranal/sigs/UnsatFun.stderr
+++ b/testsuite/tests/stranal/sigs/UnsatFun.stderr
@@ -1,10 +1,10 @@
 
 ==================== Strictness signatures ====================
 UnsatFun.$trModule: m
-UnsatFun.f: <B,1*U(U)><B,A>x
-UnsatFun.g: <B,1*U(U)>x
-UnsatFun.g': <L,1*U(U)>
-UnsatFun.g3: <L,U(U)>m
+UnsatFun.f: <B,1*U><B,A>x
+UnsatFun.g: <B,1*U>x
+UnsatFun.g': <L,1*U>
+UnsatFun.g3: <L,U>m
 UnsatFun.h: <C(S),1*C1(U(U))>
 UnsatFun.h2: <S,1*U><L,1*C1(U(U))>
 UnsatFun.h3: <C(S),1*C1(U)>m
@@ -13,9 +13,9 @@ UnsatFun.h3: <C(S),1*C1(U)>m
 
 ==================== Strictness signatures ====================
 UnsatFun.$trModule: m
-UnsatFun.f: <B,1*U(U)><B,A>x
-UnsatFun.g: <B,1*U(U)>x
-UnsatFun.g': <L,1*U(U)>
+UnsatFun.f: <B,1*U><B,A>x
+UnsatFun.g: <B,1*U>x
+UnsatFun.g': <L,1*U>
 UnsatFun.g3: <L,U(U)>m
 UnsatFun.h: <C(S),1*C1(U(U))>
 UnsatFun.h2: <S,1*U><L,1*C1(U(U))>
-- 
2.12.1


From 49b7a5b120db784319426c6ee8bcaca16c791712 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 25 Jun 2017 22:11:17 +0200
Subject: [PATCH 104/117] Cleaning up stuff

---
 compiler/basicTypes/Usage.hs             |  6 ++++--
 compiler/simplCore/CallArity/Analysis.hs | 11 ++++++-----
 compiler/utils/UnVarGraph.hs             |  5 ++---
 3 files changed, 12 insertions(+), 10 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index fcb7bb17d1..ad572f461c 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -310,8 +310,10 @@ expandArity (Used Many _) 0
 expandArity (Used _ u) cheap_arity
   = impl u cheap_arity
   where
-    impl HeadUse cheap_arity -- the application expression we accumulated does non-trivial work, so
-      -- Same reason as for the above @Absent@ case
+    impl HeadUse cheap_arity
+      -- Same reason as for the above @Absent@ case, we can expand arbitrarily. 
+      -- Although for the cheap_arity = 0 case, we *should* not expand at all,
+      -- because that would yield surprising behavior.
       = cheap_arity
     impl UnknownUse cheap_arity
       -- No chance we can expand anything
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 7cc178f955..1ec804b2b5 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -32,7 +32,6 @@ import Util
 import Var ( isId, isTyVar )
 import VarEnv
 import VarSet
-import WwLib ( findTypeShape )
 
 import Control.Arrow ( first, second, (***) )
 import Control.Monad ( forM )
@@ -584,7 +583,7 @@ callArityExpr env e@(Var id) = return transfer
       -- transparently in `registerBindingGroups`.
       = do
         ut_callee <- transfer_callee use
-        --pprTrace "callArityExpr:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
+        pprTrace "callArityExpr:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
         return (ut_callee `bothUsageType` unitUsageType id use, e)
 
       | isLocalId id
@@ -872,8 +871,10 @@ setBndrUsageInfo fam_envs id usage
   = id 
   | otherwise
     -- See Note [Trimming a demand to a type] in Demand.hs
-  = --pprTrace "setBndrUsageInfo" (ppr id <+> ppr usage') 
-    id `setIdCallArity` trimUsageToTypeShape fam_envs id usage
+  = pprTrace "setBndrUsageInfo" (ppr id <+> ppr usage') $
+    id `setIdCallArity` usage'
+    where
+      usage' = trimUsageToTypeShape fam_envs id usage
 
 setBndrsUsageInfo :: FamInstEnvs -> [Var] -> [Usage] -> [Var]
 setBndrsUsageInfo _ [] [] = []
@@ -1016,7 +1017,7 @@ unleashLet
   -> TransferFunction (UsageType, [(Id, CoreExpr)])
 unleashLet env rec_flag transferred_binds ut_usage ut_body = do
   let fam_envs = ae_fam_envs env
-  let ids = fst . unzip $ transferred_binds
+  let ids = map fst transferred_binds
   (ut_rhss, rhss') <- fmap unzip $ forM transferred_binds $ \(id, (rhs, transfer)) ->
     unleashUsage rhs transfer (lookupUsage rec_flag fam_envs ut_usage id)
   let ut_final = callArityLetEnv (zip ids ut_rhss) ut_body
diff --git a/compiler/utils/UnVarGraph.hs b/compiler/utils/UnVarGraph.hs
index 4728dadb08..96f6e8224c 100644
--- a/compiler/utils/UnVarGraph.hs
+++ b/compiler/utils/UnVarGraph.hs
@@ -163,11 +163,10 @@ unionUnVarGraph (UnVarGraph Subtractive e1 _) (UnVarGraph Subtractive e2 _)
   = balance $ mkUnVarGraph Subtractive $ IntMap.unionWith intersectionUnVarSet e1' e2'
   where
     -- diffn = nodes of the union *not* mentioned in graph n
-    diff1 = UnVarSet $ IntMap.keysSet e2 `IntSet.difference` IntMap.keysSet e1 -- 4
-    diff2 = UnVarSet $ IntMap.keysSet e1 `IntSet.difference` IntMap.keysSet e2 -- 0
+    diff1 = UnVarSet $ IntMap.keysSet e2 `IntSet.difference` IntMap.keysSet e1
+    diff2 = UnVarSet $ IntMap.keysSet e1 `IntSet.difference` IntMap.keysSet e2
     e1' = unionUnVarSet diff1 <$> e1
     e2' = unionUnVarSet diff2 <$> e2
-
 unionUnVarGraph u1 u2
   = unionUnVarGraph u1' u2' -- we could be smarter here
   where
-- 
2.12.1


From 2c9e34f445dcfd96a264ec8a23644c075480e046 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 25 Jun 2017 22:33:29 +0200
Subject: [PATCH 105/117] `expandArity` is now in line with the thesis

---
 compiler/basicTypes/Usage.hs | 9 +++------
 1 file changed, 3 insertions(+), 6 deletions(-)

diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index ad572f461c..de468b6f13 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -315,12 +315,6 @@ expandArity (Used _ u) cheap_arity
       -- Although for the cheap_arity = 0 case, we *should* not expand at all,
       -- because that would yield surprising behavior.
       = cheap_arity
-    impl UnknownUse cheap_arity
-      -- No chance we can expand anything
-      = cheap_arity
-    impl (Product _) cheap_arity
-      -- This doesn't really make sense anyway.
-      = cheap_arity
     impl (Call Many _) 0
       -- the application expression we accumulated does non-trivial work,
       -- which we aren't allowed to push into a non-one-shot lambda. So
@@ -332,6 +326,9 @@ expandArity (Used _ u) cheap_arity
       -- It's OK to push work into a one-shot lambda, or to expand as long
       -- as the accumulated application expression is cheap.
       = 1 + impl u (max 0 (cheap_arity - 1))
+    impl _ cheap_arity
+      -- No chance we can expand anything
+      = cheap_arity
 
 consUsageSig :: Usage -> UsageSig -> UsageSig
 consUsageSig u s
-- 
2.12.1


From ff9a785cdcfcd066c36e5b4a80a9d5584f54a5ab Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 26 Jun 2017 19:24:43 +0200
Subject: [PATCH 106/117] Removed debug traces

---
 compiler/simplCore/CallArity/Analysis.hs | 171 ++++++++++++++++---------------
 1 file changed, 87 insertions(+), 84 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 1ec804b2b5..3867fcb057 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -8,35 +8,38 @@ module CallArity.Analysis where
 
 #include "HsVersions.h"
 
-import CallArity.Types
-import CallArity.FrameworkBuilder
-
-import BasicTypes
-import Class
-import Coercion ( Coercion, coVarsOfCo )
-import CoreFVs ( rulesFreeVars, idRuleRhsVars )
-import CoreSyn
-import CoreUtils ( exprIsTrivial )
-import DataCon
-import DynFlags      ( DynFlags, gopt, GeneralFlag(Opt_DmdTxDictSel) )
-import FamInstEnv
-import Id
-import Maybes ( expectJust, fromMaybe, isJust )
-import MkCore
-import Outputable
-import TyCon ( isDataProductTyCon_maybe, tyConSingleDataCon_maybe )
-import UniqFM
-import UnVarGraph
-import Usage
-import Util
-import Var ( isId, isTyVar )
-import VarEnv
-import VarSet
-
-import Control.Arrow ( first, second, (***) )
-import Control.Monad ( forM )
-import qualified Data.Set as Set
-import Data.Tree
+import           CallArity.FrameworkBuilder
+import           CallArity.Types
+
+import           BasicTypes
+import           Class
+import           Coercion                   (Coercion, coVarsOfCo)
+import           CoreFVs                    (idRuleRhsVars, rulesFreeVars)
+import           CoreSyn
+import           CoreUtils                  (exprIsTrivial)
+import           DataCon
+import           DynFlags                   (DynFlags,
+                                             GeneralFlag (Opt_DmdTxDictSel),
+                                             gopt)
+import           FamInstEnv
+import           Id
+import           Maybes                     (expectJust, fromMaybe, isJust)
+import           MkCore
+import           Outputable
+import           TyCon                      (isDataProductTyCon_maybe,
+                                             tyConSingleDataCon_maybe)
+import           UniqFM
+import           UnVarGraph
+import           Usage
+import           Util
+import           Var                        (isId, isTyVar)
+import           VarEnv
+import           VarSet
+
+import           Control.Arrow              (first, second, (***))
+import           Control.Monad              (forM)
+import qualified Data.Set                   as Set
+import           Data.Tree
 
 
 {-
@@ -410,22 +413,22 @@ Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
 
 data AnalEnv
   = AE
-  { ae_dflags :: DynFlags
+  { ae_dflags              :: DynFlags
   -- ^ Configuration flags. Of particular interest to this analysis:
   --
   --     - `Opt_DmdTxDictSel`: Control analysis of dictionary selectors.
   --
-  , ae_sigs :: VarEnv (SingleUse -> TransferFunction UsageType)
+  , ae_sigs                :: VarEnv (SingleUse -> TransferFunction UsageType)
   -- ^ 'TransferFunction's of visible local let-bound identifiers. It is crucial
   -- that only the 'UsageSig' component is used, as the usage on free vars might
   -- be unstable and thus too optimistic.
-  , ae_fam_envs :: FamInstEnvs
+  , ae_fam_envs            :: FamInstEnvs
   -- ^ Needed for 'findTypeShape' to resolve type/data families.
   , ae_need_sig_annotation :: VarSet
   -- ^ `Id`s which need to be annotated with a signature, e.g. because
   -- they are visible beyond this module. These are probably top-level
   -- ids only, including exports and mentions in RULEs.
-  , ae_predicted_nodes :: Tree Int
+  , ae_predicted_nodes     :: Tree Int
   -- ^ A prediction of how many `FrameworkNode`s need to be allocated for
   -- the expression to be analyzed. We need these for allocating
   -- `FrameworkNode`s in a particular order that guarantees fast
@@ -443,19 +446,19 @@ initialAnalEnv dflags fam_envs need_sigs predicted_nodes
   }
 
 descend :: Int -> AnalEnv -> AnalEnv
-descend n env 
+descend n env
   = env { ae_predicted_nodes = subForest (ae_predicted_nodes env) !! n }
 
 predictSizeOfLetBody :: AnalEnv -> Int
 -- The body is always the first child
-predictSizeOfLetBody = rootLabel . ae_predicted_nodes . descend 0 
+predictSizeOfLetBody = rootLabel . ae_predicted_nodes . descend 0
 
-extendAnalEnv 
-  :: AnalEnv 
-  -> Id 
-  -> (SingleUse -> TransferFunction UsageType) 
+extendAnalEnv
+  :: AnalEnv
+  -> Id
+  -> (SingleUse -> TransferFunction UsageType)
   -> AnalEnv
-extendAnalEnv env id node 
+extendAnalEnv env id node
   = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
 
 -- | See Note [Analysing top-level-binds]
@@ -467,9 +470,9 @@ extendAnalEnv env id node
 -- nested lets, where the external visible ids are returned in the inner-most let
 -- as a tuple. As a result, all visible identifiers are handled as called
 -- with each other, with `topUsage`.
-programToExpr 
+programToExpr
   :: [CoreRule]
-  -> CoreProgram 
+  -> CoreProgram
   -> (VarSet, CoreExpr)
 programToExpr orphan_rules = impl [] (rulesFreeVars orphan_rules)
   where
@@ -479,15 +482,15 @@ programToExpr orphan_rules = impl [] (rulesFreeVars orphan_rules)
         -- used in the same way anyway.
     impl top_level_ids exposed (bind:prog)
       = second (Let bind) (impl (bindersOf bind ++ top_level_ids) (exposed_ids bind `unionVarSet` exposed) prog)
-    -- We need to use *at least*  
-    -- 
+    -- We need to use *at least*
+    --
     --   * exported `Id`s (`isExportedId`)
     --   * `Id`s mentioned in any RULE's RHS of this module
     --   * Manually (through a VECTORISE pragma) vectorized `Id`s.
     --     No need for RHSs of VECTORISE pragmas since we run after
     --     the initial phase of the simplifier.
     --     (See Note [Vectorisation declarations and occurrences] in SimplCore.hs)
-    --     TODO: We ignore these altogether for now, since collecting 
+    --     TODO: We ignore these altogether for now, since collecting
     --           the needed info is really tedious.
     --
     -- This essentially does the same as the Occurence Analyser,
@@ -504,20 +507,20 @@ programToExpr orphan_rules = impl [] (rulesFreeVars orphan_rules)
 -- | The left inverse to `programToExpr`: `exprToProgram . snd . programToExpr = id \@CoreProgram`
 exprToProgram :: CoreExpr -> CoreProgram
 exprToProgram (Let bind e) = bind : exprToProgram e
-exprToProgram _ = []
+exprToProgram _            = []
 
 -- Main entry point
-callArityAnalProgram 
-  :: DynFlags 
-  -> FamInstEnvs 
+callArityAnalProgram
+  :: DynFlags
+  -> FamInstEnvs
   -> [CoreRule]
-  -> CoreProgram 
+  -> CoreProgram
   -> IO CoreProgram
 callArityAnalProgram dflags fam_envs orphan_rules
-  = return 
-  -- . (\it -> pprTrace "callArity:end" (ppr (length it)) it) 
-  . exprToProgram 
-  . uncurry (callArityRHS dflags fam_envs) 
+  = return
+  -- . (\it -> pprTrace "callArity:end" (ppr (length it)) it)
+  . exprToProgram
+  . uncurry (callArityRHS dflags fam_envs)
   . programToExpr orphan_rules
   -- . (\it -> pprTrace "callArity:begin" (ppr (length it)) it)
   -- . (\prog -> pprTrace "CallArity:Program" (ppr prog) prog)
@@ -555,7 +558,7 @@ callArityExprMap env f e
       return (ut, f e')
 
 callArityExpr _ e@(Lit _)
-  = callArityExprTrivial emptyUsageType e 
+  = callArityExprTrivial emptyUsageType e
 callArityExpr _ e@(Type _)
   = callArityExprTrivial emptyUsageType e
 
@@ -583,7 +586,7 @@ callArityExpr env e@(Var id) = return transfer
       -- transparently in `registerBindingGroups`.
       = do
         ut_callee <- transfer_callee use
-        pprTrace "callArityExpr:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
+        --pprTrace "callArityExpr:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
         return (ut_callee `bothUsageType` unitUsageType id use, e)
 
       | isLocalId id
@@ -639,7 +642,7 @@ callArityExpr env (Lam id body)
           --pprTrace "callArityExpr:Lam" (vcat [text "id:" <+> ppr id, text "relative body usage:" <+> ppr u, text "id usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
           return (ut, Lam id' body')
 
-callArityExpr env (App f (Type t)) 
+callArityExpr env (App f (Type t))
   = callArityExprMap (descend 0 env) (flip App (Type t)) f
 callArityExpr env (App f a) = do
   transfer_f <- callArityExpr (descend 0 env) f
@@ -653,8 +656,8 @@ callArityExpr env (App f a) = do
       Absent -> return (ut_f', App f' (markAbsent a))
       Used m arg_use -> do
         -- `m` will be `Once` most of the time (see `considerThunkSharing`),
-        -- so that all work before the lambda is uncovered will be shared 
-        -- (call-by-need!). This is the same argument as for let-bound 
+        -- so that all work before the lambda is uncovered will be shared
+        -- (call-by-need!). This is the same argument as for let-bound
         -- right hand sides.
         -- We could also use the multiplicity in the same way we do for
         -- let-bindings: An argument only used once does not need to be
@@ -666,7 +669,7 @@ callArityExpr env (App f a) = do
 callArityExpr env (Case scrut case_bndr ty alts) = do
   transfer_scrut <- callArityExpr (descend 0 env) scrut
   -- We zip the index of the child in the ae_predicted_nodes tree
-  transfer_alts <- forM (zip [1..] alts) $ \(n, alt) -> 
+  transfer_alts <- forM (zip [1..] alts) $ \(n, alt) ->
     analyseCaseAlternative (descend n env) case_bndr alt
   return $ \use -> do
     (ut_alts, alts', scrut_uses) <- unzip3 <$> mapM ($ use) transfer_alts
@@ -681,7 +684,7 @@ callArityExpr env (Case scrut case_bndr ty alts) = do
     --pprTrace "Case" (vcat [text "ut_scrut:" <+> ppr ut_scrut, text "ut_alts:" <+> ppr ut_alts, text "ut:" <+> ppr ut]) (return ())
     return (ut, Case scrut' case_bndr' ty alts')
 
-callArityExpr env (Let bind e) 
+callArityExpr env (Let bind e)
   = registerTransferFunction register >>= deref_node
   where
     deref_node node = return $ \use -> do
@@ -708,7 +711,7 @@ callArityExpr env (Let bind e)
             --use <- pprTrace "Rec:begin" (ppr ids) $ return use
             (ut_body, e') <- transfer_body use
             (ut_usage, old_binds) <- case rec_flag of
-              NonRecursive -> 
+              NonRecursive ->
                 -- We don't need to dependOn ourselves here, because only the let body can't
                 -- call id.
                 return (ut_body, initial_binds)
@@ -721,7 +724,7 @@ callArityExpr env (Let bind e)
             (ut, binds') <- unleashLet env' rec_flag transferred_binds ut_usage ut_body
             --ut <- pprTrace "Rec:end" (ppr ids) $ return ut
             case rec_flag of
-              NonRecursive 
+              NonRecursive
                 | [(id', rhs')] <- binds'
                 -> return (ut, Let (NonRec id' rhs') e')
               _ -> return (ut, Let (Rec binds') e')
@@ -796,7 +799,7 @@ globalIdUsageSig id use
   | use <= single_call
   = ASSERT2( usg_sig `leqUsageSig` str_sig, text "usg_sig:" <+> ppr usg_sig <+> text "str_sig:" <+> ppr str_sig ) usg_sig
   | otherwise
-  = --pprTrace "many" (ppr arg_usage <+> ppr (idStrictness id) <+> ppr (manifyUsageSig arg_usage)) $ 
+  = --pprTrace "many" (ppr arg_usage <+> ppr (idStrictness id) <+> ppr (manifyUsageSig arg_usage)) $
     manifyUsageSig usg_sig
   where
     (<=) = leqSingleUse
@@ -807,7 +810,7 @@ globalIdUsageSig id use
     usg_sig = idArgUsage id
     str_sig = usageSigFromStrictSig (idStrictness id)
 
--- | Evaluation of a non-trivial RHS of a let-binding or argument 
+-- | Evaluation of a non-trivial RHS of a let-binding or argument
 -- is shared (call-by-need!). GHC however doesn't allocate a new thunk
 -- if it finds the expression to bind to be trivial (`exprIsTrivial`).
 -- This makes sure we share usage only if this is not the case.
@@ -868,10 +871,10 @@ addCaseBndrUsage (Used _ use) alt_bndr_usages
 setBndrUsageInfo :: FamInstEnvs -> Var -> Usage -> Var
 setBndrUsageInfo fam_envs id usage
   | isTyVar id
-  = id 
+  = id
   | otherwise
     -- See Note [Trimming a demand to a type] in Demand.hs
-  = pprTrace "setBndrUsageInfo" (ppr id <+> ppr usage') $
+  = --pprTrace "setBndrUsageInfo" (ppr id <+> ppr usage') $
     id `setIdCallArity` usage'
     where
       usage' = trimUsageToTypeShape fam_envs id usage
@@ -911,7 +914,7 @@ propagateProductUse alts scrut_uses
 addDataConStrictness :: DataCon -> SingleUse -> SingleUse
 -- See Note [Add demands for strict constructors] in DmdAnal.hs
 addDataConStrictness dc
-  = maybe topSingleUse (mkProductUse . add_component_strictness) 
+  = maybe topSingleUse (mkProductUse . add_component_strictness)
   . peelProductUse arity
   where
     add_component_strictness :: [Usage] -> [Usage]
@@ -926,7 +929,7 @@ addDataConStrictness dc
       | otherwise = usage
 
 recFlagOf :: CoreBind -> RecFlag
-recFlagOf Rec{} = Recursive
+recFlagOf Rec{}    = Recursive
 recFlagOf NonRec{} = NonRecursive
 
 exprForcedError :: CoreExpr
@@ -969,12 +972,12 @@ registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`
           transfer_rhs <- callArityExpr (descend n env') rhs
           let transfer_annotate = monotonize up_node $ \use -> do
                 --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
-                ret@(ut, rhs') <- transfer_rhs use 
+                ret@(ut, rhs') <- transfer_rhs use
                 --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr ut]) $ return ret
                 return ret
           let transfer_args_only use = do
-                -- This makes sure to forget the annotated expression from the up_node, 
-                -- in order to have a more forgiving change detector. That's essential for 
+                -- This makes sure to forget the annotated expression from the up_node,
+                -- in order to have a more forgiving change detector. That's essential for
                 -- termination of the analysis.
                 --use <- pprTrace "args:begin" (ppr id <+> text "::" <+> ppr use) $ return use
                 (ut, _) <- dependOnWithDefault (botUsageType, exprForcedError) (up_node, use)
@@ -1005,11 +1008,11 @@ changeDetectorUsageType _ (old, _) (new, _) =
 changeDetectorAnalResult :: FrameworkNode -> ChangeDetector
 changeDetectorAnalResult self_node changed_refs (old, e) (new, e') =
   --pprTrace "changeDetector" (ppr $ Set.map fst changed_refs) $
-  not (Set.map fst changed_refs `Set.isSubsetOf` Set.singleton self_node) || 
+  not (Set.map fst changed_refs `Set.isSubsetOf` Set.singleton self_node) ||
   changeDetectorUsageType changed_refs (old, e) (new, e')
 
 unleashLet
-  :: AnalEnv 
+  :: AnalEnv
   -> RecFlag
   -> [(Id, (CoreExpr, SingleUse -> TransferFunction AnalResult))]
   -> UsageType
@@ -1026,7 +1029,7 @@ unleashLet env rec_flag transferred_binds ut_usage ut_body = do
   -- Now use that information to annotate binders.
   let (_, usages) = findBndrsUsages rec_flag fam_envs ut_final ids
   let ids' = setBndrsUsageInfo fam_envs ids usages
-  ids'' <- forM ids' (annotateIdArgUsage env) 
+  ids'' <- forM ids' (annotateIdArgUsage env)
 
   -- This intentionally still contains the @Id@s of the binding group, because
   -- the recursive rule looks at their usages to determine stability.
@@ -1061,11 +1064,11 @@ unleashUsage rhs transfer_rhs usage
   | Absent <- usage
   = return (emptyUsageType, markAbsent rhs)
   | Used m use <- considerThunkSharing rhs usage
-  -- As with arguments, `m` should be `Once` most of the time 
+  -- As with arguments, `m` should be `Once` most of the time
   -- (e.g. if `rhs` is non-trivial, see `considerThunkSharing`).
-  -- Thus, the work required to get the RHS of let-bindings 
+  -- Thus, the work required to get the RHS of let-bindings
   -- to WHNF is shared among all use sites.
-  -- We still annotate the binder with the multiplicity later on, 
+  -- We still annotate the binder with the multiplicity later on,
   -- as @Once@ means we don't have to memoize the result anyway.
   = first (multiplyUsages m) <$> transfer_rhs use
 
@@ -1132,20 +1135,20 @@ callArityLetEnv rhss ut_body
 -- which are just too much trouble to deal with ATM. FIXME!
 markAbsent :: CoreExpr -> CoreExpr
 markAbsent = expr
-  where 
-    abs id 
+  where
+    abs id
       | isTyVar id = id
       | otherwise = id `setIdCallArity` Absent
     expr e = case e of
       App f a -> App (expr f) (expr a)
-      -- I better leave the binder untouched for now... Don't want to break 
+      -- I better leave the binder untouched for now... Don't want to break
       -- stuff that expects absent closures to be compilable
-      Lam id body -> Lam id (expr body) 
+      Lam id body -> Lam id (expr body)
       Let binds body -> Let (bind binds) (expr body)
       Case scrut bndr ty alts -> Case (expr scrut) (abs bndr) ty (map alt alts)
       Cast e co -> Cast (expr e) co
       Tick t e -> Tick t (expr e)
       _ -> e
     bind (NonRec id rhs) = NonRec (abs id) (expr rhs)
-    bind (Rec binds) = Rec (map (abs *** expr) binds)
-    alt (dc, bndrs, body) = (dc, map abs bndrs, expr body)
\ No newline at end of file
+    bind (Rec binds)     = Rec (map (abs *** expr) binds)
+    alt (dc, bndrs, body) = (dc, map abs bndrs, expr body)
-- 
2.12.1


From 71ff97f13a39a351fc14314a689a60449d18a3d3 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 30 Jun 2017 22:25:43 +0200
Subject: [PATCH 107/117] Revert "Removed debug traces"

Somehow a run of stylish-haskell screwed the diff.

This reverts commit ef3eef812548c4ea4e7bab8c6784960a2b854c42.
---
 compiler/simplCore/CallArity/Analysis.hs | 171 +++++++++++++++----------------
 1 file changed, 84 insertions(+), 87 deletions(-)

diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/CallArity/Analysis.hs
index 3867fcb057..1ec804b2b5 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/CallArity/Analysis.hs
@@ -8,38 +8,35 @@ module CallArity.Analysis where
 
 #include "HsVersions.h"
 
-import           CallArity.FrameworkBuilder
-import           CallArity.Types
-
-import           BasicTypes
-import           Class
-import           Coercion                   (Coercion, coVarsOfCo)
-import           CoreFVs                    (idRuleRhsVars, rulesFreeVars)
-import           CoreSyn
-import           CoreUtils                  (exprIsTrivial)
-import           DataCon
-import           DynFlags                   (DynFlags,
-                                             GeneralFlag (Opt_DmdTxDictSel),
-                                             gopt)
-import           FamInstEnv
-import           Id
-import           Maybes                     (expectJust, fromMaybe, isJust)
-import           MkCore
-import           Outputable
-import           TyCon                      (isDataProductTyCon_maybe,
-                                             tyConSingleDataCon_maybe)
-import           UniqFM
-import           UnVarGraph
-import           Usage
-import           Util
-import           Var                        (isId, isTyVar)
-import           VarEnv
-import           VarSet
-
-import           Control.Arrow              (first, second, (***))
-import           Control.Monad              (forM)
-import qualified Data.Set                   as Set
-import           Data.Tree
+import CallArity.Types
+import CallArity.FrameworkBuilder
+
+import BasicTypes
+import Class
+import Coercion ( Coercion, coVarsOfCo )
+import CoreFVs ( rulesFreeVars, idRuleRhsVars )
+import CoreSyn
+import CoreUtils ( exprIsTrivial )
+import DataCon
+import DynFlags      ( DynFlags, gopt, GeneralFlag(Opt_DmdTxDictSel) )
+import FamInstEnv
+import Id
+import Maybes ( expectJust, fromMaybe, isJust )
+import MkCore
+import Outputable
+import TyCon ( isDataProductTyCon_maybe, tyConSingleDataCon_maybe )
+import UniqFM
+import UnVarGraph
+import Usage
+import Util
+import Var ( isId, isTyVar )
+import VarEnv
+import VarSet
+
+import Control.Arrow ( first, second, (***) )
+import Control.Monad ( forM )
+import qualified Data.Set as Set
+import Data.Tree
 
 
 {-
@@ -413,22 +410,22 @@ Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
 
 data AnalEnv
   = AE
-  { ae_dflags              :: DynFlags
+  { ae_dflags :: DynFlags
   -- ^ Configuration flags. Of particular interest to this analysis:
   --
   --     - `Opt_DmdTxDictSel`: Control analysis of dictionary selectors.
   --
-  , ae_sigs                :: VarEnv (SingleUse -> TransferFunction UsageType)
+  , ae_sigs :: VarEnv (SingleUse -> TransferFunction UsageType)
   -- ^ 'TransferFunction's of visible local let-bound identifiers. It is crucial
   -- that only the 'UsageSig' component is used, as the usage on free vars might
   -- be unstable and thus too optimistic.
-  , ae_fam_envs            :: FamInstEnvs
+  , ae_fam_envs :: FamInstEnvs
   -- ^ Needed for 'findTypeShape' to resolve type/data families.
   , ae_need_sig_annotation :: VarSet
   -- ^ `Id`s which need to be annotated with a signature, e.g. because
   -- they are visible beyond this module. These are probably top-level
   -- ids only, including exports and mentions in RULEs.
-  , ae_predicted_nodes     :: Tree Int
+  , ae_predicted_nodes :: Tree Int
   -- ^ A prediction of how many `FrameworkNode`s need to be allocated for
   -- the expression to be analyzed. We need these for allocating
   -- `FrameworkNode`s in a particular order that guarantees fast
@@ -446,19 +443,19 @@ initialAnalEnv dflags fam_envs need_sigs predicted_nodes
   }
 
 descend :: Int -> AnalEnv -> AnalEnv
-descend n env
+descend n env 
   = env { ae_predicted_nodes = subForest (ae_predicted_nodes env) !! n }
 
 predictSizeOfLetBody :: AnalEnv -> Int
 -- The body is always the first child
-predictSizeOfLetBody = rootLabel . ae_predicted_nodes . descend 0
+predictSizeOfLetBody = rootLabel . ae_predicted_nodes . descend 0 
 
-extendAnalEnv
-  :: AnalEnv
-  -> Id
-  -> (SingleUse -> TransferFunction UsageType)
+extendAnalEnv 
+  :: AnalEnv 
+  -> Id 
+  -> (SingleUse -> TransferFunction UsageType) 
   -> AnalEnv
-extendAnalEnv env id node
+extendAnalEnv env id node 
   = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
 
 -- | See Note [Analysing top-level-binds]
@@ -470,9 +467,9 @@ extendAnalEnv env id node
 -- nested lets, where the external visible ids are returned in the inner-most let
 -- as a tuple. As a result, all visible identifiers are handled as called
 -- with each other, with `topUsage`.
-programToExpr
+programToExpr 
   :: [CoreRule]
-  -> CoreProgram
+  -> CoreProgram 
   -> (VarSet, CoreExpr)
 programToExpr orphan_rules = impl [] (rulesFreeVars orphan_rules)
   where
@@ -482,15 +479,15 @@ programToExpr orphan_rules = impl [] (rulesFreeVars orphan_rules)
         -- used in the same way anyway.
     impl top_level_ids exposed (bind:prog)
       = second (Let bind) (impl (bindersOf bind ++ top_level_ids) (exposed_ids bind `unionVarSet` exposed) prog)
-    -- We need to use *at least*
-    --
+    -- We need to use *at least*  
+    -- 
     --   * exported `Id`s (`isExportedId`)
     --   * `Id`s mentioned in any RULE's RHS of this module
     --   * Manually (through a VECTORISE pragma) vectorized `Id`s.
     --     No need for RHSs of VECTORISE pragmas since we run after
     --     the initial phase of the simplifier.
     --     (See Note [Vectorisation declarations and occurrences] in SimplCore.hs)
-    --     TODO: We ignore these altogether for now, since collecting
+    --     TODO: We ignore these altogether for now, since collecting 
     --           the needed info is really tedious.
     --
     -- This essentially does the same as the Occurence Analyser,
@@ -507,20 +504,20 @@ programToExpr orphan_rules = impl [] (rulesFreeVars orphan_rules)
 -- | The left inverse to `programToExpr`: `exprToProgram . snd . programToExpr = id \@CoreProgram`
 exprToProgram :: CoreExpr -> CoreProgram
 exprToProgram (Let bind e) = bind : exprToProgram e
-exprToProgram _            = []
+exprToProgram _ = []
 
 -- Main entry point
-callArityAnalProgram
-  :: DynFlags
-  -> FamInstEnvs
+callArityAnalProgram 
+  :: DynFlags 
+  -> FamInstEnvs 
   -> [CoreRule]
-  -> CoreProgram
+  -> CoreProgram 
   -> IO CoreProgram
 callArityAnalProgram dflags fam_envs orphan_rules
-  = return
-  -- . (\it -> pprTrace "callArity:end" (ppr (length it)) it)
-  . exprToProgram
-  . uncurry (callArityRHS dflags fam_envs)
+  = return 
+  -- . (\it -> pprTrace "callArity:end" (ppr (length it)) it) 
+  . exprToProgram 
+  . uncurry (callArityRHS dflags fam_envs) 
   . programToExpr orphan_rules
   -- . (\it -> pprTrace "callArity:begin" (ppr (length it)) it)
   -- . (\prog -> pprTrace "CallArity:Program" (ppr prog) prog)
@@ -558,7 +555,7 @@ callArityExprMap env f e
       return (ut, f e')
 
 callArityExpr _ e@(Lit _)
-  = callArityExprTrivial emptyUsageType e
+  = callArityExprTrivial emptyUsageType e 
 callArityExpr _ e@(Type _)
   = callArityExprTrivial emptyUsageType e
 
@@ -586,7 +583,7 @@ callArityExpr env e@(Var id) = return transfer
       -- transparently in `registerBindingGroups`.
       = do
         ut_callee <- transfer_callee use
-        --pprTrace "callArityExpr:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
+        pprTrace "callArityExpr:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
         return (ut_callee `bothUsageType` unitUsageType id use, e)
 
       | isLocalId id
@@ -642,7 +639,7 @@ callArityExpr env (Lam id body)
           --pprTrace "callArityExpr:Lam" (vcat [text "id:" <+> ppr id, text "relative body usage:" <+> ppr u, text "id usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
           return (ut, Lam id' body')
 
-callArityExpr env (App f (Type t))
+callArityExpr env (App f (Type t)) 
   = callArityExprMap (descend 0 env) (flip App (Type t)) f
 callArityExpr env (App f a) = do
   transfer_f <- callArityExpr (descend 0 env) f
@@ -656,8 +653,8 @@ callArityExpr env (App f a) = do
       Absent -> return (ut_f', App f' (markAbsent a))
       Used m arg_use -> do
         -- `m` will be `Once` most of the time (see `considerThunkSharing`),
-        -- so that all work before the lambda is uncovered will be shared
-        -- (call-by-need!). This is the same argument as for let-bound
+        -- so that all work before the lambda is uncovered will be shared 
+        -- (call-by-need!). This is the same argument as for let-bound 
         -- right hand sides.
         -- We could also use the multiplicity in the same way we do for
         -- let-bindings: An argument only used once does not need to be
@@ -669,7 +666,7 @@ callArityExpr env (App f a) = do
 callArityExpr env (Case scrut case_bndr ty alts) = do
   transfer_scrut <- callArityExpr (descend 0 env) scrut
   -- We zip the index of the child in the ae_predicted_nodes tree
-  transfer_alts <- forM (zip [1..] alts) $ \(n, alt) ->
+  transfer_alts <- forM (zip [1..] alts) $ \(n, alt) -> 
     analyseCaseAlternative (descend n env) case_bndr alt
   return $ \use -> do
     (ut_alts, alts', scrut_uses) <- unzip3 <$> mapM ($ use) transfer_alts
@@ -684,7 +681,7 @@ callArityExpr env (Case scrut case_bndr ty alts) = do
     --pprTrace "Case" (vcat [text "ut_scrut:" <+> ppr ut_scrut, text "ut_alts:" <+> ppr ut_alts, text "ut:" <+> ppr ut]) (return ())
     return (ut, Case scrut' case_bndr' ty alts')
 
-callArityExpr env (Let bind e)
+callArityExpr env (Let bind e) 
   = registerTransferFunction register >>= deref_node
   where
     deref_node node = return $ \use -> do
@@ -711,7 +708,7 @@ callArityExpr env (Let bind e)
             --use <- pprTrace "Rec:begin" (ppr ids) $ return use
             (ut_body, e') <- transfer_body use
             (ut_usage, old_binds) <- case rec_flag of
-              NonRecursive ->
+              NonRecursive -> 
                 -- We don't need to dependOn ourselves here, because only the let body can't
                 -- call id.
                 return (ut_body, initial_binds)
@@ -724,7 +721,7 @@ callArityExpr env (Let bind e)
             (ut, binds') <- unleashLet env' rec_flag transferred_binds ut_usage ut_body
             --ut <- pprTrace "Rec:end" (ppr ids) $ return ut
             case rec_flag of
-              NonRecursive
+              NonRecursive 
                 | [(id', rhs')] <- binds'
                 -> return (ut, Let (NonRec id' rhs') e')
               _ -> return (ut, Let (Rec binds') e')
@@ -799,7 +796,7 @@ globalIdUsageSig id use
   | use <= single_call
   = ASSERT2( usg_sig `leqUsageSig` str_sig, text "usg_sig:" <+> ppr usg_sig <+> text "str_sig:" <+> ppr str_sig ) usg_sig
   | otherwise
-  = --pprTrace "many" (ppr arg_usage <+> ppr (idStrictness id) <+> ppr (manifyUsageSig arg_usage)) $
+  = --pprTrace "many" (ppr arg_usage <+> ppr (idStrictness id) <+> ppr (manifyUsageSig arg_usage)) $ 
     manifyUsageSig usg_sig
   where
     (<=) = leqSingleUse
@@ -810,7 +807,7 @@ globalIdUsageSig id use
     usg_sig = idArgUsage id
     str_sig = usageSigFromStrictSig (idStrictness id)
 
--- | Evaluation of a non-trivial RHS of a let-binding or argument
+-- | Evaluation of a non-trivial RHS of a let-binding or argument 
 -- is shared (call-by-need!). GHC however doesn't allocate a new thunk
 -- if it finds the expression to bind to be trivial (`exprIsTrivial`).
 -- This makes sure we share usage only if this is not the case.
@@ -871,10 +868,10 @@ addCaseBndrUsage (Used _ use) alt_bndr_usages
 setBndrUsageInfo :: FamInstEnvs -> Var -> Usage -> Var
 setBndrUsageInfo fam_envs id usage
   | isTyVar id
-  = id
+  = id 
   | otherwise
     -- See Note [Trimming a demand to a type] in Demand.hs
-  = --pprTrace "setBndrUsageInfo" (ppr id <+> ppr usage') $
+  = pprTrace "setBndrUsageInfo" (ppr id <+> ppr usage') $
     id `setIdCallArity` usage'
     where
       usage' = trimUsageToTypeShape fam_envs id usage
@@ -914,7 +911,7 @@ propagateProductUse alts scrut_uses
 addDataConStrictness :: DataCon -> SingleUse -> SingleUse
 -- See Note [Add demands for strict constructors] in DmdAnal.hs
 addDataConStrictness dc
-  = maybe topSingleUse (mkProductUse . add_component_strictness)
+  = maybe topSingleUse (mkProductUse . add_component_strictness) 
   . peelProductUse arity
   where
     add_component_strictness :: [Usage] -> [Usage]
@@ -929,7 +926,7 @@ addDataConStrictness dc
       | otherwise = usage
 
 recFlagOf :: CoreBind -> RecFlag
-recFlagOf Rec{}    = Recursive
+recFlagOf Rec{} = Recursive
 recFlagOf NonRec{} = NonRecursive
 
 exprForcedError :: CoreExpr
@@ -972,12 +969,12 @@ registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`
           transfer_rhs <- callArityExpr (descend n env') rhs
           let transfer_annotate = monotonize up_node $ \use -> do
                 --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
-                ret@(ut, rhs') <- transfer_rhs use
+                ret@(ut, rhs') <- transfer_rhs use 
                 --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr ut]) $ return ret
                 return ret
           let transfer_args_only use = do
-                -- This makes sure to forget the annotated expression from the up_node,
-                -- in order to have a more forgiving change detector. That's essential for
+                -- This makes sure to forget the annotated expression from the up_node, 
+                -- in order to have a more forgiving change detector. That's essential for 
                 -- termination of the analysis.
                 --use <- pprTrace "args:begin" (ppr id <+> text "::" <+> ppr use) $ return use
                 (ut, _) <- dependOnWithDefault (botUsageType, exprForcedError) (up_node, use)
@@ -1008,11 +1005,11 @@ changeDetectorUsageType _ (old, _) (new, _) =
 changeDetectorAnalResult :: FrameworkNode -> ChangeDetector
 changeDetectorAnalResult self_node changed_refs (old, e) (new, e') =
   --pprTrace "changeDetector" (ppr $ Set.map fst changed_refs) $
-  not (Set.map fst changed_refs `Set.isSubsetOf` Set.singleton self_node) ||
+  not (Set.map fst changed_refs `Set.isSubsetOf` Set.singleton self_node) || 
   changeDetectorUsageType changed_refs (old, e) (new, e')
 
 unleashLet
-  :: AnalEnv
+  :: AnalEnv 
   -> RecFlag
   -> [(Id, (CoreExpr, SingleUse -> TransferFunction AnalResult))]
   -> UsageType
@@ -1029,7 +1026,7 @@ unleashLet env rec_flag transferred_binds ut_usage ut_body = do
   -- Now use that information to annotate binders.
   let (_, usages) = findBndrsUsages rec_flag fam_envs ut_final ids
   let ids' = setBndrsUsageInfo fam_envs ids usages
-  ids'' <- forM ids' (annotateIdArgUsage env)
+  ids'' <- forM ids' (annotateIdArgUsage env) 
 
   -- This intentionally still contains the @Id@s of the binding group, because
   -- the recursive rule looks at their usages to determine stability.
@@ -1064,11 +1061,11 @@ unleashUsage rhs transfer_rhs usage
   | Absent <- usage
   = return (emptyUsageType, markAbsent rhs)
   | Used m use <- considerThunkSharing rhs usage
-  -- As with arguments, `m` should be `Once` most of the time
+  -- As with arguments, `m` should be `Once` most of the time 
   -- (e.g. if `rhs` is non-trivial, see `considerThunkSharing`).
-  -- Thus, the work required to get the RHS of let-bindings
+  -- Thus, the work required to get the RHS of let-bindings 
   -- to WHNF is shared among all use sites.
-  -- We still annotate the binder with the multiplicity later on,
+  -- We still annotate the binder with the multiplicity later on, 
   -- as @Once@ means we don't have to memoize the result anyway.
   = first (multiplyUsages m) <$> transfer_rhs use
 
@@ -1135,20 +1132,20 @@ callArityLetEnv rhss ut_body
 -- which are just too much trouble to deal with ATM. FIXME!
 markAbsent :: CoreExpr -> CoreExpr
 markAbsent = expr
-  where
-    abs id
+  where 
+    abs id 
       | isTyVar id = id
       | otherwise = id `setIdCallArity` Absent
     expr e = case e of
       App f a -> App (expr f) (expr a)
-      -- I better leave the binder untouched for now... Don't want to break
+      -- I better leave the binder untouched for now... Don't want to break 
       -- stuff that expects absent closures to be compilable
-      Lam id body -> Lam id (expr body)
+      Lam id body -> Lam id (expr body) 
       Let binds body -> Let (bind binds) (expr body)
       Case scrut bndr ty alts -> Case (expr scrut) (abs bndr) ty (map alt alts)
       Cast e co -> Cast (expr e) co
       Tick t e -> Tick t (expr e)
       _ -> e
     bind (NonRec id rhs) = NonRec (abs id) (expr rhs)
-    bind (Rec binds)     = Rec (map (abs *** expr) binds)
-    alt (dc, bndrs, body) = (dc, map abs bndrs, expr body)
+    bind (Rec binds) = Rec (map (abs *** expr) binds)
+    alt (dc, bndrs, body) = (dc, map abs bndrs, expr body)
\ No newline at end of file
-- 
2.12.1


From a09228911e486e9a5e0909a1bd993ad54045e883 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Fri, 30 Jun 2017 22:12:31 +0200
Subject: [PATCH 108/117] Renamed CallArity to UsageAnal, also SingleUse -> Use

---
 compiler/basicTypes/Id.hs                          |  14 +-
 compiler/basicTypes/IdInfo.hs                      |  18 +-
 compiler/basicTypes/Usage.hs                       | 152 ++++++++--------
 compiler/coreSyn/CoreLint.hs                       |   2 +-
 compiler/coreSyn/CoreTidy.hs                       |   2 +-
 compiler/coreSyn/CoreUtils.hs                      |   2 +-
 compiler/coreSyn/PprCore.hs                        |   2 +-
 compiler/ghc.cabal.in                              |   8 +-
 compiler/main/DynFlags.hs                          |   6 +-
 compiler/simplCore/CallArity.hs                    |   9 -
 compiler/simplCore/CoreMonad.hs                    |   4 +-
 compiler/simplCore/DmdAnalWrapper.hs               |  14 +-
 compiler/simplCore/SimplCore.hs                    |  14 +-
 compiler/simplCore/SimplUtils.hs                   |   2 +-
 compiler/simplCore/UsageAnal.hs                    |   5 +
 .../simplCore/{CallArity => UsageAnal}/Analysis.hs | 196 ++++++++++-----------
 .../{CallArity => UsageAnal}/FrameworkBuilder.hs   |  28 +--
 .../simplCore/{CallArity => UsageAnal}/Types.hs    |  16 +-
 compiler/utils/UnVarGraph.hs                       |   9 +-
 testsuite/tests/callarity/unittest/CallArity1.hs   |   4 +-
 20 files changed, 254 insertions(+), 253 deletions(-)
 delete mode 100644 compiler/simplCore/CallArity.hs
 create mode 100644 compiler/simplCore/UsageAnal.hs
 rename compiler/simplCore/{CallArity => UsageAnal}/Analysis.hs (90%)
 rename compiler/simplCore/{CallArity => UsageAnal}/FrameworkBuilder.hs (86%)
 rename compiler/simplCore/{CallArity => UsageAnal}/Types.hs (92%)

diff --git a/compiler/basicTypes/Id.hs b/compiler/basicTypes/Id.hs
index 61381a0068..6c10ac8eb7 100644
--- a/compiler/basicTypes/Id.hs
+++ b/compiler/basicTypes/Id.hs
@@ -96,7 +96,7 @@ module Id (
         idOneShotInfo, idStateHackOneShotInfo,
         idOccInfo,
         isNeverLevPolyId,
-        idCallArity,
+        idUsage,
         idArgUsage,
         idDemandInfo,
         idStrictness,
@@ -109,7 +109,7 @@ module Id (
         setIdCafInfo,
         setIdOccInfo, zapIdOccInfo,
 
-        setIdCallArity,
+        setIdUsage,
         setIdArgUsage,
         setIdDemandInfo,
         setIdStrictness,
@@ -168,7 +168,7 @@ infixl  1 `setIdUnfolding`,
           `asJoinId`,
           `asJoinId_maybe`,
 
-          `setIdCallArity`,
+          `setIdUsage`,
           `setIdArgUsage`
 
 {-
@@ -623,11 +623,11 @@ idArity id = arityInfo (idInfo id)
 setIdArity :: Id -> Arity -> Id
 setIdArity id arity = modifyIdInfo (`setArityInfo` arity) id
 
-idCallArity :: Id -> Usage
-idCallArity id = callArityInfo (idInfo id)
+idUsage :: Id -> Usage
+idUsage id = usageInfo (idInfo id)
 
-setIdCallArity :: Id -> Usage -> Id
-setIdCallArity id used = modifyIdInfo (`setCallArityInfo` used) id
+setIdUsage :: Id -> Usage -> Id
+setIdUsage id used = modifyIdInfo (`setUsageInfo` used) id
 
 idArgUsage :: Id -> UsageSig
 idArgUsage id = argUsageInfo (idInfo id)
diff --git a/compiler/basicTypes/IdInfo.hs b/compiler/basicTypes/IdInfo.hs
index b7f5410c32..1604aabdcf 100644
--- a/compiler/basicTypes/IdInfo.hs
+++ b/compiler/basicTypes/IdInfo.hs
@@ -38,7 +38,7 @@ module IdInfo (
 
         -- ** Usage info
         argUsageInfo, setArgUsageInfo,
-        callArityInfo, setCallArityInfo,
+        usageInfo, setUsageInfo,
 
         -- ** Demand and strictness Info
         strictnessInfo, setStrictnessInfo,
@@ -112,9 +112,13 @@ infixl  1 `setRuleInfo`,
           `setCafInfo`,
           `setStrictnessInfo`,
           `setDemandInfo`,
+<<<<<<< HEAD
           `setNeverLevPoly`,
           `setLevityInfoWithType`
           `setCallArityInfo`,
+=======
+          `setUsageInfo`,
+>>>>>>> Renamed CallArity to UsageAnal, also SingleUse -> Use
           `setArgUsageInfo`
 
 {-
@@ -233,7 +237,7 @@ pprIdDetails other     = brackets (pp other)
 --
 -- Most of the 'IdInfo' gives information about the value, or definition, of
 -- the 'Id', independent of its usage. Exceptions to this
--- are 'demandInfo', 'occInfo', 'oneShotInfo' and 'callArityInfo'.
+-- are 'demandInfo', 'occInfo', 'oneShotInfo' and 'usageInfo'.
 --
 -- Performance note: when we update 'IdInfo', we have to reallocate this
 -- entire record, so it is a good idea not to let this data structure get
@@ -252,7 +256,7 @@ data IdInfo
         strictnessInfo  :: !StrictSig,
         demandInfo      :: !Demand,
         argUsageInfo    :: !UsageSig,
-        callArityInfo   :: !Usage,
+        usageInfo       :: !Usage,
 
         levityInfo      :: LevityInfo           -- ^ when applied, will this Id ever have a levity-polymorphic type?
     }
@@ -293,8 +297,8 @@ setStrictnessInfo info dd = info { strictnessInfo = dd }
 setArgUsageInfo :: IdInfo -> UsageSig -> IdInfo
 setArgUsageInfo info sig = info { argUsageInfo = sig }
 
-setCallArityInfo :: IdInfo -> Usage -> IdInfo
-setCallArityInfo info used = info { callArityInfo = used }
+setUsageInfo :: IdInfo -> Usage -> IdInfo
+setUsageInfo info used = info { usageInfo = used }
 
 -- | Basic 'IdInfo' that carries no useful information whatsoever
 vanillaIdInfo :: IdInfo
@@ -310,8 +314,12 @@ vanillaIdInfo
             strictnessInfo      = nopSig,
             demandInfo          = topDmd,
             argUsageInfo        = topUsageSig,
+<<<<<<< HEAD
             callArityInfo       = topUsage
             levityInfo          = NoLevityInfo
+=======
+            usageInfo       = topUsage
+>>>>>>> Renamed CallArity to UsageAnal, also SingleUse -> Use
             --cardinalityInfo     = emptyCardinalityInfo
            }
 
diff --git a/compiler/basicTypes/Usage.hs b/compiler/basicTypes/Usage.hs
index de468b6f13..4b9c1ab137 100644
--- a/compiler/basicTypes/Usage.hs
+++ b/compiler/basicTypes/Usage.hs
@@ -3,15 +3,15 @@
 module Usage
   ( Multiplicity (..)
   , botMultiplicity, topMultiplicity, lubMultiplicity
-  , SingleUse
-  , botSingleUse, topSingleUse, lubSingleUse, leqSingleUse, bothSingleUse, mkCallUse, peelCallUse, mkProductUse, peelProductUse, boundDepth
+  , Use
+  , botUse, topUse, lubUse, leqUse, bothUse, mkCallUse, peelCallUse, mkProductUse, peelProductUse, boundDepth
   , Usage (..)
   , multiplicity, botUsage, topUsage, lubUsage, bothUsage
   , manifyUsage, oneifyUsage, expandArity
   , UsageSig
   , botUsageSig, topUsageSig, lubUsageSig, leqUsageSig
   , consUsageSig, unconsUsageSig, usageSigFromUsages, manifyUsageSig
-  , trimSingleUse, trimUsage, trimUsageSig
+  , trimUse, trimUsage, trimUsageSig
   , u'1HU, u'1C1U
   , usageFromDemand, overwriteDemandWithUsage, usageSigFromStrictSig, overwriteStrictSigWithUsageSig
   ) where
@@ -34,7 +34,7 @@ data Multiplicity
   | Many
   deriving (Eq, Ord, Show)
 
--- | A `SingleUse` describes how an expression is used, after it hit WHNF.
+-- | A `Use` describes how an expression is used, after it hit WHNF.
 -- Some examples:
 --
 --    * A single use of @seq a b@ unleashes nothing beyond the WHNF use on @a@,
@@ -44,12 +44,12 @@ data Multiplicity
 --
 -- The `Ord` instance is incompatible with the lattice and only used when
 -- acting as a key type in a map.
-data SingleUse
+data Use
   = HeadUse
-  -- ^ A `SingleUse` which just evaluates the expression to WHNF. No resulting
+  -- ^ A `Use` which just evaluates the expression to WHNF. No resulting
   -- lambdas are called and usage of all product components is absent.
-  | Call !Multiplicity !SingleUse
-  -- ^ @Call m u@ denotes a `SingleUse` where, after hitting WHNF, the lambda
+  | Call !Multiplicity !Use
+  -- ^ @Call m u@ denotes a `Use` where, after hitting WHNF, the lambda
   -- body is used according to @u@ with multiplicity @m@. @Call Many u@ would
   -- mean the expression was called potentially many times, after being brought
   -- to WHNF.
@@ -57,13 +57,13 @@ data SingleUse
   -- Use `mkCallUse` to introduce this constructor and `peelCallUse` to
   -- eliminate `Call`s.
   | Product ![Usage]
-  -- ^ A `SingleUse` which, after evaluating a product constructor, will use the
+  -- ^ A `Use` which, after evaluating a product constructor, will use the
   -- product's components according to the `Usage`s given.
   --
   -- Use `mkProductUse` to introduce this constructor and `peelProductUse` to
   -- eliminate `Product`s.
   | UnknownUse
-  -- ^ A `SingleUse` where, after hitting WHNF of the expression,
+  -- ^ A `Use` where, after hitting WHNF of the expression,
   -- we don't know any further details of how
   --
   --     * a resulting nested lambda body is used
@@ -72,32 +72,32 @@ data SingleUse
 
 -- | A smart constructor for `Call` which normalizes according to the equivalence
 -- @Call Many UnknownUse = UnknownUse@.
-mkCallUse :: Multiplicity -> SingleUse -> SingleUse
+mkCallUse :: Multiplicity -> Use -> Use
 mkCallUse Many UnknownUse = UnknownUse
 mkCallUse m u = Call m u
 
 -- | A smart constructor for `Product` which normalizes according to the equivalences
--- @Product [topUsage, topUsage..] === topSingleUse@ and
--- @Product [botUsage, botUsage..] === botSingleUse@.
-mkProductUse :: [Usage] -> SingleUse
+-- @Product [topUsage, topUsage..] === topUse@ and
+-- @Product [botUsage, botUsage..] === botUse@.
+mkProductUse :: [Usage] -> Use
 mkProductUse components
   -- Order is important here: We want to regard U() as HU
-  | all (== botUsage) components = botSingleUse
+  | all (== botUsage) components = botUse
   -- This contradicts Note [Don't optimise UProd(Used) to Used], but
   -- I fixed the issue with WW that probably was the reason for the hack.
-  | all (== topUsage) components = topSingleUse 
+  | all (== topUsage) components = topUse 
   | otherwise = Product components
 
 -- | `CoreSym.Id`entifiers can be used multiple times and are the only means to
 -- introduce sharing of work, evaluating expressions into WHNF, that is.
 -- `Usage` can track how often an identifier was used and how each of the
--- `SingleUse`s looked like.
+-- `Use`s looked like.
 --
 -- The `Ord` instance is incompatible with the lattice and only used when
 -- acting as a key type in a map.
 data Usage
   = Absent
-  | Used !Multiplicity !SingleUse
+  | Used !Multiplicity !Use
   deriving (Eq, Ord, Show)
 
 multiplicity :: Usage -> Maybe Multiplicity
@@ -125,59 +125,59 @@ lubMultiplicity Once m = m
 lubMultiplicity m Once = m
 lubMultiplicity _ _    = Many
 
-botSingleUse :: SingleUse
-botSingleUse = HeadUse
+botUse :: Use
+botUse = HeadUse
 
-topSingleUse :: SingleUse
-topSingleUse = UnknownUse
+topUse :: Use
+topUse = UnknownUse
 
-lubSingleUse :: SingleUse -> SingleUse -> SingleUse
-lubSingleUse UnknownUse _ = UnknownUse
-lubSingleUse _ UnknownUse = UnknownUse
-lubSingleUse HeadUse u = u
-lubSingleUse u HeadUse = u
-lubSingleUse (Product c1) (Product c2)
+lubUse :: Use -> Use -> Use
+lubUse UnknownUse _ = UnknownUse
+lubUse _ UnknownUse = UnknownUse
+lubUse HeadUse u = u
+lubUse u HeadUse = u
+lubUse (Product c1) (Product c2)
   | equalLength c1 c2
   -- If this is not true, we probably have uses from different case branches.
-  -- In that case, returning topSingleUse is the right thing to do.
+  -- In that case, returning topUse is the right thing to do.
   = mkProductUse (zipWith lubUsage c1 c2)
-lubSingleUse (Call m1 u1) (Call m2 u2)
-  = mkCallUse (lubMultiplicity m1 m2) (lubSingleUse u1 u2)
-lubSingleUse _ _ = topSingleUse
-
-leqSingleUse :: SingleUse -> SingleUse -> Bool
-leqSingleUse a b = lubSingleUse a b == b
-
--- | Think \'plus\' on `SingleUse`s, for sequential composition.
-bothSingleUse :: SingleUse -> SingleUse -> SingleUse
-bothSingleUse UnknownUse _ = UnknownUse
-bothSingleUse _ UnknownUse = UnknownUse
-bothSingleUse HeadUse u = u
-bothSingleUse u HeadUse = u
-bothSingleUse (Product c1) (Product c2)
+lubUse (Call m1 u1) (Call m2 u2)
+  = mkCallUse (lubMultiplicity m1 m2) (lubUse u1 u2)
+lubUse _ _ = topUse
+
+leqUse :: Use -> Use -> Bool
+leqUse a b = lubUse a b == b
+
+-- | Think \'plus\' on `Use`s, for sequential composition.
+bothUse :: Use -> Use -> Use
+bothUse UnknownUse _ = UnknownUse
+bothUse _ UnknownUse = UnknownUse
+bothUse HeadUse u = u
+bothUse u HeadUse = u
+bothUse (Product c1) (Product c2)
   | equalLength c1 c2
   = mkProductUse (zipWith bothUsage c1 c2)
-bothSingleUse (Call _ u1) (Call _ u2)
-  = mkCallUse Many (lubSingleUse u1 u2)
-bothSingleUse _ _ = topSingleUse
+bothUse (Call _ u1) (Call _ u2)
+  = mkCallUse Many (lubUse u1 u2)
+bothUse _ _ = topUse
 
 botUsage :: Usage
 botUsage = Absent
 
 topUsage :: Usage
-topUsage = Used topMultiplicity topSingleUse
+topUsage = Used topMultiplicity topUse
 
 lubUsage :: Usage -> Usage -> Usage
 lubUsage Absent u = u
 lubUsage u Absent = u
-lubUsage (Used m1 u1) (Used m2 u2) = Used (lubMultiplicity m1 m2) (lubSingleUse u1 u2)
+lubUsage (Used m1 u1) (Used m2 u2) = Used (lubMultiplicity m1 m2) (lubUse u1 u2)
 
 -- | Think \'plus\' on `Usage`s, for sequential composition.
 -- E.g. if `Usage`s from scrutinee and case branches should be combined.
 bothUsage :: Usage -> Usage -> Usage
 bothUsage Absent u = u
 bothUsage u Absent = u
-bothUsage (Used _ u1) (Used _ u2) = Used Many (bothSingleUse u1 u2)
+bothUsage (Used _ u1) (Used _ u2) = Used Many (bothUse u1 u2)
 
 botUsageSig :: UsageSig
 botUsageSig = BotUsageSig
@@ -195,12 +195,12 @@ lubUsageSig (ArgUsage u1 s1) (ArgUsage u2 s2) = consUsageSig (lubUsage u1 u2) (l
 leqUsageSig :: UsageSig -> UsageSig -> Bool
 leqUsageSig u1 u2 = lubUsageSig u1 u2 == u2
 
--- * Working with `SingleUse`, `Usage` and `UsageSig`
+-- * Working with `Use`, `Usage` and `UsageSig`
 
 -- | Eliminates a `Call`. This will return the `Usage` of the lambda body,
--- relative to the given `SingleUse` of the outer expression. Useful in the
+-- relative to the given `Use` of the outer expression. Useful in the
 -- `CoreSyn.Lam`bda rule.
-peelCallUse :: SingleUse -> Maybe Usage
+peelCallUse :: Use -> Maybe Usage
 peelCallUse HeadUse = Just Absent -- The lambda will be reduced to WHNF, but the body will stay untouched.
 peelCallUse (Call multi use) = Just (Used multi use)
 peelCallUse UnknownUse = Just topUsage
@@ -209,21 +209,21 @@ peelCallUse _ = Nothing
 -- | @peelProductUse len_hint use@ tries to treat @use@ as a product use and
 -- returns the list of usages on its components. It will adhere to the @len_hint@,
 -- meaning that the @product_use@ is constrained to have that length.
--- This is mostly so that `botSingleUse` and `topSingleUse`, oblivious to length
+-- This is mostly so that `botUse` and `topUse`, oblivious to length
 -- information, can be translated (back) into a product use.
 --
 -- Examples:
 --
 --    - @peelProductUse (length comps) (mkProductUse comps) == Just comps@
---    - @peelProductUse n topSingleUse == Just (replicate n topUsage)@
---    - @peelProductUse n (mkCallUse Once topSingleUse) == Nothing@
-peelProductUse :: Arity -> SingleUse -> Maybe [Usage]
+--    - @peelProductUse n topUse == Just (replicate n topUsage)@
+--    - @peelProductUse n (mkCallUse Once topUse) == Nothing@
+peelProductUse :: Arity -> Use -> Maybe [Usage]
 peelProductUse n HeadUse = Just (replicate n botUsage)
 peelProductUse n UnknownUse = Just (replicate n topUsage)
 peelProductUse n (Product comps) | comps `lengthIs` n = Just comps
 peelProductUse _ _ = Nothing -- type error, might happen with GADTs and unsafeCoerce (#9208)
 
--- | Since the lattice modeled by `SingleUse` has infinite height, we run might
+-- | Since the lattice modeled by `Use` has infinite height, we run might
 -- run into trouble regarding convergence. This happens in practice for product
 -- usages on lazy infinite stream functions such as `filter`, where the recursion
 -- propagates strictly increasing product use chains for the argument.
@@ -233,7 +233,7 @@ peelProductUse _ _ = Nothing -- type error, might happen with GADTs and unsafeCo
 -- Although there also may be infinitely many nested Calls, we don't need to
 -- worry about them, since there should be no program for which the analysis
 -- constructs an infinite chain of Calls.
-boundDepth :: Int -> SingleUse -> SingleUse
+boundDepth :: Int -> Use -> Use
 boundDepth max_height use = snd (boundUse 0 use)
   where
     wrap impl height u -- simple caching wrapper around the actual impl
@@ -252,29 +252,29 @@ boundDepth max_height use = snd (boundUse 0 use)
           , (changed, comps') <- mapAndUnzip (boundUsage (height + 1)) comps
           = (or changed, mkProductUse comps')
           | otherwise
-          = (True, topSingleUse)
+          = (True, topUse)
         impl height (Call m u) = second (mkCallUse m) (boundUse height u)
         impl _ u = (False, u)
 
-trimSingleUseBounded :: Int -> TypeShape -> SingleUse -> SingleUse
-trimSingleUseBounded _ _ HeadUse = HeadUse
-trimSingleUseBounded d (TsFun shape) u
+trimUseBounded :: Int -> TypeShape -> Use -> Use
+trimUseBounded _ _ HeadUse = HeadUse
+trimUseBounded d (TsFun shape) u
   -- Infinite arity is prohibited by the type system, so we don't have to modify d here
   | Just (Used m body) <- peelCallUse u
-  = mkCallUse m (trimSingleUseBounded d shape body)
-trimSingleUseBounded d (TsProd shapes) u
+  = mkCallUse m (trimUseBounded d shape body)
+trimUseBounded d (TsProd shapes) u
   -- TsProd may be infinitely deep, so we have to cut off at some point
   | d < 10
   , Just comps <- peelProductUse (length shapes) u
   = mkProductUse (zipWith (trimUsageBounded (d+1)) shapes comps)
-trimSingleUseBounded _ _ _ = topSingleUse 
+trimUseBounded _ _ _ = topUse 
     
 trimUsageBounded :: Int -> TypeShape -> Usage -> Usage
-trimUsageBounded d shape (Used m use) = Used m (trimSingleUseBounded d shape use)
+trimUsageBounded d shape (Used m use) = Used m (trimUseBounded d shape use)
 trimUsageBounded _ _ usg = usg
 
-trimSingleUse :: TypeShape -> SingleUse -> SingleUse
-trimSingleUse = trimSingleUseBounded 0 
+trimUse :: TypeShape -> Use -> Use
+trimUse = trimUseBounded 0 
 
 trimUsage :: TypeShape -> Usage -> Usage
 trimUsage = trimUsageBounded 0
@@ -367,7 +367,7 @@ trimUsageSig n sig = consUsageSig head_usage (trimUsageSig (n-1) tail_usage)
   where
     (head_usage, tail_usage) = unconsUsageSig sig
 
--- * Specific `Usage`s/`SingleUse`s
+-- * Specific `Usage`s/`Use`s
 
 -- | `Usage` unleashed on `x` in @x `seq` ...@.
 u'1HU:: Usage
@@ -375,7 +375,7 @@ u'1HU = Used Once HeadUse
 
 -- | 'Called once with one argument' `Usage`: @1*C^1(U)@
 u'1C1U :: Usage
-u'1C1U = Used Once (mkCallUse Once topSingleUse)
+u'1C1U = Used Once (mkCallUse Once topUse)
 
 -- * Pretty-printing
 
@@ -383,7 +383,7 @@ instance Outputable Multiplicity where
   ppr Once = text "1"
   ppr Many = text "w"
 
-instance Outputable SingleUse where
+instance Outputable Use where
   ppr HeadUse = text "HU"
   ppr UnknownUse = text "U"
   ppr (Product components) = text "U" <> parens (hcat (punctuate (char ',') (map ppr components)))
@@ -414,7 +414,7 @@ instance Binary Multiplicity where
       _ -> return Many
 
 -- | Mostly important for serializing `UsageSig` in interface files.
-instance Binary SingleUse where
+instance Binary Use where
   put_ bh HeadUse = putByte bh 0
   put_ bh UnknownUse = putByte bh 1
   put_ bh (Product components) = putByte bh 2 >> put_ bh components
@@ -470,11 +470,11 @@ multiplicityFromCount :: Demand.Count -> Multiplicity
 multiplicityFromCount Demand.One = Once
 multiplicityFromCount Demand.Many = Many
 
-singleUseFromUseDmd :: Demand.UseDmd -> SingleUse
-singleUseFromUseDmd Demand.UHead = botSingleUse
+singleUseFromUseDmd :: Demand.UseDmd -> Use
+singleUseFromUseDmd Demand.UHead = botUse
 singleUseFromUseDmd (Demand.UCall c u) = mkCallUse (multiplicityFromCount c) (singleUseFromUseDmd u)
 singleUseFromUseDmd (Demand.UProd comps) = mkProductUse (map usageFromArgUse comps)
-singleUseFromUseDmd Demand.Used = topSingleUse
+singleUseFromUseDmd Demand.Used = topUse
 
 usageFromArgUse :: Demand.ArgUse -> Usage
 usageFromArgUse Demand.Abs = Absent
@@ -496,7 +496,7 @@ multiplicityToCount :: Multiplicity -> Demand.Count
 multiplicityToCount Once = Demand.One
 multiplicityToCount Many = Demand.Many
 
-singleUseToUseDmd :: SingleUse -> Demand.UseDmd
+singleUseToUseDmd :: Use -> Demand.UseDmd
 singleUseToUseDmd HeadUse = Demand.UHead
 singleUseToUseDmd UnknownUse = Demand.Used
 singleUseToUseDmd (Product comps) = Demand.UProd (map usageToArgUse comps)
diff --git a/compiler/coreSyn/CoreLint.hs b/compiler/coreSyn/CoreLint.hs
index 6dd2200c17..4a64ab6a09 100644
--- a/compiler/coreSyn/CoreLint.hs
+++ b/compiler/coreSyn/CoreLint.hs
@@ -265,7 +265,7 @@ coreDumpFlag CoreDoFloatInwards       = Just Opt_D_verbose_core2core
 coreDumpFlag (CoreDoFloatOutwards {}) = Just Opt_D_verbose_core2core
 coreDumpFlag CoreLiberateCase         = Just Opt_D_verbose_core2core
 coreDumpFlag CoreDoStaticArgs         = Just Opt_D_verbose_core2core
-coreDumpFlag CoreDoCallArity          = Just Opt_D_dump_call_arity
+coreDumpFlag CoreDoUsageAnal          = Just Opt_D_dump_call_arity
 coreDumpFlag CoreDoStrictness         = Just Opt_D_dump_stranal
 coreDumpFlag CoreDoWorkerWrapper      = Just Opt_D_dump_worker_wrapper
 coreDumpFlag CoreDoSpecialising       = Just Opt_D_dump_spec
diff --git a/compiler/coreSyn/CoreTidy.hs b/compiler/coreSyn/CoreTidy.hs
index 46db938e6d..03947edb90 100644
--- a/compiler/coreSyn/CoreTidy.hs
+++ b/compiler/coreSyn/CoreTidy.hs
@@ -203,7 +203,7 @@ tidyLetBndr rec_tidy_env env@(tidy_env, var_env) (id,rhs)
                     `setStrictnessInfo` zapUsageEnvSig (strictnessInfo old_info)
                     `setDemandInfo`     demandInfo old_info
                     `setArgUsageInfo`   argUsageInfo old_info
-                    `setCallArityInfo`  callArityInfo old_info
+                    `setUsageInfo`      usageInfo old_info
                     `setInlinePragInfo` inlinePragInfo old_info
                     `setUnfoldingInfo`  new_unf
 
diff --git a/compiler/coreSyn/CoreUtils.hs b/compiler/coreSyn/CoreUtils.hs
index 4a83e90efb..4f4ad0078e 100644
--- a/compiler/coreSyn/CoreUtils.hs
+++ b/compiler/coreSyn/CoreUtils.hs
@@ -1911,7 +1911,7 @@ diffIdInfo env bndr1 bndr2
     && inlinePragInfo info1 == inlinePragInfo info2
     && occInfo info1 == occInfo info2
     && demandInfo info1 == demandInfo info2
-    && callArityInfo info1 == callArityInfo info2
+    && usageInfo info1 == usageInfo info2
     && levityInfo info1 == levityInfo info2
   = locBind "in unfolding of" bndr1 bndr2 $
     diffUnfold env (unfoldingInfo info1) (unfoldingInfo info2)
diff --git a/compiler/coreSyn/PprCore.hs b/compiler/coreSyn/PprCore.hs
index 4dee904deb..c1e5f87a54 100644
--- a/compiler/coreSyn/PprCore.hs
+++ b/compiler/coreSyn/PprCore.hs
@@ -432,7 +432,7 @@ pprIdBndrInfo info
     prag_info = inlinePragInfo info
     occ_info  = occInfo info
     dmd_info  = demandInfo info
-    usg_info  = callArityInfo info
+    usg_info  = usageInfo info
     lbv_info  = oneShotInfo info
 
     has_prag  = not (isDefaultInlinePragma prag_info)
diff --git a/compiler/ghc.cabal.in b/compiler/ghc.cabal.in
index dc04c0a47e..9694fd0549 100644
--- a/compiler/ghc.cabal.in
+++ b/compiler/ghc.cabal.in
@@ -412,10 +412,10 @@ Library
         CoreToStg
         StgLint
         StgSyn
-        CallArity
-        CallArity.Types
-        CallArity.FrameworkBuilder
-        CallArity.Analysis
+        UsageAnal
+        UsageAnal.Types
+        UsageAnal.FrameworkBuilder
+        UsageAnal.Analysis
         DmdAnal
         DmdAnalWrapper
         WorkWrap
diff --git a/compiler/main/DynFlags.hs b/compiler/main/DynFlags.hs
index 10bf671c58..8de406e50d 100644
--- a/compiler/main/DynFlags.hs
+++ b/compiler/main/DynFlags.hs
@@ -422,7 +422,7 @@ data GeneralFlag
    | Opt_PrintTypecheckerElaboration
 
    -- optimisation opts
-   | Opt_CallArity
+   | Opt_UsageAnal
    | Opt_Strictness
    | Opt_LateDmdAnal
    | Opt_KillAbsence
@@ -3662,7 +3662,7 @@ fFlagsDeps = [
   flagGhciSpec "break-on-error"               Opt_BreakOnError,
   flagGhciSpec "break-on-exception"           Opt_BreakOnException,
   flagSpec "building-cabal-package"           Opt_BuildingCabalPackage,
-  flagSpec "call-arity"                       Opt_CallArity,
+  flagSpec "usage-anal"                       Opt_UsageAnal,
   flagSpec "case-merge"                       Opt_CaseMerge,
   flagSpec "case-folding"                     Opt_CaseFolding,
   flagSpec "cmm-elim-common-blocks"           Opt_CmmElimCommonBlocks,
@@ -4115,7 +4115,7 @@ optLevelFlags -- see Note [Documenting optimisation flags]
     , ([0],     Opt_IgnoreInterfacePragmas)
     , ([0],     Opt_OmitInterfacePragmas)
 
-    , ([1,2],   Opt_CallArity)
+    , ([1,2],   Opt_UsageAnal)
     , ([1,2],   Opt_CaseMerge)
     , ([1,2],   Opt_CaseFolding)
     , ([1,2],   Opt_CmmElimCommonBlocks)
diff --git a/compiler/simplCore/CallArity.hs b/compiler/simplCore/CallArity.hs
deleted file mode 100644
index 1ca6d6092c..0000000000
--- a/compiler/simplCore/CallArity.hs
+++ /dev/null
@@ -1,9 +0,0 @@
---
--- Copyright (c) 2014 Joachim Breitner
---
-
-module CallArity
-    ( callArityAnalProgram
-    ) where
-
-import CallArity.Analysis ( callArityAnalProgram )
diff --git a/compiler/simplCore/CoreMonad.hs b/compiler/simplCore/CoreMonad.hs
index 79a08b7ba3..16fcb57188 100644
--- a/compiler/simplCore/CoreMonad.hs
+++ b/compiler/simplCore/CoreMonad.hs
@@ -115,7 +115,7 @@ data CoreToDo           -- These are diff core-to-core passes,
   | CoreLiberateCase
   | CoreDoPrintCore
   | CoreDoStaticArgs
-  | CoreDoCallArity
+  | CoreDoUsageAnal
   | CoreDoStrictness
   | CoreDoWorkerWrapper
   | CoreDoSpecialising
@@ -142,7 +142,7 @@ instance Outputable CoreToDo where
   ppr (CoreDoFloatOutwards f)  = text "Float out" <> parens (ppr f)
   ppr CoreLiberateCase         = text "Liberate case"
   ppr CoreDoStaticArgs         = text "Static argument"
-  ppr CoreDoCallArity          = text "Called arity analysis"
+  ppr CoreDoUsageAnal          = text "Usage analysis"
   ppr CoreDoStrictness         = text "Demand analysis"
   ppr CoreDoWorkerWrapper      = text "Worker Wrapper binds"
   ppr CoreDoSpecialising       = text "Specialise"
diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index 1adc554482..6207da4a6c 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -5,7 +5,7 @@ module DmdAnalWrapper (combinedDmdAnalProgram) where
 #include "HsVersions.h"
 
 import BasicTypes
-import CallArity
+import UsageAnal
 import CoreArity
 import CoreSyn
 import Demand
@@ -22,7 +22,7 @@ combinedDmdAnalProgram :: DynFlags -> FamInstEnvs -> [CoreRule] -> CoreProgram -
 combinedDmdAnalProgram dflags fams orphan_rules prog = do
   -- Call Arity first, suggesting the fact that there's no information flow
   -- from DA to CA. There isn't from CA to DA either, of course.
-  prog' <- callArityAnalProgram dflags fams orphan_rules prog
+  prog' <- usageAnalProgram dflags fams orphan_rules prog
   prog'' <- dmdAnalProgram dflags fams prog'
   --pprTrace "Program" (ppr prog'') $ pure ()
   return (mapBndrsProgram mergeInfo prog'')
@@ -44,14 +44,14 @@ mergeInfo top_lvl is_lam_bndr id
     id'
   where
     max_arity = length (typeArity (idType id))
-    -- We merge idDemandInfo with idCallArity and idStrictness with idArgUsage.
+    -- We merge idDemandInfo with idUsage and idStrictness with idArgUsage.
     -- Since Demand.hs doesn't seem to enforce the equivalences from the paper,
     -- we first convert everything to the representation of Usage.hs.
     old_demand = idDemandInfo id
     old_str_sig = idStrictness id
     (old_arg_dmds, _) = splitStrictSig old_str_sig
     str_sig_comparable_to_usg_sig = idArity id == length old_arg_dmds -- See further below at `new_str_sig`
-    ca_usage = idCallArity id
+    ca_usage = idUsage id
     ca_usg_sig = idArgUsage id
 
     old_usage = usageFromDemand old_demand
@@ -66,7 +66,7 @@ mergeInfo top_lvl is_lam_bndr id
     new_str_sig 
       | ca_usg_sig `leqUsageSig` old_usg_sig 
       , idArity id <= length old_arg_dmds
-      -- This is only safe if DmdAnal used the same arity as CallArity.
+      -- This is only safe if DmdAnal used the same arity as UsageAnal.
       -- Otherwise we get into nasty situations where arity /= #top-level binders,
       -- like with IO's RealWorld tokens. In that situation we have
       -- a more precise usage signature, but at the cost of a higher arity.
@@ -81,7 +81,7 @@ mergeInfo top_lvl is_lam_bndr id
 
     leqUsage l r = l `lubUsage` r == r
     leqUsageSig l r = l `lubUsageSig` r == r
-    has_usage = idCallArity id /= topUsage || old_usage /= topUsage
+    has_usage = idUsage id /= topUsage || old_usage /= topUsage
     has_usg_sig = isTopLevel top_lvl
     id' = id 
       `setIdDemandInfo` new_demand
@@ -97,7 +97,7 @@ mapBndrsBind top_lvl f (Rec bndrs) = Rec (map (\(id, e) -> (f top_lvl False id,
 
 mapBndrsExprIfNotAbsent :: Var -> InfoMerger -> CoreExpr -> CoreExpr
 mapBndrsExprIfNotAbsent id f e
-  | Absent <- idCallArity id = e -- we won't have annotated e in this case.
+  | Absent <- idUsage id = e -- we won't have annotated e in this case.
   | otherwise = mapBndrsExpr f e
 
 mapBndrsExpr :: InfoMerger -> CoreExpr -> CoreExpr
diff --git a/compiler/simplCore/SimplCore.hs b/compiler/simplCore/SimplCore.hs
index c25e99d6ee..f081c8a4f5 100644
--- a/compiler/simplCore/SimplCore.hs
+++ b/compiler/simplCore/SimplCore.hs
@@ -42,7 +42,7 @@ import SAT              ( doStaticArgs )
 import Specialise       ( specProgram)
 import SpecConstr       ( specConstrProgram)
 import DmdAnalWrapper   ( combinedDmdAnalProgram )
-import CallArity        ( callArityAnalProgram )
+import UsageAnal        ( usageAnalProgram )
 import WorkWrap         ( wwTopBinds )
 import Vectorise        ( vectorise )
 import SrcLoc
@@ -119,7 +119,7 @@ getCoreToDo dflags
     phases        = simplPhases        dflags
     max_iter      = maxSimplIterations dflags
     rule_check    = ruleCheck          dflags
-    call_arity    = gopt Opt_CallArity                    dflags
+    usage_anal    = gopt Opt_UsageAnal                    dflags
     strictness    = gopt Opt_Strictness                   dflags
     full_laziness = gopt Opt_FullLaziness                 dflags
     do_specialise = gopt Opt_Specialise                   dflags
@@ -298,9 +298,9 @@ getCoreToDo dflags
             -- up after the inlining from simplification.  Example in fulsom,
             -- Csg.calc, where an arg of timesDouble thereby becomes strict.
 
-        runWhen call_arity $ CoreDoPasses
-            [ CoreDoCallArity
-            , simpl_phase 0 ["post-call-arity"] max_iter
+        runWhen usage_anal $ CoreDoPasses
+            [ CoreDoUsageAnal
+            , simpl_phase 0 ["post-usage-anal"] max_iter
             ],
 
         runWhen strictness demand_analyser,
@@ -470,8 +470,8 @@ doCorePass (CoreDoFloatOutwards f)   = {-# SCC "FloatOutwards" #-}
 doCorePass CoreDoStaticArgs          = {-# SCC "StaticArgs" #-}
                                        doPassU doStaticArgs
 
-doCorePass CoreDoCallArity           = {-# SCC "CallArity" #-}
-                                       doPassDFRM callArityAnalProgram
+doCorePass CoreDoUsageAnal           = {-# SCC "UsageAnal" #-}
+                                       doPassDFRM usageAnalProgram
 
 doCorePass CoreDoStrictness          = {-# SCC "NewStranal" #-}
                                        doPassDFRM combinedDmdAnalProgram
diff --git a/compiler/simplCore/SimplUtils.hs b/compiler/simplCore/SimplUtils.hs
index 87438f4012..683737a526 100644
--- a/compiler/simplCore/SimplUtils.hs
+++ b/compiler/simplCore/SimplUtils.hs
@@ -1431,7 +1431,7 @@ tryEtaExpandRhs env is_rec bndr rhs
       , let cheap_arity = findRhsArity dflags bndr rhs old_arity
             -- The following four lines can go away if CoreArity was aware
             -- of Usage information
-            usage = idCallArity bndr
+            usage = idUsage bndr
             expanded_arity = expandArity usage cheap_arity
             -- See Note [Trimming arity]
             new_arity = min expanded_arity (maxArity bndr)
diff --git a/compiler/simplCore/UsageAnal.hs b/compiler/simplCore/UsageAnal.hs
new file mode 100644
index 0000000000..2c3a48d8f2
--- /dev/null
+++ b/compiler/simplCore/UsageAnal.hs
@@ -0,0 +1,5 @@
+module UsageAnal
+    ( usageAnalProgram
+    ) where
+
+import UsageAnal.Analysis ( usageAnalProgram )
diff --git a/compiler/simplCore/CallArity/Analysis.hs b/compiler/simplCore/UsageAnal/Analysis.hs
similarity index 90%
rename from compiler/simplCore/CallArity/Analysis.hs
rename to compiler/simplCore/UsageAnal/Analysis.hs
index 1ec804b2b5..19dfecf40a 100644
--- a/compiler/simplCore/CallArity/Analysis.hs
+++ b/compiler/simplCore/UsageAnal/Analysis.hs
@@ -1,15 +1,14 @@
 {-# LANGUAGE CPP #-}
-{-# OPTIONS_GHC -fprof-auto #-}
 --
 -- Copyright (c) 2014 Joachim Breitner
 --
 
-module CallArity.Analysis where
+module UsageAnal.Analysis where
 
 #include "HsVersions.h"
 
-import CallArity.Types
-import CallArity.FrameworkBuilder
+import UsageAnal.Types
+import UsageAnal.FrameworkBuilder
 
 import BasicTypes
 import Class
@@ -73,7 +72,7 @@ Furthermore, an analysis that only looks at the RHS of go cannot be sufficient
 to eta-expand go: If `go` is ever called with one argument (and the result used
 multiple times), we would be doing the work in `...` multiple times.
 
-So `callArityAnalProgram` looks at the whole let expression to figure out if
+So `usageAnalProgram` looks at the whole let expression to figure out if
 all calls are nice, i.e. have a high enough arity. It then stores the result in
 the `calledArity` field of the `IdInfo` of `go`, which the next simplifier
 phase will eta-expand.
@@ -296,11 +295,11 @@ together with what other functions.
 Note [Analysis type signature]
 ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
 
-The work-hourse of the analysis is the function `callArityAnal`, with the
+The work-hourse of the analysis is the function `usageAnal`, with the
 following type:
 
     type UsageType = (UnVarGraph, VarEnv Arity)
-    callArityAnal ::
+    usageAnal ::
         Arity ->  -- The arity this expression is called with
         VarSet -> -- The set of interesting variables
         CoreExpr ->  -- The expression to analyse
@@ -415,7 +414,7 @@ data AnalEnv
   --
   --     - `Opt_DmdTxDictSel`: Control analysis of dictionary selectors.
   --
-  , ae_sigs :: VarEnv (SingleUse -> TransferFunction UsageType)
+  , ae_sigs :: VarEnv (Use -> TransferFunction UsageType)
   -- ^ 'TransferFunction's of visible local let-bound identifiers. It is crucial
   -- that only the 'UsageSig' component is used, as the usage on free vars might
   -- be unstable and thus too optimistic.
@@ -453,7 +452,7 @@ predictSizeOfLetBody = rootLabel . ae_predicted_nodes . descend 0
 extendAnalEnv 
   :: AnalEnv 
   -> Id 
-  -> (SingleUse -> TransferFunction UsageType) 
+  -> (Use -> TransferFunction UsageType) 
   -> AnalEnv
 extendAnalEnv env id node 
   = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
@@ -461,7 +460,7 @@ extendAnalEnv env id node
 -- | See Note [Analysing top-level-binds]
 -- `programToExpr` returns a pair of all top-level `Id`s
 -- and a nested `let` expression that uses everything externally visible.
--- This `let` expression is then to be analysed by `callArityRHS`.
+-- This `let` expression is then to be analysed by `usageAnalRHS`.
 --
 -- Represents the fact that a `CoreProgram` is like a sequence of
 -- nested lets, where the external visible ids are returned in the inner-most let
@@ -507,74 +506,73 @@ exprToProgram (Let bind e) = bind : exprToProgram e
 exprToProgram _ = []
 
 -- Main entry point
-callArityAnalProgram 
+usageAnalProgram 
   :: DynFlags 
   -> FamInstEnvs 
   -> [CoreRule]
   -> CoreProgram 
   -> IO CoreProgram
-callArityAnalProgram dflags fam_envs orphan_rules
+usageAnalProgram dflags fam_envs orphan_rules
   = return 
-  -- . (\it -> pprTrace "callArity:end" (ppr (length it)) it) 
+  -- . (\it -> pprTrace "usageAnal:end" (ppr (length it)) it) 
   . exprToProgram 
-  . uncurry (callArityRHS dflags fam_envs) 
+  . uncurry (usageAnalRHS dflags fam_envs) 
   . programToExpr orphan_rules
-  -- . (\it -> pprTrace "callArity:begin" (ppr (length it)) it)
-  -- . (\prog -> pprTrace "CallArity:Program" (ppr prog) prog)
+  -- . (\it -> pprTrace "usageAnal:begin" (ppr (length it)) it)
+  -- . (\prog -> pprTrace "usageAnal:Program" (ppr prog) prog)
 
-callArityRHS :: DynFlags -> FamInstEnvs -> VarSet -> CoreExpr -> CoreExpr
-callArityRHS dflags fam_envs need_sigs e
+usageAnalRHS :: DynFlags -> FamInstEnvs -> VarSet -> CoreExpr -> CoreExpr
+usageAnalRHS dflags fam_envs need_sigs e
   = ASSERT2( isEmptyUnVarSet (domType ut), text "Free vars in UsageType:" $$ ppr ut ) e'
   where
     env = initialAnalEnv dflags fam_envs need_sigs (predictAllocatedNodes e)
-    (ut, e') = buildAndRun (callArityExpr env e) topSingleUse
+    (ut, e') = buildAndRun (usageAnalExpr env e) topUse
 
--- | The main analysis function. See Note [Analysis type signature]
-callArityExpr
+usageAnalExpr
   :: AnalEnv
   -> CoreExpr
-  -> FrameworkBuilder (SingleUse -> TransferFunction AnalResult)
+  -> FrameworkBuilder (Use -> TransferFunction AnalResult)
 
-callArityExprTrivial
+usageAnalExprTrivial
   :: UsageType
   -> CoreExpr
-  -> FrameworkBuilder (SingleUse -> TransferFunction AnalResult)
-callArityExprTrivial ut e
+  -> FrameworkBuilder (Use -> TransferFunction AnalResult)
+usageAnalExprTrivial ut e
   = return (const (return (ut, e)))
 
-callArityExprMap
+usageAnalExprMap
   :: AnalEnv
   -> (CoreExpr -> a)
   -> CoreExpr
-  -> FrameworkBuilder (SingleUse -> TransferFunction (UsageType, a)) -- @a@ instead of @CoreExpr@
-callArityExprMap env f e
-  = transfer' <$> callArityExpr env e
+  -> FrameworkBuilder (Use -> TransferFunction (UsageType, a)) -- @a@ instead of @CoreExpr@
+usageAnalExprMap env f e
+  = transfer' <$> usageAnalExpr env e
   where
     transfer' transfer use = do
       (ut, e') <- transfer use
       return (ut, f e')
 
-callArityExpr _ e@(Lit _)
-  = callArityExprTrivial emptyUsageType e 
-callArityExpr _ e@(Type _)
-  = callArityExprTrivial emptyUsageType e
+usageAnalExpr _ e@(Lit _)
+  = usageAnalExprTrivial emptyUsageType e 
+usageAnalExpr _ e@(Type _)
+  = usageAnalExprTrivial emptyUsageType e
 
-callArityExpr _ e@(Coercion co)
-  = callArityExprTrivial (coercionUsageType co) e
+usageAnalExpr _ e@(Coercion co)
+  = usageAnalExprTrivial (coercionUsageType co) e
 
-callArityExpr env (Tick t e)
-  = callArityExprMap env (Tick t) e
+usageAnalExpr env (Tick t e)
+  = usageAnalExprMap env (Tick t) e
 
-callArityExpr env (Cast e co)
-  = transfer' <$> callArityExpr env e
+usageAnalExpr env (Cast e co)
+  = transfer' <$> usageAnalExpr env e
   where
     transfer' transfer use = do
       (ut, e') <- transfer use
-      -- like callArityExprMap, but we also have to combine with the UsageType
+      -- like usageAnalExprMap, but we also have to combine with the UsageType
       -- of the coercion.
       return (ut `bothUsageType` coercionUsageType co, Cast e' co)
 
-callArityExpr env e@(Var id) = return transfer
+usageAnalExpr env e@(Var id) = return transfer
   where
     transfer use
       | Just transfer_callee <- lookupVarEnv (ae_sigs env) id
@@ -583,7 +581,7 @@ callArityExpr env e@(Var id) = return transfer
       -- transparently in `registerBindingGroups`.
       = do
         ut_callee <- transfer_callee use
-        pprTrace "callArityExpr:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
+        --pprTrace "usageAnalExpr:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
         return (ut_callee `bothUsageType` unitUsageType id use, e)
 
       | isLocalId id
@@ -591,38 +589,38 @@ callArityExpr env e@(Var id) = return transfer
       -- We are only second-order, so we don't model signatures for parameters!
       -- Their usage is interesting to note nonetheless for annotating lambda
       -- binders and scrutinees.
-      = --pprTrace "callArityExpr:OtherId" (ppr id <+> ppr use) $
+      = --pprTrace "usageAnalExpr:OtherId" (ppr id <+> ppr use) $
         return (unitUsageType id use, e)
 
       -- The other cases handle global ids
       | Just dc <- ASSERT( isGlobalId id ) (isDataConWorkId_maybe id)
       -- Some data constructor, on which we can try to unleash product use
       -- as a `UsageSig`.
-      = --pprTrace "callArityExpr:DataCon" (ppr id <+> ppr use <+> ppr (dataConUsageSig dc use)) $
+      = --pprTrace "usageAnalExpr:DataCon" (ppr id <+> ppr use <+> ppr (dataConUsageSig dc use)) $
         return (emptyUsageType { ut_args = dataConUsageSig dc use }, e)
 
       | gopt Opt_DmdTxDictSel (ae_dflags env)
       , Just clazz <- isClassOpId_maybe id
       -- A dictionary component selector
-      = --pprTrace "callArityExpr:DictSel" (ppr id <+> ppr use <+> ppr (dictSelUsageSig id clazz use)) $
+      = --pprTrace "usageAnalExpr:DictSel" (ppr id <+> ppr use <+> ppr (dictSelUsageSig id clazz use)) $
         return (emptyUsageType { ut_args = dictSelUsageSig id clazz use }, e)
 
       | otherwise
       -- A global id from another module which has a usage signature.
       -- We don't need to track the id itself, though.
-      = --pprTrace "callArityExpr:GlobalId" (ppr id <+> ppr (idArity id) <+> ppr use <+> ppr (globalIdUsageSig id use) <+> ppr (idStrictness id) <+> ppr (idDetails id)) $
+      = --pprTrace "usageAnalExpr:GlobalId" (ppr id <+> ppr (idArity id) <+> ppr use <+> ppr (globalIdUsageSig id use) <+> ppr (idStrictness id) <+> ppr (idDetails id)) $
         return (emptyUsageType { ut_args = globalIdUsageSig id use }, e)
 
-callArityExpr env (Lam id body)
+usageAnalExpr env (Lam id body)
   | isTyVar id
-  = callArityExprMap env (Lam id) body
+  = usageAnalExprMap env (Lam id) body
   | otherwise
   = do
-    transfer_body <- callArityExpr env body
+    transfer_body <- usageAnalExpr env body
     return $ \use ->
       case fromMaybe topUsage (peelCallUse use) of -- Get at the relative @Usage@ of the body
         Absent -> do
-          let id' = id `setIdCallArity` Absent
+          let id' = id `setIdUsage` Absent
           return (emptyUsageType, Lam id' body)
         Used multi body_use -> do
           (ut_body, body') <- transfer_body body_use
@@ -636,14 +634,14 @@ callArityExpr env (Lam id body)
           let ut = modifyArgs (consUsageSig usage_id)
                  . multiplyUsages multi
                  $ ut_body'
-          --pprTrace "callArityExpr:Lam" (vcat [text "id:" <+> ppr id, text "relative body usage:" <+> ppr u, text "id usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
+          --pprTrace "usageAnalExpr:Lam" (vcat [text "id:" <+> ppr id, text "relative body usage:" <+> ppr u, text "id usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
           return (ut, Lam id' body')
 
-callArityExpr env (App f (Type t)) 
-  = callArityExprMap (descend 0 env) (flip App (Type t)) f
-callArityExpr env (App f a) = do
-  transfer_f <- callArityExpr (descend 0 env) f
-  transfer_a <- callArityExpr (descend 1 env) a
+usageAnalExpr env (App f (Type t)) 
+  = usageAnalExprMap (descend 0 env) (flip App (Type t)) f
+usageAnalExpr env (App f a) = do
+  transfer_f <- usageAnalExpr (descend 0 env) f
+  transfer_a <- usageAnalExpr (descend 1 env) a
   return $ \result_use -> do
     (ut_f, f') <- transfer_f (mkCallUse Once result_use)
     --pprTrace "App:f'" (ppr f') $ return ()
@@ -663,8 +661,8 @@ callArityExpr env (App f a) = do
         --pprTrace "App:a'" (text "arg_use:" <+> ppr arg_use <+> ppr (ut_a, a')) $ return ()
         return (ut_f' `bothUsageType` ut_a, App f' a')
 
-callArityExpr env (Case scrut case_bndr ty alts) = do
-  transfer_scrut <- callArityExpr (descend 0 env) scrut
+usageAnalExpr env (Case scrut case_bndr ty alts) = do
+  transfer_scrut <- usageAnalExpr (descend 0 env) scrut
   -- We zip the index of the child in the ae_predicted_nodes tree
   transfer_alts <- forM (zip [1..] alts) $ \(n, alt) -> 
     analyseCaseAlternative (descend n env) case_bndr alt
@@ -681,7 +679,7 @@ callArityExpr env (Case scrut case_bndr ty alts) = do
     --pprTrace "Case" (vcat [text "ut_scrut:" <+> ppr ut_scrut, text "ut_alts:" <+> ppr ut_alts, text "ut:" <+> ppr ut]) (return ())
     return (ut, Case scrut' case_bndr' ty alts')
 
-callArityExpr env (Let bind e) 
+usageAnalExpr env (Let bind e) 
   = registerTransferFunction register >>= deref_node
   where
     deref_node node = return $ \use -> do
@@ -701,9 +699,9 @@ callArityExpr env (Let bind e)
       -- Ideally we'd want the body to have a lower priority than the RHSs,
       -- but we need to access env' with the new sigs in the body, so we
       -- can't register it earlier.
-      transfer_body <- callArityExpr (descend 0 env') e
+      transfer_body <- usageAnalExpr (descend 0 env') e
       let rec_flag = recFlagOf bind
-      let transfer :: SingleUse -> TransferFunction AnalResult
+      let transfer :: Use -> TransferFunction AnalResult
           transfer = monotonize node $ \use -> do
             --use <- pprTrace "Rec:begin" (ppr ids) $ return use
             (ut_body, e') <- transfer_body use
@@ -721,7 +719,7 @@ callArityExpr env (Let bind e)
             (ut, binds') <- unleashLet env' rec_flag transferred_binds ut_usage ut_body
             --ut <- pprTrace "Rec:end" (ppr ids) $ return ut
             case rec_flag of
-              NonRecursive 
+              NonRecursive
                 | [(id', rhs')] <- binds'
                 -> return (ut, Let (NonRec id' rhs') e')
               _ -> return (ut, Let (Rec binds') e')
@@ -730,7 +728,7 @@ callArityExpr env (Let bind e)
 coercionUsageType :: Coercion -> UsageType
 coercionUsageType co = multiplyUsages Many ut
   where
-    ut = emptyUsageType { ut_uses = mapVarEnv (const topSingleUse) (coVarsOfCo co) }
+    ut = emptyUsageType { ut_uses = mapVarEnv (const topUse) (coVarsOfCo co) }
 
 -- | Consider the expression
 --
@@ -748,14 +746,14 @@ coercionUsageType co = multiplyUsages Many ut
 -- `dataConUsageSig` does exactly this: First peel off one-shot calls according
 -- to the constructors `idArity`, then peel off the product use to get at the
 -- usage on its components.
-dataConUsageSig :: DataCon -> SingleUse -> UsageSig
+dataConUsageSig :: DataCon -> Use -> UsageSig
 dataConUsageSig dc use = fromMaybe topUsageSig sig_maybe
   where
     arity = dataConRepArity dc
     peelSingleShotCalls 0 use = Just use
     peelSingleShotCalls n call
       | Just Absent <- peelCallUse call
-      = Just botSingleUse -- (,) x `seq` ...: Nothing unleashed in this case
+      = Just botUse -- (,) x `seq` ...: Nothing unleashed in this case
       | Just (Used Once use) <- peelCallUse call
       = peelSingleShotCalls (n - 1) use
       | otherwise
@@ -767,7 +765,7 @@ dataConUsageSig dc use = fromMaybe topUsageSig sig_maybe
       component_usages <- peelProductUse arity (addDataConStrictness dc product_use)
       return (usageSigFromUsages component_usages)
 
-dictSelUsageSig :: Id -> Class -> SingleUse -> UsageSig
+dictSelUsageSig :: Id -> Class -> Use -> UsageSig
 dictSelUsageSig id clazz use
   | Used _ dict_single_call_use <- fst . unconsUsageSig . idArgUsage $ id
   , Just dc <- tyConSingleDataCon_maybe (classTyCon clazz)
@@ -781,7 +779,7 @@ dictSelUsageSig id clazz use
   | otherwise
   = topUsageSig
 
-specializeDictSig :: [Usage] -> SingleUse -> UsageSig
+specializeDictSig :: [Usage] -> Use -> UsageSig
 specializeDictSig comps method_use = consUsageSig dict_usage topUsageSig
   where
     dict_usage = Used Once (mkProductUse (map replace_usage comps))
@@ -789,7 +787,7 @@ specializeDictSig comps method_use = consUsageSig dict_usage topUsageSig
       | old == Absent = old
       | otherwise = Used Once method_use -- This is the selector for the method we used!
 
-globalIdUsageSig :: Id -> SingleUse -> UsageSig
+globalIdUsageSig :: Id -> Use -> UsageSig
 globalIdUsageSig id use
   | use <= no_call -- @f x `seq` ...@ for a GlobalId `f` with arity > 1
   = botUsageSig
@@ -799,11 +797,11 @@ globalIdUsageSig id use
   = --pprTrace "many" (ppr arg_usage <+> ppr (idStrictness id) <+> ppr (manifyUsageSig arg_usage)) $ 
     manifyUsageSig usg_sig
   where
-    (<=) = leqSingleUse
+    (<=) = leqUse
     arity = idArity id
     mk_one_shot = mkCallUse Once
-    no_call = iterate mk_one_shot botSingleUse !! max 0 (arity - 1)
-    single_call = iterate mk_one_shot topSingleUse !! arity
+    no_call = iterate mk_one_shot botUse !! max 0 (arity - 1)
+    single_call = iterate mk_one_shot topUse !! arity
     usg_sig = idArgUsage id
     str_sig = usageSigFromStrictSig (idStrictness id)
 
@@ -820,9 +818,9 @@ analyseCaseAlternative
   :: AnalEnv
   -> Id
   -> Alt CoreBndr
-  -> FrameworkBuilder (SingleUse -> TransferFunction (UsageType, Alt CoreBndr, SingleUse))
+  -> FrameworkBuilder (Use -> TransferFunction (UsageType, Alt CoreBndr, Use))
 analyseCaseAlternative env case_bndr (dc, alt_bndrs, e)
-  = transfer <$> callArityExpr env e
+  = transfer <$> usageAnalExpr env e
   where
     transfer transfer_alt use = do
       let fam_envs = ae_fam_envs env
@@ -862,7 +860,7 @@ addCaseBndrUsage (Used _ use) alt_bndr_usages
   | otherwise
   = topUsage <$ alt_bndr_usages
 
--- | We should try avoiding to call `setIdCallArity` directly but rather go
+-- | We should try avoiding to call `setIdUsage` directly but rather go
 -- through this function. This makes sure to trim the `Usage`
 -- according to the binder's type before annotating.
 setBndrUsageInfo :: FamInstEnvs -> Var -> Usage -> Var
@@ -871,10 +869,8 @@ setBndrUsageInfo fam_envs id usage
   = id 
   | otherwise
     -- See Note [Trimming a demand to a type] in Demand.hs
-  = pprTrace "setBndrUsageInfo" (ppr id <+> ppr usage') $
-    id `setIdCallArity` usage'
-    where
-      usage' = trimUsageToTypeShape fam_envs id usage
+  = --pprTrace "setBndrUsageInfo" (ppr id <+> ppr usage') 
+    id `setIdUsage` trimUsageToTypeShape fam_envs id usage
 
 setBndrsUsageInfo :: FamInstEnvs -> [Var] -> [Usage] -> [Var]
 setBndrsUsageInfo _ [] [] = []
@@ -888,8 +884,8 @@ setBndrsUsageInfo _ _ usages
 
 propagateProductUse
   :: [Alt CoreBndr]
-  -> [SingleUse]
-  -> SingleUse
+  -> [Use]
+  -> Use
 propagateProductUse alts scrut_uses
   -- Only one alternative with a product constructor
   | [(DataAlt dc, _, _)] <- alts
@@ -906,12 +902,12 @@ propagateProductUse alts scrut_uses
   | otherwise
   -- We *could* lub the uses from the different branches, but there's not much
   -- to be won there, except for maybe head strictness.
-  = topSingleUse
+  = topUse
 
-addDataConStrictness :: DataCon -> SingleUse -> SingleUse
+addDataConStrictness :: DataCon -> Use -> Use
 -- See Note [Add demands for strict constructors] in DmdAnal.hs
 addDataConStrictness dc
-  = maybe topSingleUse (mkProductUse . add_component_strictness) 
+  = maybe topUse (mkProductUse . add_component_strictness) 
   . peelProductUse arity
   where
     add_component_strictness :: [Usage] -> [Usage]
@@ -935,14 +931,14 @@ exprForcedError = error "Expression component may not be used"
 useLetUp :: Id -> Bool
 useLetUp id = idArity id == 0
 
-transferUp :: Id -> CoreExpr -> FrameworkNode -> SingleUse -> TransferFunction AnalResult
+transferUp :: Id -> CoreExpr -> FrameworkNode -> Use -> TransferFunction AnalResult
 transferUp id rhs node use = do
   (ut, rhs') <- dependOnWithDefault (botUsageType, rhs) (node, use)
   if useLetUp id
     then return (ut, rhs')
     else return (botUsageType, rhs')
 
-transferDown :: Id -> FrameworkNode -> SingleUse -> TransferFunction UsageType
+transferDown :: Id -> FrameworkNode -> Use -> TransferFunction UsageType
 transferDown id node use = do
   (ut, _) <- dependOnWithDefault (botUsageType, exprForcedError) (node, use)
   if useLetUp id
@@ -952,7 +948,7 @@ transferDown id node use = do
 registerBindingGroup
   :: AnalEnv
   -> [(Id, CoreExpr)]
-  -> FrameworkBuilder (AnalEnv, VarEnv (SingleUse -> TransferFunction AnalResult))
+  -> FrameworkBuilder (AnalEnv, VarEnv (Use -> TransferFunction AnalResult))
 registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`ing
   where
     go env transfer_ups [] = return (env, transfer_ups)
@@ -966,7 +962,7 @@ registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`
           -- Now that the whole binding group is in scope in `env'`,
           -- we actually have to attend to our duty and register the
           -- transfer functions associated with `up_node` and `down_node`
-          transfer_rhs <- callArityExpr (descend n env') rhs
+          transfer_rhs <- usageAnalExpr (descend n env') rhs
           let transfer_annotate = monotonize up_node $ \use -> do
                 --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
                 ret@(ut, rhs') <- transfer_rhs use 
@@ -987,12 +983,12 @@ registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`
 changeDetectorUsageType :: ChangeDetector
 changeDetectorUsageType _ (old, _) (new, _) =
   -- It's crucial for termination that we don't have to check the annotated expressions.
-  ASSERT2( old_sig `leqUsageSig` new_sig, text "CallArity.changeDetector: usage sig not monotone")
+  ASSERT2( old_sig `leqUsageSig` new_sig, text "UsageAnal.changeDetector: usage sig not monotone")
   old_sig /= new_sig ||
-  ASSERT2( sizeUFM old_uses <= sizeUFM new_uses, text "CallArity.changeDetector: uses not monotone")
+  ASSERT2( sizeUFM old_uses <= sizeUFM new_uses, text "UsageAnal.changeDetector: uses not monotone")
   sizeUFM old_uses /= sizeUFM new_uses ||
   old_uses /= new_uses ||
-  ASSERT2( edgeCount old_cocalled <= edgeCount new_cocalled, text "CallArity.changeDetector: edgeCount not monotone")
+  ASSERT2( edgeCount old_cocalled <= edgeCount new_cocalled, text "UsageAnal.changeDetector: edgeCount not monotone")
   edgeCount old_cocalled /= edgeCount new_cocalled
   where
     old_sig = ut_args old
@@ -1011,7 +1007,7 @@ changeDetectorAnalResult self_node changed_refs (old, e) (new, e') =
 unleashLet
   :: AnalEnv 
   -> RecFlag
-  -> [(Id, (CoreExpr, SingleUse -> TransferFunction AnalResult))]
+  -> [(Id, (CoreExpr, Use -> TransferFunction AnalResult))]
   -> UsageType
   -> UsageType
   -> TransferFunction (UsageType, [(Id, CoreExpr)])
@@ -1020,7 +1016,7 @@ unleashLet env rec_flag transferred_binds ut_usage ut_body = do
   let ids = map fst transferred_binds
   (ut_rhss, rhss') <- fmap unzip $ forM transferred_binds $ \(id, (rhs, transfer)) ->
     unleashUsage rhs transfer (lookupUsage rec_flag fam_envs ut_usage id)
-  let ut_final = callArityLetEnv (zip ids ut_rhss) ut_body
+  let ut_final = usageAnalLetEnv (zip ids ut_rhss) ut_body
 
   --pprTrace "unleashLet" (ppr ids $$ text "ut_body" <+> ppr ut_body $$ text "ut_final" <+> ppr ut_final) $ return ()
   -- Now use that information to annotate binders.
@@ -1046,16 +1042,20 @@ annotateIdArgUsage env id
     -- @UsageSig@ to be had.
     -- In that case we *could* try to analyze with arity 1, just for the
     -- signature.
-    let single_call = iterate (mkCallUse Once) topSingleUse !! idArity id
+    let single_call = iterate (mkCallUse Once) topUse !! idArity id
     usage_sig <- ut_args <$> transfer_callee single_call
     --pprTrace "annotating" (ppr id <+> ppr usage_sig) $ return ()
     return (id `setIdArgUsage` usage_sig)
   | otherwise
   = return id
 
+-- | Lifts the domain of a transfer function of an expression to @Usage@.
+-- Non-trivial expressions (as per `exprIsTrivial`) are considered shared,
+-- while the transferred result for trivial expressions is multiplied
+-- according to usage multiplicity.
 unleashUsage
   :: CoreExpr
-  -> (SingleUse -> TransferFunction AnalResult)
+  -> (Use -> TransferFunction AnalResult)
   -> (Usage -> TransferFunction AnalResult)
 unleashUsage rhs transfer_rhs usage
   | Absent <- usage
@@ -1071,12 +1071,12 @@ unleashUsage rhs transfer_rhs usage
 
 -- Combining the results from body and rhs of a let binding
 -- See Note [Analysis II: The Co-Called analysis]
-callArityLetEnv
+usageAnalLetEnv
   :: [(Id, UsageType)]
   -> UsageType
   -> UsageType
-callArityLetEnv rhss ut_body
-    = --pprTrace "callArityLetEnv" (vcat [ppr (map fst rhss), ppr (map snd rhss), ppr ut_body, ppr ut_new, ppr (map (lookupUsage Recursive ut_new . fst) rhss)]) $
+usageAnalLetEnv rhss ut_body
+    = --pprTrace "usageAnalLetEnv" (vcat [ppr (map fst rhss), ppr (map snd rhss), ppr ut_body, ppr ut_new, ppr (map (lookupUsage Recursive ut_new . fst) rhss)]) $
       ut_new
   where
     (ids, ut_rhss) = unzip rhss
@@ -1135,7 +1135,7 @@ markAbsent = expr
   where 
     abs id 
       | isTyVar id = id
-      | otherwise = id `setIdCallArity` Absent
+      | otherwise = id `setIdUsage` Absent
     expr e = case e of
       App f a -> App (expr f) (expr a)
       -- I better leave the binder untouched for now... Don't want to break 
diff --git a/compiler/simplCore/CallArity/FrameworkBuilder.hs b/compiler/simplCore/UsageAnal/FrameworkBuilder.hs
similarity index 86%
rename from compiler/simplCore/CallArity/FrameworkBuilder.hs
rename to compiler/simplCore/UsageAnal/FrameworkBuilder.hs
index 9fe4d96ee8..f9671cd3d4 100644
--- a/compiler/simplCore/CallArity/FrameworkBuilder.hs
+++ b/compiler/simplCore/UsageAnal/FrameworkBuilder.hs
@@ -1,6 +1,6 @@
 {-# LANGUAGE GeneralizedNewtypeDeriving #-}
 
-module CallArity.FrameworkBuilder
+module UsageAnal.FrameworkBuilder
   ( predictAllocatedNodes
   , FrameworkNode
   , TransferFunction
@@ -17,7 +17,7 @@ module CallArity.FrameworkBuilder
   , buildAndRun
   ) where
 
-import CallArity.Types
+import UsageAnal.Types
 import CoreSyn
 import Outputable
 import Usage
@@ -54,11 +54,11 @@ newtype FrameworkNode
   = FrameworkNode Int
   deriving (Show, Eq, Ord, Outputable)
 
-type TransferFunction a = Worklist.TransferFunction (FrameworkNode, SingleUse) AnalResult a
-type ChangeDetector = Worklist.ChangeDetector (FrameworkNode, SingleUse) AnalResult
-type DataFlowFramework = Worklist.DataFlowFramework (FrameworkNode, SingleUse) AnalResult
+type TransferFunction a = Worklist.TransferFunction (FrameworkNode, Use) AnalResult a
+type ChangeDetector = Worklist.ChangeDetector (FrameworkNode, Use) AnalResult
+type DataFlowFramework = Worklist.DataFlowFramework (FrameworkNode, Use) AnalResult
 -- | Maps @FrameworkNode@ to incoming usage dependent @TransferFunction@s
-type NodeTransferEnv = IntMap (SingleUse -> TransferFunction AnalResult, ChangeDetector)
+type NodeTransferEnv = IntMap (Use -> TransferFunction AnalResult, ChangeDetector)
 
 data BuilderState
   = BS 
@@ -92,7 +92,7 @@ buildFramework (FB state) = (res, Worklist.DFF dff)
   where
     (res, bs) = runState state initialBuilderState
     dff (FrameworkNode node, use) = case IntMap.lookup node (bs_env bs) of
-      Nothing -> pprPanic "CallArity.FrameworkBuilder.buildFramework" (ppr node)
+      Nothing -> pprPanic "UsageAnal.FrameworkBuilder.buildFramework" (ppr node)
       Just (transfer, detectChange) -> (transfer use, detectChange)
 
 viewAt :: Int -> IntMap a -> Maybe (a, IntMap a)
@@ -141,7 +141,7 @@ popNextFreeNode :: State BuilderState Int
 popNextFreeNode = rc_start <$> unFB (retainNodes 1)
 
 registerTransferFunction
-  :: (FrameworkNode -> FrameworkBuilder (a, (SingleUse -> TransferFunction AnalResult, ChangeDetector)))
+  :: (FrameworkNode -> FrameworkBuilder (a, (Use -> TransferFunction AnalResult, ChangeDetector)))
   -> FrameworkBuilder a
 registerTransferFunction f = FB $ do
   node <- popNextFreeNode
@@ -155,28 +155,28 @@ registerTransferFunction f = FB $ do
 
 monotonize
   :: FrameworkNode
-  -> (SingleUse -> TransferFunction AnalResult)
-  -> SingleUse -> TransferFunction AnalResult
+  -> (Use -> TransferFunction AnalResult)
+  -> Use -> TransferFunction AnalResult
 monotonize node transfer use = do
   (ut_new, e') <- transfer use 
   (ut_old, _) <- fromMaybe (botUsageType, undefined) <$> Worklist.unsafePeekValue (node, use)
   return (lubUsageType ut_new ut_old, e')
 
-dependOnWithDefault :: AnalResult -> (FrameworkNode, SingleUse) -> TransferFunction AnalResult
+dependOnWithDefault :: AnalResult -> (FrameworkNode, Use) -> TransferFunction AnalResult
 dependOnWithDefault def which = do
   --which <- pprTrace "dependOnWithDefault:before" (ppr which) (return which)
   res <- fromMaybe def <$> Worklist.dependOn which
   --res <- pprTrace "dependOnWithDefault:after " (ppr which) (return res)
   return res
 
-buildAndRun :: FrameworkBuilder (SingleUse -> TransferFunction AnalResult) -> SingleUse -> AnalResult
+buildAndRun :: FrameworkBuilder (Use -> TransferFunction AnalResult) -> Use -> AnalResult
 buildAndRun buildTransfer use = lookup_result (Worklist.runFramework fw (Set.singleton (node, use)))
   where
     (node, fw) = buildFramework $ registerTransferFunction $ \node -> do
       transfer <- buildTransfer
       return (node, (transfer, Worklist.alwaysChangeDetector))
 
-    lookup_result :: Map (FrameworkNode, SingleUse) AnalResult -> AnalResult
+    lookup_result :: Map (FrameworkNode, Use) AnalResult -> AnalResult
     lookup_result result_map = case Map.lookup (node, use) result_map of
-      Nothing -> pprPanic "CallArity.FrameworkBuilder.buildAndRun" empty
+      Nothing -> pprPanic "UsageAnal.FrameworkBuilder.buildAndRun" empty
       Just res -> res
diff --git a/compiler/simplCore/CallArity/Types.hs b/compiler/simplCore/UsageAnal/Types.hs
similarity index 92%
rename from compiler/simplCore/CallArity/Types.hs
rename to compiler/simplCore/UsageAnal/Types.hs
index 48d401ef81..719125e4ed 100644
--- a/compiler/simplCore/CallArity/Types.hs
+++ b/compiler/simplCore/UsageAnal/Types.hs
@@ -1,4 +1,4 @@
-module CallArity.Types where
+module UsageAnal.Types where
 
 import BasicTypes
 import CoreSyn
@@ -24,7 +24,7 @@ data UsageType
   = UT
   { ut_cocalled :: !UnVarGraph
   -- ^ Models cardinality, e.g. at most {1, many} via the co-call relation
-  , ut_uses     :: !(VarEnv SingleUse)
+  , ut_uses     :: !(VarEnv Use)
   -- ^ Models how an `Id` was used, if at all
   , ut_args     :: !UsageSig
   -- ^ Collects the signature for captured lambda binders
@@ -43,7 +43,7 @@ emptyUsageType = UT emptyUnVarGraph emptyVarEnv topUsageSig
 botUsageType :: UsageType
 botUsageType = unusedArgs emptyUsageType
 
-unitUsageType :: Id -> SingleUse -> UsageType
+unitUsageType :: Id -> Use -> UsageType
 unitUsageType id use = emptyUsageType { ut_uses = unitVarEnv id use }
 
 unusedArgs :: UsageType -> UsageType
@@ -90,7 +90,7 @@ multiplyUsages Once ut = ut
 multiplyUsages Many ut@(UT _ u args)
   = UT
   { ut_cocalled = completeGraph (domType ut)
-  , ut_uses = mapVarEnv (\use -> bothSingleUse use use) u
+  , ut_uses = mapVarEnv (\use -> bothUse use use) u
   , ut_args = manifyUsageSig args
   }
 
@@ -126,11 +126,11 @@ lubUsageType (UT g1 u1 args1) (UT g2 u2 args2)
   , ut_args = lubUsageSig args1 args2
   }
 
-lubUseEnv :: VarEnv SingleUse -> VarEnv SingleUse -> VarEnv SingleUse
-lubUseEnv = plusVarEnv_C lubSingleUse
+lubUseEnv :: VarEnv Use -> VarEnv Use -> VarEnv Use
+lubUseEnv = plusVarEnv_C lubUse
 
-bothUseEnv :: VarEnv SingleUse -> VarEnv SingleUse -> VarEnv SingleUse
-bothUseEnv = plusVarEnv_C bothSingleUse
+bothUseEnv :: VarEnv Use -> VarEnv Use -> VarEnv Use
+bothUseEnv = plusVarEnv_C bothUse
 
 lubUsageTypes :: [UsageType] -> UsageType
 lubUsageTypes = foldl lubUsageType botUsageType
diff --git a/compiler/utils/UnVarGraph.hs b/compiler/utils/UnVarGraph.hs
index 96f6e8224c..c3d73adbc4 100644
--- a/compiler/utils/UnVarGraph.hs
+++ b/compiler/utils/UnVarGraph.hs
@@ -7,12 +7,9 @@ A data structure for undirected graphs of variables
 (or in plain terms: Sets of unordered pairs of numbers)
 
 
-This is very specifically tailored for the use in CallArity. In particular it
-stores the graph as a union of complete and complete bipartite graph, which
-would be very expensive to store as sets of edges or as adjanceny lists.
-
-It does not normalize the graphs. This means that g `unionUnVarGraph` g is
-equal to g, but twice as expensive and large.
+This is very specifically tailored for the use in UsageAnal. In particular it
+is optimized for the nearly complete and sparse cases, which are quite common
+for co-call graphs.
 
 -}
 module UnVarGraph
diff --git a/testsuite/tests/callarity/unittest/CallArity1.hs b/testsuite/tests/callarity/unittest/CallArity1.hs
index bdaa4eb82d..ea5c099dd1 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.hs
+++ b/testsuite/tests/callarity/unittest/CallArity1.hs
@@ -5,7 +5,7 @@ import CoreUtils
 import Id
 import Type
 import MkCore
-import CallArity.Analysis ( callArityRHS )
+import UsageAnal.Analysis ( usageAnalRHS )
 import MkId
 import SysTools
 import DynFlags
@@ -203,7 +203,7 @@ main = do
               -- It should be OK to use nonDetEltsUniqSet here, if it becomes a
               -- problem we should use DVarSet
             -- liftIO $ putMsg dflags (ppr e')
-            forM_ bndrs $ \v -> putMsg dflags $ nest 4 $ ppr v <+> ppr (idCallArity v)
+            forM_ bndrs $ \v -> putMsg dflags $ nest 4 $ ppr v <+> ppr (idUsage v)
 
 -- Utilities
 mkLApps :: Id -> [Integer] -> CoreExpr
-- 
2.12.1


From 03a17d9a1544cfed966f8ec73c592fc42f5851e4 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 3 Jul 2017 08:29:16 +0200
Subject: [PATCH 109/117] Removed one RHS node through a more precise
 ChangeDetector, which also cuts down on memory usage

---
 compiler/simplCore/UsageAnal/Analysis.hs         | 88 +++++++++++++-----------
 compiler/simplCore/UsageAnal/FrameworkBuilder.hs | 23 +++++--
 2 files changed, 67 insertions(+), 44 deletions(-)

diff --git a/compiler/simplCore/UsageAnal/Analysis.hs b/compiler/simplCore/UsageAnal/Analysis.hs
index 19dfecf40a..a1064eed52 100644
--- a/compiler/simplCore/UsageAnal/Analysis.hs
+++ b/compiler/simplCore/UsageAnal/Analysis.hs
@@ -445,9 +445,12 @@ descend :: Int -> AnalEnv -> AnalEnv
 descend n env 
   = env { ae_predicted_nodes = subForest (ae_predicted_nodes env) !! n }
 
+predictSizeOfExpr :: AnalEnv -> Int
+predictSizeOfExpr = rootLabel . ae_predicted_nodes
+
 predictSizeOfLetBody :: AnalEnv -> Int
 -- The body is always the first child
-predictSizeOfLetBody = rootLabel . ae_predicted_nodes . descend 0 
+predictSizeOfLetBody = predictSizeOfExpr . descend 0 
 
 extendAnalEnv 
   :: AnalEnv 
@@ -687,6 +690,10 @@ usageAnalExpr env (Let bind e)
       --pprTrace "Let" (ppr (ut, let')) $ return ()
       return (delUsageTypes (bindersOf bind) ut, let')
     register node = do
+      -- Save the range of allocated nodes for the ChangeDetector.
+      -- The current `node` is *not* included, because it doesn't
+      -- influence annotations (that's what we track this for).
+      node_range <- nextRangeOfSize (predictSizeOfExpr env - 1)
       let initial_binds = flattenBinds [bind]
       -- We retain nodes we need for the body, so that they have lower
       -- priority than the bindings.
@@ -723,7 +730,7 @@ usageAnalExpr env (Let bind e)
                 | [(id', rhs')] <- binds'
                 -> return (ut, Let (NonRec id' rhs') e')
               _ -> return (ut, Let (Rec binds') e')
-      return (node, (transfer, changeDetectorAnalResult node))
+      return (node, (transfer, changeDetectorAnalResult node_range))
 
 coercionUsageType :: Coercion -> UsageType
 coercionUsageType co = multiplyUsages Many ut
@@ -931,16 +938,16 @@ exprForcedError = error "Expression component may not be used"
 useLetUp :: Id -> Bool
 useLetUp id = idArity id == 0
 
-transferUp :: Id -> CoreExpr -> FrameworkNode -> Use -> TransferFunction AnalResult
-transferUp id rhs node use = do
-  (ut, rhs') <- dependOnWithDefault (botUsageType, rhs) (node, use)
+transferUp :: Id -> (Use -> TransferFunction AnalResult) -> Use -> TransferFunction AnalResult
+transferUp id transfer_rhs use = do
+  (ut, rhs') <- transfer_rhs use
   if useLetUp id
     then return (ut, rhs')
-    else return (botUsageType, rhs')
+    else return (forgetFreeVarUsages ut, rhs')
 
-transferDown :: Id -> FrameworkNode -> Use -> TransferFunction UsageType
-transferDown id node use = do
-  (ut, _) <- dependOnWithDefault (botUsageType, exprForcedError) (node, use)
+transferDown :: Id -> (Use -> TransferFunction AnalResult) -> Use -> TransferFunction UsageType
+transferDown id transfer_rhs use = do
+  (ut, _) <- transfer_rhs use
   if useLetUp id
     then return (forgetFreeVarUsages ut)
     else return ut
@@ -953,32 +960,26 @@ registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`
   where
     go env transfer_ups [] = return (env, transfer_ups)
     go env transfer_ups ((n, (id, rhs)):binds) =
-      registerTransferFunction $ \up_node ->
-        registerTransferFunction $ \down_node -> do
-          ret@(env', _) <- go
-            (extendAnalEnv env id (transferDown id down_node))
-            (extendVarEnv transfer_ups id (transferUp id rhs up_node))
-            binds
-          -- Now that the whole binding group is in scope in `env'`,
-          -- we actually have to attend to our duty and register the
-          -- transfer functions associated with `up_node` and `down_node`
-          transfer_rhs <- usageAnalExpr (descend n env') rhs
-          let transfer_annotate = monotonize up_node $ \use -> do
-                --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
-                ret@(ut, rhs') <- transfer_rhs use 
-                --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr ut]) $ return ret
-                return ret
-          let transfer_args_only use = do
-                -- This makes sure to forget the annotated expression from the up_node, 
-                -- in order to have a more forgiving change detector. That's essential for 
-                -- termination of the analysis.
-                --use <- pprTrace "args:begin" (ppr id <+> text "::" <+> ppr use) $ return use
-                (ut, _) <- dependOnWithDefault (botUsageType, exprForcedError) (up_node, use)
-                --ut <- pprTrace "args:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr ut]) $ return ut
-                return (ut, exprForcedError)
-          let annotate = (transfer_annotate, changeDetectorAnalResult up_node) -- What we register for `up_node`
-          let args_only = (transfer_args_only, changeDetectorUsageType)        -- What we register for `down_node`
-          return ((ret, annotate), args_only) -- `registerTransferFunction`  will peel `snd`s away for registration
+      registerTransferFunction $ \rhs_node -> do
+        let deref_node use = dependOnWithDefault (botUsageType, rhs) (rhs_node, use)
+        ret@(env', _) <- go
+          (extendAnalEnv env id (transferDown id deref_node))
+          (extendVarEnv transfer_ups id (transferUp id deref_node))
+          binds
+        -- Now that the whole binding group is in scope in `env'`,
+        -- we actually have to attend to our duty and register the
+        -- transfer function associated with `rhs_node`
+        let env'' = descend n env'
+        -- We need to know what allocated nodes for the bound sub-expressions
+        -- range over. See `changeDetectorAnalResult` why.
+        node_range <- nextRangeOfSize (predictSizeOfExpr env'')
+        transfer_rhs <- usageAnalExpr env'' rhs
+        let transfer = monotonize rhs_node $ \use -> do
+              --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
+              ret@(ut, rhs') <- transfer_rhs use 
+              --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr ut]) $ return ret
+              return ret
+        return (ret, (transfer, changeDetectorAnalResult node_range))
 
 changeDetectorUsageType :: ChangeDetector
 changeDetectorUsageType _ (old, _) (new, _) =
@@ -998,14 +999,21 @@ changeDetectorUsageType _ (old, _) (new, _) =
     old_cocalled = ut_cocalled old
     new_cocalled = ut_cocalled new
 
-changeDetectorAnalResult :: FrameworkNode -> ChangeDetector
-changeDetectorAnalResult self_node changed_refs (old, e) (new, e') =
+-- | When detecting changes in annotated expressions, we have to be
+-- really conservative and assume an annotation changed if the changed
+-- node belongs to a sub-expression.
+--
+-- This is why we need to know the `FrameworkNodeRange`
+-- of the nodes allocated to sub-expressions: 
+-- If any changed ref falls within this range, we assume changed annotations.
+changeDetectorAnalResult :: FrameworkNodeRange -> ChangeDetector
+changeDetectorAnalResult node_range changed_refs old new =
   --pprTrace "changeDetector" (ppr $ Set.map fst changed_refs) $
-  not (Set.map fst changed_refs `Set.isSubsetOf` Set.singleton self_node) || 
-  changeDetectorUsageType changed_refs (old, e) (new, e')
+  Set.filter (withinRange node_range . fst) changed_refs /= Set.empty ||
+  changeDetectorUsageType changed_refs old new
 
 unleashLet
-  :: AnalEnv 
+  :: AnalEnv
   -> RecFlag
   -> [(Id, (CoreExpr, Use -> TransferFunction AnalResult))]
   -> UsageType
diff --git a/compiler/simplCore/UsageAnal/FrameworkBuilder.hs b/compiler/simplCore/UsageAnal/FrameworkBuilder.hs
index f9671cd3d4..7068c0b7b3 100644
--- a/compiler/simplCore/UsageAnal/FrameworkBuilder.hs
+++ b/compiler/simplCore/UsageAnal/FrameworkBuilder.hs
@@ -8,11 +8,14 @@ module UsageAnal.FrameworkBuilder
   , Worklist.alwaysChangeDetector
   , DataFlowFramework
   , FrameworkBuilder
+  , FrameworkNodeRange
   , RetainedChunk
   , retainNodes
   , freeRetainedNodes
   , registerTransferFunction
   , monotonize
+  , withinRange
+  , nextRangeOfSize
   , dependOnWithDefault
   , buildAndRun
   ) where
@@ -38,14 +41,14 @@ predictAllocatedNodes = expr
   where
     expr (App f a) = mk_parent . map expr $ [f, a]
     expr (Lam _ e) = expr e
-    expr (Let bs body) = map_lbl (+1) . mk_parent $ expr body:bind bs
+    expr (Let bs body) = add_one_node_per_child . mk_parent $ expr body:bind bs
     expr (Case scrut _ _ alts) = mk_parent (expr scrut:alt alts)
     expr (Cast e _) = expr e
     expr (Tick _ e) = expr e
     expr _ = empty_node
-    bind = map (map_lbl (+2) . expr) . rhssOfBind
+    bind = map expr . rhssOfBind
     alt = map expr . rhssOfAlts
-    map_lbl f (Node l cs) = Node (f l) cs -- Can't fmap, as that also increments children
+    add_one_node_per_child (Node p cs) = Node (p + length cs) cs
     add_child c (Node p cs) = Node (rootLabel c + p) (c:cs)
     empty_node = Node 0 []
     mk_parent = foldr add_child empty_node
@@ -78,7 +81,10 @@ data RetainedChunk
   = RC 
   { rc_start :: !Int 
   , rc_end :: !Int
-  }
+  } deriving (Eq, Ord, Show)
+
+data FrameworkNodeRange
+  = FrameworkNodeRange !FrameworkNode !FrameworkNode
 
 initialBuilderState :: BuilderState
 initialBuilderState = BS IntMap.empty (IntMap.singleton 0 maxBound)
@@ -162,6 +168,15 @@ monotonize node transfer use = do
   (ut_old, _) <- fromMaybe (botUsageType, undefined) <$> Worklist.unsafePeekValue (node, use)
   return (lubUsageType ut_new ut_old, e')
 
+withinRange :: FrameworkNodeRange -> FrameworkNode -> Bool
+withinRange (FrameworkNodeRange start end) node = start <= node && node < end
+
+nextRangeOfSize :: Int -> FrameworkBuilder FrameworkNodeRange
+nextRangeOfSize n = do
+  rc@(RC start end) <- retainNodes n
+  freeRetainedNodes rc
+  return (FrameworkNodeRange (FrameworkNode start) (FrameworkNode end))
+
 dependOnWithDefault :: AnalResult -> (FrameworkNode, Use) -> TransferFunction AnalResult
 dependOnWithDefault def which = do
   --which <- pprTrace "dependOnWithDefault:before" (ppr which) (return which)
-- 
2.12.1


From aadb37ed9f16408cf3fa9d6154bdb9c2679a3d47 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 3 Jul 2017 08:38:03 +0200
Subject: [PATCH 110/117] Minor cleanup

---
 compiler/simplCore/UsageAnal/Analysis.hs | 5 +++--
 1 file changed, 3 insertions(+), 2 deletions(-)

diff --git a/compiler/simplCore/UsageAnal/Analysis.hs b/compiler/simplCore/UsageAnal/Analysis.hs
index a1064eed52..5276fed717 100644
--- a/compiler/simplCore/UsageAnal/Analysis.hs
+++ b/compiler/simplCore/UsageAnal/Analysis.hs
@@ -983,7 +983,6 @@ registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`
 
 changeDetectorUsageType :: ChangeDetector
 changeDetectorUsageType _ (old, _) (new, _) =
-  -- It's crucial for termination that we don't have to check the annotated expressions.
   ASSERT2( old_sig `leqUsageSig` new_sig, text "UsageAnal.changeDetector: usage sig not monotone")
   old_sig /= new_sig ||
   ASSERT2( sizeUFM old_uses <= sizeUFM new_uses, text "UsageAnal.changeDetector: uses not monotone")
@@ -1033,7 +1032,7 @@ unleashLet env rec_flag transferred_binds ut_usage ut_body = do
   ids'' <- forM ids' (annotateIdArgUsage env) 
 
   -- This intentionally still contains the @Id@s of the binding group, because
-  -- the recursive rule looks at their usages to determine stability.
+  -- the recursive rule looks at their usages in the next iteration.
   return (ut_final, zip ids'' rhss')
 
 annotateIdArgUsage
@@ -1061,6 +1060,8 @@ annotateIdArgUsage env id
 -- Non-trivial expressions (as per `exprIsTrivial`) are considered shared,
 -- while the transferred result for trivial expressions is multiplied
 -- according to usage multiplicity.
+--
+-- This generalises both lifting operators from the thesis.
 unleashUsage
   :: CoreExpr
   -> (Use -> TransferFunction AnalResult)
-- 
2.12.1


From f6aaea0225fe1456900cc558a90e40df60a7e00d Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sat, 8 Jul 2017 12:43:36 +0200
Subject: [PATCH 111/117] Experimentally eta-expanding cheap expressions
 (includes PAPs)

---
 compiler/coreSyn/CoreArity.hs    | 1 +
 compiler/simplCore/SimplUtils.hs | 7 ++++++-
 2 files changed, 7 insertions(+), 1 deletion(-)

diff --git a/compiler/coreSyn/CoreArity.hs b/compiler/coreSyn/CoreArity.hs
index f7d0a2f6e6..4b5ce10bc0 100644
--- a/compiler/coreSyn/CoreArity.hs
+++ b/compiler/coreSyn/CoreArity.hs
@@ -574,6 +574,7 @@ rhsEtaExpandArity dflags cheap_app e
     has_lam _          = False
 
     -- If the case wasn't cheap, the arityType would return ATop 0.
+    is_cheap_case (Tick _ e) = is_cheap_case e
     is_cheap_case Case{} = True
     is_cheap_case _ = False
 
diff --git a/compiler/simplCore/SimplUtils.hs b/compiler/simplCore/SimplUtils.hs
index 683737a526..7636c7fcae 100644
--- a/compiler/simplCore/SimplUtils.hs
+++ b/compiler/simplCore/SimplUtils.hs
@@ -1428,7 +1428,12 @@ tryEtaExpandRhs env is_rec bndr rhs
       = return (exprArity rhs, rhs)
 
       | sm_eta_expand (getMode env)      -- Provided eta-expansion is on
-      , let cheap_arity = findRhsArity dflags bndr rhs old_arity
+      , let arity = findRhsArity dflags bndr rhs old_arity
+            -- This is so that we mimimic the behavior of Call Arity. 
+            -- Remove at some later point, see Note Eta expandint thunks in CoreArity.
+            cheap_arity 
+              | exprIsCheap rhs = max 1 arity
+              | otherwise = arity
             -- The following four lines can go away if CoreArity was aware
             -- of Usage information
             usage = idUsage bndr
-- 
2.12.1


From c2e898f0008246203720aa18cbbe4aeb1482c334 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 9 Jul 2017 20:44:12 +0200
Subject: [PATCH 112/117] Reverted 785500ceda6eef6d9214841607617851431ab067.
 Eta expanded case statements in weird ways.

---
 compiler/coreSyn/CoreArity.hs    | 13 ++++---------
 compiler/simplCore/SimplUtils.hs |  9 +++++----
 2 files changed, 9 insertions(+), 13 deletions(-)

diff --git a/compiler/coreSyn/CoreArity.hs b/compiler/coreSyn/CoreArity.hs
index 4b5ce10bc0..88c3a7abaf 100644
--- a/compiler/coreSyn/CoreArity.hs
+++ b/compiler/coreSyn/CoreArity.hs
@@ -559,7 +559,7 @@ rhsEtaExpandArity :: DynFlags -> CheapAppFun -> CoreExpr -> Arity
 rhsEtaExpandArity dflags cheap_app e
   = case (arityType env e) of
       ATop (os:oss)
-        | isOneShotInfo os || has_lam e || is_cheap_case e -> 1 + length oss
+        | isOneShotInfo os || has_lam e -> 1 + length oss
                                    -- Don't expand PAPs/thunks
                                    -- Note [Eta expanding thunks]
         | otherwise       -> 0
@@ -573,11 +573,6 @@ rhsEtaExpandArity dflags cheap_app e
     has_lam (Lam b e)  = isId b || has_lam e
     has_lam _          = False
 
-    -- If the case wasn't cheap, the arityType would return ATop 0.
-    is_cheap_case (Tick _ e) = is_cheap_case e
-    is_cheap_case Case{} = True
-    is_cheap_case _ = False
-
 {-
 Note [Arity analysis]
 ~~~~~~~~~~~~~~~~~~~~~
@@ -639,9 +634,9 @@ We don't eta-expand
 When we see
      f = case y of p -> \x -> blah
 should we eta-expand it? Well, if 'x' is a one-shot state token
-then 'yes' because 'f' will only be applied once. Also if 'y' is cheap to
-compute. But otherwise we (conservatively) say no.  My main reason is to avoid
-expanding PAPs
+then 'yes' because 'f' will only be applied once.  But otherwise
+we (conservatively) say no.  My main reason is to avoid expanding
+PAPSs
         f = g d  ==>  f = \x. g d x
 because that might in turn make g inline (if it has an inline pragma),
 which we might not want.  After all, INLINE pragmas say "inline only
diff --git a/compiler/simplCore/SimplUtils.hs b/compiler/simplCore/SimplUtils.hs
index 7636c7fcae..e14a833939 100644
--- a/compiler/simplCore/SimplUtils.hs
+++ b/compiler/simplCore/SimplUtils.hs
@@ -1429,10 +1429,11 @@ tryEtaExpandRhs env is_rec bndr rhs
 
       | sm_eta_expand (getMode env)      -- Provided eta-expansion is on
       , let arity = findRhsArity dflags bndr rhs old_arity
-            -- This is so that we mimimic the behavior of Call Arity. 
-            -- Remove at some later point, see Note Eta expandint thunks in CoreArity.
+            -- This is so that we mimic the behavior of Call Arity. 
+            -- Remove at some later point, see Note [Eta expanding thunks] in CoreArity.
+            -- Also Note [Do not eta-expand PAPs]
             cheap_arity 
-              | exprIsCheap rhs = max 1 arity
+              | arity == 0 && exprIsCheap rhs = 1
               | otherwise = arity
             -- The following four lines can go away if CoreArity was aware
             -- of Usage information
@@ -1451,7 +1452,7 @@ tryEtaExpandRhs env is_rec bndr rhs
       | otherwise
       = return (old_arity, rhs)
 
-    old_arity    = exprArity rhs -- See Note [Do not expand eta-expand PAPs]
+    old_arity    = exprArity rhs -- See Note [Do not eta-expand PAPs]
     old_id_arity = idArity bndr
 
 -- See Note [Trimming arity]
-- 
2.12.1


From 1f11d3c52f8555d27c1600158724656b6aa39495 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Mon, 10 Jul 2017 21:16:46 +0200
Subject: [PATCH 113/117] Fixed leftovers from the rebase

---
 compiler/basicTypes/IdInfo.hs                          | 18 +++++-------------
 compiler/simplCore/SimplUtils.hs                       |  6 ++++--
 compiler/simplCore/Simplify.hs                         |  4 ++--
 compiler/simplCore/UsageAnal/Analysis.hs               |  5 +++--
 testsuite/tests/callarity/unittest/CallArity1.hs       | 18 +++++++++---------
 testsuite/tests/simplCore/should_compile/T13143.stderr | 14 +++++++++-----
 testsuite/tests/stranal/should_compile/T10694.stderr   |  4 ++--
 testsuite/tests/stranal/sigs/T12370.stderr             |  4 ++--
 testsuite/tests/stranal/sigs/UnsatFun.stderr           | 14 +++++++-------
 9 files changed, 43 insertions(+), 44 deletions(-)

diff --git a/compiler/basicTypes/IdInfo.hs b/compiler/basicTypes/IdInfo.hs
index 1604aabdcf..7854dce91c 100644
--- a/compiler/basicTypes/IdInfo.hs
+++ b/compiler/basicTypes/IdInfo.hs
@@ -29,7 +29,7 @@ module IdInfo (
         -- ** Zapping various forms of Info
         zapLamInfo, zapFragileInfo,
         zapDemandInfo, zapUsageInfo, zapUsageEnvInfo, zapUsedOnceInfo,
-        zapTailCallInfo, zapCallArityInfo,
+        zapTailCallInfo, zapUsageInfo',
 
         -- ** The ArityInfo type
         ArityInfo,
@@ -112,13 +112,9 @@ infixl  1 `setRuleInfo`,
           `setCafInfo`,
           `setStrictnessInfo`,
           `setDemandInfo`,
-<<<<<<< HEAD
           `setNeverLevPoly`,
-          `setLevityInfoWithType`
-          `setCallArityInfo`,
-=======
+          `setLevityInfoWithType`,
           `setUsageInfo`,
->>>>>>> Renamed CallArity to UsageAnal, also SingleUse -> Use
           `setArgUsageInfo`
 
 {-
@@ -314,12 +310,8 @@ vanillaIdInfo
             strictnessInfo      = nopSig,
             demandInfo          = topDmd,
             argUsageInfo        = topUsageSig,
-<<<<<<< HEAD
-            callArityInfo       = topUsage
+            usageInfo           = topUsage,
             levityInfo          = NoLevityInfo
-=======
-            usageInfo       = topUsage
->>>>>>> Renamed CallArity to UsageAnal, also SingleUse -> Use
             --cardinalityInfo     = emptyCardinalityInfo
            }
 
@@ -572,8 +564,8 @@ zapTailCallInfo info
         where
           safe_occ = occ { occ_tail = NoTailCallInfo }
 
-zapCallArityInfo :: IdInfo -> IdInfo
-zapCallArityInfo info = setCallArityInfo info 0
+zapUsageInfo' :: IdInfo -> IdInfo
+zapUsageInfo' info = setUsageInfo info topUsage
 
 {-
 ************************************************************************
diff --git a/compiler/simplCore/SimplUtils.hs b/compiler/simplCore/SimplUtils.hs
index e14a833939..3b24f18678 100644
--- a/compiler/simplCore/SimplUtils.hs
+++ b/compiler/simplCore/SimplUtils.hs
@@ -1433,7 +1433,9 @@ tryEtaExpandRhs env is_rec bndr rhs
             -- Remove at some later point, see Note [Eta expanding thunks] in CoreArity.
             -- Also Note [Do not eta-expand PAPs]
             cheap_arity 
-              | arity == 0 && exprIsCheap rhs = 1
+              | arity == 0 
+              , not (exprIsBottom rhs)
+              , exprIsCheap rhs = 1
               | otherwise = arity
             -- The following four lines can go away if CoreArity was aware
             -- of Usage information
@@ -1447,7 +1449,7 @@ tryEtaExpandRhs env is_rec bndr rhs
                              ppr bndr)
                 return (old_arity, rhs)
            else do { tick (EtaExpansion bndr)
-                   --; pprTrace "tryEtaExpandRhs" (vcat [ ppr bndr, text "old_arity: " <> ppr old_arity, text "cheap_arity: " <> ppr cheap_arity, text "usage: " <> ppr usage, text "expanded_arity: " <> ppr expanded_arity, text "new_arity: " <> ppr new_arity]) (return ())
+                   --; pprTrace "tryEtaExpandRhs" (vcat [ ppr bndr, text "str: " <> ppr (idStrictness bndr), text "old_arity: " <> ppr old_arity, text "cheap_arity: " <> ppr cheap_arity, text "usage: " <> ppr usage, text "expanded_arity: " <> ppr expanded_arity, text "new_arity: " <> ppr new_arity]) (return ())
                    ; return (new_arity, etaExpand new_arity rhs) }
       | otherwise
       = return (old_arity, rhs)
diff --git a/compiler/simplCore/Simplify.hs b/compiler/simplCore/Simplify.hs
index 15b74351cd..6147d08b4e 100644
--- a/compiler/simplCore/Simplify.hs
+++ b/compiler/simplCore/Simplify.hs
@@ -833,10 +833,10 @@ completeBind env top_lvl is_rec mb_cont old_bndr new_bndr new_rhs
                   | otherwise
                   = info2
 
-              -- Zap call arity info. We have used it by now (via
+              -- Zap usage info. We have used it by now (via
               -- `tryEtaExpandRhs`), and the simplifier can invalidate this
               -- information, leading to broken code later (e.g. #13479)
-            info4 = zapCallArityInfo info3
+            info4 = zapUsageInfo' info3
 
             final_id = new_bndr `setIdInfo` info4
 
diff --git a/compiler/simplCore/UsageAnal/Analysis.hs b/compiler/simplCore/UsageAnal/Analysis.hs
index 5276fed717..8d82e4fc6d 100644
--- a/compiler/simplCore/UsageAnal/Analysis.hs
+++ b/compiler/simplCore/UsageAnal/Analysis.hs
@@ -25,6 +25,7 @@ import MkCore
 import Outputable
 import TyCon ( isDataProductTyCon_maybe, tyConSingleDataCon_maybe )
 import UniqFM
+import UniqSet
 import UnVarGraph
 import Usage
 import Util
@@ -476,7 +477,7 @@ programToExpr
 programToExpr orphan_rules = impl [] (rulesFreeVars orphan_rules)
   where
     impl top_level_ids exposed []
-      = (mkVarSet top_level_ids, mkBigCoreVarTup (nonDetEltsUFM exposed))
+      = (mkVarSet top_level_ids, mkBigCoreVarTup (nonDetEltsUniqSet exposed))
         -- nonDetEltsUFM is OK, because all product components will
         -- used in the same way anyway.
     impl top_level_ids exposed (bind:prog)
@@ -735,7 +736,7 @@ usageAnalExpr env (Let bind e)
 coercionUsageType :: Coercion -> UsageType
 coercionUsageType co = multiplyUsages Many ut
   where
-    ut = emptyUsageType { ut_uses = mapVarEnv (const topUse) (coVarsOfCo co) }
+    ut = emptyUsageType { ut_uses = mapVarEnv (const topUse) (getUniqSet $ coVarsOfCo co) }
 
 -- | Consider the expression
 --
diff --git a/testsuite/tests/callarity/unittest/CallArity1.hs b/testsuite/tests/callarity/unittest/CallArity1.hs
index ea5c099dd1..649a33f844 100644
--- a/testsuite/tests/callarity/unittest/CallArity1.hs
+++ b/testsuite/tests/callarity/unittest/CallArity1.hs
@@ -160,30 +160,30 @@ exprs =
                  , (go, mkLams [x] $ mkACase (Var f `mkVarApps` [x]) (Var go `mkApps` [Var n `mkVarApps` [x]]) ) ]) $
             Var go `mkApps` [mkLit 0, go `mkLApps` [0,1]]
   , ("a thunk (function type), in mutual recursion, absent",) $
-    mkLet d (f `mkLApps` [0]) $
+    mkNrLet d (f `mkLApps` [0]) $
         Let (Rec [ (n, Var go `mkApps` [d `mkLApps` [1]]) -- FIXME: Check UsageSigs
                  , (go, mkLams [x] $ mkACase (Var n) (Var go `mkApps` [Var n `mkVarApps` [x]]) ) ]) $
             Var go `mkApps` [mkLit 0, go `mkLApps` [0,1]]
   , ("a thunk (non-function-type) co-calls with the body (d 1*_ would be bad)",) $
     mkNrLet d (f `mkLApps` [0]) $
-        mkLet x (d `mkLApps` [1]) $
+        mkNrLet x (d `mkLApps` [1]) $
             Var d `mkVarApps` [x]
   , ("body cocalls d and n, n calls d (anything other than d w*C^w(U) = w*U would be bad)",) $
     mkNrLet d (f `mkLApps` [0]) $
-        mkLet n (mkLams [y] $ d `mkLApps` [1]) $
+        mkNrLet n (mkLams [y] $ d `mkLApps` [1]) $
             Var f `mkApps` [d `mkLApps` [0], n `mkLApps` [0]]
   , ("body calls d and n mutually exclusive, n calls d. d should be called once",) $
     mkNrLet d (f `mkLApps` [0]) $
-        mkLet n (mkLams [y] $ d `mkLApps` [1]) $
+        mkNrLet n (mkLams [y] $ d `mkLApps` [1]) $
             mkACase (d `mkLApps` [0]) (n `mkLApps` [0])
   -- Product related tests
   , ("calling the first tuple component once",) $
-    mkLet d (f `mkLApps` [0]) $
-        mkLet n (mkLams [y] $ d `mkLApps` [1]) $
+    mkNrLet d (f `mkLApps` [0]) $
+        mkNrLet n (mkLams [y] $ d `mkLApps` [1]) $
             elimPair (mkVarPair d n) (_1 `mkLApps` [0])
   , ("calling the second tuple component twice (expect n w*U and d w*U by transitivity)",) $
-    mkLet d (f `mkLApps` [0]) $
-        mkLet n (mkLams [y] $ d `mkLApps` [1]) $
+    mkNrLet d (f `mkLApps` [0]) $
+        mkNrLet n (mkLams [y] $ d `mkLApps` [1]) $
             elimPair (mkVarPair d n) (Var _2 `mkApps` [_2 `mkLApps` [0]])
   ]
 
@@ -198,7 +198,7 @@ main = do
                 Nothing -> return ()
             putMsg dflags (text n <> char ':')
             -- liftIO $ putMsg dflags (ppr e)
-            let e' = callArityRHS dflags emptyFamInstEnvs emptyVarSet e
+            let e' = usageAnalRHS dflags emptyFamInstEnvs emptyVarSet e
             let bndrs = nonDetEltsUniqSet (allBoundIds e')
               -- It should be OK to use nonDetEltsUniqSet here, if it becomes a
               -- problem we should use DVarSet
diff --git a/testsuite/tests/simplCore/should_compile/T13143.stderr b/testsuite/tests/simplCore/should_compile/T13143.stderr
index c9cdd95bc2..23a0241584 100644
--- a/testsuite/tests/simplCore/should_compile/T13143.stderr
+++ b/testsuite/tests/simplCore/should_compile/T13143.stderr
@@ -7,7 +7,7 @@ Rec {
 -- RHS size: {terms: 4, types: 4, coercions: 0, joins: 0/0}
 T13143.$wf [InlPrag=NOINLINE, Occ=LoopBreaker]
   :: forall a. GHC.Prim.Void# -> a
-[GblId, Arity=1, Caf=NoCafRefs, Str=<B,A>b]
+[GblId, Arity=1, Caf=NoCafRefs, Str=<B,A>b, ArgUsg=A,A..]
 T13143.$wf = \ (@ a) _ [Occ=Dead] -> T13143.$wf @ a GHC.Prim.void#
 end Rec }
 
@@ -17,6 +17,7 @@ f [InlPrag=INLINE[0]] :: forall a. Int -> a
  Arity=1,
  Caf=NoCafRefs,
  Str=<B,A>b,
+ ArgUsg=A,A..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=1,unsat_ok=True,boring_ok=True)
@@ -69,16 +70,18 @@ T13143.$trModule
 
 -- RHS size: {terms: 2, types: 1, coercions: 0, joins: 0/0}
 lvl :: Int
-[GblId, Str=b]
+[GblId, Str=b, ArgUsg=A,A..]
 lvl = T13143.$wf @ Int GHC.Prim.void#
 
 Rec {
 -- RHS size: {terms: 28, types: 7, coercions: 0, joins: 0/0}
 T13143.$wg [InlPrag=[0], Occ=LoopBreaker]
   :: Bool -> Bool -> GHC.Prim.Int# -> GHC.Prim.Int#
-[GblId, Arity=3, Str=<S,1*U><S,1*U><S,U>]
+[GblId, Arity=3, Str=<S,1*U><S,1*U><S,U>, ArgUsg=1*U,1*U,w*U,w*U..]
 T13143.$wg
-  = \ (w :: Bool) (w1 :: Bool) (ww :: GHC.Prim.Int#) ->
+  = \ (w :: Bool)
+      (w1 [OS=OneShot] :: Bool)
+      (ww [OS=OneShot] :: GHC.Prim.Int#) ->
       case w of {
         False ->
           case w1 of {
@@ -97,7 +100,8 @@ end Rec }
 g [InlPrag=INLINE[0]] :: Bool -> Bool -> Int -> Int
 [GblId,
  Arity=3,
- Str=<S,1*U><S,1*U><S(S),1*U(U)>m,
+ Str=<S,1*U><S,1*U><S(S),1*U>m,
+ ArgUsg=1*U,1*U,1*U,w*U,w*U..,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True,
          WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=3,unsat_ok=True,boring_ok=False)
diff --git a/testsuite/tests/stranal/should_compile/T10694.stderr b/testsuite/tests/stranal/should_compile/T10694.stderr
index 5ed7587af1..8abae48695 100644
--- a/testsuite/tests/stranal/should_compile/T10694.stderr
+++ b/testsuite/tests/stranal/should_compile/T10694.stderr
@@ -4,7 +4,7 @@ Result size of Tidy Core = {terms: 70, types: 63, coercions: 0}
 
 -- RHS size: {terms: 39, types: 25, coercions: 0}
 T10694.$wpm [InlPrag=NOINLINE] :: Int -> Int -> (# Int, Int #)
-[GblId, Arity=2, Str=<L,U><L,U>m]
+[GblId, Arity=2, Str=<L,U><L,U>]
 T10694.$wpm =
   \ (w_sVU :: Int) (w1_sVV :: Int) ->
     let {
@@ -29,7 +29,7 @@ T10694.$wpm =
 pm [InlPrag=INLINE[0]] :: Int -> Int -> (Int, Int)
 [GblId,
  Arity=2,
- Str=<L,U(U)><L,U(U)>m,
+ Str=<L,U><L,U>m,
  Unf=Unf{Src=InlineStable, TopLvl=True, Value=True, ConLike=True, WorkFree=True, Expandable=True,
          Guidance=ALWAYS_IF(arity=2,unsat_ok=True,boring_ok=False)
          Tmpl= \ (w_sVU [Occ=Once] :: Int) (w1_sVV [Occ=Once] :: Int) ->
diff --git a/testsuite/tests/stranal/sigs/T12370.stderr b/testsuite/tests/stranal/sigs/T12370.stderr
index 0a629ddde4..de86884126 100644
--- a/testsuite/tests/stranal/sigs/T12370.stderr
+++ b/testsuite/tests/stranal/sigs/T12370.stderr
@@ -8,7 +8,7 @@ T12370.foo: <S(S(S)S(S)),1*U(1*U,1*U)>m
 
 ==================== Strictness signatures ====================
 T12370.$trModule: m
-T12370.bar: <S(S),1*U><S(S),1*U>m
-T12370.foo: <S(S(S)S(S)),1*U(1*U,1*U)>m
+T12370.bar: <S(S),1*U(U)><S(S),1*U(U)>m
+T12370.foo: <S(S(S)S(S)),1*U(1*U(U),1*U(U))>m
 
 
diff --git a/testsuite/tests/stranal/sigs/UnsatFun.stderr b/testsuite/tests/stranal/sigs/UnsatFun.stderr
index 050e217696..1ea2fa4773 100644
--- a/testsuite/tests/stranal/sigs/UnsatFun.stderr
+++ b/testsuite/tests/stranal/sigs/UnsatFun.stderr
@@ -1,10 +1,10 @@
 
 ==================== Strictness signatures ====================
 UnsatFun.$trModule: m
-UnsatFun.f: <B,1*U><B,A>x
-UnsatFun.g: <B,1*U>x
-UnsatFun.g': <L,1*U>
-UnsatFun.g3: <L,U>m
+UnsatFun.f: <B,1*U(U)><B,A>x
+UnsatFun.g: <B,1*U(U)>x
+UnsatFun.g': <L,1*U(U)>
+UnsatFun.g3: <L,U(U)>m
 UnsatFun.h: <C(S),1*C1(U(U))>
 UnsatFun.h2: <S,1*U><L,1*C1(U(U))>
 UnsatFun.h3: <C(S),1*C1(U)>m
@@ -13,9 +13,9 @@ UnsatFun.h3: <C(S),1*C1(U)>m
 
 ==================== Strictness signatures ====================
 UnsatFun.$trModule: m
-UnsatFun.f: <B,1*U><B,A>x
-UnsatFun.g: <B,1*U>x
-UnsatFun.g': <L,1*U>
+UnsatFun.f: <B,1*U(U)><B,A>x
+UnsatFun.g: <B,1*U(U)>x
+UnsatFun.g': <L,1*U(U)>
 UnsatFun.g3: <L,U(U)>m
 UnsatFun.h: <C(S),1*C1(U(U))>
 UnsatFun.h2: <S,1*U><L,1*C1(U(U))>
-- 
2.12.1


From b2a33ae4eb4f7e532d56fb9b3baac87d4172885f Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Tue, 11 Jul 2017 11:38:16 +0200
Subject: [PATCH 114/117] Always using LetDn for join points now (as does
 DmdAnal)

---
 compiler/simplCore/DmdAnalWrapper.hs     | 4 ++--
 compiler/simplCore/UsageAnal/Analysis.hs | 2 +-
 2 files changed, 3 insertions(+), 3 deletions(-)

diff --git a/compiler/simplCore/DmdAnalWrapper.hs b/compiler/simplCore/DmdAnalWrapper.hs
index 6207da4a6c..371683ce9a 100644
--- a/compiler/simplCore/DmdAnalWrapper.hs
+++ b/compiler/simplCore/DmdAnalWrapper.hs
@@ -38,8 +38,8 @@ mergeInfo top_lvl is_lam_bndr id
   -- instead of the whole expression, we get more conservative results in our
   -- new analysis, where there might be multiplied uses on lambda binders if
   -- it has more than one lambda. In that case we have to relax the assert.
-  = ASSERT2( (is_lam_bndr || not has_usage || ca_usage `leqUsage` old_usage), text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
-    ASSERT2( (not has_usg_sig || not str_sig_comparable_to_usg_sig || ca_usg_sig `leqUsageSig` old_usg_sig), text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
+  = WARN( not (is_lam_bndr || not has_usage || ca_usage `leqUsage` old_usage), text "Usage should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usage <+> text "ca:" <+> ppr ca_usage <+> text "new:" <+> ppr new_demand )
+    WARN( not (not has_usg_sig || not str_sig_comparable_to_usg_sig || ca_usg_sig `leqUsageSig` old_usg_sig), text "UsageSig should never be less precise:" <+> ppr id <+> text "old:" <+> ppr old_usg_sig <+> text "ca:" <+> ppr ca_usg_sig <+> text "new:" <+> ppr new_str_sig )
     --pprTrace "mergeInfo" (ppr id <+> text "Demand:" <+> ppr old_demand <+> ppr ca_usage <+> ppr new_demand <+> text "Strictness" <+> ppr old_str_sig <+> ppr ca_usg_sig <+> ppr new_str_sig) $
     id'
   where
diff --git a/compiler/simplCore/UsageAnal/Analysis.hs b/compiler/simplCore/UsageAnal/Analysis.hs
index 8d82e4fc6d..7be70da15c 100644
--- a/compiler/simplCore/UsageAnal/Analysis.hs
+++ b/compiler/simplCore/UsageAnal/Analysis.hs
@@ -937,7 +937,7 @@ exprForcedError :: CoreExpr
 exprForcedError = error "Expression component may not be used"
 
 useLetUp :: Id -> Bool
-useLetUp id = idArity id == 0
+useLetUp id = idArity id == 0 && not (isJoinId id)
 
 transferUp :: Id -> (Use -> TransferFunction AnalResult) -> Use -> TransferFunction AnalResult
 transferUp id transfer_rhs use = do
-- 
2.12.1


From 9ed22414f3e28417ceb11b46f4f8dab9e232f926 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Wed, 12 Jul 2017 17:21:28 +0200
Subject: [PATCH 115/117] Refactored and improved docs

---
 compiler/simplCore/UsageAnal/Analysis.hs         | 1461 ++++++++++------------
 compiler/simplCore/UsageAnal/FrameworkBuilder.hs |    1 +
 conftest.c                                       |   88 ++
 3 files changed, 760 insertions(+), 790 deletions(-)
 create mode 100644 conftest.c

diff --git a/compiler/simplCore/UsageAnal/Analysis.hs b/compiler/simplCore/UsageAnal/Analysis.hs
index 7be70da15c..3d039f701a 100644
--- a/compiler/simplCore/UsageAnal/Analysis.hs
+++ b/compiler/simplCore/UsageAnal/Analysis.hs
@@ -24,6 +24,7 @@ import Maybes ( expectJust, fromMaybe, isJust )
 import MkCore
 import Outputable
 import TyCon ( isDataProductTyCon_maybe, tyConSingleDataCon_maybe )
+import Type ( Type )
 import UniqFM
 import UniqSet
 import UnVarGraph
@@ -38,376 +39,12 @@ import Control.Monad ( forM )
 import qualified Data.Set as Set
 import Data.Tree
 
+--
+-- * Analysis environment
+--
 
-{-
-%************************************************************************
-%*                                                                      *
-              Call Arity Analyis
-%*                                                                      *
-%************************************************************************
-
-Note [Notes are out of date]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-While the general concept of the Co-Call Analysis still applies, much has
-changed at isn't yet on par with the implementation.
-
-Note [Call Arity: The goal]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-The goal of this analysis is to find out if we can eta-expand a local function,
-based on how it is being called. The motivating example is this code,
-which comes up when we implement foldl using foldr, and do list fusion:
-
-    let go = \x -> let d = case ... of
-                              False -> go (x+1)
-                              True  -> id
-                   in \z -> d (x + z)
-    in go 1 0
-
-If we do not eta-expand `go` to have arity 2, we are going to allocate a lot of
-partial function applications, which would be bad.
-
-The function `go` has a type of arity two, but only one lambda is manifest.
-Furthermore, an analysis that only looks at the RHS of go cannot be sufficient
-to eta-expand go: If `go` is ever called with one argument (and the result used
-multiple times), we would be doing the work in `...` multiple times.
-
-So `usageAnalProgram` looks at the whole let expression to figure out if
-all calls are nice, i.e. have a high enough arity. It then stores the result in
-the `calledArity` field of the `IdInfo` of `go`, which the next simplifier
-phase will eta-expand.
-
-The specification of the `calledArity` field is:
-
-    No work will be lost if you eta-expand me to the arity in `calledArity`.
-
-What we want to know for a variable
------------------------------------
-
-For every let-bound variable we'd like to know:
-  1. A lower bound on the arity of all calls to the variable, and
-  2. whether the variable is being called at most once or possible multiple
-     times.
-
-It is always ok to lower the arity, or pretend that there are multiple calls.
-In particular, "Minimum arity 0 and possible called multiple times" is always
-correct.
-
-
-What we want to know from an expression
----------------------------------------
-
-In order to obtain that information for variables, we analyize expression and
-obtain bits of information:
-
- I.  The arity analysis:
-     For every variable, whether it is absent, or called,
-     and if called, which what arity.
-
- II. The Co-Called analysis:
-     For every two variables, whether there is a possibility that bothUsageType are being
-     called.
-     We obtain as a special case: For every variables, whether there is a
-     possibility that it is being called twice.
-
-For efficiency reasons, we gather this information only for a set of
-*interesting variables*, to avoid spending time on, e.g., variables from pattern matches.
-
-The two analysis are not completely independent, as a higher arity can improve
-the information about what variables are being called once or multiple times.
-
-Note [Analysis I: The arity analyis]
-------------------------------------
-
-The arity analysis is quite straight forward: The information about an
-expression is an
-    VarEnv Arity
-where absent variables are bound to Nothing and otherwise to a lower bound to
-their arity.
-
-When we analyize an expression, we analyize it with a given context arity.
-Lambdas decrease and applications increase the incoming arity. Analysizing a
-variable will put that arity in the environment. In lets or cases all the
-results from the various subexpressions are lubed, which takes the point-wise
-minimum (considering Nothing an infinity).
-
-
-Note [Analysis II: The Co-Called analysis]
-------------------------------------------
-
-The second part is more sophisticated. For reasons explained below, it is not
-sufficient to simply know how often an expression evalutes a variable. Instead
-we need to know which variables are possibly called together.
-
-The data structure here is an undirected graph of variables, which is provided
-by the abstract
-    UnVarGraph
-
-It is safe to return a larger graph, i.e. one with more edges. The worst case
-(i.e. the least useful and always correct result) is the complete graph on all
-free variables, which means that anything can be called together with anything
-(including itself).
-
-Notation for the following:
-C(e)  is the co-called result for e.
-G₁∪G₂ is the union of two graphs
-fv    is the set of free variables (conveniently the domain of the arity analysis result)
-S₁×S₂ is the complete bipartite graph { {a,b} | a ∈ S₁, b ∈ S₂ }
-S²    is the complete graph on the set of variables S, S² = S×S
-C'(e) is a variant for bound expression:
-      If e is called at most once, or it is and stays a thunk (after the analysis),
-      it is simply C(e). Otherwise, the expression can be called multiple times
-      and we return (fv e)²
-
-The interesting cases of the analysis:
- * Var v:
-   No other variables are being called.
-   Return {} (the empty graph)
- * Lambda v e, under arity 0:
-   This means that e can be evaluated many times and we cannot get
-   any useful co-call information.
-   Return (fv e)²
- * Case alternatives alt₁,alt₂,...:
-   Only one can be execuded, so
-   Return (alt₁ ∪ alt₂ ∪...)
- * App e₁ e₂ (and analogously Case scrut alts), with non-trivial e₂:
-   We get the results from bothUsageType sides, with the argument evaluated at most once.
-   Additionally, anything called by e₁ can possibly be called with anything
-   from e₂.
-   Return: C(e₁) ∪ C(e₂) ∪ (fv e₁) × (fv e₂)
- * App e₁ x:
-   As this is already in A-normal form, CorePrep will not separately lambda
-   bind (and hence share) x. So we conservatively assume multiple calls to x here
-   Return: C(e₁) ∪ (fv e₁) × {x} ∪ {(x,x)}
- * Let v = rhs in body:
-   In addition to the results from the subexpressions, add all co-calls from
-   everything that the body calls together with v to everthing that is called
-   by v.
-   Return: C'(rhs) ∪ C(body) ∪ (fv rhs) × {v'| {v,v'} ∈ C(body)}
- * Letrec v₁ = rhs₁ ... vₙ = rhsₙ in body
-   Tricky.
-   We assume that it is really mutually recursive, i.e. that every variable
-   calls one of the others, and that this is strongly connected (otherwise we
-   return an over-approximation, so that's ok), see note [Recursion and fixpointing].
-
-   Let V = {v₁,...vₙ}.
-   Assume that the vs have been analysed with an incoming demand and
-   cardinality consistent with the final result (this is the fixed-pointing).
-   Again we can use the results from all subexpressions.
-   In addition, for every variable vᵢ, we need to find out what it is called
-   with (call this set Sᵢ). There are two cases:
-    * If vᵢ is a function, we need to go through all right-hand-sides and bodies,
-      and collect every variable that is called together with any variable from V:
-      Sᵢ = {v' | j ∈ {1,...,n},      {v',vⱼ} ∈ C'(rhs₁) ∪ ... ∪ C'(rhsₙ) ∪ C(body) }
-    * If vᵢ is a thunk, then its rhs is evaluated only once, so we need to
-      exclude it from this set:
-      Sᵢ = {v' | j ∈ {1,...,n}, j≠i, {v',vⱼ} ∈ C'(rhs₁) ∪ ... ∪ C'(rhsₙ) ∪ C(body) }
-   Finally, combine all this:
-   Return: C(body) ∪
-           C'(rhs₁) ∪ ... ∪ C'(rhsₙ) ∪
-           (fv rhs₁) × S₁) ∪ ... ∪ (fv rhsₙ) × Sₙ)
-
-Using the result: Eta-Expansion
--------------------------------
-
-We use the result of these two analyses to decide whether we can eta-expand the
-rhs of a let-bound variable.
-
-If the variable is already a function (exprIsCheap), and all calls to the
-variables have a higher arity than the current manifest arity (i.e. the number
-of lambdas), expand.
-
-If the variable is a thunk we must be careful: Eta-Expansion will prevent
-sharing of work, so this is only safe if there is at most one call to the
-function. Therefore, we check whether {v,v} ∈ G.
-
-    Example:
-
-        let n = case .. of .. -- A thunk!
-        in n 0 + n 1
-
-    vs.
-
-        let n = case .. of ..
-        in case .. of T -> n 0
-                      F -> n 1
-
-    We are only allowed to eta-expand `n` if it is going to be called at most
-    once in the body of the outer let. So we need to know, for each variable
-    individually, that it is going to be called at most once.
-
-
-Why the co-call graph?
-----------------------
-
-Why is it not sufficient to simply remember which variables are called once and
-which are called multiple times? It would be in the previous example, but consider
-
-        let n = case .. of ..
-        in case .. of
-            True -> let go = \y -> case .. of
-                                     True -> go (y + n 1)
-                                     False > n
-                    in go 1
-            False -> n
-
-vs.
-
-        let n = case .. of ..
-        in case .. of
-            True -> let go = \y -> case .. of
-                                     True -> go (y+1)
-                                     False > n
-                    in go 1
-            False -> n
-
-In bothUsageType cases, the body and the rhs of the inner let call n at most once.
-But only in the second case that holds for the whole expression! The
-crucial difference is that in the first case, the rhs of `go` can call
-*both* `go` and `n`, and hence can call `n` multiple times as it recurses,
-while in the second case find out that `go` and `n` are not called together.
-
-
-Why co-call information for functions?
---------------------------------------
-
-Although for eta-expansion we need the information only for thunks, we still
-need to know whether functions are being called once or multiple times, and
-together with what other functions.
-
-    Example:
-
-        let n = case .. of ..
-            f x = n (x+1)
-        in f 1 + f 2
-
-    vs.
-
-        let n = case .. of ..
-            f x = n (x+1)
-        in case .. of T -> f 0
-                      F -> f 1
-
-    Here, the body of f calls n exactly once, but f itself is being called
-    multiple times, so eta-expansion is not allowed.
-
-
-Note [Analysis type signature]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-The work-hourse of the analysis is the function `usageAnal`, with the
-following type:
-
-    type UsageType = (UnVarGraph, VarEnv Arity)
-    usageAnal ::
-        Arity ->  -- The arity this expression is called with
-        VarSet -> -- The set of interesting variables
-        CoreExpr ->  -- The expression to analyse
-        (UsageType, CoreExpr)
-
-and the following specification:
-
-  ((coCalls, callArityEnv), expr') = callArityEnv arity interestingIds expr
-
-                            <=>
-
-  Assume the expression `expr` is being passed `arity` arguments. Then it holds that
-    * The domain of `callArityEnv` is a subset of `interestingIds`.
-    * Any variable from `interestingIds` that is not mentioned in the `callArityEnv`
-      is absent, i.e. not called at all.
-    * Every call from `expr` to a variable bound to n in `callArityEnv` has at
-      least n value arguments.
-    * For two interesting variables `v1` and `v2`, they are not adjacent in `coCalls`,
-      then in no execution of `expr` bothUsageType are being called.
-  Furthermore, expr' is expr with the callArity field of the `IdInfo` updated.
-
-
-Note [Which variables are interesting]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-The analysis would quickly become prohibitive expensive if we would analyse all
-variables; for most variables we simply do not care about how often they are
-called, i.e. variables bound in a pattern match. So interesting are variables that are
- * top-level or let bound
- * and possibly functions (typeArity > 0)
-
-Note [Taking boring variables into account]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-If we decide that the variable bound in `let x = e1 in e2` is not interesting,
-the analysis of `e2` will not report anything about `x`. To ensure that
-`registerBindingGroup` does still do the right thing we have to take that into account
-everytime we look up up `x` in the analysis result of `e2`.
-  * Instead of calling lookupUsage, we return (0, True), indicating
-    that this variable might be called many times with no arguments.
-  * Instead of checking `calledWith x`, we assume that everything can be called
-    with it.
-  * In the recursive case, when calclulating the `cross_calls`, if there is
-    any boring variable in the recursive group, we ignore all co-call-results
-    and directly go to a very conservative assumption.
-
-The last point has the nice side effect that the relatively expensive
-integration of co-call results in a recursive groups is often skipped. This
-helped to avoid the compile time blowup in some real-world code with large
-recursive groups (#10293).
-
-Note [Recursion and fixpointing]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-For a mutually recursive let, we begin by
- 1. analysing the body, using the same incoming arity as for the whole expression.
- 2. Then we iterate, memoizing for each of the bound variables the last
-    analysis call, i.e. incoming arity, whether it is called once, and the UsageType.
- 3. We combine the analysis result from the body and the memoized results for
-    the arguments (if already present).
- 4. For each variable, we find out the incoming arity and whether it is called
-    once, based on the the current analysis result. If this differs from the
-    memoized results, we re-analyse the rhs and update the memoized table.
- 5. If nothing had to be reanalyzed, we are done.
-    Otherwise, repeat from step 3.
-
-
-Note [Thunks in recursive groups]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-We never eta-expand a thunk in a recursive group, on the grounds that if it is
-part of a recursive group, then it will be called multipe times.
-
-This is not necessarily true, e.g.  it would be safe to eta-expand t2 (but not
-t1) in the following code:
-
-  let go x = t1
-      t1 = if ... then t2 else ...
-      t2 = if ... then go 1 else ...
-  in go 0
-
-Detecting this would require finding out what variables are only ever called
-from thunks. While this is certainly possible, we yet have to see this to be
-relevant in the wild.
-
-
-Note [Analysing top-level binds]
-~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
-
-We can eta-expand top-level-binds if they are not exported, as we see all calls
-to them. The plan is as follows: Treat the top-level binds as nested lets around
-a body representing “all external calls”, which returns a pessimistic
-UsageType (the co-call graph is the complete graph, all arityies 0).
-
-Note [What is a thunk]
-~~~~~~~~~~~~~~~~~~~~~~
-
-Originally, everything that is not in WHNF (`exprIsWHNF`) is considered a
-thunk, not eta-expanded, to avoid losing any sharing. This is also how the
-published papers on Call Arity describe it.
-
-In practice, there are thunks that do a just little work, such as
-pattern-matching on a variable, and the benefits of eta-expansion likely
-oughtweigh the cost of doing that repeatedly. Therefore, this implementation of
-Call Arity considers everything that is not cheap (`exprIsCheap`) as a thunk.
--}
-
+-- | Contains scoped, read-only configuration and analysis information which
+-- we thread through the analysis functions (mostly) `Reader`-like.
 data AnalEnv
   = AE
   { ae_dflags :: DynFlags
@@ -415,12 +52,12 @@ data AnalEnv
   --
   --     - `Opt_DmdTxDictSel`: Control analysis of dictionary selectors.
   --
-  , ae_sigs :: VarEnv (Use -> TransferFunction UsageType)
-  -- ^ 'TransferFunction's of visible local let-bound identifiers. It is crucial
-  -- that only the 'UsageSig' component is used, as the usage on free vars might
-  -- be unstable and thus too optimistic.
+  , ae_trans :: VarEnv (Use -> TransferFunction UsageType)
+  -- ^ Usage transformers of visible local let-bound identifiers to be
+  -- unleashed at call sites. The free variable information might or
+  -- might not be pruned, see `useLetUp` and `registerBindingGroup`.
   , ae_fam_envs :: FamInstEnvs
-  -- ^ Needed for 'findTypeShape' to resolve type/data families.
+  -- ^ Needed for `findTypeShape` to resolve type/data families.
   , ae_need_sig_annotation :: VarSet
   -- ^ `Id`s which need to be annotated with a signature, e.g. because
   -- they are visible beyond this module. These are probably top-level
@@ -436,40 +73,59 @@ initialAnalEnv :: DynFlags -> FamInstEnvs -> VarSet -> Tree Int -> AnalEnv
 initialAnalEnv dflags fam_envs need_sigs predicted_nodes
   = AE
   { ae_dflags = dflags
-  , ae_sigs = emptyVarEnv
+  , ae_trans = emptyVarEnv
   , ae_fam_envs = fam_envs
   , ae_need_sig_annotation = need_sigs
   , ae_predicted_nodes = predicted_nodes
   }
 
+-- | Logically descends into a child in the `AnalEnv`s `ae_predicted_node`
+-- tree. This is mostly needed for allocating `FrameworkNode`s in a manner
+-- that results in fast termination.
 descend :: Int -> AnalEnv -> AnalEnv
 descend n env 
   = env { ae_predicted_nodes = subForest (ae_predicted_nodes env) !! n }
 
+-- | Predicts the size of the current expression in terms of `FrameworkNode`s
+-- to allocate.
 predictSizeOfExpr :: AnalEnv -> Int
 predictSizeOfExpr = rootLabel . ae_predicted_nodes
 
+-- | Predicts the size of the body of the current let-binding in terms of 
+-- the `FrameworkNode`s to allocate.
 predictSizeOfLetBody :: AnalEnv -> Int
 -- The body is always the first child
 predictSizeOfLetBody = predictSizeOfExpr . descend 0 
 
+-- | Extends the `AnalEnv`s `ae_trans` field with a new usage transformer
+-- for a let-bound `LocalId`.
 extendAnalEnv 
   :: AnalEnv 
   -> Id 
   -> (Use -> TransferFunction UsageType) 
   -> AnalEnv
 extendAnalEnv env id node 
-  = env { ae_sigs = extendVarEnv (ae_sigs env) id node }
+  = env { ae_trans = extendVarEnv (ae_trans env) id node }
+
+--
+-- * Handling top-level bindings through conversion from and to `CoreProgram`
+--
 
--- | See Note [Analysing top-level-binds]
--- `programToExpr` returns a pair of all top-level `Id`s
+-- | `programToExpr` returns a pair of all top-level `Id`s
 -- and a nested `let` expression that uses everything externally visible.
 -- This `let` expression is then to be analysed by `usageAnalRHS`.
 --
 -- Represents the fact that a `CoreProgram` is like a sequence of
--- nested lets, where the external visible ids are returned in the inner-most let
--- as a tuple. As a result, all visible identifiers are handled as called
+-- nested lets, where the external visible `Id`s are returned in the inner-most
+-- let as a tuple. As a result, all visible identifiers are handled as called
 -- with each other, with `topUsage`.
+--
+-- The set regarded externally visible directly influences the precision of the
+-- analysis: We have to jump through quite some hoops to actually include all
+-- such top-level bindings, otherwise the analysis will be unsafe.
+-- On the other hand, regarding all top-level identifiers as externally visible
+-- is certainly a safe approximation, but the resulting usage annotations will
+-- be far less than optimal due to the aggressive float-out passes.
 programToExpr 
   :: [CoreRule]
   -> CoreProgram 
@@ -504,12 +160,49 @@ programToExpr orphan_rules = impl [] (rulesFreeVars orphan_rules)
         is_active_rule _ = True -- Conservative, but we should be fine
         rules = map (idRuleRhsVars is_active_rule) bs
 
--- | The left inverse to `programToExpr`: `exprToProgram . snd . programToExpr = id \@CoreProgram`
+-- | (Almost) the left inverse to `programToExpr`: `exprToProgram . snd . programToExpr = id \@CoreProgram`
 exprToProgram :: CoreExpr -> CoreProgram
 exprToProgram (Let bind e) = bind : exprToProgram e
 exprToProgram _ = []
 
--- Main entry point
+--
+-- * Exposed analysis function
+--
+
+-- | `usageAnalProgram dflags fam_envs orphan_rules prog` annotates `prog` 
+-- with usage information. In particular, it enriches `Id`s with the 
+-- following `IdInfo` fields:
+-- 
+--   * `idUsage`: Represents the `Usage` an identifier is exposed to,
+--     relative to the most conservative use of the containing expression.
+--     Operationally, the usage `Multiplicity` is what is most useful
+--     to identify single-entry thunks. Applies to all kinds of identifiers.
+--   * `idArgUsage`: A `UsageSig` that reflects what usage the bound expression
+--     exposes its arguments to in a single call with arity at least `idArity`.
+--     Only applies to top-level identifiers.
+--   * `idOneShotInfo`: Applies to lambda-bound identifiers and is rather
+--     an assertion about the binding lambda. One-shot lambdas are lambda 
+--     expressions where the body of the lambda is called at most once,
+--     relative to a single reduction of the surrounding syntactic expression 
+--     to WHNF.
+--
+-- Usage is a relative thing: Based on what top-level binders we use how, 
+-- some sub-expression might be used differently.
+-- 
+-- We assume the most conservative use for all top-level binders that we
+-- deem "externally visible" (see `programToExpr`), our "usage roots",
+-- so to speak. That's very similar to what the Occurrence Analyser
+-- does. In order to not under-approximate the externally visible set,
+-- we have to look at the `orphan_rules` parameter and the rules attached
+-- to `prog`.
+--
+-- The other parameters are pretty standard. We need `fam_envs` for resolving
+-- type/data families and `findTypeShape`. From `dflags` we need the following
+-- compiler flags:
+--
+--   * `Opt_DmdTxDictSel`: Treat `idArgUsage` of dictionary selectors 
+--     usage-polymorphic. See `dictSelUsageSig`.
+--
 usageAnalProgram 
   :: DynFlags 
   -> FamInstEnvs 
@@ -525,219 +218,468 @@ usageAnalProgram dflags fam_envs orphan_rules
   -- . (\it -> pprTrace "usageAnal:begin" (ppr (length it)) it)
   -- . (\prog -> pprTrace "usageAnal:Program" (ppr prog) prog)
 
+-- | Like `usageAnalProgram`, but works on `CoreExpr`. Needs to be explicitly
+-- told which binders need to be annotated with `idArgUsage` through the 
+-- `VarSet`.
+--
+-- Wraps `buildAnalFramework` which builds up the data-flow framework to be iterated
+-- by `buildAndRun`. The usage transformer for the `CoreExpr` will then be 
+-- put under use `topUse`.
 usageAnalRHS :: DynFlags -> FamInstEnvs -> VarSet -> CoreExpr -> CoreExpr
 usageAnalRHS dflags fam_envs need_sigs e
   = ASSERT2( isEmptyUnVarSet (domType ut), text "Free vars in UsageType:" $$ ppr ut ) e'
   where
     env = initialAnalEnv dflags fam_envs need_sigs (predictAllocatedNodes e)
-    (ut, e') = buildAndRun (usageAnalExpr env e) topUse
+    (ut, e') = buildAndRun (buildAnalFramework env e) topUse
 
-usageAnalExpr
+--
+-- * Allocating `FrameworkNode`s to usage transformers
+--
+
+-- This section is concerned with the *outer* monad for allocating 
+-- `FrameworkNode`s, e.g. `FrameworkBuilder`.
+-- This is so that the actual transfer functions @transfer*@ are free
+-- of any fixed-pointing and unaware of nodes.
+
+-- | `buildAnalFramework env e` builds the data-flow framework that is to be iterated
+-- to yield the usage transformer denoting `e`, together with a corresponding
+-- annotated expression. The pair of `UsageType` and annotated `CoreExpr` forms
+-- the `AnalResult` synonym.
+-- 
+-- This function is mostly concerned with allocating `FrameworkNode`s in the
+-- `FrameworkBuilder` monad, which could easily be extracted. 
+-- The actual analysis logic happens in @transfer*@ variants.
+buildAnalFramework
   :: AnalEnv
   -> CoreExpr
   -> FrameworkBuilder (Use -> TransferFunction AnalResult)
 
-usageAnalExprTrivial
+-- Used for the trivial leaf cases, where the expression does not
+-- not need to allocate nodes and the usage type is a result of a pure 
+-- computation.
+buildAnalFrameworkTrivial
   :: UsageType
   -> CoreExpr
   -> FrameworkBuilder (Use -> TransferFunction AnalResult)
-usageAnalExprTrivial ut e
+buildAnalFrameworkTrivial ut e
   = return (const (return (ut, e)))
 
-usageAnalExprMap
+-- Used for the transparent compositional cases. No additional nodes
+-- beyond that of the body are allocated, and the `TransferFunction` 
+-- just maps over the `CoreExpr` of the wrapped expression.
+buildAnalFrameworkMap
   :: AnalEnv
-  -> (CoreExpr -> a)
+  -> (CoreExpr -> CoreExpr)
   -> CoreExpr
-  -> FrameworkBuilder (Use -> TransferFunction (UsageType, a)) -- @a@ instead of @CoreExpr@
-usageAnalExprMap env f e
-  = transfer' <$> usageAnalExpr env e
+  -> FrameworkBuilder (Use -> TransferFunction AnalResult)
+buildAnalFrameworkMap env f e
+  = transfer' <$> buildAnalFramework env e
   where
     transfer' transfer use = do
       (ut, e') <- transfer use
       return (ut, f e')
 
-usageAnalExpr _ e@(Lit _)
-  = usageAnalExprTrivial emptyUsageType e 
-usageAnalExpr _ e@(Type _)
-  = usageAnalExprTrivial emptyUsageType e
-
-usageAnalExpr _ e@(Coercion co)
-  = usageAnalExprTrivial (coercionUsageType co) e
+buildAnalFramework env e = 
+  case e of 
+    Lit _ -> buildAnalFrameworkTrivial emptyUsageType e 
+    Type _ -> buildAnalFrameworkTrivial emptyUsageType e 
+    Coercion co -> buildAnalFrameworkTrivial (coercionUsageType co) e
+    Tick t e' -> buildAnalFrameworkMap env (Tick t) e'
+    Cast e' co -> transferCast co <$> buildAnalFramework env e'
+    Var id -> return (transferId env id)
+    Lam id body | isTyVar id -> buildAnalFrameworkMap env (Lam id) body
+    Lam id body -> transferLam (ae_fam_envs env) id body <$> buildAnalFramework env body
+    App f (Type t) -> buildAnalFrameworkMap env (flip App (Type t)) f
+    App f a -> 
+      transferApp a 
+        <$> buildAnalFramework (descend 0 env) f 
+        <*> buildAnalFramework (descend 1 env) a
+    Case scrut case_bndr ty alts -> do
+      transfer_scrut <- buildAnalFramework (descend 0 env) scrut
+      -- We zip the index of the child in the ae_predicted_nodes tree
+      transfer_alts <- forM (zip [1..] alts) $ \(n, alt@(_, _, rhs)) ->
+        transferAlt (ae_fam_envs env) case_bndr alt 
+          <$> buildAnalFramework (descend n env) rhs
+      return (transferCase env case_bndr ty transfer_scrut transfer_alts)
+    -- Now for the actual interesting case, where all node allocation happens:
+    Let bind body -> deref_node <$> registerTransferFunction register
+      where
+        -- | `deref_node` is the actual transfer function we return.
+        -- Speaking in terms of the `TransferFunction` monad, this is as 
+        -- impure as it gets: We immediately depend on the `FrameworkNode`
+        -- we are about to register.
+        -- Note that `transferLet` will not have deleted the information
+        -- on the current binding group in order to enable change detection.
+        -- Thus we need to delete them manually here.
+        -- Morally, we should extract that into another @transfer*@-style
+        -- function.
+        deref_node node use = do
+          (ut, e') <- dependOnWithDefault (botUsageType, e) (node, use)
+          --pprTrace "Let" (ppr (ut, let')) $ return ()
+          return (delUsageTypes (bindersOf bind) ut, e')
+        -- | This will register the `TransferFunction`s for the current binding
+        -- group.
+        -- There will be a node for the fixed-point of $up$ as well as for the
+        -- fixed-point of each $down$ node for each bound expression.
+        register node = do
+          -- Save the range of allocated nodes for the ChangeDetector.
+          -- The current `node` is *not* included, because it doesn't
+          -- influence annotations (that's what we track this for).
+          node_range <- nextRangeOfSize (predictSizeOfExpr env - 1)
+          -- We retain nodes we need for the body, so that they have lower
+          -- priority than the bindings.
+          retained <- retainNodes (predictSizeOfLetBody env)
+          -- `registerBindingGroup` will register `FrameworkNode`s for each
+          -- bound expression.
+          (env', rhs_env) <- registerBindingGroup env (flattenBinds [bind])
+          -- Free the lower priority nodes we retained for the body.
+          freeRetainedNodes retained
+          let transfer_bind id =
+                expectJust ": the RHS of id wasn't registered" (lookupVarEnv rhs_env id)
+          -- We need to access env' with the new sigs in the body, so we
+          -- can't register it earlier.
+          -- On the other hand, registering nodes later will assign a higher
+          -- priority than to the RHSs, which we don't want.
+          -- That is why we retained low-priority nodes prior to calling 
+          -- `registerBindingGroup` and freed them directly after.
+          -- The retained chunk will exactly fit the nodes to be allocated
+          -- for the body.
+          transfer_body <- buildAnalFramework (descend 0 env') body
+          -- This captures the fixed-pointing: For the recursive rule, we depend on
+          -- the previous analysis result, while for non-recursive functions we can
+          -- just assume `botUsageType`. The old result will be joined with the
+          -- body's usage type regardless, so this will do the right thing.
+          -- This way, `transferLet`, as all other @transfer*@ variants, is completely 
+          -- agnostic of any fixed-pointing.
+          let transformer_old :: Use -> TransferFunction UsageType
+              transformer_old use 
+                | Rec{} <- bind = fst <$> dependOnWithDefault (botUsageType, undefined) (node, use)
+                | otherwise = return botUsageType
+          -- For reasons outlined in the thesis, we have to monotonize
+          -- the points of usage transformers explicitly.
+          -- TLDR; Although the usage transformers we denote exressions with
+          -- are monotone maps, there is no data structure that models this
+          -- yet. Thus, the `Worklist` module uses a plain map to model points
+          -- of the usage transformer. As a result, it is possible that
+          -- while approximating, the modeled usage transformer is not 
+          -- monotone. It seems to be enough to just monotonize every point
+          -- separately, e.g. making sure that points can't go down 
+          -- in the lattice.
+          let transfer = monotonize node (transferLet env' bind transfer_body transfer_bind transformer_old)
+          return (node, (transfer, changeDetectorAnalResult node_range))
+
+-- | Registers bound expressions of a binding group. 
+-- Returns an `AnalEnv` with updated `ae_transfers` for unleashing at call 
+-- sites (only `UsageType`s) and also a `VarEnv` of transferred `AnalResult`s, 
+-- for annotated expressions.
+registerBindingGroup
+  :: AnalEnv
+  -> [(Id, CoreExpr)]
+  -> FrameworkBuilder (AnalEnv, VarEnv (Use -> TransferFunction AnalResult))
+registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`ing
+  where
+    go env transfer_ups [] = return (env, transfer_ups)
+    go env transfer_ups ((n, (id, rhs)):binds) =
+      registerTransferFunction $ \rhs_node -> do
+        let deref_node use = dependOnWithDefault (botUsageType, rhs) (rhs_node, use)
+        -- We first handle the other bindings so that they can register themselves
+        -- like we just did.
+        -- Remember that we can't actually analyse RHSs without having nodes
+        -- available for all bound `Id`s!
+        -- This means that internally in `registerTransferFunction` there is some
+        -- knot-tying involved.
+        ret@(env', _) <- go
+          (extendAnalEnv env id (transferDown id deref_node))
+          (extendVarEnv transfer_ups id (transferUp id deref_node))
+          binds
+        -- Now that the whole binding group is in scope in `env'`,
+        -- we actually have to attend to our duty and register the
+        -- transfer function associated with `rhs_node`.
+        let env'' = descend n env'
+        -- We need to know what allocated nodes for the bound sub-expressions
+        -- range over. See `changeDetectorAnalResult` why.
+        node_range <- nextRangeOfSize (predictSizeOfExpr env'')
+        transfer_rhs <- buildAnalFramework env'' rhs
+        let transfer = monotonize rhs_node $ \use -> do
+              --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
+              ret@(_ut, _) <- transfer_rhs use 
+              --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr _ut]) $ return ret
+              return ret
+        return (ret, (transfer, changeDetectorAnalResult node_range))
 
-usageAnalExpr env (Tick t e)
-  = usageAnalExprMap env (Tick t) e
+-- | When detecting changes in annotated expressions, we have to be
+-- really conservative and assume an annotation changed if the changed
+-- node belongs to a sub-expression.
+--
+-- This is why we need to know the `FrameworkNodeRange`
+-- of the nodes allocated to sub-expressions: 
+-- If any changed ref falls within this range, we assume changed annotations.
+changeDetectorAnalResult :: FrameworkNodeRange -> ChangeDetector
+changeDetectorAnalResult node_range changed_refs old new =
+  --pprTrace "changeDetector" (ppr $ Set.map fst changed_refs) $
+  Set.filter (withinRange node_range . fst) changed_refs /= Set.empty ||
+  changeDetectorUsageType changed_refs old new
 
-usageAnalExpr env (Cast e co)
-  = transfer' <$> usageAnalExpr env e
+-- | This handles change detection on `UsageType`s, exploiting monotonicity 
+-- to great effect.
+changeDetectorUsageType :: ChangeDetector
+changeDetectorUsageType _ (old, _) (new, _) =
+  ASSERT2( old_sig `leqUsageSig` new_sig, text "UsageAnal.changeDetector: usage sig not monotone")
+  old_sig /= new_sig ||
+  ASSERT2( sizeUFM old_uses <= sizeUFM new_uses, text "UsageAnal.changeDetector: uses not monotone")
+  sizeUFM old_uses /= sizeUFM new_uses ||
+  old_uses /= new_uses ||
+  ASSERT2( edgeCount old_cocalled <= edgeCount new_cocalled, text "UsageAnal.changeDetector: edgeCount not monotone")
+  edgeCount old_cocalled /= edgeCount new_cocalled
   where
-    transfer' transfer use = do
-      (ut, e') <- transfer use
-      -- like usageAnalExprMap, but we also have to combine with the UsageType
-      -- of the coercion.
-      return (ut `bothUsageType` coercionUsageType co, Cast e' co)
+    old_sig = ut_args old
+    new_sig = ut_args new
+    old_uses = ut_uses old
+    new_uses = ut_uses new
+    old_cocalled = ut_cocalled old
+    new_cocalled = ut_cocalled new
 
-usageAnalExpr env e@(Var id) = return transfer
-  where
-    transfer use
-      | Just transfer_callee <- lookupVarEnv (ae_sigs env) id
-      -- A local let-binding, e.g. a binding from this module.
-      -- We apply either the LetUp or LetDown rule, which is handled
-      -- transparently in `registerBindingGroups`.
-      = do
-        ut_callee <- transfer_callee use
-        --pprTrace "usageAnalExpr:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
-        return (ut_callee `bothUsageType` unitUsageType id use, e)
-
-      | isLocalId id
-      -- A LocalId not present in @nodes@, e.g. a lambda or case-bound variable.
-      -- We are only second-order, so we don't model signatures for parameters!
-      -- Their usage is interesting to note nonetheless for annotating lambda
-      -- binders and scrutinees.
-      = --pprTrace "usageAnalExpr:OtherId" (ppr id <+> ppr use) $
-        return (unitUsageType id use, e)
-
-      -- The other cases handle global ids
-      | Just dc <- ASSERT( isGlobalId id ) (isDataConWorkId_maybe id)
-      -- Some data constructor, on which we can try to unleash product use
-      -- as a `UsageSig`.
-      = --pprTrace "usageAnalExpr:DataCon" (ppr id <+> ppr use <+> ppr (dataConUsageSig dc use)) $
-        return (emptyUsageType { ut_args = dataConUsageSig dc use }, e)
-
-      | gopt Opt_DmdTxDictSel (ae_dflags env)
-      , Just clazz <- isClassOpId_maybe id
-      -- A dictionary component selector
-      = --pprTrace "usageAnalExpr:DictSel" (ppr id <+> ppr use <+> ppr (dictSelUsageSig id clazz use)) $
-        return (emptyUsageType { ut_args = dictSelUsageSig id clazz use }, e)
+--
+-- * Transfer functions and related helpers
+--
 
-      | otherwise
-      -- A global id from another module which has a usage signature.
-      -- We don't need to track the id itself, though.
-      = --pprTrace "usageAnalExpr:GlobalId" (ppr id <+> ppr (idArity id) <+> ppr use <+> ppr (globalIdUsageSig id use) <+> ppr (idStrictness id) <+> ppr (idDetails id)) $
-        return (emptyUsageType { ut_args = globalIdUsageSig id use }, e)
-
-usageAnalExpr env (Lam id body)
-  | isTyVar id
-  = usageAnalExprMap env (Lam id) body
-  | otherwise
-  = do
-    transfer_body <- usageAnalExpr env body
-    return $ \use ->
-      case fromMaybe topUsage (peelCallUse use) of -- Get at the relative @Usage@ of the body
-        Absent -> do
-          let id' = id `setIdUsage` Absent
-          return (emptyUsageType, Lam id' body)
-        Used multi body_use -> do
-          (ut_body, body') <- transfer_body body_use
-          let fam_envs = ae_fam_envs env
-          let (ut_body', usage_id) = findBndrUsage NonRecursive fam_envs ut_body id
-          let id' = applyWhen (multi == Once) (`setIdOneShotInfo` OneShotLam)
-                  . (\id -> setBndrUsageInfo fam_envs id usage_id)
-                  $ id
-          -- Free vars are manified, closed vars are not. The usage of the current
-          -- argument `id` is *not* manified.
-          let ut = modifyArgs (consUsageSig usage_id)
-                 . multiplyUsages multi
-                 $ ut_body'
-          --pprTrace "usageAnalExpr:Lam" (vcat [text "id:" <+> ppr id, text "relative body usage:" <+> ppr u, text "id usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
-          return (ut, Lam id' body')
-
-usageAnalExpr env (App f (Type t)) 
-  = usageAnalExprMap (descend 0 env) (flip App (Type t)) f
-usageAnalExpr env (App f a) = do
-  transfer_f <- usageAnalExpr (descend 0 env) f
-  transfer_a <- usageAnalExpr (descend 1 env) a
-  return $ \result_use -> do
-    (ut_f, f') <- transfer_f (mkCallUse Once result_use)
-    --pprTrace "App:f'" (ppr f') $ return ()
-    -- peel off one argument from the type
-    let (arg_usage, ut_f') = peelArgUsage ut_f
-    case considerThunkSharing a arg_usage of
-      Absent -> return (ut_f', App f' (markAbsent a))
-      Used m arg_use -> do
-        -- `m` will be `Once` most of the time (see `considerThunkSharing`),
-        -- so that all work before the lambda is uncovered will be shared 
-        -- (call-by-need!). This is the same argument as for let-bound 
-        -- right hand sides.
-        -- We could also use the multiplicity in the same way we do for
-        -- let-bindings: An argument only used once does not need to be
-        -- memoized.
-        (ut_a, a') <- first (multiplyUsages m) <$> transfer_a arg_use
-        --pprTrace "App:a'" (text "arg_use:" <+> ppr arg_use <+> ppr (ut_a, a')) $ return ()
-        return (ut_f' `bothUsageType` ut_a, App f' a')
-
-usageAnalExpr env (Case scrut case_bndr ty alts) = do
-  transfer_scrut <- usageAnalExpr (descend 0 env) scrut
-  -- We zip the index of the child in the ae_predicted_nodes tree
-  transfer_alts <- forM (zip [1..] alts) $ \(n, alt) -> 
-    analyseCaseAlternative (descend n env) case_bndr alt
-  return $ \use -> do
-    (ut_alts, alts', scrut_uses) <- unzip3 <$> mapM ($ use) transfer_alts
-    let ut_alt = lubUsageTypes ut_alts
-    let fam_envs = ae_fam_envs env
-    let case_bndr_usage = lookupUsage NonRecursive fam_envs ut_alt case_bndr
-    let case_bndr' = setBndrUsageInfo fam_envs case_bndr case_bndr_usage
-    let ut_alt' = delUsageType case_bndr ut_alt
-    let scrut_use = propagateProductUse alts' scrut_uses
-    (ut_scrut, scrut') <- transfer_scrut scrut_use
-    let ut = ut_alt' `bothUsageType` ut_scrut
-    --pprTrace "Case" (vcat [text "ut_scrut:" <+> ppr ut_scrut, text "ut_alts:" <+> ppr ut_alts, text "ut:" <+> ppr ut]) (return ())
-    return (ut, Case scrut' case_bndr' ty alts')
-
-usageAnalExpr env (Let bind e) 
-  = registerTransferFunction register >>= deref_node
-  where
-    deref_node node = return $ \use -> do
-      (ut, let') <- dependOnWithDefault (botUsageType, Let bind e) (node, use)
-      --pprTrace "Let" (ppr (ut, let')) $ return ()
-      return (delUsageTypes (bindersOf bind) ut, let')
-    register node = do
-      -- Save the range of allocated nodes for the ChangeDetector.
-      -- The current `node` is *not* included, because it doesn't
-      -- influence annotations (that's what we track this for).
-      node_range <- nextRangeOfSize (predictSizeOfExpr env - 1)
-      let initial_binds = flattenBinds [bind]
-      -- We retain nodes we need for the body, so that they have lower
-      -- priority than the bindings.
-      retained <- retainNodes (predictSizeOfLetBody env)
-      (env', rhs_env) <- registerBindingGroup env initial_binds
-      freeRetainedNodes retained
-      let lookup_node id =
-            expectJust ": the RHS of id wasn't registered" (lookupVarEnv rhs_env id)
-      let transferred_bind (id, rhs) = (id, (rhs, lookup_node id))
-      -- Ideally we'd want the body to have a lower priority than the RHSs,
-      -- but we need to access env' with the new sigs in the body, so we
-      -- can't register it earlier.
-      transfer_body <- usageAnalExpr (descend 0 env') e
-      let rec_flag = recFlagOf bind
-      let transfer :: Use -> TransferFunction AnalResult
-          transfer = monotonize node $ \use -> do
-            --use <- pprTrace "Rec:begin" (ppr ids) $ return use
-            (ut_body, e') <- transfer_body use
-            (ut_usage, old_binds) <- case rec_flag of
-              NonRecursive -> 
-                -- We don't need to dependOn ourselves here, because only the let body can't
-                -- call id.
-                return (ut_body, initial_binds)
-              Recursive -> do
-                -- This is the actual fixed-point iteration: we depend on usage
-                -- results from the previous iteration, defaulting to just the body.
-                (ut_usage, Let (Rec old_binds) _) <- dependOnWithDefault (ut_body, Let bind e) (node, use)
-                return (ut_usage, old_binds)
-            let transferred_binds = map transferred_bind old_binds
-            (ut, binds') <- unleashLet env' rec_flag transferred_binds ut_usage ut_body
-            --ut <- pprTrace "Rec:end" (ppr ids) $ return ut
-            case rec_flag of
-              NonRecursive
-                | [(id', rhs')] <- binds'
-                -> return (ut, Let (NonRec id' rhs') e')
-              _ -> return (ut, Let (Rec binds') e')
-      return (node, (transfer, changeDetectorAnalResult node_range))
+-- | Mostly transparent, but we also have to sequentially compose with the 
+-- `UsageType` of the coercion.
+transferCast 
+  :: Coercion 
+  -> (Use -> TransferFunction AnalResult) 
+  -> Use -> TransferFunction AnalResult
+transferCast co transfer_e use = do
+  (ut, e') <- transfer_e use
+  return (ut `bothUsageType` coercionUsageType co, Cast e' co)
 
 coercionUsageType :: Coercion -> UsageType
 coercionUsageType co = multiplyUsages Many ut
   where
     ut = emptyUsageType { ut_uses = mapVarEnv (const topUse) (getUniqSet $ coVarsOfCo co) }
 
+-- | This is the variable rule of the transfer function. We unleash the 
+-- identifier's usage transformer, which is differently approximated
+-- depending on what kind of identifier is called.
+transferId :: AnalEnv -> Id -> Use -> TransferFunction AnalResult
+transferId env id use
+  | Just transfer_callee <- lookupVarEnv (ae_trans env) id
+  -- A local let-binding, e.g. a binding from this module.
+  -- We apply either the LetUp or LetDown rule, which is handled
+  -- transparently in `registerBindingGroup`.
+  = do
+    ut_callee <- transfer_callee use
+    --pprTrace "buildAnalFramework:LocalId" (ppr id <+> ppr use <+> ppr (ut_args ut_callee)) (return ())
+    return (ut_callee `bothUsageType` unitUsageType id use, Var id)
+
+  | isLocalId id
+  -- A LocalId not present in @nodes@, e.g. a lambda or case-bound variable.
+  -- We are only second-order, so we don't model signatures for parameters!
+  -- Their usage is interesting to note nonetheless for annotating lambda
+  -- binders and scrutinees.
+  = --pprTrace "buildAnalFramework:OtherId" (ppr id <+> ppr use) $
+    return (unitUsageType id use, Var id)
+
+  -- The other cases handle global ids
+  | Just dc <- ASSERT( isGlobalId id ) (isDataConWorkId_maybe id)
+  -- Some data constructor, on which we can try to unleash product use
+  -- as a `UsageSig`.
+  = --pprTrace "buildAnalFramework:DataCon" (ppr id <+> ppr use <+> ppr (dataConUsageSig dc use)) $
+    return (emptyUsageType { ut_args = dataConUsageSig dc use }, Var id)
+
+  | gopt Opt_DmdTxDictSel (ae_dflags env)
+  , Just clazz <- isClassOpId_maybe id
+  -- A dictionary component selector
+  = --pprTrace "buildAnalFramework:DictSel" (ppr id <+> ppr use <+> ppr (dictSelUsageSig id clazz use)) $
+    return (emptyUsageType { ut_args = dictSelUsageSig id clazz use }, Var id)
+
+  | otherwise
+  -- A global id from another module which has a usage signature.
+  -- We don't need to track the id itself, though.
+  = --pprTrace "buildAnalFramework:GlobalId" (ppr id <+> ppr (idArity id) <+> ppr use <+> ppr (globalIdUsageSig id use) <+> ppr (idStrictness id) <+> ppr (idDetails id)) $
+    return (emptyUsageType { ut_args = globalIdUsageSig id use }, Var id)
+ 
+-- | For lambdas, we peel off one layer of the incoming call `Use` to get at
+-- the relative `Usage` of the body. The body is then analysed according to
+-- that usage and the resulting `UsageType` is multiplied appropriately.
+-- Finally, the argument `Usage` is consed to the `ut_args` signature.
+transferLam 
+  :: FamInstEnvs
+  -> Id 
+  -> CoreExpr
+  -> (Use -> TransferFunction AnalResult)
+  -> Use -> TransferFunction AnalResult
+transferLam fam_envs id body transfer_body use =
+  case fromMaybe topUsage (peelCallUse use) of -- Get at the relative @Usage@ of the body
+    Absent -> do
+      let id' = id `setIdUsage` Absent
+      return (emptyUsageType, Lam id' body)
+    Used multi body_use -> do
+      (ut_body, body') <- transfer_body body_use
+      let (ut_body', usage_id) = findBndrUsage NonRecursive fam_envs ut_body id
+      let id' = applyWhen (multi == Once) (`setIdOneShotInfo` OneShotLam)
+              . (\id -> setBndrUsageInfo fam_envs id usage_id)
+              $ id
+      -- Free vars are manified, closed vars are not. The usage of the current
+      -- argument `id` is *not* manified.
+      let ut = modifyArgs (consUsageSig usage_id)
+              . multiplyUsages multi
+              $ ut_body'
+      --pprTrace "buildAnalFramework:Lam" (vcat [text "id:" <+> ppr id, text "relative body usage:" <+> ppr u, text "id usage:" <+> ppr usage_id, text "usage sig:" <+> ppr (ut_args ut)]) (return ())
+      return (ut, Lam id' body')
+
+-- | Analyses the argument `a` according to the usage expressed in the usage
+-- signature of the `UsageType` of the call to `f`.
+-- Analogous to let-bindings, we may or may not multiply the usage on `a`
+-- if the argument will not be shared through a thunk later on (`unleashUsage`).
+transferApp
+  :: CoreExpr
+  -> (Use -> TransferFunction AnalResult)
+  -> (Use -> TransferFunction AnalResult)
+  -> Use -> TransferFunction AnalResult
+transferApp a transfer_f transfer_a result_use = do
+  (ut_f, f') <- transfer_f (mkCallUse Once result_use)
+  --pprTrace "App:f'" (ppr f') $ return ()
+  -- peel off one argument from the usage type
+  let (arg_usage, ut_f') = peelArgUsage ut_f
+  (ut_a, a') <- unleashUsage a transfer_a arg_usage
+  return (ut_f' `bothUsageType` ut_a, App f' a')
+
+-- | Lifts the domain of a transfer function of an expression to @Usage@.
+-- Non-trivial expressions (as per `exprIsTrivial`) are considered shared,
+-- while the transferred result for trivial expressions is multiplied
+-- according to usage multiplicity.
+--
+-- This generalises both lifting operators from the thesis.
+unleashUsage
+  :: CoreExpr
+  -> (Use -> TransferFunction AnalResult)
+  -> Usage -> TransferFunction AnalResult
+unleashUsage e transfer_e usage =
+  case considerThunkSharing e usage of
+    Absent -> return (emptyUsageType, markAbsent e)
+    Used m use ->
+      -- As with arguments, `m` should be `Once` most of the time 
+      -- (e.g. if `rhs` is non-trivial, see `considerThunkSharing`).
+      -- Thus, the work required to get the RHS of let-bindings 
+      -- to WHNF is shared among all use sites.
+      -- We still annotate the binder with the multiplicity later on, 
+      -- as @Once@ means we don't have to memoize the result anyway.
+      first (multiplyUsages m) <$> transfer_e use
+
+-- | Takes care of figuring out usage on data constructor binders, 
+-- case binders and the use on the scrutinee from analysis results
+-- of a case branch.
+transferAlt
+  :: FamInstEnvs
+  -> Id
+  -> Alt CoreBndr
+  -> (Use -> TransferFunction AnalResult)
+  -> Use -> TransferFunction (UsageType, Alt CoreBndr, Use)
+transferAlt fam_envs case_bndr (dc, alt_bndrs, _) transfer_alt use = do
+  (ut_alt, e') <- transfer_alt use
+  let (ut_alt', alt_bndr_usages) = findBndrsUsages NonRecursive fam_envs ut_alt alt_bndrs
+  let (_, case_bndr_usage) = findBndrUsage NonRecursive fam_envs ut_alt case_bndr
+  -- We have to combine usages of alts_bndrs with that of case_bndr.
+  -- Usage info flows from case_bndr to alt_bndrs, but not the other way
+  -- around! This means that we later on annotate case_bndr solely based
+  -- on how its @Id@ was used, not on how the components were used.
+  let alt_bndr_usages' = addCaseBndrUsage case_bndr_usage alt_bndr_usages
+  let alt_bndrs' = setBndrsUsageInfo fam_envs alt_bndrs alt_bndr_usages
+  let product_use = mkProductUse alt_bndr_usages'
+  -- product_use doesn't yet take into account strictness annotations of the
+  -- constructor. That's to be done when we finally match on dc.
+  return (ut_alt', (dc, alt_bndrs', e'), product_use)
+
+-- | Joins the results on case alternatives from `transferAlt` to find out
+-- the usage the case binder is exposed to and the use the scrutinee is put
+-- under. The resulting `UsageType` of analysing the scrutinee in that use
+-- is then sequentially composed (`bothUsageType`) with the joined usage type
+-- from all case alternatives.
+transferCase 
+  :: AnalEnv
+  -> Id
+  -> Type
+  -> (Use -> TransferFunction AnalResult)
+  -> [Use -> TransferFunction (UsageType, Alt CoreBndr, Use)]
+  -> Use -> TransferFunction AnalResult
+transferCase env case_bndr ty transfer_scrut transfer_alts use = do
+  (ut_alts, alts', scrut_uses) <- unzip3 <$> mapM ($ use) transfer_alts
+  let ut_alt = lubUsageTypes ut_alts
+  let fam_envs = ae_fam_envs env
+  let case_bndr_usage = lookupUsage NonRecursive fam_envs ut_alt case_bndr
+  let case_bndr' = setBndrUsageInfo fam_envs case_bndr case_bndr_usage
+  let ut_alt' = delUsageType case_bndr ut_alt
+  let scrut_use = propagateProductUse alts' scrut_uses
+  (ut_scrut, scrut') <- transfer_scrut scrut_use
+  let ut = ut_alt' `bothUsageType` ut_scrut
+  --pprTrace "Case" (vcat [text "ut_scrut:" <+> ppr ut_scrut, text "ut_alts:" <+> ppr ut_alts, text "ut:" <+> ppr ut]) (return ())
+  return (ut, Case scrut' case_bndr' ty alts')
+
+-- | Determines when the uses in the case alternatives on the scrutinee
+-- can be joined into a sensible use and defaults to `topUse`.
+propagateProductUse
+  :: [Alt CoreBndr]
+  -> [Use]
+  -> Use
+propagateProductUse alts scrut_uses
+  -- Only one alternative with a product constructor
+  | [(DataAlt dc, _, _)] <- alts
+  , [scrut_use] <- scrut_uses
+  , let tycon = dataConTyCon dc
+  -- Don't include newtypes, as they aren't really constructors introducing
+  -- indirections.
+  , isJust (isDataProductTyCon_maybe tycon)
+  -- This is a good place to make sure we don't construct an infinitely deep
+  -- use, which can happen when analysing e.g. lazy streams.
+  -- Also see Note [Demand on scrutinee of a product case] in DmdAnal.hs.
+  = addDataConStrictness dc (boundDepth 10 scrut_use) -- 10 seems to be just enough to match DmdAnal
+  | otherwise
+  -- We *could* lub the uses from the different branches, but there's not much
+  -- to be won there, except for maybe head strictness.
+  = topUse
+
+-- | Given ways to transfer body and bound expressions of a let-binding,
+-- this function transfers let-bindings into a denoting usage transformer
+-- that unleashes usage types of identifiers we `useLetUp` for and
+-- performs the necessary co-call graph substitution via `unleashLet`.
+transferLet 
+  :: AnalEnv 
+  -> CoreBind
+  -> (Use -> TransferFunction AnalResult)
+  -> (Id -> Use -> TransferFunction AnalResult)
+  -> (Use -> TransferFunction UsageType)
+  -> Use -> TransferFunction AnalResult
+transferLet env bind transfer_body transfer_bind transformer_old use = do
+  --use <- pprTrace "Rec:begin" (ppr ids) $ return use
+  (ut_body, body) <- transfer_body use
+  -- The passed `transformer_old` captures the fixed-pointing through a
+  -- call to `dependOnWithDefault` in the recursive case, which we can
+  -- even spare in the non-recursive one.
+  ut_scope <- lubUsageType ut_body <$> transformer_old use
+  -- We treat `flattenBinds [bind]` like an association list from `Id`s to RHSs. 
+  -- Now we zip to each RHS the transferred usage transformer:
+  let zip_transfer (id, rhs) = (id, (rhs, transfer_bind id))
+  let transferred_binds = map zip_transfer (flattenBinds [bind])
+  -- Finally, we perform the graph substitution step in `unleashLet`.
+  (ut, binds') <- unleashLet env (recFlagOf bind) transferred_binds ut_scope ut_body
+  --ut <- pprTrace "Rec:end" (ppr ids) $ return ut
+  -- Note that `ut` still contains the bindings of `bind` for purposes of 
+  -- change detection.
+  -- This is a consequence of the fact that we thread annotated expressions
+  -- through the analysis: Otherwise we couldn't detect when to stop
+  -- iterating the let up node (which would have to be included in the
+  -- `node_range` to look out for).
+  case bind of
+    NonRec{}
+      | [(id', rhs')] <- binds'
+      -> return (ut, Let (NonRec id' rhs') body)
+    _ -> return (ut, Let (Rec binds') body)
+
+--
+-- * `UsageSig`s for `GlobalId`s
+--
+
 -- | Consider the expression
 --
 -- @
@@ -773,20 +715,58 @@ dataConUsageSig dc use = fromMaybe topUsageSig sig_maybe
       component_usages <- peelProductUse arity (addDataConStrictness dc product_use)
       return (usageSigFromUsages component_usages)
 
+-- | Takes into account strictness annotations on data constructor fields.
+addDataConStrictness :: DataCon -> Use -> Use
+-- See Note [Add demands for strict constructors] in DmdAnal.hs
+addDataConStrictness dc
+  = maybe topUse (mkProductUse . add_component_strictness) 
+  . peelProductUse arity
+  where
+    add_component_strictness :: [Usage] -> [Usage]
+    add_component_strictness = zipWith add strs
+
+    strs = dataConRepStrictness dc
+    arity = length strs
+
+    add _ Absent = Absent -- See the note; We want to eliminate these in WW.
+    add str usage@(Used _ _)
+      | isMarkedStrict str = usage `bothUsage` u'1HU -- head usage imposed by `seq`
+      | otherwise = usage
+
+-- | Constructs a more precise usage sig for a call to a dictionary selector.
+-- Consider
+-- 
+-- @
+--     (+) $dNumInt x y
+-- @
+-- 
+-- under `Use` @U@. This puts `(+)` under use @C^1(C^1(C^1(U)))@ and unleashes
+-- a `UsageSig` of @1*U(A,..,A,n*U,A,..,A),w*U,w*U,..@. We want that U to be 
+-- substituted by @C^1(C^1(U))@, as that more accurately represents the call to
+-- the dictionary field.
+-- We make the usage signature of the selector polymorphic, so to speak,
+-- turning @C^1(u)@ into a usage signature of @1*U(A,..,A,n*u,A,..,A),w*U,w*U,..@.
 dictSelUsageSig :: Id -> Class -> Use -> UsageSig
 dictSelUsageSig id clazz use
+  -- @dict_single_call_use = U(A,..,A,n*U,A,..,A)@
   | Used _ dict_single_call_use <- fst . unconsUsageSig . idArgUsage $ id
   , Just dc <- tyConSingleDataCon_maybe (classTyCon clazz)
   , let dict_length = idArity (dataConWorkId dc)
+  -- @comps = [A,..,A,U,A,..,A]@
   , Just comps <- peelProductUse dict_length dict_single_call_use
-  = case peelCallUse use of -- The outer call is the selector. The inner use is on the actual method!
+  -- @use = C^1(C^1(C^1(U)))@
+  = case peelCallUse use of -- The outer call is on the selector. The inner use is on the actual method!
       Nothing -> topUsageSig -- weird
       Just Absent -> botUsageSig
+      -- @method_use = C^1(C^1(U))@
       Just (Used Once method_use) -> specializeDictSig comps method_use
       Just (Used Many method_use) -> manifyUsageSig (specializeDictSig comps method_use)
   | otherwise
   = topUsageSig
 
+-- | `speacializeDictSig comps method_use` substitutes the single @U@ in `comps`
+-- with `method_use` @u@ and constructs a usage signature of 
+-- @1*U(A,..,A,n*u,A,..,A),w*U,w*U,..@ accordingly.
 specializeDictSig :: [Usage] -> Use -> UsageSig
 specializeDictSig comps method_use = consUsageSig dict_usage topUsageSig
   where
@@ -795,6 +775,17 @@ specializeDictSig comps method_use = consUsageSig dict_usage topUsageSig
       | old == Absent = old
       | otherwise = Used Once method_use -- This is the selector for the method we used!
 
+-- | This unleashes the usage signature of a `GlobalId` that was stored in the
+-- defining interface file.
+-- This basically approximates the usage transformer in three points:
+--
+--   * `use` is less than a single call with `idArity`: No work is done, unleash
+--     a `botUsageSig`.
+--   * `use` is less or equal to a single call with `idArity`: The usage
+--     is a conservative approximation for this case, unleash `idArgUsage`
+--   * `use` is stronger than a single call with `idArity` (e.g. unsaturated or
+--     incomparable), unleash a manified version of `idArgUsage`.
+--
 globalIdUsageSig :: Id -> Use -> UsageSig
 globalIdUsageSig id use
   | use <= no_call -- @f x `seq` ...@ for a GlobalId `f` with arity > 1
@@ -813,6 +804,10 @@ globalIdUsageSig id use
     usg_sig = idArgUsage id
     str_sig = usageSigFromStrictSig (idStrictness id)
 
+--
+-- * Unleashing let-bindings
+--
+
 -- | Evaluation of a non-trivial RHS of a let-binding or argument 
 -- is shared (call-by-need!). GHC however doesn't allocate a new thunk
 -- if it finds the expression to bind to be trivial (`exprIsTrivial`).
@@ -822,123 +817,20 @@ considerThunkSharing e
   | exprIsTrivial e = id
   | otherwise = oneifyUsage
 
-analyseCaseAlternative
-  :: AnalEnv
-  -> Id
-  -> Alt CoreBndr
-  -> FrameworkBuilder (Use -> TransferFunction (UsageType, Alt CoreBndr, Use))
-analyseCaseAlternative env case_bndr (dc, alt_bndrs, e)
-  = transfer <$> usageAnalExpr env e
-  where
-    transfer transfer_alt use = do
-      let fam_envs = ae_fam_envs env
-      (ut_alt, e') <- transfer_alt use
-      let (ut_alt', alt_bndr_usages) = findBndrsUsages NonRecursive fam_envs ut_alt alt_bndrs
-      let (_, case_bndr_usage) = findBndrUsage NonRecursive fam_envs ut_alt case_bndr
-      -- We have to combine usages of alts_bndrs with that of case_bndr.
-      -- Usage info flows from case_bndr to alt_bndrs, but not the other way
-      -- around! This means that we later on annotate case_bndr solely based
-      -- on how its @Id@ was used, not on how the components were used.
-      let alt_bndr_usages' = addCaseBndrUsage case_bndr_usage alt_bndr_usages
-      let alt_bndrs' = setBndrsUsageInfo fam_envs alt_bndrs alt_bndr_usages
-      let product_use = mkProductUse alt_bndr_usages'
-      -- product_use doesn't yet take into account strictness annotations of the
-      -- constructor. That's to be done when we finally match on dc.
-      return (ut_alt', (dc, alt_bndrs', e'), product_use)
-
-findBndrUsage :: RecFlag -> FamInstEnvs -> UsageType -> Id -> (UsageType, Usage)
-findBndrUsage rec_flag fam_envs ut id
-  = (delUsageType id ut, lookupUsage rec_flag fam_envs ut id)
-
-findBndrsUsages :: RecFlag -> FamInstEnvs -> UsageType -> [Var] -> (UsageType, [Usage])
-findBndrsUsages rec_flag fam_envs ut = foldr step (ut, [])
-  where
-    step b (ut, usages)
-      | isId b
-      , (ut', usage) <- findBndrUsage rec_flag fam_envs ut b
-      = (ut', usage:usages)
-      | otherwise
-      = (ut, usages)
-
-addCaseBndrUsage :: Usage -> [Usage] -> [Usage]
-addCaseBndrUsage Absent alt_bndr_usages = alt_bndr_usages
-addCaseBndrUsage (Used _ use) alt_bndr_usages
-  | Just case_comp_usages <- peelProductUse (length alt_bndr_usages) use
-  = zipWith bothUsage case_comp_usages alt_bndr_usages
-  | otherwise
-  = topUsage <$ alt_bndr_usages
-
--- | We should try avoiding to call `setIdUsage` directly but rather go
--- through this function. This makes sure to trim the `Usage`
--- according to the binder's type before annotating.
-setBndrUsageInfo :: FamInstEnvs -> Var -> Usage -> Var
-setBndrUsageInfo fam_envs id usage
-  | isTyVar id
-  = id 
-  | otherwise
-    -- See Note [Trimming a demand to a type] in Demand.hs
-  = --pprTrace "setBndrUsageInfo" (ppr id <+> ppr usage') 
-    id `setIdUsage` trimUsageToTypeShape fam_envs id usage
-
-setBndrsUsageInfo :: FamInstEnvs -> [Var] -> [Usage] -> [Var]
-setBndrsUsageInfo _ [] [] = []
-setBndrsUsageInfo fam_envs (b:bndrs) (usage:usages)
-  | isId b
-  = setBndrUsageInfo fam_envs b usage : setBndrsUsageInfo fam_envs bndrs usages
-setBndrsUsageInfo fam_envs (b:bndrs) usages
-  = b : setBndrsUsageInfo fam_envs bndrs usages
-setBndrsUsageInfo _ _ usages
-  = pprPanic "No Ids, but a Usage left" (ppr usages)
-
-propagateProductUse
-  :: [Alt CoreBndr]
-  -> [Use]
-  -> Use
-propagateProductUse alts scrut_uses
-  -- Only one alternative with a product constructor
-  | [(DataAlt dc, _, _)] <- alts
-  , [scrut_use] <- scrut_uses
-  , let tycon = dataConTyCon dc
-  -- Don't include newtypes, as they aren't really constructors introducing
-  -- indirections.
-  , isJust (isDataProductTyCon_maybe tycon)
-  -- This is a good place to make sure we don't construct an infinitely deep
-  -- use, which can happen when analysing e.g. lazy streams.
-  -- Also see Note [Demand on scrutinee of a product case] in DmdAnal.hs.
-  = addDataConStrictness dc (boundDepth 10 scrut_use) -- 10 seems to be just enough to match DmdAnal
-
-  | otherwise
-  -- We *could* lub the uses from the different branches, but there's not much
-  -- to be won there, except for maybe head strictness.
-  = topUse
-
-addDataConStrictness :: DataCon -> Use -> Use
--- See Note [Add demands for strict constructors] in DmdAnal.hs
-addDataConStrictness dc
-  = maybe topUse (mkProductUse . add_component_strictness) 
-  . peelProductUse arity
-  where
-    add_component_strictness :: [Usage] -> [Usage]
-    add_component_strictness = zipWith add strs
-
-    strs = dataConRepStrictness dc
-    arity = length strs
-
-    add _ Absent = Absent -- See the note; We want to eliminate these in WW.
-    add str usage@(Used _ _)
-      | isMarkedStrict str = usage `bothUsage` u'1HU -- head usage imposed by `seq`
-      | otherwise = usage
-
-recFlagOf :: CoreBind -> RecFlag
-recFlagOf Rec{} = Recursive
-recFlagOf NonRec{} = NonRecursive
-
-exprForcedError :: CoreExpr
-exprForcedError = error "Expression component may not be used"
-
+-- | Determines whether to unleash free variables in the `UsageType` of 
+-- let-bound identifiers LetDown-style (e.g. directly at call sites, 
+-- `transferId`) or LetUp-style (after analysing the bindings scope, 
+-- in `unleashLet`).
+-- LetUp is does not duplicate work needed to bring the bound expression
+-- to WHNF, while LetDown is more precise in general if that work is
+-- negligible or we are sure that there are no multiple calls (e.g. for 
+-- non-thunks and join points).
 useLetUp :: Id -> Bool
 useLetUp id = idArity id == 0 && not (isJoinId id)
 
+-- | Embodies LetUp-style unleashing of free variables (c.f. `useLetUp`).
+-- This is the transfer function which will be used in `unleashLet`.
+-- In my thesis, this is done by the LetDn combinator.
 transferUp :: Id -> (Use -> TransferFunction AnalResult) -> Use -> TransferFunction AnalResult
 transferUp id transfer_rhs use = do
   (ut, rhs') <- transfer_rhs use
@@ -946,6 +838,9 @@ transferUp id transfer_rhs use = do
     then return (ut, rhs')
     else return (forgetFreeVarUsages ut, rhs')
 
+-- | Embodies LetDown-style unleashing of free variables (c.f. `useLetUp`).
+-- This is the transfer function which will be used in `transferId` for `LocalId`s.
+-- In my thesis, this is done by the LetUp combinator.
 transferDown :: Id -> (Use -> TransferFunction AnalResult) -> Use -> TransferFunction UsageType
 transferDown id transfer_rhs use = do
   (ut, _) <- transfer_rhs use
@@ -953,65 +848,17 @@ transferDown id transfer_rhs use = do
     then return (forgetFreeVarUsages ut)
     else return ut
 
-registerBindingGroup
-  :: AnalEnv
-  -> [(Id, CoreExpr)]
-  -> FrameworkBuilder (AnalEnv, VarEnv (Use -> TransferFunction AnalResult))
-registerBindingGroup env = go env emptyVarEnv . zip [1..] -- `zip` for `descend`ing
-  where
-    go env transfer_ups [] = return (env, transfer_ups)
-    go env transfer_ups ((n, (id, rhs)):binds) =
-      registerTransferFunction $ \rhs_node -> do
-        let deref_node use = dependOnWithDefault (botUsageType, rhs) (rhs_node, use)
-        ret@(env', _) <- go
-          (extendAnalEnv env id (transferDown id deref_node))
-          (extendVarEnv transfer_ups id (transferUp id deref_node))
-          binds
-        -- Now that the whole binding group is in scope in `env'`,
-        -- we actually have to attend to our duty and register the
-        -- transfer function associated with `rhs_node`
-        let env'' = descend n env'
-        -- We need to know what allocated nodes for the bound sub-expressions
-        -- range over. See `changeDetectorAnalResult` why.
-        node_range <- nextRangeOfSize (predictSizeOfExpr env'')
-        transfer_rhs <- usageAnalExpr env'' rhs
-        let transfer = monotonize rhs_node $ \use -> do
-              --use <- pprTrace "RHS:begin" (ppr id <+> text "::" <+> ppr use) $ return use
-              ret@(ut, rhs') <- transfer_rhs use 
-              --ret <- pprTrace "RHS:end" (vcat [ppr id <+> text "::" <+> ppr use, ppr ut]) $ return ret
-              return ret
-        return (ret, (transfer, changeDetectorAnalResult node_range))
-
-changeDetectorUsageType :: ChangeDetector
-changeDetectorUsageType _ (old, _) (new, _) =
-  ASSERT2( old_sig `leqUsageSig` new_sig, text "UsageAnal.changeDetector: usage sig not monotone")
-  old_sig /= new_sig ||
-  ASSERT2( sizeUFM old_uses <= sizeUFM new_uses, text "UsageAnal.changeDetector: uses not monotone")
-  sizeUFM old_uses /= sizeUFM new_uses ||
-  old_uses /= new_uses ||
-  ASSERT2( edgeCount old_cocalled <= edgeCount new_cocalled, text "UsageAnal.changeDetector: edgeCount not monotone")
-  edgeCount old_cocalled /= edgeCount new_cocalled
-  where
-    old_sig = ut_args old
-    new_sig = ut_args new
-    old_uses = ut_uses old
-    new_uses = ut_uses new
-    old_cocalled = ut_cocalled old
-    new_cocalled = ut_cocalled new
-
--- | When detecting changes in annotated expressions, we have to be
--- really conservative and assume an annotation changed if the changed
--- node belongs to a sub-expression.
+-- | `unleashLet env rec_flag transferred_binds ut_scope ut_body` will unleash
+-- the usages of every binder in the association list `transferred_binds` by
+-- looking up their usages in `ut_scope`.
 --
--- This is why we need to know the `FrameworkNodeRange`
--- of the nodes allocated to sub-expressions: 
--- If any changed ref falls within this range, we assume changed annotations.
-changeDetectorAnalResult :: FrameworkNodeRange -> ChangeDetector
-changeDetectorAnalResult node_range changed_refs old new =
-  --pprTrace "changeDetector" (ppr $ Set.map fst changed_refs) $
-  Set.filter (withinRange node_range . fst) changed_refs /= Set.empty ||
-  changeDetectorUsageType changed_refs old new
-
+-- This results in a `UsageType` and annotated RHS per binding, which is then
+-- substituted into `ut_body`, its co-call graph in particular, in 
+-- `substituteUsageTypes`.
+--
+-- Finally, all `Id`s of the binding group are annotated with their `idUsage`
+-- and `idArgUsage`. The `Id` are still present in the resulting `UsageType`
+-- for reasons of detecting fixed-points, see the comments within `transferLet`.
 unleashLet
   :: AnalEnv
   -> RecFlag
@@ -1019,74 +866,31 @@ unleashLet
   -> UsageType
   -> UsageType
   -> TransferFunction (UsageType, [(Id, CoreExpr)])
-unleashLet env rec_flag transferred_binds ut_usage ut_body = do
+unleashLet env rec_flag transferred_binds ut_scope ut_body = do
   let fam_envs = ae_fam_envs env
   let ids = map fst transferred_binds
   (ut_rhss, rhss') <- fmap unzip $ forM transferred_binds $ \(id, (rhs, transfer)) ->
-    unleashUsage rhs transfer (lookupUsage rec_flag fam_envs ut_usage id)
-  let ut_final = usageAnalLetEnv (zip ids ut_rhss) ut_body
-
+    unleashUsage rhs transfer (lookupUsage rec_flag fam_envs ut_scope id)
+  let ut_final = substituteUsageTypes (zip ids ut_rhss) ut_body
   --pprTrace "unleashLet" (ppr ids $$ text "ut_body" <+> ppr ut_body $$ text "ut_final" <+> ppr ut_final) $ return ()
   -- Now use that information to annotate binders.
   let (_, usages) = findBndrsUsages rec_flag fam_envs ut_final ids
   let ids' = setBndrsUsageInfo fam_envs ids usages
   ids'' <- forM ids' (annotateIdArgUsage env) 
-
   -- This intentionally still contains the @Id@s of the binding group, because
-  -- the recursive rule looks at their usages in the next iteration.
+  -- we need the usages for detecting the fixed-point.
   return (ut_final, zip ids'' rhss')
 
-annotateIdArgUsage
-  :: AnalEnv
-  -> Id
-  -> TransferFunction Id
-annotateIdArgUsage env id
-  | id `elemVarSet` (ae_need_sig_annotation env)
-  , Just transfer_callee <- lookupVarEnv (ae_sigs env) id
-  = do
-    -- We can't eta-expand beyond idArity anyway (exported!), so our best
-    -- bet is a single call with idArity.
-    -- Note that in the case where idArity id == 0, there is no interesting
-    -- @UsageSig@ to be had.
-    -- In that case we *could* try to analyze with arity 1, just for the
-    -- signature.
-    let single_call = iterate (mkCallUse Once) topUse !! idArity id
-    usage_sig <- ut_args <$> transfer_callee single_call
-    --pprTrace "annotating" (ppr id <+> ppr usage_sig) $ return ()
-    return (id `setIdArgUsage` usage_sig)
-  | otherwise
-  = return id
-
--- | Lifts the domain of a transfer function of an expression to @Usage@.
--- Non-trivial expressions (as per `exprIsTrivial`) are considered shared,
--- while the transferred result for trivial expressions is multiplied
--- according to usage multiplicity.
---
--- This generalises both lifting operators from the thesis.
-unleashUsage
-  :: CoreExpr
-  -> (Use -> TransferFunction AnalResult)
-  -> (Usage -> TransferFunction AnalResult)
-unleashUsage rhs transfer_rhs usage
-  | Absent <- usage
-  = return (emptyUsageType, markAbsent rhs)
-  | Used m use <- considerThunkSharing rhs usage
-  -- As with arguments, `m` should be `Once` most of the time 
-  -- (e.g. if `rhs` is non-trivial, see `considerThunkSharing`).
-  -- Thus, the work required to get the RHS of let-bindings 
-  -- to WHNF is shared among all use sites.
-  -- We still annotate the binder with the multiplicity later on, 
-  -- as @Once@ means we don't have to memoize the result anyway.
-  = first (multiplyUsages m) <$> transfer_rhs use
-
--- Combining the results from body and rhs of a let binding
--- See Note [Analysis II: The Co-Called analysis]
-usageAnalLetEnv
+-- | `substituteUsageTypes rhss ut_body` will substitute the usage types in the
+-- association list `rhss` into the co-call graph of `ut_body` and "do the right
+-- thing", e.g. adds cross-call edges where there was an edge between two `Id`,
+-- one of which is mentioned in `rhss`.
+substituteUsageTypes
   :: [(Id, UsageType)]
   -> UsageType
   -> UsageType
-usageAnalLetEnv rhss ut_body
-    = --pprTrace "usageAnalLetEnv" (vcat [ppr (map fst rhss), ppr (map snd rhss), ppr ut_body, ppr ut_new, ppr (map (lookupUsage Recursive ut_new . fst) rhss)]) $
+substituteUsageTypes rhss ut_body
+    = --pprTrace "substituteUsageTypes" (vcat [ppr (map fst rhss), ppr (map snd rhss), ppr ut_body, ppr ut_new, ppr (map (lookupUsage Recursive ut_new . fst) rhss)]) $
       ut_new
   where
     (ids, ut_rhss) = unzip rhss
@@ -1103,7 +907,7 @@ usageAnalLetEnv rhss ut_body
     -- which we have to handle, for the recursive case even any of ut_rhss may.
     -- This is why we have to union in appropriate cross_calls, which basically
     -- perform substitution of Id to UsageType.
-    ut_all = body_and_rhss (\id_rhs -> True)
+    ut_all = body_and_rhss (const True)
 
     cross_calls (id, ut_rhs) = botUsageType { ut_uses = uses, ut_cocalled = graph }
       where
@@ -1135,6 +939,83 @@ usageAnalLetEnv rhss ut_body
         | length ut_rhss > 25 = bothUsageTypes ut_all
         | otherwise           = lubUsageTypes (ut_all ++ map cross_calls rhss)
 
+--
+-- * Looking up `Usage` of binders in `UsageType`s and annotating them
+--
+
+findBndrUsage :: RecFlag -> FamInstEnvs -> UsageType -> Id -> (UsageType, Usage)
+findBndrUsage rec_flag fam_envs ut id
+  = (delUsageType id ut, lookupUsage rec_flag fam_envs ut id)
+
+findBndrsUsages :: RecFlag -> FamInstEnvs -> UsageType -> [Var] -> (UsageType, [Usage])
+findBndrsUsages rec_flag fam_envs ut = foldr step (ut, [])
+  where
+    step b (ut, usages)
+      | isId b
+      , (ut', usage) <- findBndrUsage rec_flag fam_envs ut b
+      = (ut', usage:usages)
+      | otherwise
+      = (ut, usages)
+
+addCaseBndrUsage :: Usage -> [Usage] -> [Usage]
+addCaseBndrUsage Absent alt_bndr_usages = alt_bndr_usages
+addCaseBndrUsage (Used _ use) alt_bndr_usages
+  | Just case_comp_usages <- peelProductUse (length alt_bndr_usages) use
+  = zipWith bothUsage case_comp_usages alt_bndr_usages
+  | otherwise
+  = topUsage <$ alt_bndr_usages
+
+-- | We should try avoiding to call `setIdUsage` directly but rather go
+-- through this function. This makes sure to trim the `Usage`
+-- according to the binder's type before annotating.
+setBndrUsageInfo :: FamInstEnvs -> Var -> Usage -> Var
+setBndrUsageInfo fam_envs id usage
+  | isTyVar id
+  = id 
+  | otherwise
+    -- See Note [Trimming a demand to a type] in Demand.hs
+  = --pprTrace "setBndrUsageInfo" (ppr id <+> ppr usage') 
+    id `setIdUsage` trimUsageToTypeShape fam_envs id usage
+
+setBndrsUsageInfo :: FamInstEnvs -> [Var] -> [Usage] -> [Var]
+setBndrsUsageInfo _ [] [] = []
+setBndrsUsageInfo fam_envs (b:bndrs) (usage:usages)
+  | isId b
+  = setBndrUsageInfo fam_envs b usage : setBndrsUsageInfo fam_envs bndrs usages
+setBndrsUsageInfo fam_envs (b:bndrs) usages
+  = b : setBndrsUsageInfo fam_envs bndrs usages
+setBndrsUsageInfo _ _ usages
+  = pprPanic "No Ids, but a Usage left" (ppr usages)
+
+annotateIdArgUsage
+  :: AnalEnv
+  -> Id
+  -> TransferFunction Id
+annotateIdArgUsage env id
+  | id `elemVarSet` ae_need_sig_annotation env
+  , Just transfer_callee <- lookupVarEnv (ae_trans env) id
+  = do
+    -- We can't eta-expand beyond idArity anyway (exported!), so our best
+    -- bet is a single call with idArity.
+    -- Note that in the case where idArity id == 0, there is no interesting
+    -- @UsageSig@ to be had.
+    -- In that case we *could* try to analyze with arity 1, just for the
+    -- signature.
+    let single_call = iterate (mkCallUse Once) topUse !! idArity id
+    usage_sig <- ut_args <$> transfer_callee single_call
+    --pprTrace "annotating" (ppr id <+> ppr usage_sig) $ return ()
+    return (id `setIdArgUsage` usage_sig)
+  | otherwise
+  = return id
+
+--
+-- * Other helpers
+--
+
+recFlagOf :: CoreBind -> RecFlag
+recFlagOf Rec{} = Recursive
+recFlagOf NonRec{} = NonRecursive
+
 -- | Marks every binder it reaches as absent, but does *not* descend into absent
 -- RHSs. These are implicitly assumed as absent. This is so that we don't trigger
 -- CoreLint warnings on stuff the Occurence Anaylzer deems reachable but we do not.
diff --git a/compiler/simplCore/UsageAnal/FrameworkBuilder.hs b/compiler/simplCore/UsageAnal/FrameworkBuilder.hs
index 7068c0b7b3..93108d0e26 100644
--- a/compiler/simplCore/UsageAnal/FrameworkBuilder.hs
+++ b/compiler/simplCore/UsageAnal/FrameworkBuilder.hs
@@ -39,6 +39,7 @@ import Data.Tree
 predictAllocatedNodes :: Expr b -> Tree Int
 predictAllocatedNodes = expr
   where
+    expr (App f (Type _)) = expr f
     expr (App f a) = mk_parent . map expr $ [f, a]
     expr (Lam _ e) = expr e
     expr (Let bs body) = add_one_node_per_child . mk_parent $ expr body:bind bs
diff --git a/conftest.c b/conftest.c
new file mode 100644
index 0000000000..a0c6335cc5
--- /dev/null
+++ b/conftest.c
@@ -0,0 +1,88 @@
+/* confdefs.h */
+#define PACKAGE_NAME "The Glorious Glasgow Haskell Compilation System"
+#define PACKAGE_TARNAME "ghc-8.2.0"
+#define PACKAGE_VERSION "8.2.0"
+#define PACKAGE_STRING "The Glorious Glasgow Haskell Compilation System 8.2.0"
+#define PACKAGE_BUGREPORT "glasgow-haskell-bugs@haskell.org"
+#define PACKAGE_URL ""
+#define STDC_HEADERS 1
+#define HAVE_SYS_TYPES_H 1
+#define HAVE_SYS_STAT_H 1
+#define HAVE_STDLIB_H 1
+#define HAVE_STRING_H 1
+#define HAVE_MEMORY_H 1
+#define HAVE_STRINGS_H 1
+#define HAVE_INTTYPES_H 1
+#define HAVE_STDINT_H 1
+#define HAVE_UNISTD_H 1
+#define __EXTENSIONS__ 1
+#define _ALL_SOURCE 1
+#define _GNU_SOURCE 1
+#define _POSIX_PTHREAD_SEMANTICS 1
+#define _TANDEM_SOURCE 1
+#define sUPPORTED_LLVM_VERSION (3,9)
+#define STDC_HEADERS 1
+#define _FILE_OFFSET_BITS 64
+#define HAVE_CTYPE_H 1
+#define HAVE_DIRENT_H 1
+#define HAVE_ERRNO_H 1
+#define HAVE_FCNTL_H 1
+#define HAVE_LIMITS_H 1
+#define HAVE_LOCALE_H 1
+#define HAVE_PTHREAD_H 1
+#define HAVE_SIGNAL_H 1
+#define HAVE_SYS_PARAM_H 1
+#define HAVE_SYS_TIME_H 1
+#define HAVE_SYS_TIMEB_H 1
+#define HAVE_TIME_H 1
+#define HAVE_UTIME_H 1
+#define HAVE_WINDOWS_H 1
+#define HAVE_WINSOCK_H 1
+#define HAVE_SCHED_H 1
+#define TIME_WITH_SYS_TIME 1
+#define HAVE_LONG_LONG 1
+#define SIZEOF_CHAR 1
+#define ALIGNMENT_CHAR 1
+#define SIZEOF_DOUBLE 8
+/* end confdefs.h.  */
+#include <stdio.h>
+#ifdef HAVE_SYS_TYPES_H
+# include <sys/types.h>
+#endif
+#ifdef HAVE_SYS_STAT_H
+# include <sys/stat.h>
+#endif
+#ifdef STDC_HEADERS
+# include <stdlib.h>
+# include <stddef.h>
+#else
+# ifdef HAVE_STDLIB_H
+#  include <stdlib.h>
+# endif
+#endif
+#ifdef HAVE_STRING_H
+# if !defined STDC_HEADERS && defined HAVE_MEMORY_H
+#  include <memory.h>
+# endif
+# include <string.h>
+#endif
+#ifdef HAVE_STRINGS_H
+# include <strings.h>
+#endif
+#ifdef HAVE_INTTYPES_H
+# include <inttypes.h>
+#endif
+#ifdef HAVE_STDINT_H
+# include <stdint.h>
+#endif
+#ifdef HAVE_UNISTD_H
+# include <unistd.h>
+#endif
+int
+main ()
+{
+if (sizeof (double))
+	 return 0;
+  ;
+  return 0;
+}
-- 
2.12.1


From 6f9f06c2d1bf3a9168ec4079ebf6da26398e54b9 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Sun, 23 Jul 2017 17:57:44 +0200
Subject: [PATCH 116/117] Using ghc-8.2.1-release's nofib again

---
 nofib | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/nofib b/nofib
index 48e36515ae..3ac6f2db09 160000
--- a/nofib
+++ b/nofib
@@ -1 +1 @@
-Subproject commit 48e36515ae308b6dc356e6b059ce223212696f41
+Subproject commit 3ac6f2db09254c52a87f3f1c79798f27d390e899
-- 
2.12.1


From 949a2da2fde8b60a324b3ed60a81fde972af56c6 Mon Sep 17 00:00:00 2001
From: Sebastian Graf <sgraf1337@gmail.com>
Date: Thu, 13 Jul 2017 13:31:06 +0200
Subject: [PATCH 117/117] Truncating product use in the down rule, to
 approximate the behavior of the demand analyser

---
 compiler/simplCore/UsageAnal/Analysis.hs | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/compiler/simplCore/UsageAnal/Analysis.hs b/compiler/simplCore/UsageAnal/Analysis.hs
index 3d039f701a..19a1fc2789 100644
--- a/compiler/simplCore/UsageAnal/Analysis.hs
+++ b/compiler/simplCore/UsageAnal/Analysis.hs
@@ -843,7 +843,7 @@ transferUp id transfer_rhs use = do
 -- In my thesis, this is done by the LetUp combinator.
 transferDown :: Id -> (Use -> TransferFunction AnalResult) -> Use -> TransferFunction UsageType
 transferDown id transfer_rhs use = do
-  (ut, _) <- transfer_rhs use
+  (ut, _) <- transfer_rhs (boundDepth 0 use)
   if useLetUp id
     then return (forgetFreeVarUsages ut)
     else return ut
-- 
2.12.1

